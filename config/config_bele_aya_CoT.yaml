model:
  model_name_or_path: CohereForAI/aya-expanse-8b # models/bllossom_aug/checkpoint-1400 # Bllossom/llama-3.2-Korean-Bllossom-3B
  load_in_8b: True

data:
  train_csv: data/combined_clean_bele.csv
  inference_csv: data/test.csv
  output_csv: outputs/aya_bele.csv
  train_test_split_ratio: 0.1
  tokenize_max_length: 1800

train:
  do_train: True
  do_eval: True
  lr_scheduler_type: cosine
  max_seq_length: 1800
  output_dir: models/aya_bele
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1
  gradient_accumulation_steps: 8
  max_steps: 800
  learning_rate: 5e-5
  weight_decay: 0.01
  logging_steps: 20
  save_strategy: steps
  eval_strategy: steps
  eval_steps: 100
  save_steps: 100
  save_total_limit: 5
  save_only_model: True
  fp16: False
  warmup_steps: 500
  report_to: none

seed: 42

peft:
  r: 16
  lora_alpha: 32
  lora_dropout: 0.1
  target_modules: ['q_proj', 'k_proj', 'v_proj']
  bias: none
  task_type: CAUSAL_LM

prompt:
  PROMPT_NO_QUESTION_PLUS: |
    지문:
    {paragraph}

    질문:
    {question}

    선택지:
    {choices}

    풀이과정:
    
  PROMPT_QUESTION_PLUS: |
    지문:
    {paragraph}

    질문:
    {question}

    <보기>:
    {question_plus}

    선택지:
    {choices}

    풀이과정:
  
  tokenizer_chat_template: "{{ bos_token }}{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% elif false == true %}{% set loop_messages = messages %}{% set system_message = 'You are Aya, a brilliant, sophisticated, multilingual AI-assistant trained to assist human users by providing thorough responses. You are able to interact and respond to questions in 23 languages and you are powered by a multilingual model built by Cohere For AI.' %}{% else %}{% set loop_messages = messages %}{% set system_message = false %}{% endif %}{% if system_message != false %}{{ '<|START_OF_TURN_TOKEN|><|SYSTEM_TOKEN|>' + system_message + '<|END_OF_TURN_TOKEN|>' }}{% endif %}{% for message in loop_messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% set content = message['content'] %}{% if message['role'] == 'user' %}{{ '<|START_OF_TURN_TOKEN|><|USER_TOKEN|>' + content.strip() + '<|END_OF_TURN_TOKEN|>' + '<|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>' }}{% elif message['role'] == 'assistant' %}{{ content.strip() + '<|END_OF_TURN_TOKEN|>' }}{% endif %}{% endfor %}"
  
  response_template: "<|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>"
  
  # evaluation.py의 compute_metrics에서 정답 분리할 때 쓰는 compute_metrics_split
  compute_metrics_end_token: "<|END_OF_TURN_TOKEN|>"

  system_message: "당신은 지문을 읽고 객관식 문제의 정답을 찾는 AI 어시스턴트입니다. 지문을 분석한 뒤, 풀이과정을 단게별로 작성하고 정답을 고르세요"
