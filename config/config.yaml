model:
  model_name_or_path: Bllossom/llama-3.2-Korean-Bllossom-3B # beomi/Llama-3-Open-Ko-8B # beomi/gemma-ko-2b # models/gemma/checkpoint-4416 #beomi/gemma-ko-2b
  load_in_8b: False # 추론할 때, 8b 양자화

data:
  train_csv: data/cleaned_data_utf8.csv
  inference_csv: data/test.csv
  output_csv: outputs/output_bllossom_prompt3.csv
  train_test_split_ratio: 0.1
  tokenize_max_length: 1800 # 아래 train.max_seq_length도 같이 바꿔주기

train:
  do_train: True
  do_eval: True
  lr_scheduler_type: cosine
  max_seq_length: 1800
  output_dir: models/bllossom_prompt3
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1
  gradient_accumulation_steps: 8
  num_train_epochs: 20
  learning_rate: 5e-5
  weight_decay: 0.01
  logging_steps: 20
  save_strategy: steps
  eval_strategy: steps
  eval_steps: 100
  save_steps: 100
  save_total_limit: 5
  save_only_model: True
  fp16: True
  warmup_steps: 500
  report_to: none

seed: 42

peft:
  r: 8 # 6
  lora_alpha: 16 #8
  lora_dropout: 0.1 #0.05
  target_modules: ['q_proj', 'k_proj']
  bias: none
  task_type: CAUSAL_LM

prompt:
  PROMPT_NO_QUESTION_PLUS: |
    정답은 지문과 질문의 논리적 관계를 바탕으로 정확히 선택해야 합니다. 답변은 반드시 선택지 번호(1, 2, 3, 4, 5)로만 작성하며, 추가 설명이나 텍스트를 포함하지 마세요.
    지문:
    {paragraph}

    질문:
    {question}

    선택지:
    {choices}

    정답:
    
  PROMPT_QUESTION_PLUS: |
    정답은 지문과 질문의 논리적 관계를 바탕으로 정확히 선택해야 합니다. 답변은 반드시 선택지 번호(1, 2, 3, 4, 5)로만 작성하며, 추가 설명이나 텍스트를 포함하지 마세요.

    지문:
    {paragraph}

    질문:
    {question}

    <보기>:
    {question_plus}

    선택지:
    {choices}

    정답:
  
  tokenizer_chat_template: default
  # "{% if messages[0]['role'] == 'system' %}{% set system_message = messages[0]['content'] %}{% endif %}{% if system_message is defined %}{{ system_message }}{% endif %}{% for message in messages %}{% set content = message['content'] %}{% if message['role'] == 'user' %}{{ '<start_of_turn>user\n' + content + '<end_of_turn>\n<start_of_turn>model\n' }}{% elif message['role'] == 'assistant' %}{{ content + '<end_of_turn>\n' }}{% endif %}{% endfor %}"
  # |
  #   {% set system_message = None %}
  #   {% if messages[0]['role'] == 'system' %}
  #       {% set system_message = '<|start_header_id|>system<|end_header_id|>\n\n' + messages[0]['content'] + '<|eot_id|>' %}
  #   {% endif %}

  #   {% if system_message is not none %}
  #       {{ bos_token + system_message }}
  #   {% endif %}

  #   {% for message in messages %}
  #       {% if message['role'] == 'user' %}
  #           {{ '<|start_header_id|>user<|end_header_id|>\n\n' + message['content'] + '<|eot_id|>' + '<|start_header_id|>assistant<|end_header_id|>\n\n'}}
  #       {% elif message['role'] == 'assistant' %}
  #           {{ message['content'] + '<|eot_id|>' }}
  #       {% endif %}
  #   {% endfor %}

  #   {% if add_generation_prompt %}
  #       {{ '<|start_header_id|>assistant<|end_header_id|>\n\n' }}
  #   {% endif %}
  
  response_template: "<|start_header_id|>assistant<|end_header_id|>\n\n" # <start_of_turn>model
  
  # evaluation.py의 compute_metrics에서 정답 분리할 때 쓰는 compute_metrics_split
  compute_metrics_end_token: "<|eot_id|>" # <end_of_turn>

  system_message: 당신은 지문을 읽고 객관식 문제의 정답을 찾는 AI 어시스턴트입니다. \
    지문을 분석한 뒤, 선택지 번호 중 하나만을 반환해야 합니다. 추가 설명은 작성하지 마세요.