model:
  model_name_or_path: princeton-nlp/gemma-2-9b-it-SimPO # models/bllossom_aug/checkpoint-1400 # Bllossom/llama-3.2-Korean-Bllossom-3B
  load_in_8b: True

data:
  train_csv: data/combined_cleaned_org.csv
  inference_csv: data/test.csv
  output_csv: outputs/gemma-2-9b-it-SimPO.csv
  train_test_split_ratio: 0.1
  tokenize_max_length: 1700

train:
  do_train: True
  do_eval: True
  lr_scheduler_type: cosine
  max_seq_length: 1700
  output_dir: models/gemma-2-9b-it-SimPO
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1
  gradient_accumulation_steps: 8
  max_steps: 800
  learning_rate: 5e-5
  weight_decay: 0.01
  logging_steps: 20
  save_strategy: steps
  eval_strategy: steps
  eval_steps: 40
  save_steps: 120
  save_total_limit: 5
  save_only_model: True
  fp16: True
  warmup_steps: 300
  report_to: none

seed: 42

peft:
  r: 16
  lora_alpha: 32
  lora_dropout: 0.1
  target_modules: ['q_proj', 'k_proj', 'v_proj']
  bias: none
  task_type: CAUSAL_LM

prompt:
  PROMPT_NO_QUESTION_PLUS: |
    지문:
    {paragraph}

    질문:
    {question}

    선택지:
    {choices}

    1, 2, 3, 4, 5 중에 하나를 정답으로 고르세요.
    정답:
    
  PROMPT_QUESTION_PLUS: |
    지문:
    {paragraph}

    질문:
    {question}

    <보기>:
    {question_plus}

    선택지:
    {choices}

    1, 2, 3, 4, 5 중에 하나를 정답으로 고르세요.
    정답:
  
  tokenizer_chat_template: "{{ bos_token }}{% if messages[0]['role'] == 'system' %}{% set system_message = messages[0]['content'] | trim + '\n' %}{% set messages = messages[1:] %}{% else %}{% set system_message = '' %}{% endif %}{% for message in messages %}{% if loop.index0 == 0 %}{% set content = system_message + message['content'] %}{% else %}{% set content = message['content'] %}{% endif %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{% if role == 'user' %}{{ '<start_of_turn>' + role + '\n' + content | trim + '<end_of_turn>\n' + '<start_of_turn>' + 'model' + '\n' }}{% elif role == 'model' %}{{ content | trim + '<end_of_turn>\n' }}{% endif %}{% endfor %}"
  
  response_template: "<start_of_turn>model\n"
  
  # evaluation.py의 compute_metrics에서 정답 분리할 때 쓰는 compute_metrics_split
  compute_metrics_end_token: "<end_of_turn>\n"

  system_message: "당신은 지문을 읽고 객관식 문제의 정답을 찾는 AI 어시스턴트입니다. 지문을 분석한 뒤, 선택지 번호(1, 2, 3, 4, 5) 중 하나만 반환하세요. 추가 설명은 작성하지 마세요."
