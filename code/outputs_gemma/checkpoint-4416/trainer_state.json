{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 4416,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0006793478260869565,
      "grad_norm": 1.8629131317138672,
      "learning_rate": 1.999999746946935e-05,
      "loss": 0.0591,
      "step": 1
    },
    {
      "epoch": 0.001358695652173913,
      "grad_norm": 5.040953636169434,
      "learning_rate": 1.999998987787868e-05,
      "loss": 0.1922,
      "step": 2
    },
    {
      "epoch": 0.0020380434782608695,
      "grad_norm": 0.5635272264480591,
      "learning_rate": 1.9999977225231833e-05,
      "loss": 0.0052,
      "step": 3
    },
    {
      "epoch": 0.002717391304347826,
      "grad_norm": 9.323261260986328,
      "learning_rate": 1.9999959511535207e-05,
      "loss": 0.2294,
      "step": 4
    },
    {
      "epoch": 0.0033967391304347825,
      "grad_norm": 3.2032790184020996,
      "learning_rate": 1.9999936736797775e-05,
      "loss": 0.107,
      "step": 5
    },
    {
      "epoch": 0.004076086956521739,
      "grad_norm": 3.3910162448883057,
      "learning_rate": 1.999990890103106e-05,
      "loss": 0.1494,
      "step": 6
    },
    {
      "epoch": 0.004755434782608696,
      "grad_norm": 6.87730073928833,
      "learning_rate": 1.999987600424915e-05,
      "loss": 0.2819,
      "step": 7
    },
    {
      "epoch": 0.005434782608695652,
      "grad_norm": 1.307465672492981,
      "learning_rate": 1.9999838046468693e-05,
      "loss": 0.0287,
      "step": 8
    },
    {
      "epoch": 0.006114130434782609,
      "grad_norm": 0.014632279053330421,
      "learning_rate": 1.99997950277089e-05,
      "loss": 0.0003,
      "step": 9
    },
    {
      "epoch": 0.006793478260869565,
      "grad_norm": 4.836890697479248,
      "learning_rate": 1.9999746947991546e-05,
      "loss": 0.2581,
      "step": 10
    },
    {
      "epoch": 0.007472826086956522,
      "grad_norm": 0.15576182305812836,
      "learning_rate": 1.999969380734096e-05,
      "loss": 0.0011,
      "step": 11
    },
    {
      "epoch": 0.008152173913043478,
      "grad_norm": 5.937380313873291,
      "learning_rate": 1.9999635605784042e-05,
      "loss": 0.3423,
      "step": 12
    },
    {
      "epoch": 0.008831521739130434,
      "grad_norm": 4.712078094482422,
      "learning_rate": 1.999957234335024e-05,
      "loss": 0.0927,
      "step": 13
    },
    {
      "epoch": 0.009510869565217392,
      "grad_norm": 0.03946136683225632,
      "learning_rate": 1.9999504020071586e-05,
      "loss": 0.0007,
      "step": 14
    },
    {
      "epoch": 0.010190217391304348,
      "grad_norm": 3.101717472076416,
      "learning_rate": 1.9999430635982643e-05,
      "loss": 0.0832,
      "step": 15
    },
    {
      "epoch": 0.010869565217391304,
      "grad_norm": 1.218788743019104,
      "learning_rate": 1.9999352191120556e-05,
      "loss": 0.0624,
      "step": 16
    },
    {
      "epoch": 0.01154891304347826,
      "grad_norm": 5.830277442932129,
      "learning_rate": 1.9999268685525034e-05,
      "loss": 0.0577,
      "step": 17
    },
    {
      "epoch": 0.012228260869565218,
      "grad_norm": 6.427099227905273,
      "learning_rate": 1.9999180119238327e-05,
      "loss": 0.0827,
      "step": 18
    },
    {
      "epoch": 0.012907608695652174,
      "grad_norm": 9.621614456176758,
      "learning_rate": 1.999908649230527e-05,
      "loss": 0.2134,
      "step": 19
    },
    {
      "epoch": 0.01358695652173913,
      "grad_norm": 1.841453194618225,
      "learning_rate": 1.9998987804773244e-05,
      "loss": 0.0592,
      "step": 20
    },
    {
      "epoch": 0.014266304347826086,
      "grad_norm": 2.125173330307007,
      "learning_rate": 1.9998884056692195e-05,
      "loss": 0.1071,
      "step": 21
    },
    {
      "epoch": 0.014945652173913044,
      "grad_norm": 4.427806377410889,
      "learning_rate": 1.999877524811463e-05,
      "loss": 0.263,
      "step": 22
    },
    {
      "epoch": 0.015625,
      "grad_norm": 2.068814754486084,
      "learning_rate": 1.9998661379095622e-05,
      "loss": 0.0891,
      "step": 23
    },
    {
      "epoch": 0.016304347826086956,
      "grad_norm": 0.025511058047413826,
      "learning_rate": 1.9998542449692794e-05,
      "loss": 0.0004,
      "step": 24
    },
    {
      "epoch": 0.016983695652173912,
      "grad_norm": 0.10073287039995193,
      "learning_rate": 1.999841845996634e-05,
      "loss": 0.0012,
      "step": 25
    },
    {
      "epoch": 0.017663043478260868,
      "grad_norm": 10.630753517150879,
      "learning_rate": 1.999828940997901e-05,
      "loss": 0.3727,
      "step": 26
    },
    {
      "epoch": 0.018342391304347828,
      "grad_norm": 0.5635399222373962,
      "learning_rate": 1.9998155299796122e-05,
      "loss": 0.004,
      "step": 27
    },
    {
      "epoch": 0.019021739130434784,
      "grad_norm": 4.824479103088379,
      "learning_rate": 1.9998016129485548e-05,
      "loss": 0.1504,
      "step": 28
    },
    {
      "epoch": 0.01970108695652174,
      "grad_norm": 0.973718523979187,
      "learning_rate": 1.9997871899117723e-05,
      "loss": 0.0098,
      "step": 29
    },
    {
      "epoch": 0.020380434782608696,
      "grad_norm": 3.721508502960205,
      "learning_rate": 1.999772260876564e-05,
      "loss": 0.1696,
      "step": 30
    },
    {
      "epoch": 0.021059782608695652,
      "grad_norm": 2.1698708534240723,
      "learning_rate": 1.9997568258504856e-05,
      "loss": 0.1818,
      "step": 31
    },
    {
      "epoch": 0.021739130434782608,
      "grad_norm": 7.723087310791016,
      "learning_rate": 1.9997408848413494e-05,
      "loss": 0.3045,
      "step": 32
    },
    {
      "epoch": 0.022418478260869564,
      "grad_norm": 3.804450273513794,
      "learning_rate": 1.9997244378572227e-05,
      "loss": 0.1935,
      "step": 33
    },
    {
      "epoch": 0.02309782608695652,
      "grad_norm": 0.04228443279862404,
      "learning_rate": 1.9997074849064296e-05,
      "loss": 0.0004,
      "step": 34
    },
    {
      "epoch": 0.02377717391304348,
      "grad_norm": 12.498047828674316,
      "learning_rate": 1.99969002599755e-05,
      "loss": 0.1661,
      "step": 35
    },
    {
      "epoch": 0.024456521739130436,
      "grad_norm": 0.6129363775253296,
      "learning_rate": 1.99967206113942e-05,
      "loss": 0.0056,
      "step": 36
    },
    {
      "epoch": 0.025135869565217392,
      "grad_norm": 1.0659078359603882,
      "learning_rate": 1.999653590341132e-05,
      "loss": 0.0115,
      "step": 37
    },
    {
      "epoch": 0.025815217391304348,
      "grad_norm": 2.1829159259796143,
      "learning_rate": 1.9996346136120342e-05,
      "loss": 0.1572,
      "step": 38
    },
    {
      "epoch": 0.026494565217391304,
      "grad_norm": 8.371170997619629,
      "learning_rate": 1.99961513096173e-05,
      "loss": 0.2634,
      "step": 39
    },
    {
      "epoch": 0.02717391304347826,
      "grad_norm": 6.705822467803955,
      "learning_rate": 1.999595142400081e-05,
      "loss": 0.2143,
      "step": 40
    },
    {
      "epoch": 0.027853260869565216,
      "grad_norm": 8.116935729980469,
      "learning_rate": 1.9995746479372023e-05,
      "loss": 0.2842,
      "step": 41
    },
    {
      "epoch": 0.028532608695652172,
      "grad_norm": 1.5838924646377563,
      "learning_rate": 1.9995536475834667e-05,
      "loss": 0.1012,
      "step": 42
    },
    {
      "epoch": 0.029211956521739132,
      "grad_norm": 4.950756549835205,
      "learning_rate": 1.999532141349503e-05,
      "loss": 0.0861,
      "step": 43
    },
    {
      "epoch": 0.029891304347826088,
      "grad_norm": 4.412251949310303,
      "learning_rate": 1.9995101292461954e-05,
      "loss": 0.1348,
      "step": 44
    },
    {
      "epoch": 0.030570652173913044,
      "grad_norm": 2.843536138534546,
      "learning_rate": 1.999487611284684e-05,
      "loss": 0.1955,
      "step": 45
    },
    {
      "epoch": 0.03125,
      "grad_norm": 1.5998808145523071,
      "learning_rate": 1.9994645874763657e-05,
      "loss": 0.1636,
      "step": 46
    },
    {
      "epoch": 0.03192934782608696,
      "grad_norm": 0.13732534646987915,
      "learning_rate": 1.999441057832893e-05,
      "loss": 0.0014,
      "step": 47
    },
    {
      "epoch": 0.03260869565217391,
      "grad_norm": 8.707810401916504,
      "learning_rate": 1.999417022366174e-05,
      "loss": 0.2284,
      "step": 48
    },
    {
      "epoch": 0.03328804347826087,
      "grad_norm": 2.5655665397644043,
      "learning_rate": 1.9993924810883737e-05,
      "loss": 0.1031,
      "step": 49
    },
    {
      "epoch": 0.033967391304347824,
      "grad_norm": 0.09022364020347595,
      "learning_rate": 1.9993674340119124e-05,
      "loss": 0.0009,
      "step": 50
    },
    {
      "epoch": 0.034646739130434784,
      "grad_norm": 0.661696195602417,
      "learning_rate": 1.9993418811494663e-05,
      "loss": 0.007,
      "step": 51
    },
    {
      "epoch": 0.035326086956521736,
      "grad_norm": 2.293893575668335,
      "learning_rate": 1.9993158225139682e-05,
      "loss": 0.1306,
      "step": 52
    },
    {
      "epoch": 0.036005434782608696,
      "grad_norm": 8.952310562133789,
      "learning_rate": 1.9992892581186067e-05,
      "loss": 0.3007,
      "step": 53
    },
    {
      "epoch": 0.036684782608695655,
      "grad_norm": 2.070751905441284,
      "learning_rate": 1.9992621879768256e-05,
      "loss": 0.0243,
      "step": 54
    },
    {
      "epoch": 0.03736413043478261,
      "grad_norm": 0.8030319213867188,
      "learning_rate": 1.999234612102326e-05,
      "loss": 0.0085,
      "step": 55
    },
    {
      "epoch": 0.03804347826086957,
      "grad_norm": 0.7753491997718811,
      "learning_rate": 1.999206530509063e-05,
      "loss": 0.0092,
      "step": 56
    },
    {
      "epoch": 0.03872282608695652,
      "grad_norm": 0.12823054194450378,
      "learning_rate": 1.9991779432112503e-05,
      "loss": 0.0011,
      "step": 57
    },
    {
      "epoch": 0.03940217391304348,
      "grad_norm": 0.04010338708758354,
      "learning_rate": 1.9991488502233553e-05,
      "loss": 0.0007,
      "step": 58
    },
    {
      "epoch": 0.04008152173913043,
      "grad_norm": 7.476400852203369,
      "learning_rate": 1.9991192515601024e-05,
      "loss": 0.2993,
      "step": 59
    },
    {
      "epoch": 0.04076086956521739,
      "grad_norm": 1.0156575441360474,
      "learning_rate": 1.999089147236472e-05,
      "loss": 0.0093,
      "step": 60
    },
    {
      "epoch": 0.041440217391304345,
      "grad_norm": 1.9173312187194824,
      "learning_rate": 1.999058537267699e-05,
      "loss": 0.0982,
      "step": 61
    },
    {
      "epoch": 0.042119565217391304,
      "grad_norm": 0.08576299250125885,
      "learning_rate": 1.9990274216692762e-05,
      "loss": 0.0008,
      "step": 62
    },
    {
      "epoch": 0.042798913043478264,
      "grad_norm": 6.497671604156494,
      "learning_rate": 1.9989958004569514e-05,
      "loss": 0.2861,
      "step": 63
    },
    {
      "epoch": 0.043478260869565216,
      "grad_norm": 0.015174591913819313,
      "learning_rate": 1.9989636736467278e-05,
      "loss": 0.0003,
      "step": 64
    },
    {
      "epoch": 0.044157608695652176,
      "grad_norm": 3.9002883434295654,
      "learning_rate": 1.9989310412548653e-05,
      "loss": 0.2103,
      "step": 65
    },
    {
      "epoch": 0.04483695652173913,
      "grad_norm": 3.6000783443450928,
      "learning_rate": 1.998897903297879e-05,
      "loss": 0.144,
      "step": 66
    },
    {
      "epoch": 0.04551630434782609,
      "grad_norm": 3.419005870819092,
      "learning_rate": 1.9988642597925408e-05,
      "loss": 0.2255,
      "step": 67
    },
    {
      "epoch": 0.04619565217391304,
      "grad_norm": 5.959144592285156,
      "learning_rate": 1.9988301107558777e-05,
      "loss": 0.1976,
      "step": 68
    },
    {
      "epoch": 0.046875,
      "grad_norm": 0.20648233592510223,
      "learning_rate": 1.9987954562051724e-05,
      "loss": 0.0018,
      "step": 69
    },
    {
      "epoch": 0.04755434782608696,
      "grad_norm": 0.06419888883829117,
      "learning_rate": 1.9987602961579646e-05,
      "loss": 0.0007,
      "step": 70
    },
    {
      "epoch": 0.04823369565217391,
      "grad_norm": 5.120381832122803,
      "learning_rate": 1.9987246306320476e-05,
      "loss": 0.1631,
      "step": 71
    },
    {
      "epoch": 0.04891304347826087,
      "grad_norm": 1.4990625381469727,
      "learning_rate": 1.998688459645473e-05,
      "loss": 0.0798,
      "step": 72
    },
    {
      "epoch": 0.049592391304347824,
      "grad_norm": 2.3915326595306396,
      "learning_rate": 1.998651783216547e-05,
      "loss": 0.1488,
      "step": 73
    },
    {
      "epoch": 0.050271739130434784,
      "grad_norm": 1.9481086730957031,
      "learning_rate": 1.9986146013638315e-05,
      "loss": 0.1192,
      "step": 74
    },
    {
      "epoch": 0.050951086956521736,
      "grad_norm": 1.701699137687683,
      "learning_rate": 1.998576914106145e-05,
      "loss": 0.0742,
      "step": 75
    },
    {
      "epoch": 0.051630434782608696,
      "grad_norm": 2.5093064308166504,
      "learning_rate": 1.998538721462561e-05,
      "loss": 0.1146,
      "step": 76
    },
    {
      "epoch": 0.052309782608695655,
      "grad_norm": 3.985302686691284,
      "learning_rate": 1.9985000234524086e-05,
      "loss": 0.1829,
      "step": 77
    },
    {
      "epoch": 0.05298913043478261,
      "grad_norm": 0.1472351849079132,
      "learning_rate": 1.9984608200952736e-05,
      "loss": 0.0014,
      "step": 78
    },
    {
      "epoch": 0.05366847826086957,
      "grad_norm": 1.2535247802734375,
      "learning_rate": 1.998421111410997e-05,
      "loss": 0.012,
      "step": 79
    },
    {
      "epoch": 0.05434782608695652,
      "grad_norm": 11.769497871398926,
      "learning_rate": 1.9983808974196752e-05,
      "loss": 0.1257,
      "step": 80
    },
    {
      "epoch": 0.05502717391304348,
      "grad_norm": 2.6902318000793457,
      "learning_rate": 1.998340178141661e-05,
      "loss": 0.1918,
      "step": 81
    },
    {
      "epoch": 0.05570652173913043,
      "grad_norm": 2.6673102378845215,
      "learning_rate": 1.998298953597563e-05,
      "loss": 0.1224,
      "step": 82
    },
    {
      "epoch": 0.05638586956521739,
      "grad_norm": 2.9240806102752686,
      "learning_rate": 1.9982572238082446e-05,
      "loss": 0.1567,
      "step": 83
    },
    {
      "epoch": 0.057065217391304345,
      "grad_norm": 3.4864838123321533,
      "learning_rate": 1.9982149887948264e-05,
      "loss": 0.2546,
      "step": 84
    },
    {
      "epoch": 0.057744565217391304,
      "grad_norm": 3.7989377975463867,
      "learning_rate": 1.9981722485786828e-05,
      "loss": 0.212,
      "step": 85
    },
    {
      "epoch": 0.058423913043478264,
      "grad_norm": 4.064075469970703,
      "learning_rate": 1.9981290031814456e-05,
      "loss": 0.2294,
      "step": 86
    },
    {
      "epoch": 0.059103260869565216,
      "grad_norm": 2.5052151679992676,
      "learning_rate": 1.998085252625001e-05,
      "loss": 0.1079,
      "step": 87
    },
    {
      "epoch": 0.059782608695652176,
      "grad_norm": 0.7624921202659607,
      "learning_rate": 1.9980409969314917e-05,
      "loss": 0.0068,
      "step": 88
    },
    {
      "epoch": 0.06046195652173913,
      "grad_norm": 1.5256627798080444,
      "learning_rate": 1.997996236123316e-05,
      "loss": 0.0708,
      "step": 89
    },
    {
      "epoch": 0.06114130434782609,
      "grad_norm": 11.192481994628906,
      "learning_rate": 1.997950970223127e-05,
      "loss": 0.1227,
      "step": 90
    },
    {
      "epoch": 0.06182065217391304,
      "grad_norm": 0.2952893078327179,
      "learning_rate": 1.9979051992538346e-05,
      "loss": 0.0022,
      "step": 91
    },
    {
      "epoch": 0.0625,
      "grad_norm": 1.6648790836334229,
      "learning_rate": 1.9978589232386036e-05,
      "loss": 0.1905,
      "step": 92
    },
    {
      "epoch": 0.06317934782608696,
      "grad_norm": 3.2630584239959717,
      "learning_rate": 1.9978121422008547e-05,
      "loss": 0.1354,
      "step": 93
    },
    {
      "epoch": 0.06385869565217392,
      "grad_norm": 5.2558441162109375,
      "learning_rate": 1.997764856164264e-05,
      "loss": 0.2623,
      "step": 94
    },
    {
      "epoch": 0.06453804347826086,
      "grad_norm": 2.133613348007202,
      "learning_rate": 1.997717065152763e-05,
      "loss": 0.0727,
      "step": 95
    },
    {
      "epoch": 0.06521739130434782,
      "grad_norm": 3.9992268085479736,
      "learning_rate": 1.9976687691905394e-05,
      "loss": 0.1257,
      "step": 96
    },
    {
      "epoch": 0.06589673913043478,
      "grad_norm": 3.9781510829925537,
      "learning_rate": 1.997619968302036e-05,
      "loss": 0.236,
      "step": 97
    },
    {
      "epoch": 0.06657608695652174,
      "grad_norm": 2.8673455715179443,
      "learning_rate": 1.997570662511951e-05,
      "loss": 0.1619,
      "step": 98
    },
    {
      "epoch": 0.06725543478260869,
      "grad_norm": 0.08126026391983032,
      "learning_rate": 1.9975208518452384e-05,
      "loss": 0.0009,
      "step": 99
    },
    {
      "epoch": 0.06793478260869565,
      "grad_norm": 0.5220625400543213,
      "learning_rate": 1.9974705363271076e-05,
      "loss": 0.0048,
      "step": 100
    },
    {
      "epoch": 0.06861413043478261,
      "grad_norm": 3.213183641433716,
      "learning_rate": 1.9974197159830243e-05,
      "loss": 0.1591,
      "step": 101
    },
    {
      "epoch": 0.06929347826086957,
      "grad_norm": 0.7663608193397522,
      "learning_rate": 1.997368390838708e-05,
      "loss": 0.0057,
      "step": 102
    },
    {
      "epoch": 0.06997282608695653,
      "grad_norm": 8.78122329711914,
      "learning_rate": 1.9973165609201354e-05,
      "loss": 0.3519,
      "step": 103
    },
    {
      "epoch": 0.07065217391304347,
      "grad_norm": 3.3311312198638916,
      "learning_rate": 1.997264226253538e-05,
      "loss": 0.1008,
      "step": 104
    },
    {
      "epoch": 0.07133152173913043,
      "grad_norm": 0.13349686563014984,
      "learning_rate": 1.9972113868654016e-05,
      "loss": 0.0012,
      "step": 105
    },
    {
      "epoch": 0.07201086956521739,
      "grad_norm": 0.662675678730011,
      "learning_rate": 1.99715804278247e-05,
      "loss": 0.007,
      "step": 106
    },
    {
      "epoch": 0.07269021739130435,
      "grad_norm": 0.1187664195895195,
      "learning_rate": 1.99710419403174e-05,
      "loss": 0.0012,
      "step": 107
    },
    {
      "epoch": 0.07336956521739131,
      "grad_norm": 3.9911386966705322,
      "learning_rate": 1.997049840640465e-05,
      "loss": 0.1609,
      "step": 108
    },
    {
      "epoch": 0.07404891304347826,
      "grad_norm": 11.848402976989746,
      "learning_rate": 1.996994982636154e-05,
      "loss": 0.5527,
      "step": 109
    },
    {
      "epoch": 0.07472826086956522,
      "grad_norm": 1.9172980785369873,
      "learning_rate": 1.99693962004657e-05,
      "loss": 0.0219,
      "step": 110
    },
    {
      "epoch": 0.07540760869565218,
      "grad_norm": 2.5390965938568115,
      "learning_rate": 1.9968837528997333e-05,
      "loss": 0.0567,
      "step": 111
    },
    {
      "epoch": 0.07608695652173914,
      "grad_norm": 0.286597341299057,
      "learning_rate": 1.9968273812239185e-05,
      "loss": 0.0021,
      "step": 112
    },
    {
      "epoch": 0.07676630434782608,
      "grad_norm": 0.10883186757564545,
      "learning_rate": 1.9967705050476552e-05,
      "loss": 0.0013,
      "step": 113
    },
    {
      "epoch": 0.07744565217391304,
      "grad_norm": 4.594017505645752,
      "learning_rate": 1.996713124399729e-05,
      "loss": 0.0367,
      "step": 114
    },
    {
      "epoch": 0.078125,
      "grad_norm": 2.324808359146118,
      "learning_rate": 1.9966552393091804e-05,
      "loss": 0.1917,
      "step": 115
    },
    {
      "epoch": 0.07880434782608696,
      "grad_norm": 0.03507773578166962,
      "learning_rate": 1.996596849805306e-05,
      "loss": 0.0004,
      "step": 116
    },
    {
      "epoch": 0.07948369565217392,
      "grad_norm": 1.8812072277069092,
      "learning_rate": 1.9965379559176562e-05,
      "loss": 0.1072,
      "step": 117
    },
    {
      "epoch": 0.08016304347826086,
      "grad_norm": 1.598358154296875,
      "learning_rate": 1.9964785576760385e-05,
      "loss": 0.0543,
      "step": 118
    },
    {
      "epoch": 0.08084239130434782,
      "grad_norm": 2.867462158203125,
      "learning_rate": 1.996418655110514e-05,
      "loss": 0.1244,
      "step": 119
    },
    {
      "epoch": 0.08152173913043478,
      "grad_norm": 2.0730018615722656,
      "learning_rate": 1.9963582482514003e-05,
      "loss": 0.0691,
      "step": 120
    },
    {
      "epoch": 0.08220108695652174,
      "grad_norm": 3.5135414600372314,
      "learning_rate": 1.9962973371292692e-05,
      "loss": 0.2283,
      "step": 121
    },
    {
      "epoch": 0.08288043478260869,
      "grad_norm": 2.959740161895752,
      "learning_rate": 1.9962359217749482e-05,
      "loss": 0.0255,
      "step": 122
    },
    {
      "epoch": 0.08355978260869565,
      "grad_norm": 3.68644118309021,
      "learning_rate": 1.9961740022195202e-05,
      "loss": 0.041,
      "step": 123
    },
    {
      "epoch": 0.08423913043478261,
      "grad_norm": 3.170959711074829,
      "learning_rate": 1.9961115784943232e-05,
      "loss": 0.1405,
      "step": 124
    },
    {
      "epoch": 0.08491847826086957,
      "grad_norm": 3.6250624656677246,
      "learning_rate": 1.99604865063095e-05,
      "loss": 0.095,
      "step": 125
    },
    {
      "epoch": 0.08559782608695653,
      "grad_norm": 3.479396104812622,
      "learning_rate": 1.9959852186612492e-05,
      "loss": 0.178,
      "step": 126
    },
    {
      "epoch": 0.08627717391304347,
      "grad_norm": 2.3622829914093018,
      "learning_rate": 1.9959212826173236e-05,
      "loss": 0.1187,
      "step": 127
    },
    {
      "epoch": 0.08695652173913043,
      "grad_norm": 0.13165895640850067,
      "learning_rate": 1.9958568425315316e-05,
      "loss": 0.0015,
      "step": 128
    },
    {
      "epoch": 0.08763586956521739,
      "grad_norm": 0.018928224220871925,
      "learning_rate": 1.995791898436487e-05,
      "loss": 0.0004,
      "step": 129
    },
    {
      "epoch": 0.08831521739130435,
      "grad_norm": 1.2693122625350952,
      "learning_rate": 1.995726450365058e-05,
      "loss": 0.0331,
      "step": 130
    },
    {
      "epoch": 0.08899456521739131,
      "grad_norm": 2.311523914337158,
      "learning_rate": 1.9956604983503686e-05,
      "loss": 0.1396,
      "step": 131
    },
    {
      "epoch": 0.08967391304347826,
      "grad_norm": 0.007915275171399117,
      "learning_rate": 1.995594042425798e-05,
      "loss": 0.0002,
      "step": 132
    },
    {
      "epoch": 0.09035326086956522,
      "grad_norm": 3.102302074432373,
      "learning_rate": 1.995527082624979e-05,
      "loss": 0.1609,
      "step": 133
    },
    {
      "epoch": 0.09103260869565218,
      "grad_norm": 3.852931261062622,
      "learning_rate": 1.995459618981801e-05,
      "loss": 0.2025,
      "step": 134
    },
    {
      "epoch": 0.09171195652173914,
      "grad_norm": 3.93009877204895,
      "learning_rate": 1.9953916515304077e-05,
      "loss": 0.1767,
      "step": 135
    },
    {
      "epoch": 0.09239130434782608,
      "grad_norm": 0.09938829392194748,
      "learning_rate": 1.9953231803051977e-05,
      "loss": 0.0007,
      "step": 136
    },
    {
      "epoch": 0.09307065217391304,
      "grad_norm": 0.06423509120941162,
      "learning_rate": 1.9952542053408247e-05,
      "loss": 0.0006,
      "step": 137
    },
    {
      "epoch": 0.09375,
      "grad_norm": 4.696931838989258,
      "learning_rate": 1.995184726672197e-05,
      "loss": 0.2007,
      "step": 138
    },
    {
      "epoch": 0.09442934782608696,
      "grad_norm": 0.0617285817861557,
      "learning_rate": 1.9951147443344788e-05,
      "loss": 0.0007,
      "step": 139
    },
    {
      "epoch": 0.09510869565217392,
      "grad_norm": 0.07934188842773438,
      "learning_rate": 1.9950442583630884e-05,
      "loss": 0.0009,
      "step": 140
    },
    {
      "epoch": 0.09578804347826086,
      "grad_norm": 5.652678966522217,
      "learning_rate": 1.9949732687936992e-05,
      "loss": 0.2802,
      "step": 141
    },
    {
      "epoch": 0.09646739130434782,
      "grad_norm": 3.1691129207611084,
      "learning_rate": 1.9949017756622393e-05,
      "loss": 0.1645,
      "step": 142
    },
    {
      "epoch": 0.09714673913043478,
      "grad_norm": 6.047858238220215,
      "learning_rate": 1.994829779004892e-05,
      "loss": 0.254,
      "step": 143
    },
    {
      "epoch": 0.09782608695652174,
      "grad_norm": 17.261777877807617,
      "learning_rate": 1.994757278858095e-05,
      "loss": 0.65,
      "step": 144
    },
    {
      "epoch": 0.09850543478260869,
      "grad_norm": 2.8560285568237305,
      "learning_rate": 1.9946842752585414e-05,
      "loss": 0.116,
      "step": 145
    },
    {
      "epoch": 0.09918478260869565,
      "grad_norm": 0.04773275926709175,
      "learning_rate": 1.9946107682431784e-05,
      "loss": 0.0005,
      "step": 146
    },
    {
      "epoch": 0.09986413043478261,
      "grad_norm": 0.11833947151899338,
      "learning_rate": 1.9945367578492085e-05,
      "loss": 0.0013,
      "step": 147
    },
    {
      "epoch": 0.10054347826086957,
      "grad_norm": 1.966505765914917,
      "learning_rate": 1.994462244114089e-05,
      "loss": 0.0254,
      "step": 148
    },
    {
      "epoch": 0.10122282608695653,
      "grad_norm": 4.2299370765686035,
      "learning_rate": 1.9943872270755316e-05,
      "loss": 0.1659,
      "step": 149
    },
    {
      "epoch": 0.10190217391304347,
      "grad_norm": 17.854412078857422,
      "learning_rate": 1.994311706771503e-05,
      "loss": 0.2358,
      "step": 150
    },
    {
      "epoch": 0.10258152173913043,
      "grad_norm": 4.537680149078369,
      "learning_rate": 1.9942356832402242e-05,
      "loss": 0.0422,
      "step": 151
    },
    {
      "epoch": 0.10326086956521739,
      "grad_norm": 2.468311071395874,
      "learning_rate": 1.9941591565201712e-05,
      "loss": 0.1365,
      "step": 152
    },
    {
      "epoch": 0.10394021739130435,
      "grad_norm": 4.407186508178711,
      "learning_rate": 1.994082126650075e-05,
      "loss": 0.2414,
      "step": 153
    },
    {
      "epoch": 0.10461956521739131,
      "grad_norm": 1.2103736400604248,
      "learning_rate": 1.9940045936689208e-05,
      "loss": 0.0328,
      "step": 154
    },
    {
      "epoch": 0.10529891304347826,
      "grad_norm": 18.200332641601562,
      "learning_rate": 1.9939265576159483e-05,
      "loss": 0.5534,
      "step": 155
    },
    {
      "epoch": 0.10597826086956522,
      "grad_norm": 2.135012626647949,
      "learning_rate": 1.993848018530652e-05,
      "loss": 0.2068,
      "step": 156
    },
    {
      "epoch": 0.10665760869565218,
      "grad_norm": 1.9715083837509155,
      "learning_rate": 1.9937689764527812e-05,
      "loss": 0.121,
      "step": 157
    },
    {
      "epoch": 0.10733695652173914,
      "grad_norm": 3.4033515453338623,
      "learning_rate": 1.9936894314223395e-05,
      "loss": 0.1363,
      "step": 158
    },
    {
      "epoch": 0.10801630434782608,
      "grad_norm": 3.669900894165039,
      "learning_rate": 1.9936093834795853e-05,
      "loss": 0.1573,
      "step": 159
    },
    {
      "epoch": 0.10869565217391304,
      "grad_norm": 0.03256780654191971,
      "learning_rate": 1.9935288326650314e-05,
      "loss": 0.0006,
      "step": 160
    },
    {
      "epoch": 0.109375,
      "grad_norm": 2.7019283771514893,
      "learning_rate": 1.9934477790194445e-05,
      "loss": 0.1182,
      "step": 161
    },
    {
      "epoch": 0.11005434782608696,
      "grad_norm": 0.2654156982898712,
      "learning_rate": 1.993366222583847e-05,
      "loss": 0.0027,
      "step": 162
    },
    {
      "epoch": 0.11073369565217392,
      "grad_norm": 0.5178082585334778,
      "learning_rate": 1.9932841633995147e-05,
      "loss": 0.0058,
      "step": 163
    },
    {
      "epoch": 0.11141304347826086,
      "grad_norm": 6.488332271575928,
      "learning_rate": 1.9932016015079784e-05,
      "loss": 0.3729,
      "step": 164
    },
    {
      "epoch": 0.11209239130434782,
      "grad_norm": 7.751968860626221,
      "learning_rate": 1.9931185369510228e-05,
      "loss": 0.2832,
      "step": 165
    },
    {
      "epoch": 0.11277173913043478,
      "grad_norm": 3.3881800174713135,
      "learning_rate": 1.9930349697706882e-05,
      "loss": 0.1704,
      "step": 166
    },
    {
      "epoch": 0.11345108695652174,
      "grad_norm": 0.9571385979652405,
      "learning_rate": 1.9929509000092676e-05,
      "loss": 0.0115,
      "step": 167
    },
    {
      "epoch": 0.11413043478260869,
      "grad_norm": 0.0885196328163147,
      "learning_rate": 1.99286632770931e-05,
      "loss": 0.0009,
      "step": 168
    },
    {
      "epoch": 0.11480978260869565,
      "grad_norm": 1.6827744245529175,
      "learning_rate": 1.9927812529136175e-05,
      "loss": 0.028,
      "step": 169
    },
    {
      "epoch": 0.11548913043478261,
      "grad_norm": 4.7409257888793945,
      "learning_rate": 1.992695675665247e-05,
      "loss": 0.1506,
      "step": 170
    },
    {
      "epoch": 0.11616847826086957,
      "grad_norm": 2.025632381439209,
      "learning_rate": 1.9926095960075097e-05,
      "loss": 0.1315,
      "step": 171
    },
    {
      "epoch": 0.11684782608695653,
      "grad_norm": 3.692263603210449,
      "learning_rate": 1.9925230139839714e-05,
      "loss": 0.105,
      "step": 172
    },
    {
      "epoch": 0.11752717391304347,
      "grad_norm": 2.3151166439056396,
      "learning_rate": 1.992435929638451e-05,
      "loss": 0.0349,
      "step": 173
    },
    {
      "epoch": 0.11820652173913043,
      "grad_norm": 3.2644121646881104,
      "learning_rate": 1.992348343015023e-05,
      "loss": 0.2377,
      "step": 174
    },
    {
      "epoch": 0.11888586956521739,
      "grad_norm": 2.28210711479187,
      "learning_rate": 1.9922602541580158e-05,
      "loss": 0.142,
      "step": 175
    },
    {
      "epoch": 0.11956521739130435,
      "grad_norm": 2.0764169692993164,
      "learning_rate": 1.992171663112011e-05,
      "loss": 0.1259,
      "step": 176
    },
    {
      "epoch": 0.12024456521739131,
      "grad_norm": 2.2452213764190674,
      "learning_rate": 1.9920825699218453e-05,
      "loss": 0.0954,
      "step": 177
    },
    {
      "epoch": 0.12092391304347826,
      "grad_norm": 0.2933761775493622,
      "learning_rate": 1.9919929746326095e-05,
      "loss": 0.0024,
      "step": 178
    },
    {
      "epoch": 0.12160326086956522,
      "grad_norm": 2.0788283348083496,
      "learning_rate": 1.9919028772896484e-05,
      "loss": 0.1688,
      "step": 179
    },
    {
      "epoch": 0.12228260869565218,
      "grad_norm": 2.2234904766082764,
      "learning_rate": 1.99181227793856e-05,
      "loss": 0.1349,
      "step": 180
    },
    {
      "epoch": 0.12296195652173914,
      "grad_norm": 0.7851950526237488,
      "learning_rate": 1.9917211766251987e-05,
      "loss": 0.0075,
      "step": 181
    },
    {
      "epoch": 0.12364130434782608,
      "grad_norm": 0.20910614728927612,
      "learning_rate": 1.9916295733956702e-05,
      "loss": 0.0027,
      "step": 182
    },
    {
      "epoch": 0.12432065217391304,
      "grad_norm": 0.6500880122184753,
      "learning_rate": 1.9915374682963358e-05,
      "loss": 0.0062,
      "step": 183
    },
    {
      "epoch": 0.125,
      "grad_norm": 12.104527473449707,
      "learning_rate": 1.9914448613738107e-05,
      "loss": 0.5353,
      "step": 184
    },
    {
      "epoch": 0.12567934782608695,
      "grad_norm": 11.389892578125,
      "learning_rate": 1.9913517526749632e-05,
      "loss": 0.1645,
      "step": 185
    },
    {
      "epoch": 0.12635869565217392,
      "grad_norm": 0.016295814886689186,
      "learning_rate": 1.991258142246917e-05,
      "loss": 0.0003,
      "step": 186
    },
    {
      "epoch": 0.12703804347826086,
      "grad_norm": 16.93265724182129,
      "learning_rate": 1.9911640301370484e-05,
      "loss": 0.3805,
      "step": 187
    },
    {
      "epoch": 0.12771739130434784,
      "grad_norm": 10.996623992919922,
      "learning_rate": 1.991069416392988e-05,
      "loss": 0.5131,
      "step": 188
    },
    {
      "epoch": 0.12839673913043478,
      "grad_norm": 3.2760255336761475,
      "learning_rate": 1.990974301062621e-05,
      "loss": 0.219,
      "step": 189
    },
    {
      "epoch": 0.12907608695652173,
      "grad_norm": 0.11714225262403488,
      "learning_rate": 1.990878684194085e-05,
      "loss": 0.001,
      "step": 190
    },
    {
      "epoch": 0.1297554347826087,
      "grad_norm": 0.010150901973247528,
      "learning_rate": 1.990782565835773e-05,
      "loss": 0.0002,
      "step": 191
    },
    {
      "epoch": 0.13043478260869565,
      "grad_norm": 1.9183855056762695,
      "learning_rate": 1.9906859460363307e-05,
      "loss": 0.1496,
      "step": 192
    },
    {
      "epoch": 0.13111413043478262,
      "grad_norm": 0.25095129013061523,
      "learning_rate": 1.9905888248446584e-05,
      "loss": 0.0031,
      "step": 193
    },
    {
      "epoch": 0.13179347826086957,
      "grad_norm": 0.49905747175216675,
      "learning_rate": 1.9904912023099096e-05,
      "loss": 0.0051,
      "step": 194
    },
    {
      "epoch": 0.1324728260869565,
      "grad_norm": 2.178438663482666,
      "learning_rate": 1.9903930784814908e-05,
      "loss": 0.1378,
      "step": 195
    },
    {
      "epoch": 0.1331521739130435,
      "grad_norm": 1.4038512706756592,
      "learning_rate": 1.9902944534090644e-05,
      "loss": 0.0188,
      "step": 196
    },
    {
      "epoch": 0.13383152173913043,
      "grad_norm": 0.5579654574394226,
      "learning_rate": 1.990195327142544e-05,
      "loss": 0.0056,
      "step": 197
    },
    {
      "epoch": 0.13451086956521738,
      "grad_norm": 2.484121799468994,
      "learning_rate": 1.990095699732099e-05,
      "loss": 0.1592,
      "step": 198
    },
    {
      "epoch": 0.13519021739130435,
      "grad_norm": 2.7288856506347656,
      "learning_rate": 1.989995571228151e-05,
      "loss": 0.1407,
      "step": 199
    },
    {
      "epoch": 0.1358695652173913,
      "grad_norm": 2.668649911880493,
      "learning_rate": 1.9898949416813757e-05,
      "loss": 0.1482,
      "step": 200
    },
    {
      "epoch": 0.13654891304347827,
      "grad_norm": 0.036954741925001144,
      "learning_rate": 1.989793811142702e-05,
      "loss": 0.0005,
      "step": 201
    },
    {
      "epoch": 0.13722826086956522,
      "grad_norm": 3.6081056594848633,
      "learning_rate": 1.989692179663313e-05,
      "loss": 0.1449,
      "step": 202
    },
    {
      "epoch": 0.13790760869565216,
      "grad_norm": 4.6919474601745605,
      "learning_rate": 1.989590047294645e-05,
      "loss": 0.2303,
      "step": 203
    },
    {
      "epoch": 0.13858695652173914,
      "grad_norm": 0.09144303947687149,
      "learning_rate": 1.9894874140883877e-05,
      "loss": 0.001,
      "step": 204
    },
    {
      "epoch": 0.13926630434782608,
      "grad_norm": 1.5549741983413696,
      "learning_rate": 1.9893842800964845e-05,
      "loss": 0.1155,
      "step": 205
    },
    {
      "epoch": 0.13994565217391305,
      "grad_norm": 1.9133689403533936,
      "learning_rate": 1.9892806453711325e-05,
      "loss": 0.0322,
      "step": 206
    },
    {
      "epoch": 0.140625,
      "grad_norm": 1.7207578420639038,
      "learning_rate": 1.989176509964781e-05,
      "loss": 0.0232,
      "step": 207
    },
    {
      "epoch": 0.14130434782608695,
      "grad_norm": 4.018390655517578,
      "learning_rate": 1.9890718739301346e-05,
      "loss": 0.2713,
      "step": 208
    },
    {
      "epoch": 0.14198369565217392,
      "grad_norm": 4.390851020812988,
      "learning_rate": 1.988966737320149e-05,
      "loss": 0.0391,
      "step": 209
    },
    {
      "epoch": 0.14266304347826086,
      "grad_norm": 2.838894844055176,
      "learning_rate": 1.9888611001880357e-05,
      "loss": 0.0674,
      "step": 210
    },
    {
      "epoch": 0.14334239130434784,
      "grad_norm": 8.025857925415039,
      "learning_rate": 1.9887549625872577e-05,
      "loss": 0.376,
      "step": 211
    },
    {
      "epoch": 0.14402173913043478,
      "grad_norm": 2.342423677444458,
      "learning_rate": 1.988648324571532e-05,
      "loss": 0.1361,
      "step": 212
    },
    {
      "epoch": 0.14470108695652173,
      "grad_norm": 0.998401403427124,
      "learning_rate": 1.9885411861948287e-05,
      "loss": 0.0106,
      "step": 213
    },
    {
      "epoch": 0.1453804347826087,
      "grad_norm": 5.691372871398926,
      "learning_rate": 1.988433547511371e-05,
      "loss": 0.149,
      "step": 214
    },
    {
      "epoch": 0.14605978260869565,
      "grad_norm": 2.2613818645477295,
      "learning_rate": 1.9883254085756357e-05,
      "loss": 0.1341,
      "step": 215
    },
    {
      "epoch": 0.14673913043478262,
      "grad_norm": 2.1344079971313477,
      "learning_rate": 1.988216769442353e-05,
      "loss": 0.1442,
      "step": 216
    },
    {
      "epoch": 0.14741847826086957,
      "grad_norm": 5.1438775062561035,
      "learning_rate": 1.988107630166505e-05,
      "loss": 0.2956,
      "step": 217
    },
    {
      "epoch": 0.1480978260869565,
      "grad_norm": 4.92598819732666,
      "learning_rate": 1.9879979908033287e-05,
      "loss": 0.0598,
      "step": 218
    },
    {
      "epoch": 0.1487771739130435,
      "grad_norm": 2.800651788711548,
      "learning_rate": 1.9878878514083124e-05,
      "loss": 0.1425,
      "step": 219
    },
    {
      "epoch": 0.14945652173913043,
      "grad_norm": 2.7551610469818115,
      "learning_rate": 1.9877772120371986e-05,
      "loss": 0.0862,
      "step": 220
    },
    {
      "epoch": 0.15013586956521738,
      "grad_norm": 2.207801580429077,
      "learning_rate": 1.9876660727459826e-05,
      "loss": 0.1151,
      "step": 221
    },
    {
      "epoch": 0.15081521739130435,
      "grad_norm": 9.795785903930664,
      "learning_rate": 1.987554433590913e-05,
      "loss": 0.4313,
      "step": 222
    },
    {
      "epoch": 0.1514945652173913,
      "grad_norm": 3.769669532775879,
      "learning_rate": 1.9874422946284904e-05,
      "loss": 0.2907,
      "step": 223
    },
    {
      "epoch": 0.15217391304347827,
      "grad_norm": 1.6602706909179688,
      "learning_rate": 1.98732965591547e-05,
      "loss": 0.1308,
      "step": 224
    },
    {
      "epoch": 0.15285326086956522,
      "grad_norm": 0.7881489396095276,
      "learning_rate": 1.9872165175088578e-05,
      "loss": 0.0139,
      "step": 225
    },
    {
      "epoch": 0.15353260869565216,
      "grad_norm": 2.786900281906128,
      "learning_rate": 1.987102879465914e-05,
      "loss": 0.1333,
      "step": 226
    },
    {
      "epoch": 0.15421195652173914,
      "grad_norm": 2.619004726409912,
      "learning_rate": 1.9869887418441525e-05,
      "loss": 0.177,
      "step": 227
    },
    {
      "epoch": 0.15489130434782608,
      "grad_norm": 1.9802147150039673,
      "learning_rate": 1.9868741047013382e-05,
      "loss": 0.1242,
      "step": 228
    },
    {
      "epoch": 0.15557065217391305,
      "grad_norm": 0.5852559804916382,
      "learning_rate": 1.9867589680954902e-05,
      "loss": 0.0072,
      "step": 229
    },
    {
      "epoch": 0.15625,
      "grad_norm": 0.19608303904533386,
      "learning_rate": 1.9866433320848793e-05,
      "loss": 0.0018,
      "step": 230
    },
    {
      "epoch": 0.15692934782608695,
      "grad_norm": 5.480025768280029,
      "learning_rate": 1.9865271967280297e-05,
      "loss": 0.2304,
      "step": 231
    },
    {
      "epoch": 0.15760869565217392,
      "grad_norm": 0.9126811623573303,
      "learning_rate": 1.9864105620837182e-05,
      "loss": 0.0084,
      "step": 232
    },
    {
      "epoch": 0.15828804347826086,
      "grad_norm": 1.4558072090148926,
      "learning_rate": 1.9862934282109746e-05,
      "loss": 0.0205,
      "step": 233
    },
    {
      "epoch": 0.15896739130434784,
      "grad_norm": 0.025305312126874924,
      "learning_rate": 1.9861757951690813e-05,
      "loss": 0.0004,
      "step": 234
    },
    {
      "epoch": 0.15964673913043478,
      "grad_norm": 2.7103829383850098,
      "learning_rate": 1.9860576630175723e-05,
      "loss": 0.055,
      "step": 235
    },
    {
      "epoch": 0.16032608695652173,
      "grad_norm": 2.948634386062622,
      "learning_rate": 1.9859390318162354e-05,
      "loss": 0.2122,
      "step": 236
    },
    {
      "epoch": 0.1610054347826087,
      "grad_norm": 0.1367320865392685,
      "learning_rate": 1.9858199016251106e-05,
      "loss": 0.0014,
      "step": 237
    },
    {
      "epoch": 0.16168478260869565,
      "grad_norm": 0.19067589938640594,
      "learning_rate": 1.9857002725044907e-05,
      "loss": 0.0023,
      "step": 238
    },
    {
      "epoch": 0.16236413043478262,
      "grad_norm": 0.44957417249679565,
      "learning_rate": 1.9855801445149204e-05,
      "loss": 0.0064,
      "step": 239
    },
    {
      "epoch": 0.16304347826086957,
      "grad_norm": 0.8898889422416687,
      "learning_rate": 1.9854595177171968e-05,
      "loss": 0.0096,
      "step": 240
    },
    {
      "epoch": 0.1637228260869565,
      "grad_norm": 0.1431356519460678,
      "learning_rate": 1.9853383921723708e-05,
      "loss": 0.0019,
      "step": 241
    },
    {
      "epoch": 0.1644021739130435,
      "grad_norm": 1.3714118003845215,
      "learning_rate": 1.9852167679417445e-05,
      "loss": 0.0555,
      "step": 242
    },
    {
      "epoch": 0.16508152173913043,
      "grad_norm": 2.5305328369140625,
      "learning_rate": 1.985094645086872e-05,
      "loss": 0.1239,
      "step": 243
    },
    {
      "epoch": 0.16576086956521738,
      "grad_norm": 0.44657811522483826,
      "learning_rate": 1.984972023669561e-05,
      "loss": 0.0039,
      "step": 244
    },
    {
      "epoch": 0.16644021739130435,
      "grad_norm": 11.94597339630127,
      "learning_rate": 1.984848903751871e-05,
      "loss": 0.3883,
      "step": 245
    },
    {
      "epoch": 0.1671195652173913,
      "grad_norm": 0.014804990030825138,
      "learning_rate": 1.9847252853961136e-05,
      "loss": 0.0003,
      "step": 246
    },
    {
      "epoch": 0.16779891304347827,
      "grad_norm": 11.394709587097168,
      "learning_rate": 1.9846011686648525e-05,
      "loss": 0.1592,
      "step": 247
    },
    {
      "epoch": 0.16847826086956522,
      "grad_norm": 4.005213737487793,
      "learning_rate": 1.9844765536209045e-05,
      "loss": 0.2617,
      "step": 248
    },
    {
      "epoch": 0.16915760869565216,
      "grad_norm": 0.6870856881141663,
      "learning_rate": 1.9843514403273378e-05,
      "loss": 0.0082,
      "step": 249
    },
    {
      "epoch": 0.16983695652173914,
      "grad_norm": 0.32277894020080566,
      "learning_rate": 1.984225828847473e-05,
      "loss": 0.0048,
      "step": 250
    },
    {
      "epoch": 0.17051630434782608,
      "grad_norm": 11.242080688476562,
      "learning_rate": 1.9840997192448827e-05,
      "loss": 0.168,
      "step": 251
    },
    {
      "epoch": 0.17119565217391305,
      "grad_norm": 0.1517542451620102,
      "learning_rate": 1.983973111583392e-05,
      "loss": 0.0017,
      "step": 252
    },
    {
      "epoch": 0.171875,
      "grad_norm": 2.896796703338623,
      "learning_rate": 1.9838460059270775e-05,
      "loss": 0.1748,
      "step": 253
    },
    {
      "epoch": 0.17255434782608695,
      "grad_norm": 5.03916072845459,
      "learning_rate": 1.9837184023402683e-05,
      "loss": 0.1801,
      "step": 254
    },
    {
      "epoch": 0.17323369565217392,
      "grad_norm": 8.170997619628906,
      "learning_rate": 1.9835903008875458e-05,
      "loss": 0.1033,
      "step": 255
    },
    {
      "epoch": 0.17391304347826086,
      "grad_norm": 0.06565805524587631,
      "learning_rate": 1.9834617016337424e-05,
      "loss": 0.0009,
      "step": 256
    },
    {
      "epoch": 0.17459239130434784,
      "grad_norm": 2.5079848766326904,
      "learning_rate": 1.9833326046439428e-05,
      "loss": 0.1065,
      "step": 257
    },
    {
      "epoch": 0.17527173913043478,
      "grad_norm": 10.261606216430664,
      "learning_rate": 1.983203009983484e-05,
      "loss": 0.3744,
      "step": 258
    },
    {
      "epoch": 0.17595108695652173,
      "grad_norm": 0.08793282508850098,
      "learning_rate": 1.9830729177179552e-05,
      "loss": 0.001,
      "step": 259
    },
    {
      "epoch": 0.1766304347826087,
      "grad_norm": 10.567391395568848,
      "learning_rate": 1.9829423279131962e-05,
      "loss": 0.4625,
      "step": 260
    },
    {
      "epoch": 0.17730978260869565,
      "grad_norm": 1.5140795707702637,
      "learning_rate": 1.9828112406352994e-05,
      "loss": 0.0918,
      "step": 261
    },
    {
      "epoch": 0.17798913043478262,
      "grad_norm": 2.4050509929656982,
      "learning_rate": 1.9826796559506092e-05,
      "loss": 0.0316,
      "step": 262
    },
    {
      "epoch": 0.17866847826086957,
      "grad_norm": 1.7080907821655273,
      "learning_rate": 1.982547573925721e-05,
      "loss": 0.0744,
      "step": 263
    },
    {
      "epoch": 0.1793478260869565,
      "grad_norm": 0.3341623842716217,
      "learning_rate": 1.9824149946274827e-05,
      "loss": 0.0032,
      "step": 264
    },
    {
      "epoch": 0.1800271739130435,
      "grad_norm": 1.9990593194961548,
      "learning_rate": 1.9822819181229934e-05,
      "loss": 0.0363,
      "step": 265
    },
    {
      "epoch": 0.18070652173913043,
      "grad_norm": 0.073196180164814,
      "learning_rate": 1.982148344479604e-05,
      "loss": 0.0009,
      "step": 266
    },
    {
      "epoch": 0.18138586956521738,
      "grad_norm": 2.7728660106658936,
      "learning_rate": 1.982014273764916e-05,
      "loss": 0.091,
      "step": 267
    },
    {
      "epoch": 0.18206521739130435,
      "grad_norm": 0.4080811142921448,
      "learning_rate": 1.9818797060467848e-05,
      "loss": 0.0031,
      "step": 268
    },
    {
      "epoch": 0.1827445652173913,
      "grad_norm": 2.701366662979126,
      "learning_rate": 1.9817446413933153e-05,
      "loss": 0.1781,
      "step": 269
    },
    {
      "epoch": 0.18342391304347827,
      "grad_norm": 13.204878807067871,
      "learning_rate": 1.9816090798728648e-05,
      "loss": 0.4898,
      "step": 270
    },
    {
      "epoch": 0.18410326086956522,
      "grad_norm": 1.6390994787216187,
      "learning_rate": 1.9814730215540412e-05,
      "loss": 0.061,
      "step": 271
    },
    {
      "epoch": 0.18478260869565216,
      "grad_norm": 5.1306681632995605,
      "learning_rate": 1.981336466505705e-05,
      "loss": 0.1484,
      "step": 272
    },
    {
      "epoch": 0.18546195652173914,
      "grad_norm": 1.2556391954421997,
      "learning_rate": 1.9811994147969676e-05,
      "loss": 0.0858,
      "step": 273
    },
    {
      "epoch": 0.18614130434782608,
      "grad_norm": 3.563459634780884,
      "learning_rate": 1.9810618664971915e-05,
      "loss": 0.1707,
      "step": 274
    },
    {
      "epoch": 0.18682065217391305,
      "grad_norm": 3.3237128257751465,
      "learning_rate": 1.9809238216759906e-05,
      "loss": 0.1901,
      "step": 275
    },
    {
      "epoch": 0.1875,
      "grad_norm": 4.368372917175293,
      "learning_rate": 1.9807852804032306e-05,
      "loss": 0.1174,
      "step": 276
    },
    {
      "epoch": 0.18817934782608695,
      "grad_norm": 2.358210325241089,
      "learning_rate": 1.9806462427490278e-05,
      "loss": 0.1758,
      "step": 277
    },
    {
      "epoch": 0.18885869565217392,
      "grad_norm": 6.985863208770752,
      "learning_rate": 1.98050670878375e-05,
      "loss": 0.2684,
      "step": 278
    },
    {
      "epoch": 0.18953804347826086,
      "grad_norm": 4.468461990356445,
      "learning_rate": 1.9803666785780165e-05,
      "loss": 0.1492,
      "step": 279
    },
    {
      "epoch": 0.19021739130434784,
      "grad_norm": 4.388031959533691,
      "learning_rate": 1.980226152202697e-05,
      "loss": 0.1773,
      "step": 280
    },
    {
      "epoch": 0.19089673913043478,
      "grad_norm": 4.926743984222412,
      "learning_rate": 1.980085129728913e-05,
      "loss": 0.0756,
      "step": 281
    },
    {
      "epoch": 0.19157608695652173,
      "grad_norm": 1.001658320426941,
      "learning_rate": 1.9799436112280374e-05,
      "loss": 0.1069,
      "step": 282
    },
    {
      "epoch": 0.1922554347826087,
      "grad_norm": 0.24332894384860992,
      "learning_rate": 1.9798015967716924e-05,
      "loss": 0.0024,
      "step": 283
    },
    {
      "epoch": 0.19293478260869565,
      "grad_norm": 0.020307844504714012,
      "learning_rate": 1.979659086431753e-05,
      "loss": 0.0003,
      "step": 284
    },
    {
      "epoch": 0.19361413043478262,
      "grad_norm": 6.648280620574951,
      "learning_rate": 1.979516080280345e-05,
      "loss": 0.1531,
      "step": 285
    },
    {
      "epoch": 0.19429347826086957,
      "grad_norm": 3.3608131408691406,
      "learning_rate": 1.979372578389844e-05,
      "loss": 0.0531,
      "step": 286
    },
    {
      "epoch": 0.1949728260869565,
      "grad_norm": 0.17235882580280304,
      "learning_rate": 1.9792285808328772e-05,
      "loss": 0.0018,
      "step": 287
    },
    {
      "epoch": 0.1956521739130435,
      "grad_norm": 4.91769552230835,
      "learning_rate": 1.979084087682323e-05,
      "loss": 0.2532,
      "step": 288
    },
    {
      "epoch": 0.19633152173913043,
      "grad_norm": 1.2922229766845703,
      "learning_rate": 1.9789390990113106e-05,
      "loss": 0.0492,
      "step": 289
    },
    {
      "epoch": 0.19701086956521738,
      "grad_norm": 0.970062255859375,
      "learning_rate": 1.9787936148932186e-05,
      "loss": 0.0115,
      "step": 290
    },
    {
      "epoch": 0.19769021739130435,
      "grad_norm": 0.015408712439239025,
      "learning_rate": 1.9786476354016782e-05,
      "loss": 0.0003,
      "step": 291
    },
    {
      "epoch": 0.1983695652173913,
      "grad_norm": 2.4657928943634033,
      "learning_rate": 1.9785011606105702e-05,
      "loss": 0.0538,
      "step": 292
    },
    {
      "epoch": 0.19904891304347827,
      "grad_norm": 3.7870736122131348,
      "learning_rate": 1.978354190594027e-05,
      "loss": 0.1836,
      "step": 293
    },
    {
      "epoch": 0.19972826086956522,
      "grad_norm": 5.838490962982178,
      "learning_rate": 1.97820672542643e-05,
      "loss": 0.1311,
      "step": 294
    },
    {
      "epoch": 0.20040760869565216,
      "grad_norm": 1.8991889953613281,
      "learning_rate": 1.978058765182413e-05,
      "loss": 0.12,
      "step": 295
    },
    {
      "epoch": 0.20108695652173914,
      "grad_norm": 1.4318671226501465,
      "learning_rate": 1.9779103099368596e-05,
      "loss": 0.0214,
      "step": 296
    },
    {
      "epoch": 0.20176630434782608,
      "grad_norm": 6.84533166885376,
      "learning_rate": 1.9777613597649033e-05,
      "loss": 0.3337,
      "step": 297
    },
    {
      "epoch": 0.20244565217391305,
      "grad_norm": 0.25011253356933594,
      "learning_rate": 1.9776119147419292e-05,
      "loss": 0.0028,
      "step": 298
    },
    {
      "epoch": 0.203125,
      "grad_norm": 0.0057248338125646114,
      "learning_rate": 1.977461974943572e-05,
      "loss": 0.0001,
      "step": 299
    },
    {
      "epoch": 0.20380434782608695,
      "grad_norm": 11.967988014221191,
      "learning_rate": 1.9773115404457175e-05,
      "loss": 0.3547,
      "step": 300
    },
    {
      "epoch": 0.20448369565217392,
      "grad_norm": 3.9719467163085938,
      "learning_rate": 1.9771606113245014e-05,
      "loss": 0.2382,
      "step": 301
    },
    {
      "epoch": 0.20516304347826086,
      "grad_norm": 15.382871627807617,
      "learning_rate": 1.97700918765631e-05,
      "loss": 0.7426,
      "step": 302
    },
    {
      "epoch": 0.20584239130434784,
      "grad_norm": 0.005114897154271603,
      "learning_rate": 1.976857269517779e-05,
      "loss": 0.0001,
      "step": 303
    },
    {
      "epoch": 0.20652173913043478,
      "grad_norm": 114.50570678710938,
      "learning_rate": 1.9767048569857963e-05,
      "loss": 0.3456,
      "step": 304
    },
    {
      "epoch": 0.20720108695652173,
      "grad_norm": 1.3758398294448853,
      "learning_rate": 1.9765519501374977e-05,
      "loss": 0.0238,
      "step": 305
    },
    {
      "epoch": 0.2078804347826087,
      "grad_norm": 5.964051246643066,
      "learning_rate": 1.9763985490502714e-05,
      "loss": 0.2389,
      "step": 306
    },
    {
      "epoch": 0.20855978260869565,
      "grad_norm": 2.781933069229126,
      "learning_rate": 1.9762446538017535e-05,
      "loss": 0.1882,
      "step": 307
    },
    {
      "epoch": 0.20923913043478262,
      "grad_norm": 0.005878090858459473,
      "learning_rate": 1.9760902644698323e-05,
      "loss": 0.0002,
      "step": 308
    },
    {
      "epoch": 0.20991847826086957,
      "grad_norm": 2.8851981163024902,
      "learning_rate": 1.975935381132644e-05,
      "loss": 0.072,
      "step": 309
    },
    {
      "epoch": 0.2105978260869565,
      "grad_norm": 7.990438938140869,
      "learning_rate": 1.9757800038685773e-05,
      "loss": 0.3157,
      "step": 310
    },
    {
      "epoch": 0.2112771739130435,
      "grad_norm": 0.08835995942354202,
      "learning_rate": 1.975624132756269e-05,
      "loss": 0.0011,
      "step": 311
    },
    {
      "epoch": 0.21195652173913043,
      "grad_norm": 0.024252740666270256,
      "learning_rate": 1.9754677678746064e-05,
      "loss": 0.0004,
      "step": 312
    },
    {
      "epoch": 0.21263586956521738,
      "grad_norm": 2.2520837783813477,
      "learning_rate": 1.9753109093027264e-05,
      "loss": 0.124,
      "step": 313
    },
    {
      "epoch": 0.21331521739130435,
      "grad_norm": 9.888625144958496,
      "learning_rate": 1.975153557120017e-05,
      "loss": 0.5903,
      "step": 314
    },
    {
      "epoch": 0.2139945652173913,
      "grad_norm": 0.02919132262468338,
      "learning_rate": 1.9749957114061143e-05,
      "loss": 0.0006,
      "step": 315
    },
    {
      "epoch": 0.21467391304347827,
      "grad_norm": 3.5682451725006104,
      "learning_rate": 1.9748373722409052e-05,
      "loss": 0.0828,
      "step": 316
    },
    {
      "epoch": 0.21535326086956522,
      "grad_norm": 0.019152848049998283,
      "learning_rate": 1.9746785397045262e-05,
      "loss": 0.0004,
      "step": 317
    },
    {
      "epoch": 0.21603260869565216,
      "grad_norm": 0.022553768008947372,
      "learning_rate": 1.9745192138773633e-05,
      "loss": 0.0005,
      "step": 318
    },
    {
      "epoch": 0.21671195652173914,
      "grad_norm": 1.7896853685379028,
      "learning_rate": 1.9743593948400527e-05,
      "loss": 0.113,
      "step": 319
    },
    {
      "epoch": 0.21739130434782608,
      "grad_norm": 6.330065727233887,
      "learning_rate": 1.9741990826734793e-05,
      "loss": 0.2984,
      "step": 320
    },
    {
      "epoch": 0.21807065217391305,
      "grad_norm": 0.05956081300973892,
      "learning_rate": 1.974038277458778e-05,
      "loss": 0.0006,
      "step": 321
    },
    {
      "epoch": 0.21875,
      "grad_norm": 0.3017987608909607,
      "learning_rate": 1.9738769792773338e-05,
      "loss": 0.0031,
      "step": 322
    },
    {
      "epoch": 0.21942934782608695,
      "grad_norm": 0.054629914462566376,
      "learning_rate": 1.9737151882107803e-05,
      "loss": 0.0006,
      "step": 323
    },
    {
      "epoch": 0.22010869565217392,
      "grad_norm": 1.7726248502731323,
      "learning_rate": 1.9735529043410012e-05,
      "loss": 0.1176,
      "step": 324
    },
    {
      "epoch": 0.22078804347826086,
      "grad_norm": 3.6434428691864014,
      "learning_rate": 1.9733901277501292e-05,
      "loss": 0.1563,
      "step": 325
    },
    {
      "epoch": 0.22146739130434784,
      "grad_norm": 3.3401901721954346,
      "learning_rate": 1.9732268585205465e-05,
      "loss": 0.2375,
      "step": 326
    },
    {
      "epoch": 0.22214673913043478,
      "grad_norm": 3.6598057746887207,
      "learning_rate": 1.973063096734885e-05,
      "loss": 0.2279,
      "step": 327
    },
    {
      "epoch": 0.22282608695652173,
      "grad_norm": 4.297120571136475,
      "learning_rate": 1.972898842476025e-05,
      "loss": 0.1635,
      "step": 328
    },
    {
      "epoch": 0.2235054347826087,
      "grad_norm": 0.0045732371509075165,
      "learning_rate": 1.9727340958270968e-05,
      "loss": 0.0001,
      "step": 329
    },
    {
      "epoch": 0.22418478260869565,
      "grad_norm": 3.5305449962615967,
      "learning_rate": 1.97256885687148e-05,
      "loss": 0.1206,
      "step": 330
    },
    {
      "epoch": 0.22486413043478262,
      "grad_norm": 0.029640404507517815,
      "learning_rate": 1.9724031256928028e-05,
      "loss": 0.0005,
      "step": 331
    },
    {
      "epoch": 0.22554347826086957,
      "grad_norm": 4.0356035232543945,
      "learning_rate": 1.9722369023749426e-05,
      "loss": 0.2376,
      "step": 332
    },
    {
      "epoch": 0.2262228260869565,
      "grad_norm": 0.1579984873533249,
      "learning_rate": 1.972070187002026e-05,
      "loss": 0.0014,
      "step": 333
    },
    {
      "epoch": 0.2269021739130435,
      "grad_norm": 0.0074868169613182545,
      "learning_rate": 1.9719029796584293e-05,
      "loss": 0.0002,
      "step": 334
    },
    {
      "epoch": 0.22758152173913043,
      "grad_norm": 7.188286304473877,
      "learning_rate": 1.9717352804287766e-05,
      "loss": 0.1707,
      "step": 335
    },
    {
      "epoch": 0.22826086956521738,
      "grad_norm": 2.3603289127349854,
      "learning_rate": 1.9715670893979416e-05,
      "loss": 0.1218,
      "step": 336
    },
    {
      "epoch": 0.22894021739130435,
      "grad_norm": 0.6495533585548401,
      "learning_rate": 1.971398406651047e-05,
      "loss": 0.0077,
      "step": 337
    },
    {
      "epoch": 0.2296195652173913,
      "grad_norm": 2.2443034648895264,
      "learning_rate": 1.971229232273464e-05,
      "loss": 0.1142,
      "step": 338
    },
    {
      "epoch": 0.23029891304347827,
      "grad_norm": 0.006162473000586033,
      "learning_rate": 1.9710595663508125e-05,
      "loss": 0.0002,
      "step": 339
    },
    {
      "epoch": 0.23097826086956522,
      "grad_norm": 1.569474220275879,
      "learning_rate": 1.9708894089689622e-05,
      "loss": 0.0119,
      "step": 340
    },
    {
      "epoch": 0.23165760869565216,
      "grad_norm": 3.2025868892669678,
      "learning_rate": 1.9707187602140304e-05,
      "loss": 0.1237,
      "step": 341
    },
    {
      "epoch": 0.23233695652173914,
      "grad_norm": 0.1183307021856308,
      "learning_rate": 1.970547620172383e-05,
      "loss": 0.0011,
      "step": 342
    },
    {
      "epoch": 0.23301630434782608,
      "grad_norm": 2.6412408351898193,
      "learning_rate": 1.970375988930636e-05,
      "loss": 0.1454,
      "step": 343
    },
    {
      "epoch": 0.23369565217391305,
      "grad_norm": 0.10826492309570312,
      "learning_rate": 1.9702038665756522e-05,
      "loss": 0.0009,
      "step": 344
    },
    {
      "epoch": 0.234375,
      "grad_norm": 3.848822832107544,
      "learning_rate": 1.9700312531945444e-05,
      "loss": 0.0563,
      "step": 345
    },
    {
      "epoch": 0.23505434782608695,
      "grad_norm": 0.2065720558166504,
      "learning_rate": 1.9698581488746728e-05,
      "loss": 0.003,
      "step": 346
    },
    {
      "epoch": 0.23573369565217392,
      "grad_norm": 0.2674217224121094,
      "learning_rate": 1.9696845537036463e-05,
      "loss": 0.0038,
      "step": 347
    },
    {
      "epoch": 0.23641304347826086,
      "grad_norm": 1.1232446432113647,
      "learning_rate": 1.9695104677693234e-05,
      "loss": 0.0376,
      "step": 348
    },
    {
      "epoch": 0.23709239130434784,
      "grad_norm": 2.6141960620880127,
      "learning_rate": 1.9693358911598097e-05,
      "loss": 0.1203,
      "step": 349
    },
    {
      "epoch": 0.23777173913043478,
      "grad_norm": 12.592584609985352,
      "learning_rate": 1.969160823963459e-05,
      "loss": 0.5764,
      "step": 350
    },
    {
      "epoch": 0.23845108695652173,
      "grad_norm": 1.8996728658676147,
      "learning_rate": 1.9689852662688743e-05,
      "loss": 0.1192,
      "step": 351
    },
    {
      "epoch": 0.2391304347826087,
      "grad_norm": 1.0143238306045532,
      "learning_rate": 1.9688092181649065e-05,
      "loss": 0.0081,
      "step": 352
    },
    {
      "epoch": 0.23980978260869565,
      "grad_norm": 1.8527499437332153,
      "learning_rate": 1.9686326797406547e-05,
      "loss": 0.0222,
      "step": 353
    },
    {
      "epoch": 0.24048913043478262,
      "grad_norm": 2.0540754795074463,
      "learning_rate": 1.9684556510854655e-05,
      "loss": 0.1117,
      "step": 354
    },
    {
      "epoch": 0.24116847826086957,
      "grad_norm": 10.46847915649414,
      "learning_rate": 1.9682781322889344e-05,
      "loss": 0.2978,
      "step": 355
    },
    {
      "epoch": 0.2418478260869565,
      "grad_norm": 0.4136292040348053,
      "learning_rate": 1.9681001234409053e-05,
      "loss": 0.0057,
      "step": 356
    },
    {
      "epoch": 0.2425271739130435,
      "grad_norm": 0.0855577141046524,
      "learning_rate": 1.9679216246314694e-05,
      "loss": 0.001,
      "step": 357
    },
    {
      "epoch": 0.24320652173913043,
      "grad_norm": 3.9501259326934814,
      "learning_rate": 1.9677426359509653e-05,
      "loss": 0.0391,
      "step": 358
    },
    {
      "epoch": 0.24388586956521738,
      "grad_norm": 5.240283966064453,
      "learning_rate": 1.967563157489981e-05,
      "loss": 0.1752,
      "step": 359
    },
    {
      "epoch": 0.24456521739130435,
      "grad_norm": 0.02913174033164978,
      "learning_rate": 1.967383189339352e-05,
      "loss": 0.0004,
      "step": 360
    },
    {
      "epoch": 0.2452445652173913,
      "grad_norm": 2.0920796394348145,
      "learning_rate": 1.96720273159016e-05,
      "loss": 0.1118,
      "step": 361
    },
    {
      "epoch": 0.24592391304347827,
      "grad_norm": 0.04103199020028114,
      "learning_rate": 1.9670217843337366e-05,
      "loss": 0.0004,
      "step": 362
    },
    {
      "epoch": 0.24660326086956522,
      "grad_norm": 5.552677154541016,
      "learning_rate": 1.9668403476616604e-05,
      "loss": 0.2405,
      "step": 363
    },
    {
      "epoch": 0.24728260869565216,
      "grad_norm": 4.1470627784729,
      "learning_rate": 1.9666584216657572e-05,
      "loss": 0.1534,
      "step": 364
    },
    {
      "epoch": 0.24796195652173914,
      "grad_norm": 0.9116083383560181,
      "learning_rate": 1.9664760064381015e-05,
      "loss": 0.0248,
      "step": 365
    },
    {
      "epoch": 0.24864130434782608,
      "grad_norm": 0.02342625893652439,
      "learning_rate": 1.9662931020710138e-05,
      "loss": 0.0003,
      "step": 366
    },
    {
      "epoch": 0.24932065217391305,
      "grad_norm": 2.0240421295166016,
      "learning_rate": 1.9661097086570642e-05,
      "loss": 0.048,
      "step": 367
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.04146191105246544,
      "learning_rate": 1.9659258262890683e-05,
      "loss": 0.0005,
      "step": 368
    },
    {
      "epoch": 0.250679347826087,
      "grad_norm": 0.4701245427131653,
      "learning_rate": 1.9657414550600907e-05,
      "loss": 0.0038,
      "step": 369
    },
    {
      "epoch": 0.2513586956521739,
      "grad_norm": 3.455327272415161,
      "learning_rate": 1.9655565950634428e-05,
      "loss": 0.1905,
      "step": 370
    },
    {
      "epoch": 0.25203804347826086,
      "grad_norm": 3.237414836883545,
      "learning_rate": 1.965371246392683e-05,
      "loss": 0.1862,
      "step": 371
    },
    {
      "epoch": 0.25271739130434784,
      "grad_norm": 4.296609878540039,
      "learning_rate": 1.9651854091416175e-05,
      "loss": 0.1887,
      "step": 372
    },
    {
      "epoch": 0.25339673913043476,
      "grad_norm": 6.347016334533691,
      "learning_rate": 1.9649990834042998e-05,
      "loss": 0.2548,
      "step": 373
    },
    {
      "epoch": 0.25407608695652173,
      "grad_norm": 3.592940330505371,
      "learning_rate": 1.9648122692750307e-05,
      "loss": 0.2063,
      "step": 374
    },
    {
      "epoch": 0.2547554347826087,
      "grad_norm": 2.8463127613067627,
      "learning_rate": 1.9646249668483575e-05,
      "loss": 0.1536,
      "step": 375
    },
    {
      "epoch": 0.2554347826086957,
      "grad_norm": 1.6314687728881836,
      "learning_rate": 1.964437176219075e-05,
      "loss": 0.0834,
      "step": 376
    },
    {
      "epoch": 0.2561141304347826,
      "grad_norm": 0.11099740117788315,
      "learning_rate": 1.964248897482226e-05,
      "loss": 0.0011,
      "step": 377
    },
    {
      "epoch": 0.25679347826086957,
      "grad_norm": 5.201112270355225,
      "learning_rate": 1.964060130733099e-05,
      "loss": 0.183,
      "step": 378
    },
    {
      "epoch": 0.25747282608695654,
      "grad_norm": 0.3568248152732849,
      "learning_rate": 1.96387087606723e-05,
      "loss": 0.0037,
      "step": 379
    },
    {
      "epoch": 0.25815217391304346,
      "grad_norm": 0.13894926011562347,
      "learning_rate": 1.963681133580402e-05,
      "loss": 0.0014,
      "step": 380
    },
    {
      "epoch": 0.25883152173913043,
      "grad_norm": 3.5567033290863037,
      "learning_rate": 1.963490903368645e-05,
      "loss": 0.1392,
      "step": 381
    },
    {
      "epoch": 0.2595108695652174,
      "grad_norm": 1.4919124841690063,
      "learning_rate": 1.9633001855282353e-05,
      "loss": 0.0516,
      "step": 382
    },
    {
      "epoch": 0.2601902173913043,
      "grad_norm": 0.02308373898267746,
      "learning_rate": 1.9631089801556967e-05,
      "loss": 0.0006,
      "step": 383
    },
    {
      "epoch": 0.2608695652173913,
      "grad_norm": 2.0518054962158203,
      "learning_rate": 1.9629172873477995e-05,
      "loss": 0.1277,
      "step": 384
    },
    {
      "epoch": 0.26154891304347827,
      "grad_norm": 3.1787118911743164,
      "learning_rate": 1.9627251072015602e-05,
      "loss": 0.2247,
      "step": 385
    },
    {
      "epoch": 0.26222826086956524,
      "grad_norm": 0.6460824608802795,
      "learning_rate": 1.9625324398142425e-05,
      "loss": 0.0065,
      "step": 386
    },
    {
      "epoch": 0.26290760869565216,
      "grad_norm": 10.887002944946289,
      "learning_rate": 1.962339285283357e-05,
      "loss": 0.3253,
      "step": 387
    },
    {
      "epoch": 0.26358695652173914,
      "grad_norm": 4.511264324188232,
      "learning_rate": 1.9621456437066593e-05,
      "loss": 0.042,
      "step": 388
    },
    {
      "epoch": 0.2642663043478261,
      "grad_norm": 4.21681022644043,
      "learning_rate": 1.9619515151821537e-05,
      "loss": 0.0793,
      "step": 389
    },
    {
      "epoch": 0.264945652173913,
      "grad_norm": 5.064891338348389,
      "learning_rate": 1.9617568998080893e-05,
      "loss": 0.2971,
      "step": 390
    },
    {
      "epoch": 0.265625,
      "grad_norm": 2.678626537322998,
      "learning_rate": 1.9615617976829622e-05,
      "loss": 0.1179,
      "step": 391
    },
    {
      "epoch": 0.266304347826087,
      "grad_norm": 8.970144271850586,
      "learning_rate": 1.9613662089055148e-05,
      "loss": 0.8728,
      "step": 392
    },
    {
      "epoch": 0.2669836956521739,
      "grad_norm": 0.6007668375968933,
      "learning_rate": 1.961170133574736e-05,
      "loss": 0.0056,
      "step": 393
    },
    {
      "epoch": 0.26766304347826086,
      "grad_norm": 2.8855605125427246,
      "learning_rate": 1.9609735717898602e-05,
      "loss": 0.1875,
      "step": 394
    },
    {
      "epoch": 0.26834239130434784,
      "grad_norm": 1.644380807876587,
      "learning_rate": 1.9607765236503694e-05,
      "loss": 0.0753,
      "step": 395
    },
    {
      "epoch": 0.26902173913043476,
      "grad_norm": 0.024916142225265503,
      "learning_rate": 1.9605789892559902e-05,
      "loss": 0.0002,
      "step": 396
    },
    {
      "epoch": 0.26970108695652173,
      "grad_norm": 0.1881779134273529,
      "learning_rate": 1.9603809687066958e-05,
      "loss": 0.0021,
      "step": 397
    },
    {
      "epoch": 0.2703804347826087,
      "grad_norm": 9.66759967803955,
      "learning_rate": 1.960182462102706e-05,
      "loss": 0.5894,
      "step": 398
    },
    {
      "epoch": 0.2710597826086957,
      "grad_norm": 0.261897474527359,
      "learning_rate": 1.9599834695444863e-05,
      "loss": 0.0027,
      "step": 399
    },
    {
      "epoch": 0.2717391304347826,
      "grad_norm": 8.5338773727417,
      "learning_rate": 1.9597839911327475e-05,
      "loss": 0.2833,
      "step": 400
    },
    {
      "epoch": 0.27241847826086957,
      "grad_norm": 3.925375461578369,
      "learning_rate": 1.9595840269684478e-05,
      "loss": 0.1002,
      "step": 401
    },
    {
      "epoch": 0.27309782608695654,
      "grad_norm": 0.011926950886845589,
      "learning_rate": 1.9593835771527893e-05,
      "loss": 0.0002,
      "step": 402
    },
    {
      "epoch": 0.27377717391304346,
      "grad_norm": 0.015748996287584305,
      "learning_rate": 1.9591826417872214e-05,
      "loss": 0.0003,
      "step": 403
    },
    {
      "epoch": 0.27445652173913043,
      "grad_norm": 0.05312046781182289,
      "learning_rate": 1.9589812209734383e-05,
      "loss": 0.0006,
      "step": 404
    },
    {
      "epoch": 0.2751358695652174,
      "grad_norm": 0.34294745326042175,
      "learning_rate": 1.958779314813381e-05,
      "loss": 0.0028,
      "step": 405
    },
    {
      "epoch": 0.2758152173913043,
      "grad_norm": 2.588204860687256,
      "learning_rate": 1.9585769234092354e-05,
      "loss": 0.1499,
      "step": 406
    },
    {
      "epoch": 0.2764945652173913,
      "grad_norm": 5.444492816925049,
      "learning_rate": 1.958374046863432e-05,
      "loss": 0.0297,
      "step": 407
    },
    {
      "epoch": 0.27717391304347827,
      "grad_norm": 2.729625701904297,
      "learning_rate": 1.9581706852786492e-05,
      "loss": 0.1511,
      "step": 408
    },
    {
      "epoch": 0.27785326086956524,
      "grad_norm": 2.3557605743408203,
      "learning_rate": 1.9579668387578083e-05,
      "loss": 0.0193,
      "step": 409
    },
    {
      "epoch": 0.27853260869565216,
      "grad_norm": 6.19365119934082,
      "learning_rate": 1.9577625074040782e-05,
      "loss": 0.1726,
      "step": 410
    },
    {
      "epoch": 0.27921195652173914,
      "grad_norm": 0.02089623548090458,
      "learning_rate": 1.9575576913208718e-05,
      "loss": 0.0004,
      "step": 411
    },
    {
      "epoch": 0.2798913043478261,
      "grad_norm": 3.3172531127929688,
      "learning_rate": 1.957352390611848e-05,
      "loss": 0.1999,
      "step": 412
    },
    {
      "epoch": 0.280570652173913,
      "grad_norm": 0.028638605028390884,
      "learning_rate": 1.9571466053809107e-05,
      "loss": 0.0004,
      "step": 413
    },
    {
      "epoch": 0.28125,
      "grad_norm": 3.1541264057159424,
      "learning_rate": 1.956940335732209e-05,
      "loss": 0.0779,
      "step": 414
    },
    {
      "epoch": 0.281929347826087,
      "grad_norm": 0.011861797422170639,
      "learning_rate": 1.9567335817701373e-05,
      "loss": 0.0002,
      "step": 415
    },
    {
      "epoch": 0.2826086956521739,
      "grad_norm": 3.0805256366729736,
      "learning_rate": 1.956526343599335e-05,
      "loss": 0.1032,
      "step": 416
    },
    {
      "epoch": 0.28328804347826086,
      "grad_norm": 5.338487148284912,
      "learning_rate": 1.9563186213246864e-05,
      "loss": 0.1556,
      "step": 417
    },
    {
      "epoch": 0.28396739130434784,
      "grad_norm": 3.1930551528930664,
      "learning_rate": 1.9561104150513214e-05,
      "loss": 0.1437,
      "step": 418
    },
    {
      "epoch": 0.28464673913043476,
      "grad_norm": 4.607407569885254,
      "learning_rate": 1.955901724884614e-05,
      "loss": 0.1981,
      "step": 419
    },
    {
      "epoch": 0.28532608695652173,
      "grad_norm": 7.058594226837158,
      "learning_rate": 1.9556925509301844e-05,
      "loss": 0.1466,
      "step": 420
    },
    {
      "epoch": 0.2860054347826087,
      "grad_norm": 0.028429972007870674,
      "learning_rate": 1.9554828932938962e-05,
      "loss": 0.0006,
      "step": 421
    },
    {
      "epoch": 0.2866847826086957,
      "grad_norm": 1.893748164176941,
      "learning_rate": 1.955272752081858e-05,
      "loss": 0.1582,
      "step": 422
    },
    {
      "epoch": 0.2873641304347826,
      "grad_norm": 5.560004711151123,
      "learning_rate": 1.9550621274004248e-05,
      "loss": 0.1892,
      "step": 423
    },
    {
      "epoch": 0.28804347826086957,
      "grad_norm": 2.0423808097839355,
      "learning_rate": 1.9548510193561938e-05,
      "loss": 0.0181,
      "step": 424
    },
    {
      "epoch": 0.28872282608695654,
      "grad_norm": 0.564856231212616,
      "learning_rate": 1.9546394280560087e-05,
      "loss": 0.009,
      "step": 425
    },
    {
      "epoch": 0.28940217391304346,
      "grad_norm": 3.752626419067383,
      "learning_rate": 1.9544273536069573e-05,
      "loss": 0.1981,
      "step": 426
    },
    {
      "epoch": 0.29008152173913043,
      "grad_norm": 0.7997865676879883,
      "learning_rate": 1.9542147961163707e-05,
      "loss": 0.0079,
      "step": 427
    },
    {
      "epoch": 0.2907608695652174,
      "grad_norm": 0.08967340737581253,
      "learning_rate": 1.954001755691827e-05,
      "loss": 0.0009,
      "step": 428
    },
    {
      "epoch": 0.2914402173913043,
      "grad_norm": 3.3214566707611084,
      "learning_rate": 1.953788232441147e-05,
      "loss": 0.1467,
      "step": 429
    },
    {
      "epoch": 0.2921195652173913,
      "grad_norm": 2.1167831420898438,
      "learning_rate": 1.953574226472395e-05,
      "loss": 0.1308,
      "step": 430
    },
    {
      "epoch": 0.29279891304347827,
      "grad_norm": 4.147287845611572,
      "learning_rate": 1.9533597378938818e-05,
      "loss": 0.1157,
      "step": 431
    },
    {
      "epoch": 0.29347826086956524,
      "grad_norm": 2.733354330062866,
      "learning_rate": 1.953144766814161e-05,
      "loss": 0.0965,
      "step": 432
    },
    {
      "epoch": 0.29415760869565216,
      "grad_norm": 0.3989437520503998,
      "learning_rate": 1.9529293133420307e-05,
      "loss": 0.0036,
      "step": 433
    },
    {
      "epoch": 0.29483695652173914,
      "grad_norm": 3.042905330657959,
      "learning_rate": 1.952713377586534e-05,
      "loss": 0.166,
      "step": 434
    },
    {
      "epoch": 0.2955163043478261,
      "grad_norm": 2.30060076713562,
      "learning_rate": 1.952496959656956e-05,
      "loss": 0.143,
      "step": 435
    },
    {
      "epoch": 0.296195652173913,
      "grad_norm": 1.9009824991226196,
      "learning_rate": 1.9522800596628282e-05,
      "loss": 0.0884,
      "step": 436
    },
    {
      "epoch": 0.296875,
      "grad_norm": 2.6605942249298096,
      "learning_rate": 1.9520626777139243e-05,
      "loss": 0.1189,
      "step": 437
    },
    {
      "epoch": 0.297554347826087,
      "grad_norm": 12.156656265258789,
      "learning_rate": 1.9518448139202632e-05,
      "loss": 0.1189,
      "step": 438
    },
    {
      "epoch": 0.2982336956521739,
      "grad_norm": 3.8257133960723877,
      "learning_rate": 1.9516264683921073e-05,
      "loss": 0.2492,
      "step": 439
    },
    {
      "epoch": 0.29891304347826086,
      "grad_norm": 1.8096792697906494,
      "learning_rate": 1.9514076412399615e-05,
      "loss": 0.0141,
      "step": 440
    },
    {
      "epoch": 0.29959239130434784,
      "grad_norm": 0.05176172032952309,
      "learning_rate": 1.9511883325745767e-05,
      "loss": 0.0007,
      "step": 441
    },
    {
      "epoch": 0.30027173913043476,
      "grad_norm": 0.5093918442726135,
      "learning_rate": 1.9509685425069457e-05,
      "loss": 0.0052,
      "step": 442
    },
    {
      "epoch": 0.30095108695652173,
      "grad_norm": 2.601433515548706,
      "learning_rate": 1.9507482711483057e-05,
      "loss": 0.2029,
      "step": 443
    },
    {
      "epoch": 0.3016304347826087,
      "grad_norm": 2.0718259811401367,
      "learning_rate": 1.9505275186101378e-05,
      "loss": 0.138,
      "step": 444
    },
    {
      "epoch": 0.3023097826086957,
      "grad_norm": 4.491552829742432,
      "learning_rate": 1.9503062850041655e-05,
      "loss": 0.2974,
      "step": 445
    },
    {
      "epoch": 0.3029891304347826,
      "grad_norm": 0.10958550870418549,
      "learning_rate": 1.9500845704423574e-05,
      "loss": 0.0012,
      "step": 446
    },
    {
      "epoch": 0.30366847826086957,
      "grad_norm": 2.3330984115600586,
      "learning_rate": 1.949862375036924e-05,
      "loss": 0.124,
      "step": 447
    },
    {
      "epoch": 0.30434782608695654,
      "grad_norm": 7.352832794189453,
      "learning_rate": 1.9496396989003195e-05,
      "loss": 0.1889,
      "step": 448
    },
    {
      "epoch": 0.30502717391304346,
      "grad_norm": 0.3318358063697815,
      "learning_rate": 1.9494165421452422e-05,
      "loss": 0.0034,
      "step": 449
    },
    {
      "epoch": 0.30570652173913043,
      "grad_norm": 0.026912737637758255,
      "learning_rate": 1.9491929048846328e-05,
      "loss": 0.0004,
      "step": 450
    },
    {
      "epoch": 0.3063858695652174,
      "grad_norm": 4.2930145263671875,
      "learning_rate": 1.9489687872316757e-05,
      "loss": 0.0721,
      "step": 451
    },
    {
      "epoch": 0.3070652173913043,
      "grad_norm": 2.883751153945923,
      "learning_rate": 1.948744189299798e-05,
      "loss": 0.1191,
      "step": 452
    },
    {
      "epoch": 0.3077445652173913,
      "grad_norm": 1.8131097555160522,
      "learning_rate": 1.9485191112026707e-05,
      "loss": 0.1186,
      "step": 453
    },
    {
      "epoch": 0.30842391304347827,
      "grad_norm": 0.1512511968612671,
      "learning_rate": 1.9482935530542063e-05,
      "loss": 0.0015,
      "step": 454
    },
    {
      "epoch": 0.30910326086956524,
      "grad_norm": 0.06888718158006668,
      "learning_rate": 1.9480675149685616e-05,
      "loss": 0.0012,
      "step": 455
    },
    {
      "epoch": 0.30978260869565216,
      "grad_norm": 1.348776936531067,
      "learning_rate": 1.947840997060136e-05,
      "loss": 0.021,
      "step": 456
    },
    {
      "epoch": 0.31046195652173914,
      "grad_norm": 3.115615129470825,
      "learning_rate": 1.9476139994435713e-05,
      "loss": 0.1635,
      "step": 457
    },
    {
      "epoch": 0.3111413043478261,
      "grad_norm": 2.829045534133911,
      "learning_rate": 1.9473865222337523e-05,
      "loss": 0.1526,
      "step": 458
    },
    {
      "epoch": 0.311820652173913,
      "grad_norm": 2.436734676361084,
      "learning_rate": 1.9471585655458073e-05,
      "loss": 0.0409,
      "step": 459
    },
    {
      "epoch": 0.3125,
      "grad_norm": 2.3763837814331055,
      "learning_rate": 1.946930129495106e-05,
      "loss": 0.1513,
      "step": 460
    },
    {
      "epoch": 0.313179347826087,
      "grad_norm": 2.4386301040649414,
      "learning_rate": 1.946701214197261e-05,
      "loss": 0.0701,
      "step": 461
    },
    {
      "epoch": 0.3138586956521739,
      "grad_norm": 5.25871467590332,
      "learning_rate": 1.9464718197681284e-05,
      "loss": 0.1775,
      "step": 462
    },
    {
      "epoch": 0.31453804347826086,
      "grad_norm": 2.208885908126831,
      "learning_rate": 1.9462419463238057e-05,
      "loss": 0.1594,
      "step": 463
    },
    {
      "epoch": 0.31521739130434784,
      "grad_norm": 4.689267635345459,
      "learning_rate": 1.946011593980634e-05,
      "loss": 0.2347,
      "step": 464
    },
    {
      "epoch": 0.31589673913043476,
      "grad_norm": 7.973460674285889,
      "learning_rate": 1.9457807628551947e-05,
      "loss": 0.2621,
      "step": 465
    },
    {
      "epoch": 0.31657608695652173,
      "grad_norm": 7.8710618019104,
      "learning_rate": 1.945549453064314e-05,
      "loss": 0.2177,
      "step": 466
    },
    {
      "epoch": 0.3172554347826087,
      "grad_norm": 1.3663513660430908,
      "learning_rate": 1.945317664725059e-05,
      "loss": 0.0127,
      "step": 467
    },
    {
      "epoch": 0.3179347826086957,
      "grad_norm": 5.08943510055542,
      "learning_rate": 1.9450853979547384e-05,
      "loss": 0.1425,
      "step": 468
    },
    {
      "epoch": 0.3186141304347826,
      "grad_norm": 3.298375368118286,
      "learning_rate": 1.944852652870905e-05,
      "loss": 0.1369,
      "step": 469
    },
    {
      "epoch": 0.31929347826086957,
      "grad_norm": 0.091883085668087,
      "learning_rate": 1.9446194295913515e-05,
      "loss": 0.0012,
      "step": 470
    },
    {
      "epoch": 0.31997282608695654,
      "grad_norm": 2.8227694034576416,
      "learning_rate": 1.9443857282341144e-05,
      "loss": 0.1986,
      "step": 471
    },
    {
      "epoch": 0.32065217391304346,
      "grad_norm": 3.8523664474487305,
      "learning_rate": 1.9441515489174708e-05,
      "loss": 0.0882,
      "step": 472
    },
    {
      "epoch": 0.32133152173913043,
      "grad_norm": 8.231279373168945,
      "learning_rate": 1.943916891759941e-05,
      "loss": 0.2563,
      "step": 473
    },
    {
      "epoch": 0.3220108695652174,
      "grad_norm": 0.1189606711268425,
      "learning_rate": 1.9436817568802854e-05,
      "loss": 0.001,
      "step": 474
    },
    {
      "epoch": 0.3226902173913043,
      "grad_norm": 10.127432823181152,
      "learning_rate": 1.9434461443975082e-05,
      "loss": 0.4176,
      "step": 475
    },
    {
      "epoch": 0.3233695652173913,
      "grad_norm": 1.703434705734253,
      "learning_rate": 1.943210054430854e-05,
      "loss": 0.1225,
      "step": 476
    },
    {
      "epoch": 0.32404891304347827,
      "grad_norm": 1.5421911478042603,
      "learning_rate": 1.942973487099809e-05,
      "loss": 0.0625,
      "step": 477
    },
    {
      "epoch": 0.32472826086956524,
      "grad_norm": 1.7932977676391602,
      "learning_rate": 1.9427364425241017e-05,
      "loss": 0.0637,
      "step": 478
    },
    {
      "epoch": 0.32540760869565216,
      "grad_norm": 0.13644267618656158,
      "learning_rate": 1.942498920823702e-05,
      "loss": 0.0011,
      "step": 479
    },
    {
      "epoch": 0.32608695652173914,
      "grad_norm": 6.250022888183594,
      "learning_rate": 1.9422609221188208e-05,
      "loss": 0.1878,
      "step": 480
    },
    {
      "epoch": 0.3267663043478261,
      "grad_norm": 0.029528910294175148,
      "learning_rate": 1.9420224465299108e-05,
      "loss": 0.0004,
      "step": 481
    },
    {
      "epoch": 0.327445652173913,
      "grad_norm": 1.3936234712600708,
      "learning_rate": 1.9417834941776657e-05,
      "loss": 0.0095,
      "step": 482
    },
    {
      "epoch": 0.328125,
      "grad_norm": 0.04056531935930252,
      "learning_rate": 1.941544065183021e-05,
      "loss": 0.0005,
      "step": 483
    },
    {
      "epoch": 0.328804347826087,
      "grad_norm": 3.670982837677002,
      "learning_rate": 1.941304159667153e-05,
      "loss": 0.1692,
      "step": 484
    },
    {
      "epoch": 0.3294836956521739,
      "grad_norm": 0.2805989980697632,
      "learning_rate": 1.94106377775148e-05,
      "loss": 0.002,
      "step": 485
    },
    {
      "epoch": 0.33016304347826086,
      "grad_norm": 4.737954139709473,
      "learning_rate": 1.94082291955766e-05,
      "loss": 0.1478,
      "step": 486
    },
    {
      "epoch": 0.33084239130434784,
      "grad_norm": 2.7655725479125977,
      "learning_rate": 1.940581585207593e-05,
      "loss": 0.1286,
      "step": 487
    },
    {
      "epoch": 0.33152173913043476,
      "grad_norm": 2.1185224056243896,
      "learning_rate": 1.94033977482342e-05,
      "loss": 0.1299,
      "step": 488
    },
    {
      "epoch": 0.33220108695652173,
      "grad_norm": 3.163609743118286,
      "learning_rate": 1.9400974885275226e-05,
      "loss": 0.1157,
      "step": 489
    },
    {
      "epoch": 0.3328804347826087,
      "grad_norm": 3.4851973056793213,
      "learning_rate": 1.9398547264425237e-05,
      "loss": 0.0461,
      "step": 490
    },
    {
      "epoch": 0.3335597826086957,
      "grad_norm": 0.10651756078004837,
      "learning_rate": 1.9396114886912858e-05,
      "loss": 0.002,
      "step": 491
    },
    {
      "epoch": 0.3342391304347826,
      "grad_norm": 0.005728670861572027,
      "learning_rate": 1.9393677753969137e-05,
      "loss": 0.0001,
      "step": 492
    },
    {
      "epoch": 0.33491847826086957,
      "grad_norm": 0.7928670048713684,
      "learning_rate": 1.9391235866827522e-05,
      "loss": 0.0163,
      "step": 493
    },
    {
      "epoch": 0.33559782608695654,
      "grad_norm": 3.23921537399292,
      "learning_rate": 1.9388789226723865e-05,
      "loss": 0.1575,
      "step": 494
    },
    {
      "epoch": 0.33627717391304346,
      "grad_norm": 2.387016773223877,
      "learning_rate": 1.9386337834896428e-05,
      "loss": 0.0769,
      "step": 495
    },
    {
      "epoch": 0.33695652173913043,
      "grad_norm": 2.7905001640319824,
      "learning_rate": 1.938388169258587e-05,
      "loss": 0.1486,
      "step": 496
    },
    {
      "epoch": 0.3376358695652174,
      "grad_norm": 2.5522868633270264,
      "learning_rate": 1.9381420801035265e-05,
      "loss": 0.0317,
      "step": 497
    },
    {
      "epoch": 0.3383152173913043,
      "grad_norm": 2.2118916511535645,
      "learning_rate": 1.9378955161490086e-05,
      "loss": 0.1444,
      "step": 498
    },
    {
      "epoch": 0.3389945652173913,
      "grad_norm": 4.489401817321777,
      "learning_rate": 1.9376484775198203e-05,
      "loss": 0.1132,
      "step": 499
    },
    {
      "epoch": 0.33967391304347827,
      "grad_norm": 4.027195930480957,
      "learning_rate": 1.9374009643409895e-05,
      "loss": 0.0937,
      "step": 500
    },
    {
      "epoch": 0.34035326086956524,
      "grad_norm": 5.888962268829346,
      "learning_rate": 1.937152976737785e-05,
      "loss": 0.1667,
      "step": 501
    },
    {
      "epoch": 0.34103260869565216,
      "grad_norm": 1.2445439100265503,
      "learning_rate": 1.9369045148357136e-05,
      "loss": 0.0138,
      "step": 502
    },
    {
      "epoch": 0.34171195652173914,
      "grad_norm": 3.0166516304016113,
      "learning_rate": 1.936655578760524e-05,
      "loss": 0.0703,
      "step": 503
    },
    {
      "epoch": 0.3423913043478261,
      "grad_norm": 0.293849915266037,
      "learning_rate": 1.9364061686382042e-05,
      "loss": 0.0033,
      "step": 504
    },
    {
      "epoch": 0.343070652173913,
      "grad_norm": 0.012614238075911999,
      "learning_rate": 1.9361562845949823e-05,
      "loss": 0.0003,
      "step": 505
    },
    {
      "epoch": 0.34375,
      "grad_norm": 4.767040252685547,
      "learning_rate": 1.935905926757326e-05,
      "loss": 0.2934,
      "step": 506
    },
    {
      "epoch": 0.344429347826087,
      "grad_norm": 0.13712643086910248,
      "learning_rate": 1.935655095251943e-05,
      "loss": 0.0014,
      "step": 507
    },
    {
      "epoch": 0.3451086956521739,
      "grad_norm": 4.5441155433654785,
      "learning_rate": 1.9354037902057806e-05,
      "loss": 0.1476,
      "step": 508
    },
    {
      "epoch": 0.34578804347826086,
      "grad_norm": 2.877714157104492,
      "learning_rate": 1.9351520117460255e-05,
      "loss": 0.0694,
      "step": 509
    },
    {
      "epoch": 0.34646739130434784,
      "grad_norm": 13.092633247375488,
      "learning_rate": 1.9348997600001052e-05,
      "loss": 0.3764,
      "step": 510
    },
    {
      "epoch": 0.34714673913043476,
      "grad_norm": 3.7667195796966553,
      "learning_rate": 1.9346470350956853e-05,
      "loss": 0.0969,
      "step": 511
    },
    {
      "epoch": 0.34782608695652173,
      "grad_norm": 8.939111709594727,
      "learning_rate": 1.9343938371606714e-05,
      "loss": 0.2434,
      "step": 512
    },
    {
      "epoch": 0.3485054347826087,
      "grad_norm": 2.4354305267333984,
      "learning_rate": 1.9341401663232083e-05,
      "loss": 0.1512,
      "step": 513
    },
    {
      "epoch": 0.3491847826086957,
      "grad_norm": 0.03290529549121857,
      "learning_rate": 1.933886022711681e-05,
      "loss": 0.0004,
      "step": 514
    },
    {
      "epoch": 0.3498641304347826,
      "grad_norm": 3.4343767166137695,
      "learning_rate": 1.9336314064547127e-05,
      "loss": 0.1108,
      "step": 515
    },
    {
      "epoch": 0.35054347826086957,
      "grad_norm": 13.256150245666504,
      "learning_rate": 1.9333763176811663e-05,
      "loss": 0.153,
      "step": 516
    },
    {
      "epoch": 0.35122282608695654,
      "grad_norm": 0.1592787504196167,
      "learning_rate": 1.933120756520144e-05,
      "loss": 0.0014,
      "step": 517
    },
    {
      "epoch": 0.35190217391304346,
      "grad_norm": 0.27118879556655884,
      "learning_rate": 1.9328647231009868e-05,
      "loss": 0.0019,
      "step": 518
    },
    {
      "epoch": 0.35258152173913043,
      "grad_norm": 3.1335723400115967,
      "learning_rate": 1.9326082175532744e-05,
      "loss": 0.1383,
      "step": 519
    },
    {
      "epoch": 0.3532608695652174,
      "grad_norm": 2.2226831912994385,
      "learning_rate": 1.9323512400068262e-05,
      "loss": 0.0377,
      "step": 520
    },
    {
      "epoch": 0.3539402173913043,
      "grad_norm": 2.1885948181152344,
      "learning_rate": 1.9320937905917002e-05,
      "loss": 0.0285,
      "step": 521
    },
    {
      "epoch": 0.3546195652173913,
      "grad_norm": 1.5240068435668945,
      "learning_rate": 1.9318358694381926e-05,
      "loss": 0.1042,
      "step": 522
    },
    {
      "epoch": 0.35529891304347827,
      "grad_norm": 1.3482645750045776,
      "learning_rate": 1.9315774766768394e-05,
      "loss": 0.0758,
      "step": 523
    },
    {
      "epoch": 0.35597826086956524,
      "grad_norm": 10.508939743041992,
      "learning_rate": 1.9313186124384147e-05,
      "loss": 0.2674,
      "step": 524
    },
    {
      "epoch": 0.35665760869565216,
      "grad_norm": 0.03032786026597023,
      "learning_rate": 1.9310592768539315e-05,
      "loss": 0.0004,
      "step": 525
    },
    {
      "epoch": 0.35733695652173914,
      "grad_norm": 0.8201510310173035,
      "learning_rate": 1.93079947005464e-05,
      "loss": 0.0316,
      "step": 526
    },
    {
      "epoch": 0.3580163043478261,
      "grad_norm": 2.2366297245025635,
      "learning_rate": 1.9305391921720313e-05,
      "loss": 0.0974,
      "step": 527
    },
    {
      "epoch": 0.358695652173913,
      "grad_norm": 7.641753673553467,
      "learning_rate": 1.9302784433378333e-05,
      "loss": 0.155,
      "step": 528
    },
    {
      "epoch": 0.359375,
      "grad_norm": 3.0063366889953613,
      "learning_rate": 1.930017223684012e-05,
      "loss": 0.0241,
      "step": 529
    },
    {
      "epoch": 0.360054347826087,
      "grad_norm": 0.6973177194595337,
      "learning_rate": 1.9297555333427733e-05,
      "loss": 0.006,
      "step": 530
    },
    {
      "epoch": 0.3607336956521739,
      "grad_norm": 12.218143463134766,
      "learning_rate": 1.9294933724465593e-05,
      "loss": 0.267,
      "step": 531
    },
    {
      "epoch": 0.36141304347826086,
      "grad_norm": 0.006752142682671547,
      "learning_rate": 1.9292307411280514e-05,
      "loss": 0.0001,
      "step": 532
    },
    {
      "epoch": 0.36209239130434784,
      "grad_norm": 2.8318212032318115,
      "learning_rate": 1.9289676395201697e-05,
      "loss": 0.1919,
      "step": 533
    },
    {
      "epoch": 0.36277173913043476,
      "grad_norm": 2.1413745880126953,
      "learning_rate": 1.928704067756071e-05,
      "loss": 0.0997,
      "step": 534
    },
    {
      "epoch": 0.36345108695652173,
      "grad_norm": 0.014868141151964664,
      "learning_rate": 1.92844002596915e-05,
      "loss": 0.0002,
      "step": 535
    },
    {
      "epoch": 0.3641304347826087,
      "grad_norm": 0.019611986353993416,
      "learning_rate": 1.928175514293041e-05,
      "loss": 0.0003,
      "step": 536
    },
    {
      "epoch": 0.3648097826086957,
      "grad_norm": 2.738799810409546,
      "learning_rate": 1.927910532861614e-05,
      "loss": 0.1579,
      "step": 537
    },
    {
      "epoch": 0.3654891304347826,
      "grad_norm": 2.1770505905151367,
      "learning_rate": 1.927645081808978e-05,
      "loss": 0.0532,
      "step": 538
    },
    {
      "epoch": 0.36616847826086957,
      "grad_norm": 0.3590112626552582,
      "learning_rate": 1.9273791612694798e-05,
      "loss": 0.0032,
      "step": 539
    },
    {
      "epoch": 0.36684782608695654,
      "grad_norm": 9.532622337341309,
      "learning_rate": 1.9271127713777033e-05,
      "loss": 0.3202,
      "step": 540
    },
    {
      "epoch": 0.36752717391304346,
      "grad_norm": 12.371495246887207,
      "learning_rate": 1.92684591226847e-05,
      "loss": 0.7426,
      "step": 541
    },
    {
      "epoch": 0.36820652173913043,
      "grad_norm": 13.603428840637207,
      "learning_rate": 1.9265785840768387e-05,
      "loss": 0.5217,
      "step": 542
    },
    {
      "epoch": 0.3688858695652174,
      "grad_norm": 1.5311884880065918,
      "learning_rate": 1.926310786938106e-05,
      "loss": 0.0476,
      "step": 543
    },
    {
      "epoch": 0.3695652173913043,
      "grad_norm": 1.9939548969268799,
      "learning_rate": 1.9260425209878052e-05,
      "loss": 0.0233,
      "step": 544
    },
    {
      "epoch": 0.3702445652173913,
      "grad_norm": 0.005910896696150303,
      "learning_rate": 1.925773786361708e-05,
      "loss": 0.0001,
      "step": 545
    },
    {
      "epoch": 0.37092391304347827,
      "grad_norm": 3.7563610076904297,
      "learning_rate": 1.925504583195823e-05,
      "loss": 0.0439,
      "step": 546
    },
    {
      "epoch": 0.37160326086956524,
      "grad_norm": 0.0192668829113245,
      "learning_rate": 1.9252349116263945e-05,
      "loss": 0.0003,
      "step": 547
    },
    {
      "epoch": 0.37228260869565216,
      "grad_norm": 15.071317672729492,
      "learning_rate": 1.924964771789906e-05,
      "loss": 0.2628,
      "step": 548
    },
    {
      "epoch": 0.37296195652173914,
      "grad_norm": 5.116539478302002,
      "learning_rate": 1.924694163823076e-05,
      "loss": 0.155,
      "step": 549
    },
    {
      "epoch": 0.3736413043478261,
      "grad_norm": 4.505560874938965,
      "learning_rate": 1.924423087862861e-05,
      "loss": 0.2356,
      "step": 550
    },
    {
      "epoch": 0.374320652173913,
      "grad_norm": 0.1229107528924942,
      "learning_rate": 1.924151544046455e-05,
      "loss": 0.001,
      "step": 551
    },
    {
      "epoch": 0.375,
      "grad_norm": 10.540914535522461,
      "learning_rate": 1.9238795325112867e-05,
      "loss": 0.1589,
      "step": 552
    },
    {
      "epoch": 0.375679347826087,
      "grad_norm": 5.478411674499512,
      "learning_rate": 1.9236070533950242e-05,
      "loss": 0.2079,
      "step": 553
    },
    {
      "epoch": 0.3763586956521739,
      "grad_norm": 7.301924705505371,
      "learning_rate": 1.92333410683557e-05,
      "loss": 0.294,
      "step": 554
    },
    {
      "epoch": 0.37703804347826086,
      "grad_norm": 1.3952761888504028,
      "learning_rate": 1.923060692971064e-05,
      "loss": 0.0183,
      "step": 555
    },
    {
      "epoch": 0.37771739130434784,
      "grad_norm": 3.7399399280548096,
      "learning_rate": 1.922786811939883e-05,
      "loss": 0.1804,
      "step": 556
    },
    {
      "epoch": 0.37839673913043476,
      "grad_norm": 3.9522697925567627,
      "learning_rate": 1.9225124638806396e-05,
      "loss": 0.1949,
      "step": 557
    },
    {
      "epoch": 0.37907608695652173,
      "grad_norm": 0.20496343076229095,
      "learning_rate": 1.922237648932183e-05,
      "loss": 0.0019,
      "step": 558
    },
    {
      "epoch": 0.3797554347826087,
      "grad_norm": 4.050694942474365,
      "learning_rate": 1.9219623672335994e-05,
      "loss": 0.2314,
      "step": 559
    },
    {
      "epoch": 0.3804347826086957,
      "grad_norm": 0.005373193882405758,
      "learning_rate": 1.9216866189242095e-05,
      "loss": 0.0001,
      "step": 560
    },
    {
      "epoch": 0.3811141304347826,
      "grad_norm": 0.009728371165692806,
      "learning_rate": 1.921410404143572e-05,
      "loss": 0.0002,
      "step": 561
    },
    {
      "epoch": 0.38179347826086957,
      "grad_norm": 0.7233765721321106,
      "learning_rate": 1.921133723031481e-05,
      "loss": 0.0191,
      "step": 562
    },
    {
      "epoch": 0.38247282608695654,
      "grad_norm": 2.4326281547546387,
      "learning_rate": 1.9208565757279654e-05,
      "loss": 0.0853,
      "step": 563
    },
    {
      "epoch": 0.38315217391304346,
      "grad_norm": 6.777514457702637,
      "learning_rate": 1.9205789623732923e-05,
      "loss": 0.146,
      "step": 564
    },
    {
      "epoch": 0.38383152173913043,
      "grad_norm": 0.15012004971504211,
      "learning_rate": 1.920300883107963e-05,
      "loss": 0.0014,
      "step": 565
    },
    {
      "epoch": 0.3845108695652174,
      "grad_norm": 0.01648319698870182,
      "learning_rate": 1.9200223380727153e-05,
      "loss": 0.0002,
      "step": 566
    },
    {
      "epoch": 0.3851902173913043,
      "grad_norm": 3.951822519302368,
      "learning_rate": 1.9197433274085225e-05,
      "loss": 0.2539,
      "step": 567
    },
    {
      "epoch": 0.3858695652173913,
      "grad_norm": 0.0072119953110814095,
      "learning_rate": 1.9194638512565937e-05,
      "loss": 0.0002,
      "step": 568
    },
    {
      "epoch": 0.38654891304347827,
      "grad_norm": 3.1996991634368896,
      "learning_rate": 1.919183909758373e-05,
      "loss": 0.1929,
      "step": 569
    },
    {
      "epoch": 0.38722826086956524,
      "grad_norm": 0.3685474097728729,
      "learning_rate": 1.918903503055541e-05,
      "loss": 0.0051,
      "step": 570
    },
    {
      "epoch": 0.38790760869565216,
      "grad_norm": 0.03960692510008812,
      "learning_rate": 1.9186226312900134e-05,
      "loss": 0.0004,
      "step": 571
    },
    {
      "epoch": 0.38858695652173914,
      "grad_norm": 1.9201271533966064,
      "learning_rate": 1.918341294603941e-05,
      "loss": 0.0477,
      "step": 572
    },
    {
      "epoch": 0.3892663043478261,
      "grad_norm": 6.9986748695373535,
      "learning_rate": 1.9180594931397094e-05,
      "loss": 0.2144,
      "step": 573
    },
    {
      "epoch": 0.389945652173913,
      "grad_norm": 4.642021656036377,
      "learning_rate": 1.917777227039941e-05,
      "loss": 0.2401,
      "step": 574
    },
    {
      "epoch": 0.390625,
      "grad_norm": 2.1662986278533936,
      "learning_rate": 1.9174944964474914e-05,
      "loss": 0.0949,
      "step": 575
    },
    {
      "epoch": 0.391304347826087,
      "grad_norm": 4.718809604644775,
      "learning_rate": 1.917211301505453e-05,
      "loss": 0.2189,
      "step": 576
    },
    {
      "epoch": 0.3919836956521739,
      "grad_norm": 9.87214469909668,
      "learning_rate": 1.9169276423571525e-05,
      "loss": 0.2549,
      "step": 577
    },
    {
      "epoch": 0.39266304347826086,
      "grad_norm": 5.762049674987793,
      "learning_rate": 1.9166435191461514e-05,
      "loss": 0.1566,
      "step": 578
    },
    {
      "epoch": 0.39334239130434784,
      "grad_norm": 4.525755405426025,
      "learning_rate": 1.916358932016246e-05,
      "loss": 0.184,
      "step": 579
    },
    {
      "epoch": 0.39402173913043476,
      "grad_norm": 11.067924499511719,
      "learning_rate": 1.916073881111468e-05,
      "loss": 0.4028,
      "step": 580
    },
    {
      "epoch": 0.39470108695652173,
      "grad_norm": 1.5843853950500488,
      "learning_rate": 1.9157883665760827e-05,
      "loss": 0.0927,
      "step": 581
    },
    {
      "epoch": 0.3953804347826087,
      "grad_norm": 1.9618481397628784,
      "learning_rate": 1.9155023885545914e-05,
      "loss": 0.0871,
      "step": 582
    },
    {
      "epoch": 0.3960597826086957,
      "grad_norm": 0.43344900012016296,
      "learning_rate": 1.9152159471917292e-05,
      "loss": 0.0058,
      "step": 583
    },
    {
      "epoch": 0.3967391304347826,
      "grad_norm": 0.08059785515069962,
      "learning_rate": 1.9149290426324658e-05,
      "loss": 0.0009,
      "step": 584
    },
    {
      "epoch": 0.39741847826086957,
      "grad_norm": 0.045321494340896606,
      "learning_rate": 1.914641675022005e-05,
      "loss": 0.0004,
      "step": 585
    },
    {
      "epoch": 0.39809782608695654,
      "grad_norm": 0.012453150935471058,
      "learning_rate": 1.914353844505786e-05,
      "loss": 0.0002,
      "step": 586
    },
    {
      "epoch": 0.39877717391304346,
      "grad_norm": 0.6565359234809875,
      "learning_rate": 1.914065551229481e-05,
      "loss": 0.007,
      "step": 587
    },
    {
      "epoch": 0.39945652173913043,
      "grad_norm": 12.433162689208984,
      "learning_rate": 1.913776795338998e-05,
      "loss": 0.2747,
      "step": 588
    },
    {
      "epoch": 0.4001358695652174,
      "grad_norm": 0.01239782851189375,
      "learning_rate": 1.9134875769804763e-05,
      "loss": 0.0002,
      "step": 589
    },
    {
      "epoch": 0.4008152173913043,
      "grad_norm": 10.074464797973633,
      "learning_rate": 1.9131978963002927e-05,
      "loss": 0.2944,
      "step": 590
    },
    {
      "epoch": 0.4014945652173913,
      "grad_norm": 1.478949785232544,
      "learning_rate": 1.9129077534450556e-05,
      "loss": 0.0627,
      "step": 591
    },
    {
      "epoch": 0.40217391304347827,
      "grad_norm": 2.0132246017456055,
      "learning_rate": 1.912617148561608e-05,
      "loss": 0.0173,
      "step": 592
    },
    {
      "epoch": 0.40285326086956524,
      "grad_norm": 2.1433651447296143,
      "learning_rate": 1.912326081797028e-05,
      "loss": 0.1051,
      "step": 593
    },
    {
      "epoch": 0.40353260869565216,
      "grad_norm": 6.283173561096191,
      "learning_rate": 1.9120345532986243e-05,
      "loss": 0.2648,
      "step": 594
    },
    {
      "epoch": 0.40421195652173914,
      "grad_norm": 1.8142045736312866,
      "learning_rate": 1.911742563213943e-05,
      "loss": 0.0145,
      "step": 595
    },
    {
      "epoch": 0.4048913043478261,
      "grad_norm": 0.8845374584197998,
      "learning_rate": 1.911450111690761e-05,
      "loss": 0.0058,
      "step": 596
    },
    {
      "epoch": 0.405570652173913,
      "grad_norm": 3.0335793495178223,
      "learning_rate": 1.9111571988770903e-05,
      "loss": 0.0234,
      "step": 597
    },
    {
      "epoch": 0.40625,
      "grad_norm": 3.9375061988830566,
      "learning_rate": 1.910863824921176e-05,
      "loss": 0.0786,
      "step": 598
    },
    {
      "epoch": 0.406929347826087,
      "grad_norm": 0.9839775562286377,
      "learning_rate": 1.910569989971496e-05,
      "loss": 0.0124,
      "step": 599
    },
    {
      "epoch": 0.4076086956521739,
      "grad_norm": 4.875421524047852,
      "learning_rate": 1.9102756941767625e-05,
      "loss": 0.2083,
      "step": 600
    },
    {
      "epoch": 0.40828804347826086,
      "grad_norm": 1.9194450378417969,
      "learning_rate": 1.9099809376859196e-05,
      "loss": 0.0175,
      "step": 601
    },
    {
      "epoch": 0.40896739130434784,
      "grad_norm": 0.02131466381251812,
      "learning_rate": 1.909685720648146e-05,
      "loss": 0.0003,
      "step": 602
    },
    {
      "epoch": 0.40964673913043476,
      "grad_norm": 6.428951740264893,
      "learning_rate": 1.9093900432128532e-05,
      "loss": 0.1884,
      "step": 603
    },
    {
      "epoch": 0.41032608695652173,
      "grad_norm": 7.062008857727051,
      "learning_rate": 1.9090939055296846e-05,
      "loss": 0.0501,
      "step": 604
    },
    {
      "epoch": 0.4110054347826087,
      "grad_norm": 0.25489211082458496,
      "learning_rate": 1.9087973077485175e-05,
      "loss": 0.0027,
      "step": 605
    },
    {
      "epoch": 0.4116847826086957,
      "grad_norm": 0.23482605814933777,
      "learning_rate": 1.908500250019462e-05,
      "loss": 0.0018,
      "step": 606
    },
    {
      "epoch": 0.4123641304347826,
      "grad_norm": 6.554823875427246,
      "learning_rate": 1.9082027324928603e-05,
      "loss": 0.0949,
      "step": 607
    },
    {
      "epoch": 0.41304347826086957,
      "grad_norm": 0.9074299931526184,
      "learning_rate": 1.907904755319289e-05,
      "loss": 0.0232,
      "step": 608
    },
    {
      "epoch": 0.41372282608695654,
      "grad_norm": 2.886758327484131,
      "learning_rate": 1.907606318649555e-05,
      "loss": 0.1198,
      "step": 609
    },
    {
      "epoch": 0.41440217391304346,
      "grad_norm": 0.8651123046875,
      "learning_rate": 1.9073074226347e-05,
      "loss": 0.007,
      "step": 610
    },
    {
      "epoch": 0.41508152173913043,
      "grad_norm": 6.811877250671387,
      "learning_rate": 1.9070080674259962e-05,
      "loss": 0.227,
      "step": 611
    },
    {
      "epoch": 0.4157608695652174,
      "grad_norm": 3.561354637145996,
      "learning_rate": 1.9067082531749496e-05,
      "loss": 0.0623,
      "step": 612
    },
    {
      "epoch": 0.4164402173913043,
      "grad_norm": 0.3489355742931366,
      "learning_rate": 1.9064079800332977e-05,
      "loss": 0.0039,
      "step": 613
    },
    {
      "epoch": 0.4171195652173913,
      "grad_norm": 6.1837849617004395,
      "learning_rate": 1.906107248153011e-05,
      "loss": 0.2128,
      "step": 614
    },
    {
      "epoch": 0.41779891304347827,
      "grad_norm": 0.0037389122880995274,
      "learning_rate": 1.9058060576862912e-05,
      "loss": 0.0001,
      "step": 615
    },
    {
      "epoch": 0.41847826086956524,
      "grad_norm": 0.012271691113710403,
      "learning_rate": 1.9055044087855728e-05,
      "loss": 0.0002,
      "step": 616
    },
    {
      "epoch": 0.41915760869565216,
      "grad_norm": 0.2874256372451782,
      "learning_rate": 1.9052023016035224e-05,
      "loss": 0.0028,
      "step": 617
    },
    {
      "epoch": 0.41983695652173914,
      "grad_norm": 2.4459753036499023,
      "learning_rate": 1.9048997362930384e-05,
      "loss": 0.1282,
      "step": 618
    },
    {
      "epoch": 0.4205163043478261,
      "grad_norm": 10.436415672302246,
      "learning_rate": 1.9045967130072504e-05,
      "loss": 0.3097,
      "step": 619
    },
    {
      "epoch": 0.421195652173913,
      "grad_norm": 2.9261608123779297,
      "learning_rate": 1.904293231899521e-05,
      "loss": 0.1657,
      "step": 620
    },
    {
      "epoch": 0.421875,
      "grad_norm": 3.231769561767578,
      "learning_rate": 1.9039892931234434e-05,
      "loss": 0.1224,
      "step": 621
    },
    {
      "epoch": 0.422554347826087,
      "grad_norm": 3.232574701309204,
      "learning_rate": 1.9036848968328433e-05,
      "loss": 0.1985,
      "step": 622
    },
    {
      "epoch": 0.4232336956521739,
      "grad_norm": 1.6882301568984985,
      "learning_rate": 1.903380043181777e-05,
      "loss": 0.0638,
      "step": 623
    },
    {
      "epoch": 0.42391304347826086,
      "grad_norm": 0.007255540229380131,
      "learning_rate": 1.903074732324533e-05,
      "loss": 0.0001,
      "step": 624
    },
    {
      "epoch": 0.42459239130434784,
      "grad_norm": 8.537725448608398,
      "learning_rate": 1.9027689644156312e-05,
      "loss": 0.1782,
      "step": 625
    },
    {
      "epoch": 0.42527173913043476,
      "grad_norm": 0.4745766520500183,
      "learning_rate": 1.9024627396098222e-05,
      "loss": 0.0047,
      "step": 626
    },
    {
      "epoch": 0.42595108695652173,
      "grad_norm": 0.03800228238105774,
      "learning_rate": 1.9021560580620883e-05,
      "loss": 0.0004,
      "step": 627
    },
    {
      "epoch": 0.4266304347826087,
      "grad_norm": 6.983978271484375,
      "learning_rate": 1.9018489199276438e-05,
      "loss": 0.1363,
      "step": 628
    },
    {
      "epoch": 0.4273097826086957,
      "grad_norm": 2.4315853118896484,
      "learning_rate": 1.901541325361932e-05,
      "loss": 0.0445,
      "step": 629
    },
    {
      "epoch": 0.4279891304347826,
      "grad_norm": 0.021416788920760155,
      "learning_rate": 1.901233274520629e-05,
      "loss": 0.0003,
      "step": 630
    },
    {
      "epoch": 0.42866847826086957,
      "grad_norm": 7.151036262512207,
      "learning_rate": 1.9009247675596412e-05,
      "loss": 0.0829,
      "step": 631
    },
    {
      "epoch": 0.42934782608695654,
      "grad_norm": 2.6483757495880127,
      "learning_rate": 1.900615804635106e-05,
      "loss": 0.0834,
      "step": 632
    },
    {
      "epoch": 0.43002717391304346,
      "grad_norm": 0.009483001194894314,
      "learning_rate": 1.9003063859033906e-05,
      "loss": 0.0002,
      "step": 633
    },
    {
      "epoch": 0.43070652173913043,
      "grad_norm": 3.3109054565429688,
      "learning_rate": 1.899996511521095e-05,
      "loss": 0.1284,
      "step": 634
    },
    {
      "epoch": 0.4313858695652174,
      "grad_norm": 11.826688766479492,
      "learning_rate": 1.8996861816450475e-05,
      "loss": 0.4844,
      "step": 635
    },
    {
      "epoch": 0.4320652173913043,
      "grad_norm": 6.53032922744751,
      "learning_rate": 1.8993753964323086e-05,
      "loss": 0.1422,
      "step": 636
    },
    {
      "epoch": 0.4327445652173913,
      "grad_norm": 4.000208377838135,
      "learning_rate": 1.899064156040168e-05,
      "loss": 0.2931,
      "step": 637
    },
    {
      "epoch": 0.43342391304347827,
      "grad_norm": 3.282759428024292,
      "learning_rate": 1.8987524606261467e-05,
      "loss": 0.1932,
      "step": 638
    },
    {
      "epoch": 0.43410326086956524,
      "grad_norm": 7.5744781494140625,
      "learning_rate": 1.8984403103479957e-05,
      "loss": 0.3183,
      "step": 639
    },
    {
      "epoch": 0.43478260869565216,
      "grad_norm": 0.09308599680662155,
      "learning_rate": 1.8981277053636963e-05,
      "loss": 0.0007,
      "step": 640
    },
    {
      "epoch": 0.43546195652173914,
      "grad_norm": 4.227621078491211,
      "learning_rate": 1.8978146458314596e-05,
      "loss": 0.1701,
      "step": 641
    },
    {
      "epoch": 0.4361413043478261,
      "grad_norm": 0.01764422282576561,
      "learning_rate": 1.8975011319097264e-05,
      "loss": 0.0003,
      "step": 642
    },
    {
      "epoch": 0.436820652173913,
      "grad_norm": 9.371330261230469,
      "learning_rate": 1.8971871637571692e-05,
      "loss": 0.3828,
      "step": 643
    },
    {
      "epoch": 0.4375,
      "grad_norm": 0.21214079856872559,
      "learning_rate": 1.8968727415326885e-05,
      "loss": 0.002,
      "step": 644
    },
    {
      "epoch": 0.438179347826087,
      "grad_norm": 0.01652608998119831,
      "learning_rate": 1.8965578653954152e-05,
      "loss": 0.0003,
      "step": 645
    },
    {
      "epoch": 0.4388586956521739,
      "grad_norm": 2.5540080070495605,
      "learning_rate": 1.8962425355047106e-05,
      "loss": 0.0177,
      "step": 646
    },
    {
      "epoch": 0.43953804347826086,
      "grad_norm": 2.483381748199463,
      "learning_rate": 1.8959267520201642e-05,
      "loss": 0.1397,
      "step": 647
    },
    {
      "epoch": 0.44021739130434784,
      "grad_norm": 0.01847444288432598,
      "learning_rate": 1.8956105151015966e-05,
      "loss": 0.0004,
      "step": 648
    },
    {
      "epoch": 0.44089673913043476,
      "grad_norm": 2.6670825481414795,
      "learning_rate": 1.8952938249090574e-05,
      "loss": 0.031,
      "step": 649
    },
    {
      "epoch": 0.44157608695652173,
      "grad_norm": 0.12207681685686111,
      "learning_rate": 1.894976681602825e-05,
      "loss": 0.0013,
      "step": 650
    },
    {
      "epoch": 0.4422554347826087,
      "grad_norm": 0.022755760699510574,
      "learning_rate": 1.894659085343408e-05,
      "loss": 0.0003,
      "step": 651
    },
    {
      "epoch": 0.4429347826086957,
      "grad_norm": 2.61293625831604,
      "learning_rate": 1.8943410362915437e-05,
      "loss": 0.1231,
      "step": 652
    },
    {
      "epoch": 0.4436141304347826,
      "grad_norm": 1.6312379837036133,
      "learning_rate": 1.894022534608198e-05,
      "loss": 0.1194,
      "step": 653
    },
    {
      "epoch": 0.44429347826086957,
      "grad_norm": 0.13655133545398712,
      "learning_rate": 1.893703580454567e-05,
      "loss": 0.0012,
      "step": 654
    },
    {
      "epoch": 0.44497282608695654,
      "grad_norm": 13.231178283691406,
      "learning_rate": 1.893384173992076e-05,
      "loss": 0.2825,
      "step": 655
    },
    {
      "epoch": 0.44565217391304346,
      "grad_norm": 0.02662567049264908,
      "learning_rate": 1.8930643153823777e-05,
      "loss": 0.0003,
      "step": 656
    },
    {
      "epoch": 0.44633152173913043,
      "grad_norm": 2.570207118988037,
      "learning_rate": 1.892744004787355e-05,
      "loss": 0.1414,
      "step": 657
    },
    {
      "epoch": 0.4470108695652174,
      "grad_norm": 8.056534767150879,
      "learning_rate": 1.8924232423691188e-05,
      "loss": 0.2176,
      "step": 658
    },
    {
      "epoch": 0.4476902173913043,
      "grad_norm": 1.45375394821167,
      "learning_rate": 1.8921020282900092e-05,
      "loss": 0.0105,
      "step": 659
    },
    {
      "epoch": 0.4483695652173913,
      "grad_norm": 5.058150768280029,
      "learning_rate": 1.891780362712594e-05,
      "loss": 0.2104,
      "step": 660
    },
    {
      "epoch": 0.44904891304347827,
      "grad_norm": 0.025927087292075157,
      "learning_rate": 1.8914582457996706e-05,
      "loss": 0.0004,
      "step": 661
    },
    {
      "epoch": 0.44972826086956524,
      "grad_norm": 3.88554310798645,
      "learning_rate": 1.8911356777142646e-05,
      "loss": 0.043,
      "step": 662
    },
    {
      "epoch": 0.45040760869565216,
      "grad_norm": 0.5297116041183472,
      "learning_rate": 1.890812658619629e-05,
      "loss": 0.0051,
      "step": 663
    },
    {
      "epoch": 0.45108695652173914,
      "grad_norm": 1.567878007888794,
      "learning_rate": 1.8904891886792465e-05,
      "loss": 0.1011,
      "step": 664
    },
    {
      "epoch": 0.4517663043478261,
      "grad_norm": 1.6372215747833252,
      "learning_rate": 1.8901652680568267e-05,
      "loss": 0.1172,
      "step": 665
    },
    {
      "epoch": 0.452445652173913,
      "grad_norm": 3.2296481132507324,
      "learning_rate": 1.8898408969163078e-05,
      "loss": 0.0702,
      "step": 666
    },
    {
      "epoch": 0.453125,
      "grad_norm": 0.045495469123125076,
      "learning_rate": 1.8895160754218562e-05,
      "loss": 0.0007,
      "step": 667
    },
    {
      "epoch": 0.453804347826087,
      "grad_norm": 0.1564001441001892,
      "learning_rate": 1.889190803737866e-05,
      "loss": 0.0014,
      "step": 668
    },
    {
      "epoch": 0.4544836956521739,
      "grad_norm": 4.951213359832764,
      "learning_rate": 1.8888650820289594e-05,
      "loss": 0.3087,
      "step": 669
    },
    {
      "epoch": 0.45516304347826086,
      "grad_norm": 14.477408409118652,
      "learning_rate": 1.888538910459986e-05,
      "loss": 0.134,
      "step": 670
    },
    {
      "epoch": 0.45584239130434784,
      "grad_norm": 0.13573747873306274,
      "learning_rate": 1.8882122891960226e-05,
      "loss": 0.0013,
      "step": 671
    },
    {
      "epoch": 0.45652173913043476,
      "grad_norm": 1.8277124166488647,
      "learning_rate": 1.8878852184023754e-05,
      "loss": 0.1178,
      "step": 672
    },
    {
      "epoch": 0.45720108695652173,
      "grad_norm": 0.013360350392758846,
      "learning_rate": 1.8875576982445764e-05,
      "loss": 0.0002,
      "step": 673
    },
    {
      "epoch": 0.4578804347826087,
      "grad_norm": 3.939424991607666,
      "learning_rate": 1.887229728888385e-05,
      "loss": 0.0957,
      "step": 674
    },
    {
      "epoch": 0.4585597826086957,
      "grad_norm": 4.812492370605469,
      "learning_rate": 1.8869013104997896e-05,
      "loss": 0.2227,
      "step": 675
    },
    {
      "epoch": 0.4592391304347826,
      "grad_norm": 3.746711492538452,
      "learning_rate": 1.8865724432450036e-05,
      "loss": 0.0835,
      "step": 676
    },
    {
      "epoch": 0.45991847826086957,
      "grad_norm": 0.13412250578403473,
      "learning_rate": 1.8862431272904697e-05,
      "loss": 0.0016,
      "step": 677
    },
    {
      "epoch": 0.46059782608695654,
      "grad_norm": 3.8472537994384766,
      "learning_rate": 1.8859133628028564e-05,
      "loss": 0.1438,
      "step": 678
    },
    {
      "epoch": 0.46127717391304346,
      "grad_norm": 2.214998245239258,
      "learning_rate": 1.885583149949059e-05,
      "loss": 0.0974,
      "step": 679
    },
    {
      "epoch": 0.46195652173913043,
      "grad_norm": 2.4202308654785156,
      "learning_rate": 1.885252488896201e-05,
      "loss": 0.1103,
      "step": 680
    },
    {
      "epoch": 0.4626358695652174,
      "grad_norm": 6.489506244659424,
      "learning_rate": 1.8849213798116318e-05,
      "loss": 0.2526,
      "step": 681
    },
    {
      "epoch": 0.4633152173913043,
      "grad_norm": 0.07190217822790146,
      "learning_rate": 1.8845898228629273e-05,
      "loss": 0.0007,
      "step": 682
    },
    {
      "epoch": 0.4639945652173913,
      "grad_norm": 0.003891007974743843,
      "learning_rate": 1.8842578182178912e-05,
      "loss": 0.0001,
      "step": 683
    },
    {
      "epoch": 0.46467391304347827,
      "grad_norm": 0.011629742570221424,
      "learning_rate": 1.8839253660445523e-05,
      "loss": 0.0002,
      "step": 684
    },
    {
      "epoch": 0.46535326086956524,
      "grad_norm": 6.965911388397217,
      "learning_rate": 1.8835924665111672e-05,
      "loss": 0.1392,
      "step": 685
    },
    {
      "epoch": 0.46603260869565216,
      "grad_norm": 5.328233242034912,
      "learning_rate": 1.8832591197862186e-05,
      "loss": 0.1361,
      "step": 686
    },
    {
      "epoch": 0.46671195652173914,
      "grad_norm": 0.36065003275871277,
      "learning_rate": 1.882925326038415e-05,
      "loss": 0.0023,
      "step": 687
    },
    {
      "epoch": 0.4673913043478261,
      "grad_norm": 2.625765562057495,
      "learning_rate": 1.8825910854366914e-05,
      "loss": 0.068,
      "step": 688
    },
    {
      "epoch": 0.468070652173913,
      "grad_norm": 2.815302848815918,
      "learning_rate": 1.8822563981502088e-05,
      "loss": 0.1498,
      "step": 689
    },
    {
      "epoch": 0.46875,
      "grad_norm": 4.828354358673096,
      "learning_rate": 1.881921264348355e-05,
      "loss": 0.066,
      "step": 690
    },
    {
      "epoch": 0.469429347826087,
      "grad_norm": 2.528681993484497,
      "learning_rate": 1.8815856842007433e-05,
      "loss": 0.0281,
      "step": 691
    },
    {
      "epoch": 0.4701086956521739,
      "grad_norm": 2.7839434146881104,
      "learning_rate": 1.8812496578772123e-05,
      "loss": 0.1126,
      "step": 692
    },
    {
      "epoch": 0.47078804347826086,
      "grad_norm": 0.14864353835582733,
      "learning_rate": 1.8809131855478276e-05,
      "loss": 0.0016,
      "step": 693
    },
    {
      "epoch": 0.47146739130434784,
      "grad_norm": 9.576354026794434,
      "learning_rate": 1.8805762673828792e-05,
      "loss": 0.3364,
      "step": 694
    },
    {
      "epoch": 0.47214673913043476,
      "grad_norm": 4.8816070556640625,
      "learning_rate": 1.8802389035528842e-05,
      "loss": 0.2343,
      "step": 695
    },
    {
      "epoch": 0.47282608695652173,
      "grad_norm": 1.3197729587554932,
      "learning_rate": 1.879901094228584e-05,
      "loss": 0.0509,
      "step": 696
    },
    {
      "epoch": 0.4735054347826087,
      "grad_norm": 8.192424774169922,
      "learning_rate": 1.8795628395809464e-05,
      "loss": 0.1319,
      "step": 697
    },
    {
      "epoch": 0.4741847826086957,
      "grad_norm": 4.1584882736206055,
      "learning_rate": 1.8792241397811634e-05,
      "loss": 0.0881,
      "step": 698
    },
    {
      "epoch": 0.4748641304347826,
      "grad_norm": 1.3690847158432007,
      "learning_rate": 1.878884995000654e-05,
      "loss": 0.0151,
      "step": 699
    },
    {
      "epoch": 0.47554347826086957,
      "grad_norm": 2.524716854095459,
      "learning_rate": 1.878545405411061e-05,
      "loss": 0.0835,
      "step": 700
    },
    {
      "epoch": 0.47622282608695654,
      "grad_norm": 3.481313943862915,
      "learning_rate": 1.8782053711842524e-05,
      "loss": 0.0409,
      "step": 701
    },
    {
      "epoch": 0.47690217391304346,
      "grad_norm": 0.1121542826294899,
      "learning_rate": 1.8778648924923222e-05,
      "loss": 0.0008,
      "step": 702
    },
    {
      "epoch": 0.47758152173913043,
      "grad_norm": 0.06235566735267639,
      "learning_rate": 1.8775239695075883e-05,
      "loss": 0.0005,
      "step": 703
    },
    {
      "epoch": 0.4782608695652174,
      "grad_norm": 2.5619657039642334,
      "learning_rate": 1.8771826024025944e-05,
      "loss": 0.0991,
      "step": 704
    },
    {
      "epoch": 0.4789402173913043,
      "grad_norm": 2.849090576171875,
      "learning_rate": 1.876840791350108e-05,
      "loss": 0.035,
      "step": 705
    },
    {
      "epoch": 0.4796195652173913,
      "grad_norm": 0.5014469623565674,
      "learning_rate": 1.876498536523122e-05,
      "loss": 0.0048,
      "step": 706
    },
    {
      "epoch": 0.48029891304347827,
      "grad_norm": 0.2008994072675705,
      "learning_rate": 1.876155838094854e-05,
      "loss": 0.0015,
      "step": 707
    },
    {
      "epoch": 0.48097826086956524,
      "grad_norm": 3.1954870223999023,
      "learning_rate": 1.875812696238745e-05,
      "loss": 0.1678,
      "step": 708
    },
    {
      "epoch": 0.48165760869565216,
      "grad_norm": 4.279149532318115,
      "learning_rate": 1.875469111128462e-05,
      "loss": 0.2791,
      "step": 709
    },
    {
      "epoch": 0.48233695652173914,
      "grad_norm": 0.06333202868700027,
      "learning_rate": 1.875125082937895e-05,
      "loss": 0.0006,
      "step": 710
    },
    {
      "epoch": 0.4830163043478261,
      "grad_norm": 0.03432009369134903,
      "learning_rate": 1.8747806118411588e-05,
      "loss": 0.0004,
      "step": 711
    },
    {
      "epoch": 0.483695652173913,
      "grad_norm": 0.24793510138988495,
      "learning_rate": 1.8744356980125922e-05,
      "loss": 0.0033,
      "step": 712
    },
    {
      "epoch": 0.484375,
      "grad_norm": 4.890347957611084,
      "learning_rate": 1.874090341626759e-05,
      "loss": 0.1726,
      "step": 713
    },
    {
      "epoch": 0.485054347826087,
      "grad_norm": 2.8165364265441895,
      "learning_rate": 1.8737445428584456e-05,
      "loss": 0.0244,
      "step": 714
    },
    {
      "epoch": 0.4857336956521739,
      "grad_norm": 9.585034370422363,
      "learning_rate": 1.8733983018826626e-05,
      "loss": 0.3432,
      "step": 715
    },
    {
      "epoch": 0.48641304347826086,
      "grad_norm": 0.5315204858779907,
      "learning_rate": 1.8730516188746452e-05,
      "loss": 0.0049,
      "step": 716
    },
    {
      "epoch": 0.48709239130434784,
      "grad_norm": 2.195309638977051,
      "learning_rate": 1.8727044940098516e-05,
      "loss": 0.0699,
      "step": 717
    },
    {
      "epoch": 0.48777173913043476,
      "grad_norm": 2.1196391582489014,
      "learning_rate": 1.872356927463964e-05,
      "loss": 0.1672,
      "step": 718
    },
    {
      "epoch": 0.48845108695652173,
      "grad_norm": 7.905351638793945,
      "learning_rate": 1.8720089194128873e-05,
      "loss": 0.3127,
      "step": 719
    },
    {
      "epoch": 0.4891304347826087,
      "grad_norm": 12.413883209228516,
      "learning_rate": 1.8716604700327516e-05,
      "loss": 0.3331,
      "step": 720
    },
    {
      "epoch": 0.4898097826086957,
      "grad_norm": 3.4044065475463867,
      "learning_rate": 1.8713115794999083e-05,
      "loss": 0.1698,
      "step": 721
    },
    {
      "epoch": 0.4904891304347826,
      "grad_norm": 2.7287144660949707,
      "learning_rate": 1.8709622479909333e-05,
      "loss": 0.1129,
      "step": 722
    },
    {
      "epoch": 0.49116847826086957,
      "grad_norm": 2.9667999744415283,
      "learning_rate": 1.8706124756826255e-05,
      "loss": 0.0782,
      "step": 723
    },
    {
      "epoch": 0.49184782608695654,
      "grad_norm": 4.687361240386963,
      "learning_rate": 1.870262262752007e-05,
      "loss": 0.112,
      "step": 724
    },
    {
      "epoch": 0.49252717391304346,
      "grad_norm": 0.025551609694957733,
      "learning_rate": 1.8699116093763226e-05,
      "loss": 0.0003,
      "step": 725
    },
    {
      "epoch": 0.49320652173913043,
      "grad_norm": 3.1714067459106445,
      "learning_rate": 1.8695605157330398e-05,
      "loss": 0.0334,
      "step": 726
    },
    {
      "epoch": 0.4938858695652174,
      "grad_norm": 12.58841323852539,
      "learning_rate": 1.8692089819998498e-05,
      "loss": 0.3594,
      "step": 727
    },
    {
      "epoch": 0.4945652173913043,
      "grad_norm": 0.07894670218229294,
      "learning_rate": 1.8688570083546658e-05,
      "loss": 0.0007,
      "step": 728
    },
    {
      "epoch": 0.4952445652173913,
      "grad_norm": 0.00700553460046649,
      "learning_rate": 1.8685045949756232e-05,
      "loss": 0.0001,
      "step": 729
    },
    {
      "epoch": 0.49592391304347827,
      "grad_norm": 0.6419008374214172,
      "learning_rate": 1.8681517420410814e-05,
      "loss": 0.0048,
      "step": 730
    },
    {
      "epoch": 0.49660326086956524,
      "grad_norm": 3.1180403232574463,
      "learning_rate": 1.8677984497296207e-05,
      "loss": 0.1688,
      "step": 731
    },
    {
      "epoch": 0.49728260869565216,
      "grad_norm": 0.9462388157844543,
      "learning_rate": 1.8674447182200457e-05,
      "loss": 0.0105,
      "step": 732
    },
    {
      "epoch": 0.49796195652173914,
      "grad_norm": 8.999876976013184,
      "learning_rate": 1.8670905476913805e-05,
      "loss": 0.2715,
      "step": 733
    },
    {
      "epoch": 0.4986413043478261,
      "grad_norm": 3.0488109588623047,
      "learning_rate": 1.8667359383228745e-05,
      "loss": 0.2571,
      "step": 734
    },
    {
      "epoch": 0.499320652173913,
      "grad_norm": 0.06766762584447861,
      "learning_rate": 1.8663808902939965e-05,
      "loss": 0.0007,
      "step": 735
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.08052603900432587,
      "learning_rate": 1.866025403784439e-05,
      "loss": 0.001,
      "step": 736
    },
    {
      "epoch": 0.5006793478260869,
      "grad_norm": 0.005733192432671785,
      "learning_rate": 1.8656694789741157e-05,
      "loss": 0.0001,
      "step": 737
    },
    {
      "epoch": 0.501358695652174,
      "grad_norm": 3.473367929458618,
      "learning_rate": 1.8653131160431622e-05,
      "loss": 0.1212,
      "step": 738
    },
    {
      "epoch": 0.5020380434782609,
      "grad_norm": 1.9747055768966675,
      "learning_rate": 1.864956315171937e-05,
      "loss": 0.1267,
      "step": 739
    },
    {
      "epoch": 0.5027173913043478,
      "grad_norm": 5.082598686218262,
      "learning_rate": 1.864599076541018e-05,
      "loss": 0.2742,
      "step": 740
    },
    {
      "epoch": 0.5033967391304348,
      "grad_norm": 9.204185485839844,
      "learning_rate": 1.8642414003312063e-05,
      "loss": 0.1565,
      "step": 741
    },
    {
      "epoch": 0.5040760869565217,
      "grad_norm": 7.191376686096191,
      "learning_rate": 1.8638832867235238e-05,
      "loss": 0.2964,
      "step": 742
    },
    {
      "epoch": 0.5047554347826086,
      "grad_norm": 0.006550299469381571,
      "learning_rate": 1.8635247358992146e-05,
      "loss": 0.0001,
      "step": 743
    },
    {
      "epoch": 0.5054347826086957,
      "grad_norm": 1.806339979171753,
      "learning_rate": 1.863165748039743e-05,
      "loss": 0.173,
      "step": 744
    },
    {
      "epoch": 0.5061141304347826,
      "grad_norm": 0.008867676369845867,
      "learning_rate": 1.8628063233267948e-05,
      "loss": 0.0002,
      "step": 745
    },
    {
      "epoch": 0.5067934782608695,
      "grad_norm": 1.0343300104141235,
      "learning_rate": 1.8624464619422776e-05,
      "loss": 0.0313,
      "step": 746
    },
    {
      "epoch": 0.5074728260869565,
      "grad_norm": 14.29102611541748,
      "learning_rate": 1.862086164068319e-05,
      "loss": 0.1296,
      "step": 747
    },
    {
      "epoch": 0.5081521739130435,
      "grad_norm": 0.013864025473594666,
      "learning_rate": 1.861725429887268e-05,
      "loss": 0.0002,
      "step": 748
    },
    {
      "epoch": 0.5088315217391305,
      "grad_norm": 0.1703614443540573,
      "learning_rate": 1.8613642595816947e-05,
      "loss": 0.0016,
      "step": 749
    },
    {
      "epoch": 0.5095108695652174,
      "grad_norm": 3.6699814796447754,
      "learning_rate": 1.861002653334389e-05,
      "loss": 0.2002,
      "step": 750
    },
    {
      "epoch": 0.5101902173913043,
      "grad_norm": 0.42023754119873047,
      "learning_rate": 1.8606406113283625e-05,
      "loss": 0.0056,
      "step": 751
    },
    {
      "epoch": 0.5108695652173914,
      "grad_norm": 0.12006186693906784,
      "learning_rate": 1.8602781337468472e-05,
      "loss": 0.0008,
      "step": 752
    },
    {
      "epoch": 0.5115489130434783,
      "grad_norm": 0.05321434512734413,
      "learning_rate": 1.8599152207732945e-05,
      "loss": 0.0005,
      "step": 753
    },
    {
      "epoch": 0.5122282608695652,
      "grad_norm": 0.6184799671173096,
      "learning_rate": 1.8595518725913773e-05,
      "loss": 0.0047,
      "step": 754
    },
    {
      "epoch": 0.5129076086956522,
      "grad_norm": 4.110049724578857,
      "learning_rate": 1.859188089384988e-05,
      "loss": 0.1269,
      "step": 755
    },
    {
      "epoch": 0.5135869565217391,
      "grad_norm": 2.847414016723633,
      "learning_rate": 1.85882387133824e-05,
      "loss": 0.1304,
      "step": 756
    },
    {
      "epoch": 0.514266304347826,
      "grad_norm": 1.8058197498321533,
      "learning_rate": 1.858459218635466e-05,
      "loss": 0.0385,
      "step": 757
    },
    {
      "epoch": 0.5149456521739131,
      "grad_norm": 1.5145702362060547,
      "learning_rate": 1.8580941314612193e-05,
      "loss": 0.0705,
      "step": 758
    },
    {
      "epoch": 0.515625,
      "grad_norm": 2.745992422103882,
      "learning_rate": 1.8577286100002723e-05,
      "loss": 0.0961,
      "step": 759
    },
    {
      "epoch": 0.5163043478260869,
      "grad_norm": 2.137394905090332,
      "learning_rate": 1.857362654437618e-05,
      "loss": 0.0779,
      "step": 760
    },
    {
      "epoch": 0.516983695652174,
      "grad_norm": 0.30778375267982483,
      "learning_rate": 1.856996264958468e-05,
      "loss": 0.0027,
      "step": 761
    },
    {
      "epoch": 0.5176630434782609,
      "grad_norm": 2.3649652004241943,
      "learning_rate": 1.8566294417482552e-05,
      "loss": 0.0965,
      "step": 762
    },
    {
      "epoch": 0.5183423913043478,
      "grad_norm": 1.3813344240188599,
      "learning_rate": 1.856262184992631e-05,
      "loss": 0.0149,
      "step": 763
    },
    {
      "epoch": 0.5190217391304348,
      "grad_norm": 2.5201573371887207,
      "learning_rate": 1.8558944948774655e-05,
      "loss": 0.171,
      "step": 764
    },
    {
      "epoch": 0.5197010869565217,
      "grad_norm": 3.2705533504486084,
      "learning_rate": 1.8555263715888493e-05,
      "loss": 0.1461,
      "step": 765
    },
    {
      "epoch": 0.5203804347826086,
      "grad_norm": 3.22802996635437,
      "learning_rate": 1.8551578153130926e-05,
      "loss": 0.1861,
      "step": 766
    },
    {
      "epoch": 0.5210597826086957,
      "grad_norm": 1.4981019496917725,
      "learning_rate": 1.8547888262367232e-05,
      "loss": 0.0911,
      "step": 767
    },
    {
      "epoch": 0.5217391304347826,
      "grad_norm": 0.3887646198272705,
      "learning_rate": 1.8544194045464888e-05,
      "loss": 0.0028,
      "step": 768
    },
    {
      "epoch": 0.5224184782608695,
      "grad_norm": 9.730484962463379,
      "learning_rate": 1.854049550429356e-05,
      "loss": 0.4849,
      "step": 769
    },
    {
      "epoch": 0.5230978260869565,
      "grad_norm": 11.536765098571777,
      "learning_rate": 1.8536792640725103e-05,
      "loss": 0.7096,
      "step": 770
    },
    {
      "epoch": 0.5237771739130435,
      "grad_norm": 3.322173595428467,
      "learning_rate": 1.853308545663356e-05,
      "loss": 0.1791,
      "step": 771
    },
    {
      "epoch": 0.5244565217391305,
      "grad_norm": 0.004249463323503733,
      "learning_rate": 1.852937395389516e-05,
      "loss": 0.0001,
      "step": 772
    },
    {
      "epoch": 0.5251358695652174,
      "grad_norm": 1.3663413524627686,
      "learning_rate": 1.852565813438832e-05,
      "loss": 0.018,
      "step": 773
    },
    {
      "epoch": 0.5258152173913043,
      "grad_norm": 1.6953502893447876,
      "learning_rate": 1.8521937999993627e-05,
      "loss": 0.1372,
      "step": 774
    },
    {
      "epoch": 0.5264945652173914,
      "grad_norm": 0.14986181259155273,
      "learning_rate": 1.8518213552593877e-05,
      "loss": 0.0011,
      "step": 775
    },
    {
      "epoch": 0.5271739130434783,
      "grad_norm": 3.2478771209716797,
      "learning_rate": 1.8514484794074028e-05,
      "loss": 0.1573,
      "step": 776
    },
    {
      "epoch": 0.5278532608695652,
      "grad_norm": 4.406482219696045,
      "learning_rate": 1.8510751726321233e-05,
      "loss": 0.0472,
      "step": 777
    },
    {
      "epoch": 0.5285326086956522,
      "grad_norm": 1.6328681707382202,
      "learning_rate": 1.8507014351224816e-05,
      "loss": 0.1236,
      "step": 778
    },
    {
      "epoch": 0.5292119565217391,
      "grad_norm": 0.005501443054527044,
      "learning_rate": 1.8503272670676286e-05,
      "loss": 0.0001,
      "step": 779
    },
    {
      "epoch": 0.529891304347826,
      "grad_norm": 3.578624725341797,
      "learning_rate": 1.849952668656933e-05,
      "loss": 0.0436,
      "step": 780
    },
    {
      "epoch": 0.5305706521739131,
      "grad_norm": 17.339679718017578,
      "learning_rate": 1.849577640079982e-05,
      "loss": 0.57,
      "step": 781
    },
    {
      "epoch": 0.53125,
      "grad_norm": 1.5991250276565552,
      "learning_rate": 1.849202181526579e-05,
      "loss": 0.0589,
      "step": 782
    },
    {
      "epoch": 0.5319293478260869,
      "grad_norm": 12.986868858337402,
      "learning_rate": 1.8488262931867464e-05,
      "loss": 0.1083,
      "step": 783
    },
    {
      "epoch": 0.532608695652174,
      "grad_norm": 6.833276271820068,
      "learning_rate": 1.8484499752507234e-05,
      "loss": 0.3574,
      "step": 784
    },
    {
      "epoch": 0.5332880434782609,
      "grad_norm": 4.767954349517822,
      "learning_rate": 1.8480732279089667e-05,
      "loss": 0.0769,
      "step": 785
    },
    {
      "epoch": 0.5339673913043478,
      "grad_norm": 3.98065447807312,
      "learning_rate": 1.847696051352151e-05,
      "loss": 0.0939,
      "step": 786
    },
    {
      "epoch": 0.5346467391304348,
      "grad_norm": 0.16461990773677826,
      "learning_rate": 1.847318445771167e-05,
      "loss": 0.0014,
      "step": 787
    },
    {
      "epoch": 0.5353260869565217,
      "grad_norm": 0.01218872144818306,
      "learning_rate": 1.8469404113571235e-05,
      "loss": 0.0002,
      "step": 788
    },
    {
      "epoch": 0.5360054347826086,
      "grad_norm": 4.501532554626465,
      "learning_rate": 1.846561948301346e-05,
      "loss": 0.0812,
      "step": 789
    },
    {
      "epoch": 0.5366847826086957,
      "grad_norm": 0.03959216922521591,
      "learning_rate": 1.846183056795377e-05,
      "loss": 0.0004,
      "step": 790
    },
    {
      "epoch": 0.5373641304347826,
      "grad_norm": 14.772947311401367,
      "learning_rate": 1.8458037370309757e-05,
      "loss": 0.4104,
      "step": 791
    },
    {
      "epoch": 0.5380434782608695,
      "grad_norm": 2.5079848766326904,
      "learning_rate": 1.845423989200118e-05,
      "loss": 0.1797,
      "step": 792
    },
    {
      "epoch": 0.5387228260869565,
      "grad_norm": 4.439591407775879,
      "learning_rate": 1.845043813494997e-05,
      "loss": 0.2259,
      "step": 793
    },
    {
      "epoch": 0.5394021739130435,
      "grad_norm": 0.13707679510116577,
      "learning_rate": 1.844663210108022e-05,
      "loss": 0.001,
      "step": 794
    },
    {
      "epoch": 0.5400815217391305,
      "grad_norm": 0.021740412339568138,
      "learning_rate": 1.8442821792318183e-05,
      "loss": 0.0002,
      "step": 795
    },
    {
      "epoch": 0.5407608695652174,
      "grad_norm": 5.395104885101318,
      "learning_rate": 1.8439007210592282e-05,
      "loss": 0.1519,
      "step": 796
    },
    {
      "epoch": 0.5414402173913043,
      "grad_norm": 0.011203402653336525,
      "learning_rate": 1.84351883578331e-05,
      "loss": 0.0002,
      "step": 797
    },
    {
      "epoch": 0.5421195652173914,
      "grad_norm": 0.007616091053932905,
      "learning_rate": 1.8431365235973383e-05,
      "loss": 0.0001,
      "step": 798
    },
    {
      "epoch": 0.5427989130434783,
      "grad_norm": 2.2425992488861084,
      "learning_rate": 1.842753784694803e-05,
      "loss": 0.1525,
      "step": 799
    },
    {
      "epoch": 0.5434782608695652,
      "grad_norm": 2.9477455615997314,
      "learning_rate": 1.8423706192694118e-05,
      "loss": 0.0859,
      "step": 800
    },
    {
      "epoch": 0.5441576086956522,
      "grad_norm": 0.004874065052717924,
      "learning_rate": 1.841987027515086e-05,
      "loss": 0.0001,
      "step": 801
    },
    {
      "epoch": 0.5448369565217391,
      "grad_norm": 2.2444212436676025,
      "learning_rate": 1.8416030096259643e-05,
      "loss": 0.132,
      "step": 802
    },
    {
      "epoch": 0.545516304347826,
      "grad_norm": 10.999241828918457,
      "learning_rate": 1.8412185657964e-05,
      "loss": 0.3394,
      "step": 803
    },
    {
      "epoch": 0.5461956521739131,
      "grad_norm": 8.334179878234863,
      "learning_rate": 1.840833696220963e-05,
      "loss": 0.4194,
      "step": 804
    },
    {
      "epoch": 0.546875,
      "grad_norm": 12.15500545501709,
      "learning_rate": 1.840448401094438e-05,
      "loss": 0.1647,
      "step": 805
    },
    {
      "epoch": 0.5475543478260869,
      "grad_norm": 1.5081126689910889,
      "learning_rate": 1.8400626806118253e-05,
      "loss": 0.0468,
      "step": 806
    },
    {
      "epoch": 0.548233695652174,
      "grad_norm": 0.01664634607732296,
      "learning_rate": 1.8396765349683404e-05,
      "loss": 0.0002,
      "step": 807
    },
    {
      "epoch": 0.5489130434782609,
      "grad_norm": 5.853525638580322,
      "learning_rate": 1.8392899643594135e-05,
      "loss": 0.238,
      "step": 808
    },
    {
      "epoch": 0.5495923913043478,
      "grad_norm": 7.80018949508667,
      "learning_rate": 1.8389029689806907e-05,
      "loss": 0.1118,
      "step": 809
    },
    {
      "epoch": 0.5502717391304348,
      "grad_norm": 1.2102347612380981,
      "learning_rate": 1.8385155490280327e-05,
      "loss": 0.036,
      "step": 810
    },
    {
      "epoch": 0.5509510869565217,
      "grad_norm": 3.8395838737487793,
      "learning_rate": 1.8381277046975156e-05,
      "loss": 0.1766,
      "step": 811
    },
    {
      "epoch": 0.5516304347826086,
      "grad_norm": 2.629185676574707,
      "learning_rate": 1.837739436185429e-05,
      "loss": 0.1505,
      "step": 812
    },
    {
      "epoch": 0.5523097826086957,
      "grad_norm": 6.73167610168457,
      "learning_rate": 1.8373507436882784e-05,
      "loss": 0.1637,
      "step": 813
    },
    {
      "epoch": 0.5529891304347826,
      "grad_norm": 7.697131156921387,
      "learning_rate": 1.836961627402783e-05,
      "loss": 0.1487,
      "step": 814
    },
    {
      "epoch": 0.5536684782608695,
      "grad_norm": 2.226806879043579,
      "learning_rate": 1.8365720875258783e-05,
      "loss": 0.1478,
      "step": 815
    },
    {
      "epoch": 0.5543478260869565,
      "grad_norm": 9.382963180541992,
      "learning_rate": 1.836182124254711e-05,
      "loss": 0.2023,
      "step": 816
    },
    {
      "epoch": 0.5550271739130435,
      "grad_norm": 2.092188835144043,
      "learning_rate": 1.835791737786645e-05,
      "loss": 0.1591,
      "step": 817
    },
    {
      "epoch": 0.5557065217391305,
      "grad_norm": 1.8844578266143799,
      "learning_rate": 1.835400928319257e-05,
      "loss": 0.0184,
      "step": 818
    },
    {
      "epoch": 0.5563858695652174,
      "grad_norm": 0.2188083380460739,
      "learning_rate": 1.8350096960503383e-05,
      "loss": 0.0013,
      "step": 819
    },
    {
      "epoch": 0.5570652173913043,
      "grad_norm": 0.5616734623908997,
      "learning_rate": 1.8346180411778934e-05,
      "loss": 0.0037,
      "step": 820
    },
    {
      "epoch": 0.5577445652173914,
      "grad_norm": 2.982720136642456,
      "learning_rate": 1.8342259639001415e-05,
      "loss": 0.1843,
      "step": 821
    },
    {
      "epoch": 0.5584239130434783,
      "grad_norm": 0.10307921469211578,
      "learning_rate": 1.833833464415516e-05,
      "loss": 0.0009,
      "step": 822
    },
    {
      "epoch": 0.5591032608695652,
      "grad_norm": 0.14690306782722473,
      "learning_rate": 1.833440542922662e-05,
      "loss": 0.0016,
      "step": 823
    },
    {
      "epoch": 0.5597826086956522,
      "grad_norm": 5.297775745391846,
      "learning_rate": 1.8330471996204408e-05,
      "loss": 0.1435,
      "step": 824
    },
    {
      "epoch": 0.5604619565217391,
      "grad_norm": 1.1031935214996338,
      "learning_rate": 1.832653434707925e-05,
      "loss": 0.0137,
      "step": 825
    },
    {
      "epoch": 0.561141304347826,
      "grad_norm": 0.26419445872306824,
      "learning_rate": 1.832259248384401e-05,
      "loss": 0.0019,
      "step": 826
    },
    {
      "epoch": 0.5618206521739131,
      "grad_norm": 2.6616873741149902,
      "learning_rate": 1.8318646408493704e-05,
      "loss": 0.1474,
      "step": 827
    },
    {
      "epoch": 0.5625,
      "grad_norm": 7.605353832244873,
      "learning_rate": 1.8314696123025456e-05,
      "loss": 0.1272,
      "step": 828
    },
    {
      "epoch": 0.5631793478260869,
      "grad_norm": 2.8093669414520264,
      "learning_rate": 1.8310741629438528e-05,
      "loss": 0.1139,
      "step": 829
    },
    {
      "epoch": 0.563858695652174,
      "grad_norm": 3.5151801109313965,
      "learning_rate": 1.8306782929734313e-05,
      "loss": 0.1754,
      "step": 830
    },
    {
      "epoch": 0.5645380434782609,
      "grad_norm": 4.784469127655029,
      "learning_rate": 1.830282002591634e-05,
      "loss": 0.2359,
      "step": 831
    },
    {
      "epoch": 0.5652173913043478,
      "grad_norm": 10.824867248535156,
      "learning_rate": 1.8298852919990254e-05,
      "loss": 0.4119,
      "step": 832
    },
    {
      "epoch": 0.5658967391304348,
      "grad_norm": 2.461160182952881,
      "learning_rate": 1.829488161396383e-05,
      "loss": 0.0572,
      "step": 833
    },
    {
      "epoch": 0.5665760869565217,
      "grad_norm": 3.044496774673462,
      "learning_rate": 1.8290906109846974e-05,
      "loss": 0.2036,
      "step": 834
    },
    {
      "epoch": 0.5672554347826086,
      "grad_norm": 1.4554696083068848,
      "learning_rate": 1.8286926409651714e-05,
      "loss": 0.0755,
      "step": 835
    },
    {
      "epoch": 0.5679347826086957,
      "grad_norm": 3.3621442317962646,
      "learning_rate": 1.82829425153922e-05,
      "loss": 0.2014,
      "step": 836
    },
    {
      "epoch": 0.5686141304347826,
      "grad_norm": 5.8252177238464355,
      "learning_rate": 1.82789544290847e-05,
      "loss": 0.2007,
      "step": 837
    },
    {
      "epoch": 0.5692934782608695,
      "grad_norm": 1.8683897256851196,
      "learning_rate": 1.8274962152747613e-05,
      "loss": 0.0814,
      "step": 838
    },
    {
      "epoch": 0.5699728260869565,
      "grad_norm": 2.816164016723633,
      "learning_rate": 1.8270965688401453e-05,
      "loss": 0.1799,
      "step": 839
    },
    {
      "epoch": 0.5706521739130435,
      "grad_norm": 2.420531749725342,
      "learning_rate": 1.8266965038068856e-05,
      "loss": 0.0443,
      "step": 840
    },
    {
      "epoch": 0.5713315217391305,
      "grad_norm": 2.9043524265289307,
      "learning_rate": 1.8262960203774584e-05,
      "loss": 0.1342,
      "step": 841
    },
    {
      "epoch": 0.5720108695652174,
      "grad_norm": 3.785320281982422,
      "learning_rate": 1.825895118754549e-05,
      "loss": 0.2231,
      "step": 842
    },
    {
      "epoch": 0.5726902173913043,
      "grad_norm": 2.701789379119873,
      "learning_rate": 1.825493799141058e-05,
      "loss": 0.1012,
      "step": 843
    },
    {
      "epoch": 0.5733695652173914,
      "grad_norm": 1.6497129201889038,
      "learning_rate": 1.8250920617400943e-05,
      "loss": 0.0083,
      "step": 844
    },
    {
      "epoch": 0.5740489130434783,
      "grad_norm": 2.9322166442871094,
      "learning_rate": 1.8246899067549804e-05,
      "loss": 0.034,
      "step": 845
    },
    {
      "epoch": 0.5747282608695652,
      "grad_norm": 0.0730520710349083,
      "learning_rate": 1.8242873343892494e-05,
      "loss": 0.0006,
      "step": 846
    },
    {
      "epoch": 0.5754076086956522,
      "grad_norm": 4.204582214355469,
      "learning_rate": 1.8238843448466456e-05,
      "loss": 0.1396,
      "step": 847
    },
    {
      "epoch": 0.5760869565217391,
      "grad_norm": 9.420333862304688,
      "learning_rate": 1.823480938331124e-05,
      "loss": 0.3901,
      "step": 848
    },
    {
      "epoch": 0.576766304347826,
      "grad_norm": 1.1863024234771729,
      "learning_rate": 1.8230771150468517e-05,
      "loss": 0.0101,
      "step": 849
    },
    {
      "epoch": 0.5774456521739131,
      "grad_norm": 2.145416021347046,
      "learning_rate": 1.822672875198206e-05,
      "loss": 0.059,
      "step": 850
    },
    {
      "epoch": 0.578125,
      "grad_norm": 1.5710573196411133,
      "learning_rate": 1.822268218989775e-05,
      "loss": 0.0754,
      "step": 851
    },
    {
      "epoch": 0.5788043478260869,
      "grad_norm": 4.766087532043457,
      "learning_rate": 1.8218631466263584e-05,
      "loss": 0.0574,
      "step": 852
    },
    {
      "epoch": 0.579483695652174,
      "grad_norm": 1.6849473714828491,
      "learning_rate": 1.8214576583129646e-05,
      "loss": 0.0442,
      "step": 853
    },
    {
      "epoch": 0.5801630434782609,
      "grad_norm": 4.404601097106934,
      "learning_rate": 1.8210517542548145e-05,
      "loss": 0.0373,
      "step": 854
    },
    {
      "epoch": 0.5808423913043478,
      "grad_norm": 0.023418188095092773,
      "learning_rate": 1.820645434657338e-05,
      "loss": 0.0004,
      "step": 855
    },
    {
      "epoch": 0.5815217391304348,
      "grad_norm": 0.04981400445103645,
      "learning_rate": 1.820238699726177e-05,
      "loss": 0.0005,
      "step": 856
    },
    {
      "epoch": 0.5822010869565217,
      "grad_norm": 2.8698697090148926,
      "learning_rate": 1.8198315496671815e-05,
      "loss": 0.0367,
      "step": 857
    },
    {
      "epoch": 0.5828804347826086,
      "grad_norm": 3.55391001701355,
      "learning_rate": 1.8194239846864133e-05,
      "loss": 0.1283,
      "step": 858
    },
    {
      "epoch": 0.5835597826086957,
      "grad_norm": 1.5491890907287598,
      "learning_rate": 1.819016004990143e-05,
      "loss": 0.0561,
      "step": 859
    },
    {
      "epoch": 0.5842391304347826,
      "grad_norm": 0.00868503749370575,
      "learning_rate": 1.8186076107848524e-05,
      "loss": 0.0002,
      "step": 860
    },
    {
      "epoch": 0.5849184782608695,
      "grad_norm": 7.124699592590332,
      "learning_rate": 1.8181988022772315e-05,
      "loss": 0.1772,
      "step": 861
    },
    {
      "epoch": 0.5855978260869565,
      "grad_norm": 0.11131551116704941,
      "learning_rate": 1.817789579674181e-05,
      "loss": 0.0011,
      "step": 862
    },
    {
      "epoch": 0.5862771739130435,
      "grad_norm": 0.009927459061145782,
      "learning_rate": 1.8173799431828116e-05,
      "loss": 0.0002,
      "step": 863
    },
    {
      "epoch": 0.5869565217391305,
      "grad_norm": 4.2504072189331055,
      "learning_rate": 1.816969893010442e-05,
      "loss": 0.1165,
      "step": 864
    },
    {
      "epoch": 0.5876358695652174,
      "grad_norm": 0.006750602275133133,
      "learning_rate": 1.8165594293646016e-05,
      "loss": 0.0001,
      "step": 865
    },
    {
      "epoch": 0.5883152173913043,
      "grad_norm": 3.6556644439697266,
      "learning_rate": 1.8161485524530283e-05,
      "loss": 0.073,
      "step": 866
    },
    {
      "epoch": 0.5889945652173914,
      "grad_norm": 3.582205295562744,
      "learning_rate": 1.81573726248367e-05,
      "loss": 0.2052,
      "step": 867
    },
    {
      "epoch": 0.5896739130434783,
      "grad_norm": 21.125341415405273,
      "learning_rate": 1.8153255596646818e-05,
      "loss": 0.6041,
      "step": 868
    },
    {
      "epoch": 0.5903532608695652,
      "grad_norm": 0.5768905282020569,
      "learning_rate": 1.8149134442044305e-05,
      "loss": 0.007,
      "step": 869
    },
    {
      "epoch": 0.5910326086956522,
      "grad_norm": 15.728450775146484,
      "learning_rate": 1.8145009163114894e-05,
      "loss": 0.2147,
      "step": 870
    },
    {
      "epoch": 0.5917119565217391,
      "grad_norm": 0.8053457140922546,
      "learning_rate": 1.8140879761946414e-05,
      "loss": 0.0069,
      "step": 871
    },
    {
      "epoch": 0.592391304347826,
      "grad_norm": 17.30498695373535,
      "learning_rate": 1.8136746240628783e-05,
      "loss": 0.2845,
      "step": 872
    },
    {
      "epoch": 0.5930706521739131,
      "grad_norm": 0.008083879016339779,
      "learning_rate": 1.8132608601254003e-05,
      "loss": 0.0001,
      "step": 873
    },
    {
      "epoch": 0.59375,
      "grad_norm": 5.152544975280762,
      "learning_rate": 1.8128466845916156e-05,
      "loss": 0.0815,
      "step": 874
    },
    {
      "epoch": 0.5944293478260869,
      "grad_norm": 14.931382179260254,
      "learning_rate": 1.8124320976711404e-05,
      "loss": 0.4302,
      "step": 875
    },
    {
      "epoch": 0.595108695652174,
      "grad_norm": 0.009930805303156376,
      "learning_rate": 1.812017099573801e-05,
      "loss": 0.0001,
      "step": 876
    },
    {
      "epoch": 0.5957880434782609,
      "grad_norm": 0.0486995130777359,
      "learning_rate": 1.8116016905096295e-05,
      "loss": 0.0005,
      "step": 877
    },
    {
      "epoch": 0.5964673913043478,
      "grad_norm": 0.31844350695610046,
      "learning_rate": 1.8111858706888673e-05,
      "loss": 0.0028,
      "step": 878
    },
    {
      "epoch": 0.5971467391304348,
      "grad_norm": 5.707702159881592,
      "learning_rate": 1.810769640321963e-05,
      "loss": 0.2178,
      "step": 879
    },
    {
      "epoch": 0.5978260869565217,
      "grad_norm": 3.8134777545928955,
      "learning_rate": 1.810352999619574e-05,
      "loss": 0.1741,
      "step": 880
    },
    {
      "epoch": 0.5985054347826086,
      "grad_norm": 0.18594859540462494,
      "learning_rate": 1.8099359487925644e-05,
      "loss": 0.0018,
      "step": 881
    },
    {
      "epoch": 0.5991847826086957,
      "grad_norm": 17.534610748291016,
      "learning_rate": 1.8095184880520058e-05,
      "loss": 0.1184,
      "step": 882
    },
    {
      "epoch": 0.5998641304347826,
      "grad_norm": 1.7025840282440186,
      "learning_rate": 1.809100617609178e-05,
      "loss": 0.0189,
      "step": 883
    },
    {
      "epoch": 0.6005434782608695,
      "grad_norm": 3.110318899154663,
      "learning_rate": 1.808682337675568e-05,
      "loss": 0.0839,
      "step": 884
    },
    {
      "epoch": 0.6012228260869565,
      "grad_norm": 0.10265153646469116,
      "learning_rate": 1.80826364846287e-05,
      "loss": 0.0008,
      "step": 885
    },
    {
      "epoch": 0.6019021739130435,
      "grad_norm": 15.328635215759277,
      "learning_rate": 1.807844550182984e-05,
      "loss": 0.0894,
      "step": 886
    },
    {
      "epoch": 0.6025815217391305,
      "grad_norm": 1.7138032913208008,
      "learning_rate": 1.8074250430480193e-05,
      "loss": 0.0306,
      "step": 887
    },
    {
      "epoch": 0.6032608695652174,
      "grad_norm": 0.01313195750117302,
      "learning_rate": 1.8070051272702905e-05,
      "loss": 0.0002,
      "step": 888
    },
    {
      "epoch": 0.6039402173913043,
      "grad_norm": 10.72237491607666,
      "learning_rate": 1.8065848030623203e-05,
      "loss": 0.1219,
      "step": 889
    },
    {
      "epoch": 0.6046195652173914,
      "grad_norm": 0.046778708696365356,
      "learning_rate": 1.8061640706368364e-05,
      "loss": 0.0004,
      "step": 890
    },
    {
      "epoch": 0.6052989130434783,
      "grad_norm": 6.296620845794678,
      "learning_rate": 1.8057429302067748e-05,
      "loss": 0.1316,
      "step": 891
    },
    {
      "epoch": 0.6059782608695652,
      "grad_norm": 0.648980438709259,
      "learning_rate": 1.8053213819852765e-05,
      "loss": 0.008,
      "step": 892
    },
    {
      "epoch": 0.6066576086956522,
      "grad_norm": 0.017763203009963036,
      "learning_rate": 1.8048994261856908e-05,
      "loss": 0.0003,
      "step": 893
    },
    {
      "epoch": 0.6073369565217391,
      "grad_norm": 4.547799587249756,
      "learning_rate": 1.8044770630215706e-05,
      "loss": 0.2809,
      "step": 894
    },
    {
      "epoch": 0.608016304347826,
      "grad_norm": 2.8207297325134277,
      "learning_rate": 1.804054292706678e-05,
      "loss": 0.0727,
      "step": 895
    },
    {
      "epoch": 0.6086956521739131,
      "grad_norm": 1.2127082347869873,
      "learning_rate": 1.8036311154549783e-05,
      "loss": 0.0228,
      "step": 896
    },
    {
      "epoch": 0.609375,
      "grad_norm": 0.29792672395706177,
      "learning_rate": 1.803207531480645e-05,
      "loss": 0.0019,
      "step": 897
    },
    {
      "epoch": 0.6100543478260869,
      "grad_norm": 0.6066359877586365,
      "learning_rate": 1.8027835409980565e-05,
      "loss": 0.006,
      "step": 898
    },
    {
      "epoch": 0.610733695652174,
      "grad_norm": 0.053608402609825134,
      "learning_rate": 1.8023591442217965e-05,
      "loss": 0.0006,
      "step": 899
    },
    {
      "epoch": 0.6114130434782609,
      "grad_norm": 9.118043899536133,
      "learning_rate": 1.801934341366655e-05,
      "loss": 0.3535,
      "step": 900
    },
    {
      "epoch": 0.6120923913043478,
      "grad_norm": 3.3100571632385254,
      "learning_rate": 1.8015091326476275e-05,
      "loss": 0.1642,
      "step": 901
    },
    {
      "epoch": 0.6127717391304348,
      "grad_norm": 0.3767133355140686,
      "learning_rate": 1.801083518279915e-05,
      "loss": 0.0035,
      "step": 902
    },
    {
      "epoch": 0.6134510869565217,
      "grad_norm": 0.031552594155073166,
      "learning_rate": 1.8006574984789226e-05,
      "loss": 0.0003,
      "step": 903
    },
    {
      "epoch": 0.6141304347826086,
      "grad_norm": 10.566083908081055,
      "learning_rate": 1.8002310734602625e-05,
      "loss": 0.1594,
      "step": 904
    },
    {
      "epoch": 0.6148097826086957,
      "grad_norm": 5.172733783721924,
      "learning_rate": 1.7998042434397507e-05,
      "loss": 0.0529,
      "step": 905
    },
    {
      "epoch": 0.6154891304347826,
      "grad_norm": 0.08535879850387573,
      "learning_rate": 1.7993770086334082e-05,
      "loss": 0.0009,
      "step": 906
    },
    {
      "epoch": 0.6161684782608695,
      "grad_norm": 3.009850025177002,
      "learning_rate": 1.7989493692574614e-05,
      "loss": 0.0439,
      "step": 907
    },
    {
      "epoch": 0.6168478260869565,
      "grad_norm": 1.66839599609375,
      "learning_rate": 1.7985213255283412e-05,
      "loss": 0.0103,
      "step": 908
    },
    {
      "epoch": 0.6175271739130435,
      "grad_norm": 1.8787705898284912,
      "learning_rate": 1.7980928776626833e-05,
      "loss": 0.0829,
      "step": 909
    },
    {
      "epoch": 0.6182065217391305,
      "grad_norm": 16.66822052001953,
      "learning_rate": 1.797664025877327e-05,
      "loss": 0.3444,
      "step": 910
    },
    {
      "epoch": 0.6188858695652174,
      "grad_norm": 11.75096607208252,
      "learning_rate": 1.7972347703893184e-05,
      "loss": 0.4044,
      "step": 911
    },
    {
      "epoch": 0.6195652173913043,
      "grad_norm": 3.726106643676758,
      "learning_rate": 1.7968051114159046e-05,
      "loss": 0.1543,
      "step": 912
    },
    {
      "epoch": 0.6202445652173914,
      "grad_norm": 0.007387351244688034,
      "learning_rate": 1.79637504917454e-05,
      "loss": 0.0001,
      "step": 913
    },
    {
      "epoch": 0.6209239130434783,
      "grad_norm": 2.0158023834228516,
      "learning_rate": 1.795944583882881e-05,
      "loss": 0.0325,
      "step": 914
    },
    {
      "epoch": 0.6216032608695652,
      "grad_norm": 5.396486282348633,
      "learning_rate": 1.7955137157587886e-05,
      "loss": 0.1409,
      "step": 915
    },
    {
      "epoch": 0.6222826086956522,
      "grad_norm": 0.30835065245628357,
      "learning_rate": 1.7950824450203283e-05,
      "loss": 0.0019,
      "step": 916
    },
    {
      "epoch": 0.6229619565217391,
      "grad_norm": 0.0145802553743124,
      "learning_rate": 1.7946507718857686e-05,
      "loss": 0.0002,
      "step": 917
    },
    {
      "epoch": 0.623641304347826,
      "grad_norm": 15.802399635314941,
      "learning_rate": 1.794218696573582e-05,
      "loss": 0.2373,
      "step": 918
    },
    {
      "epoch": 0.6243206521739131,
      "grad_norm": 0.8504178524017334,
      "learning_rate": 1.7937862193024446e-05,
      "loss": 0.0094,
      "step": 919
    },
    {
      "epoch": 0.625,
      "grad_norm": 17.885719299316406,
      "learning_rate": 1.7933533402912354e-05,
      "loss": 0.1341,
      "step": 920
    },
    {
      "epoch": 0.6256793478260869,
      "grad_norm": 2.669830560684204,
      "learning_rate": 1.7929200597590375e-05,
      "loss": 0.0855,
      "step": 921
    },
    {
      "epoch": 0.626358695652174,
      "grad_norm": 0.005550442263484001,
      "learning_rate": 1.7924863779251366e-05,
      "loss": 0.0001,
      "step": 922
    },
    {
      "epoch": 0.6270380434782609,
      "grad_norm": 0.035279225558042526,
      "learning_rate": 1.792052295009022e-05,
      "loss": 0.0001,
      "step": 923
    },
    {
      "epoch": 0.6277173913043478,
      "grad_norm": 3.0359456539154053,
      "learning_rate": 1.791617811230385e-05,
      "loss": 0.0653,
      "step": 924
    },
    {
      "epoch": 0.6283967391304348,
      "grad_norm": 5.587945461273193,
      "learning_rate": 1.7911829268091213e-05,
      "loss": 0.2547,
      "step": 925
    },
    {
      "epoch": 0.6290760869565217,
      "grad_norm": 3.790417432785034,
      "learning_rate": 1.7907476419653287e-05,
      "loss": 0.1527,
      "step": 926
    },
    {
      "epoch": 0.6297554347826086,
      "grad_norm": 14.417975425720215,
      "learning_rate": 1.7903119569193066e-05,
      "loss": 0.655,
      "step": 927
    },
    {
      "epoch": 0.6304347826086957,
      "grad_norm": 2.256422281265259,
      "learning_rate": 1.789875871891559e-05,
      "loss": 0.1132,
      "step": 928
    },
    {
      "epoch": 0.6311141304347826,
      "grad_norm": 2.475022315979004,
      "learning_rate": 1.7894393871027903e-05,
      "loss": 0.0704,
      "step": 929
    },
    {
      "epoch": 0.6317934782608695,
      "grad_norm": 9.018959999084473,
      "learning_rate": 1.7890025027739084e-05,
      "loss": 0.3211,
      "step": 930
    },
    {
      "epoch": 0.6324728260869565,
      "grad_norm": 8.2802152633667,
      "learning_rate": 1.788565219126023e-05,
      "loss": 0.1246,
      "step": 931
    },
    {
      "epoch": 0.6331521739130435,
      "grad_norm": 3.4171652793884277,
      "learning_rate": 1.7881275363804465e-05,
      "loss": 0.1505,
      "step": 932
    },
    {
      "epoch": 0.6338315217391305,
      "grad_norm": 0.006108957342803478,
      "learning_rate": 1.7876894547586924e-05,
      "loss": 0.0001,
      "step": 933
    },
    {
      "epoch": 0.6345108695652174,
      "grad_norm": 0.7215098738670349,
      "learning_rate": 1.787250974482477e-05,
      "loss": 0.0042,
      "step": 934
    },
    {
      "epoch": 0.6351902173913043,
      "grad_norm": 4.153552055358887,
      "learning_rate": 1.7868120957737173e-05,
      "loss": 0.1318,
      "step": 935
    },
    {
      "epoch": 0.6358695652173914,
      "grad_norm": 11.92782974243164,
      "learning_rate": 1.7863728188545326e-05,
      "loss": 0.1403,
      "step": 936
    },
    {
      "epoch": 0.6365489130434783,
      "grad_norm": 3.889890432357788,
      "learning_rate": 1.7859331439472438e-05,
      "loss": 0.1478,
      "step": 937
    },
    {
      "epoch": 0.6372282608695652,
      "grad_norm": 29.16872215270996,
      "learning_rate": 1.785493071274373e-05,
      "loss": 0.4006,
      "step": 938
    },
    {
      "epoch": 0.6379076086956522,
      "grad_norm": 0.28119605779647827,
      "learning_rate": 1.7850526010586437e-05,
      "loss": 0.0022,
      "step": 939
    },
    {
      "epoch": 0.6385869565217391,
      "grad_norm": 0.009585488587617874,
      "learning_rate": 1.7846117335229808e-05,
      "loss": 0.0001,
      "step": 940
    },
    {
      "epoch": 0.639266304347826,
      "grad_norm": 6.860721111297607,
      "learning_rate": 1.7841704688905093e-05,
      "loss": 0.0778,
      "step": 941
    },
    {
      "epoch": 0.6399456521739131,
      "grad_norm": 7.075294494628906,
      "learning_rate": 1.7837288073845566e-05,
      "loss": 0.0749,
      "step": 942
    },
    {
      "epoch": 0.640625,
      "grad_norm": 0.12586992979049683,
      "learning_rate": 1.7832867492286506e-05,
      "loss": 0.0007,
      "step": 943
    },
    {
      "epoch": 0.6413043478260869,
      "grad_norm": 0.3780277967453003,
      "learning_rate": 1.7828442946465188e-05,
      "loss": 0.0026,
      "step": 944
    },
    {
      "epoch": 0.641983695652174,
      "grad_norm": 4.7584991455078125,
      "learning_rate": 1.7824014438620906e-05,
      "loss": 0.058,
      "step": 945
    },
    {
      "epoch": 0.6426630434782609,
      "grad_norm": 4.341507434844971,
      "learning_rate": 1.7819581970994955e-05,
      "loss": 0.0903,
      "step": 946
    },
    {
      "epoch": 0.6433423913043478,
      "grad_norm": 1.5199620723724365,
      "learning_rate": 1.7815145545830638e-05,
      "loss": 0.0661,
      "step": 947
    },
    {
      "epoch": 0.6440217391304348,
      "grad_norm": 0.26970601081848145,
      "learning_rate": 1.7810705165373245e-05,
      "loss": 0.003,
      "step": 948
    },
    {
      "epoch": 0.6447010869565217,
      "grad_norm": 4.906480312347412,
      "learning_rate": 1.7806260831870092e-05,
      "loss": 0.1727,
      "step": 949
    },
    {
      "epoch": 0.6453804347826086,
      "grad_norm": 1.8001381158828735,
      "learning_rate": 1.780181254757048e-05,
      "loss": 0.0918,
      "step": 950
    },
    {
      "epoch": 0.6460597826086957,
      "grad_norm": 0.017574135214090347,
      "learning_rate": 1.7797360314725707e-05,
      "loss": 0.0002,
      "step": 951
    },
    {
      "epoch": 0.6467391304347826,
      "grad_norm": 7.10784387588501,
      "learning_rate": 1.7792904135589085e-05,
      "loss": 0.3045,
      "step": 952
    },
    {
      "epoch": 0.6474184782608695,
      "grad_norm": 15.26378345489502,
      "learning_rate": 1.7788444012415905e-05,
      "loss": 0.1606,
      "step": 953
    },
    {
      "epoch": 0.6480978260869565,
      "grad_norm": 13.783862113952637,
      "learning_rate": 1.778397994746347e-05,
      "loss": 0.1736,
      "step": 954
    },
    {
      "epoch": 0.6487771739130435,
      "grad_norm": 4.949047088623047,
      "learning_rate": 1.7779511942991065e-05,
      "loss": 0.1965,
      "step": 955
    },
    {
      "epoch": 0.6494565217391305,
      "grad_norm": 2.561997890472412,
      "learning_rate": 1.7775040001259976e-05,
      "loss": 0.1071,
      "step": 956
    },
    {
      "epoch": 0.6501358695652174,
      "grad_norm": 0.006502049509435892,
      "learning_rate": 1.777056412453348e-05,
      "loss": 0.0001,
      "step": 957
    },
    {
      "epoch": 0.6508152173913043,
      "grad_norm": 2.517810583114624,
      "learning_rate": 1.776608431507685e-05,
      "loss": 0.1221,
      "step": 958
    },
    {
      "epoch": 0.6514945652173914,
      "grad_norm": 3.2515814304351807,
      "learning_rate": 1.776160057515734e-05,
      "loss": 0.2189,
      "step": 959
    },
    {
      "epoch": 0.6521739130434783,
      "grad_norm": 1.1497446298599243,
      "learning_rate": 1.77571129070442e-05,
      "loss": 0.021,
      "step": 960
    },
    {
      "epoch": 0.6528532608695652,
      "grad_norm": 4.99002742767334,
      "learning_rate": 1.7752621313008663e-05,
      "loss": 0.0826,
      "step": 961
    },
    {
      "epoch": 0.6535326086956522,
      "grad_norm": 14.21081829071045,
      "learning_rate": 1.774812579532396e-05,
      "loss": 0.2102,
      "step": 962
    },
    {
      "epoch": 0.6542119565217391,
      "grad_norm": 5.027926921844482,
      "learning_rate": 1.7743626356265292e-05,
      "loss": 0.2427,
      "step": 963
    },
    {
      "epoch": 0.654891304347826,
      "grad_norm": 8.342817306518555,
      "learning_rate": 1.7739122998109857e-05,
      "loss": 0.1046,
      "step": 964
    },
    {
      "epoch": 0.6555706521739131,
      "grad_norm": 1.998294472694397,
      "learning_rate": 1.773461572313683e-05,
      "loss": 0.057,
      "step": 965
    },
    {
      "epoch": 0.65625,
      "grad_norm": 0.12386923283338547,
      "learning_rate": 1.773010453362737e-05,
      "loss": 0.0011,
      "step": 966
    },
    {
      "epoch": 0.6569293478260869,
      "grad_norm": 0.3273298442363739,
      "learning_rate": 1.7725589431864622e-05,
      "loss": 0.0039,
      "step": 967
    },
    {
      "epoch": 0.657608695652174,
      "grad_norm": 18.914011001586914,
      "learning_rate": 1.7721070420133702e-05,
      "loss": 0.5477,
      "step": 968
    },
    {
      "epoch": 0.6582880434782609,
      "grad_norm": 14.537581443786621,
      "learning_rate": 1.7716547500721715e-05,
      "loss": 0.4098,
      "step": 969
    },
    {
      "epoch": 0.6589673913043478,
      "grad_norm": 0.03419581055641174,
      "learning_rate": 1.7712020675917734e-05,
      "loss": 0.0004,
      "step": 970
    },
    {
      "epoch": 0.6596467391304348,
      "grad_norm": 2.605675220489502,
      "learning_rate": 1.770748994801281e-05,
      "loss": 0.0322,
      "step": 971
    },
    {
      "epoch": 0.6603260869565217,
      "grad_norm": 5.162605285644531,
      "learning_rate": 1.770295531929998e-05,
      "loss": 0.1878,
      "step": 972
    },
    {
      "epoch": 0.6610054347826086,
      "grad_norm": 15.765323638916016,
      "learning_rate": 1.769841679207424e-05,
      "loss": 0.1579,
      "step": 973
    },
    {
      "epoch": 0.6616847826086957,
      "grad_norm": 0.01410304382443428,
      "learning_rate": 1.769387436863257e-05,
      "loss": 0.0001,
      "step": 974
    },
    {
      "epoch": 0.6623641304347826,
      "grad_norm": 4.287075042724609,
      "learning_rate": 1.768932805127392e-05,
      "loss": 0.1103,
      "step": 975
    },
    {
      "epoch": 0.6630434782608695,
      "grad_norm": 4.042736530303955,
      "learning_rate": 1.7684777842299206e-05,
      "loss": 0.1033,
      "step": 976
    },
    {
      "epoch": 0.6637228260869565,
      "grad_norm": 19.204736709594727,
      "learning_rate": 1.7680223744011315e-05,
      "loss": 0.7917,
      "step": 977
    },
    {
      "epoch": 0.6644021739130435,
      "grad_norm": 0.07758446037769318,
      "learning_rate": 1.767566575871511e-05,
      "loss": 0.0006,
      "step": 978
    },
    {
      "epoch": 0.6650815217391305,
      "grad_norm": 1.1736265420913696,
      "learning_rate": 1.767110388871741e-05,
      "loss": 0.0086,
      "step": 979
    },
    {
      "epoch": 0.6657608695652174,
      "grad_norm": 0.019456692039966583,
      "learning_rate": 1.7666538136327007e-05,
      "loss": 0.0002,
      "step": 980
    },
    {
      "epoch": 0.6664402173913043,
      "grad_norm": 3.442884683609009,
      "learning_rate": 1.766196850385466e-05,
      "loss": 0.0294,
      "step": 981
    },
    {
      "epoch": 0.6671195652173914,
      "grad_norm": 8.440053939819336,
      "learning_rate": 1.7657394993613078e-05,
      "loss": 0.2271,
      "step": 982
    },
    {
      "epoch": 0.6677989130434783,
      "grad_norm": 0.06383752077817917,
      "learning_rate": 1.7652817607916957e-05,
      "loss": 0.0006,
      "step": 983
    },
    {
      "epoch": 0.6684782608695652,
      "grad_norm": 4.531557083129883,
      "learning_rate": 1.7648236349082928e-05,
      "loss": 0.2291,
      "step": 984
    },
    {
      "epoch": 0.6691576086956522,
      "grad_norm": 13.894609451293945,
      "learning_rate": 1.7643651219429602e-05,
      "loss": 0.0881,
      "step": 985
    },
    {
      "epoch": 0.6698369565217391,
      "grad_norm": 2.5329487323760986,
      "learning_rate": 1.7639062221277533e-05,
      "loss": 0.0093,
      "step": 986
    },
    {
      "epoch": 0.670516304347826,
      "grad_norm": 0.02310699038207531,
      "learning_rate": 1.7634469356949246e-05,
      "loss": 0.0003,
      "step": 987
    },
    {
      "epoch": 0.6711956521739131,
      "grad_norm": 4.024659156799316,
      "learning_rate": 1.7629872628769222e-05,
      "loss": 0.1429,
      "step": 988
    },
    {
      "epoch": 0.671875,
      "grad_norm": 0.28274428844451904,
      "learning_rate": 1.7625272039063884e-05,
      "loss": 0.0023,
      "step": 989
    },
    {
      "epoch": 0.6725543478260869,
      "grad_norm": 6.132426738739014,
      "learning_rate": 1.7620667590161626e-05,
      "loss": 0.1699,
      "step": 990
    },
    {
      "epoch": 0.673233695652174,
      "grad_norm": 2.359194040298462,
      "learning_rate": 1.7616059284392783e-05,
      "loss": 0.122,
      "step": 991
    },
    {
      "epoch": 0.6739130434782609,
      "grad_norm": 1.9210922718048096,
      "learning_rate": 1.761144712408965e-05,
      "loss": 0.0832,
      "step": 992
    },
    {
      "epoch": 0.6745923913043478,
      "grad_norm": 1.972703218460083,
      "learning_rate": 1.7606831111586467e-05,
      "loss": 0.096,
      "step": 993
    },
    {
      "epoch": 0.6752717391304348,
      "grad_norm": 0.4278907775878906,
      "learning_rate": 1.7602211249219433e-05,
      "loss": 0.0031,
      "step": 994
    },
    {
      "epoch": 0.6759510869565217,
      "grad_norm": 4.945072650909424,
      "learning_rate": 1.7597587539326677e-05,
      "loss": 0.1033,
      "step": 995
    },
    {
      "epoch": 0.6766304347826086,
      "grad_norm": 5.779685974121094,
      "learning_rate": 1.75929599842483e-05,
      "loss": 0.1912,
      "step": 996
    },
    {
      "epoch": 0.6773097826086957,
      "grad_norm": 2.9676718711853027,
      "learning_rate": 1.7588328586326325e-05,
      "loss": 0.1274,
      "step": 997
    },
    {
      "epoch": 0.6779891304347826,
      "grad_norm": 0.01552977692335844,
      "learning_rate": 1.7583693347904736e-05,
      "loss": 0.0002,
      "step": 998
    },
    {
      "epoch": 0.6786684782608695,
      "grad_norm": 1.6731913089752197,
      "learning_rate": 1.7579054271329457e-05,
      "loss": 0.0138,
      "step": 999
    },
    {
      "epoch": 0.6793478260869565,
      "grad_norm": 3.646669864654541,
      "learning_rate": 1.7574411358948347e-05,
      "loss": 0.1818,
      "step": 1000
    },
    {
      "epoch": 0.6800271739130435,
      "grad_norm": 0.06294898688793182,
      "learning_rate": 1.7569764613111216e-05,
      "loss": 0.0007,
      "step": 1001
    },
    {
      "epoch": 0.6807065217391305,
      "grad_norm": 0.05493376404047012,
      "learning_rate": 1.756511403616982e-05,
      "loss": 0.0004,
      "step": 1002
    },
    {
      "epoch": 0.6813858695652174,
      "grad_norm": 0.011150224134325981,
      "learning_rate": 1.7560459630477828e-05,
      "loss": 0.0002,
      "step": 1003
    },
    {
      "epoch": 0.6820652173913043,
      "grad_norm": 2.4156599044799805,
      "learning_rate": 1.755580139839087e-05,
      "loss": 0.0722,
      "step": 1004
    },
    {
      "epoch": 0.6827445652173914,
      "grad_norm": 2.422325849533081,
      "learning_rate": 1.755113934226651e-05,
      "loss": 0.0916,
      "step": 1005
    },
    {
      "epoch": 0.6834239130434783,
      "grad_norm": 3.6420042514801025,
      "learning_rate": 1.7546473464464237e-05,
      "loss": 0.1963,
      "step": 1006
    },
    {
      "epoch": 0.6841032608695652,
      "grad_norm": 2.284209728240967,
      "learning_rate": 1.7541803767345484e-05,
      "loss": 0.0627,
      "step": 1007
    },
    {
      "epoch": 0.6847826086956522,
      "grad_norm": 17.076740264892578,
      "learning_rate": 1.7537130253273613e-05,
      "loss": 0.9621,
      "step": 1008
    },
    {
      "epoch": 0.6854619565217391,
      "grad_norm": 2.1916167736053467,
      "learning_rate": 1.753245292461392e-05,
      "loss": 0.1273,
      "step": 1009
    },
    {
      "epoch": 0.686141304347826,
      "grad_norm": 3.188335418701172,
      "learning_rate": 1.7527771783733622e-05,
      "loss": 0.1436,
      "step": 1010
    },
    {
      "epoch": 0.6868206521739131,
      "grad_norm": 0.09143046289682388,
      "learning_rate": 1.752308683300188e-05,
      "loss": 0.0007,
      "step": 1011
    },
    {
      "epoch": 0.6875,
      "grad_norm": 0.012099302373826504,
      "learning_rate": 1.7518398074789776e-05,
      "loss": 0.0002,
      "step": 1012
    },
    {
      "epoch": 0.6881793478260869,
      "grad_norm": 2.9306833744049072,
      "learning_rate": 1.7513705511470317e-05,
      "loss": 0.0154,
      "step": 1013
    },
    {
      "epoch": 0.688858695652174,
      "grad_norm": 0.005093787331134081,
      "learning_rate": 1.750900914541844e-05,
      "loss": 0.0001,
      "step": 1014
    },
    {
      "epoch": 0.6895380434782609,
      "grad_norm": 2.930687427520752,
      "learning_rate": 1.7504308979011004e-05,
      "loss": 0.0257,
      "step": 1015
    },
    {
      "epoch": 0.6902173913043478,
      "grad_norm": 3.1183433532714844,
      "learning_rate": 1.7499605014626786e-05,
      "loss": 0.1269,
      "step": 1016
    },
    {
      "epoch": 0.6908967391304348,
      "grad_norm": 0.35056787729263306,
      "learning_rate": 1.7494897254646503e-05,
      "loss": 0.0024,
      "step": 1017
    },
    {
      "epoch": 0.6915760869565217,
      "grad_norm": 15.277763366699219,
      "learning_rate": 1.7490185701452774e-05,
      "loss": 0.2969,
      "step": 1018
    },
    {
      "epoch": 0.6922554347826086,
      "grad_norm": 2.2933359146118164,
      "learning_rate": 1.7485470357430145e-05,
      "loss": 0.0503,
      "step": 1019
    },
    {
      "epoch": 0.6929347826086957,
      "grad_norm": 3.235081434249878,
      "learning_rate": 1.7480751224965083e-05,
      "loss": 0.1323,
      "step": 1020
    },
    {
      "epoch": 0.6936141304347826,
      "grad_norm": 6.911288738250732,
      "learning_rate": 1.7476028306445966e-05,
      "loss": 0.0588,
      "step": 1021
    },
    {
      "epoch": 0.6942934782608695,
      "grad_norm": 4.19899845123291,
      "learning_rate": 1.7471301604263095e-05,
      "loss": 0.1203,
      "step": 1022
    },
    {
      "epoch": 0.6949728260869565,
      "grad_norm": 12.523709297180176,
      "learning_rate": 1.7466571120808684e-05,
      "loss": 0.5688,
      "step": 1023
    },
    {
      "epoch": 0.6956521739130435,
      "grad_norm": 2.1181766986846924,
      "learning_rate": 1.7461836858476858e-05,
      "loss": 0.1546,
      "step": 1024
    },
    {
      "epoch": 0.6963315217391305,
      "grad_norm": 4.330661296844482,
      "learning_rate": 1.7457098819663653e-05,
      "loss": 0.1411,
      "step": 1025
    },
    {
      "epoch": 0.6970108695652174,
      "grad_norm": 3.8455777168273926,
      "learning_rate": 1.7452357006767026e-05,
      "loss": 0.063,
      "step": 1026
    },
    {
      "epoch": 0.6976902173913043,
      "grad_norm": 1.1488611698150635,
      "learning_rate": 1.744761142218683e-05,
      "loss": 0.0068,
      "step": 1027
    },
    {
      "epoch": 0.6983695652173914,
      "grad_norm": 2.8640010356903076,
      "learning_rate": 1.7442862068324843e-05,
      "loss": 0.1168,
      "step": 1028
    },
    {
      "epoch": 0.6990489130434783,
      "grad_norm": 8.744491577148438,
      "learning_rate": 1.7438108947584737e-05,
      "loss": 0.1865,
      "step": 1029
    },
    {
      "epoch": 0.6997282608695652,
      "grad_norm": 1.5427560806274414,
      "learning_rate": 1.7433352062372098e-05,
      "loss": 0.0066,
      "step": 1030
    },
    {
      "epoch": 0.7004076086956522,
      "grad_norm": 4.143617153167725,
      "learning_rate": 1.7428591415094408e-05,
      "loss": 0.2319,
      "step": 1031
    },
    {
      "epoch": 0.7010869565217391,
      "grad_norm": 12.029706001281738,
      "learning_rate": 1.742382700816107e-05,
      "loss": 0.1244,
      "step": 1032
    },
    {
      "epoch": 0.701766304347826,
      "grad_norm": 0.051638104021549225,
      "learning_rate": 1.741905884398337e-05,
      "loss": 0.0007,
      "step": 1033
    },
    {
      "epoch": 0.7024456521739131,
      "grad_norm": 2.2519731521606445,
      "learning_rate": 1.7414286924974516e-05,
      "loss": 0.0642,
      "step": 1034
    },
    {
      "epoch": 0.703125,
      "grad_norm": 0.010442281141877174,
      "learning_rate": 1.7409511253549592e-05,
      "loss": 0.0002,
      "step": 1035
    },
    {
      "epoch": 0.7038043478260869,
      "grad_norm": 3.0888607501983643,
      "learning_rate": 1.7404731832125606e-05,
      "loss": 0.1187,
      "step": 1036
    },
    {
      "epoch": 0.704483695652174,
      "grad_norm": 10.724442481994629,
      "learning_rate": 1.7399948663121448e-05,
      "loss": 0.3338,
      "step": 1037
    },
    {
      "epoch": 0.7051630434782609,
      "grad_norm": 6.209827899932861,
      "learning_rate": 1.7395161748957905e-05,
      "loss": 0.2212,
      "step": 1038
    },
    {
      "epoch": 0.7058423913043478,
      "grad_norm": 0.021100880578160286,
      "learning_rate": 1.739037109205767e-05,
      "loss": 0.0003,
      "step": 1039
    },
    {
      "epoch": 0.7065217391304348,
      "grad_norm": 0.018066836521029472,
      "learning_rate": 1.7385576694845324e-05,
      "loss": 0.0002,
      "step": 1040
    },
    {
      "epoch": 0.7072010869565217,
      "grad_norm": 0.015074553899466991,
      "learning_rate": 1.7380778559747335e-05,
      "loss": 0.0002,
      "step": 1041
    },
    {
      "epoch": 0.7078804347826086,
      "grad_norm": 5.535478115081787,
      "learning_rate": 1.7375976689192076e-05,
      "loss": 0.181,
      "step": 1042
    },
    {
      "epoch": 0.7085597826086957,
      "grad_norm": 5.539044380187988,
      "learning_rate": 1.7371171085609794e-05,
      "loss": 0.1093,
      "step": 1043
    },
    {
      "epoch": 0.7092391304347826,
      "grad_norm": 4.111346244812012,
      "learning_rate": 1.7366361751432645e-05,
      "loss": 0.0716,
      "step": 1044
    },
    {
      "epoch": 0.7099184782608695,
      "grad_norm": 11.76512336730957,
      "learning_rate": 1.7361548689094653e-05,
      "loss": 0.2506,
      "step": 1045
    },
    {
      "epoch": 0.7105978260869565,
      "grad_norm": 6.870562553405762,
      "learning_rate": 1.7356731901031746e-05,
      "loss": 0.1137,
      "step": 1046
    },
    {
      "epoch": 0.7112771739130435,
      "grad_norm": 4.773958206176758,
      "learning_rate": 1.7351911389681725e-05,
      "loss": 0.1492,
      "step": 1047
    },
    {
      "epoch": 0.7119565217391305,
      "grad_norm": 0.00677903089672327,
      "learning_rate": 1.7347087157484282e-05,
      "loss": 0.0001,
      "step": 1048
    },
    {
      "epoch": 0.7126358695652174,
      "grad_norm": 0.6786006689071655,
      "learning_rate": 1.734225920688099e-05,
      "loss": 0.0035,
      "step": 1049
    },
    {
      "epoch": 0.7133152173913043,
      "grad_norm": 1.9569556713104248,
      "learning_rate": 1.7337427540315305e-05,
      "loss": 0.0681,
      "step": 1050
    },
    {
      "epoch": 0.7139945652173914,
      "grad_norm": 0.004092338960617781,
      "learning_rate": 1.733259216023256e-05,
      "loss": 0.0001,
      "step": 1051
    },
    {
      "epoch": 0.7146739130434783,
      "grad_norm": 0.026637176051735878,
      "learning_rate": 1.7327753069079977e-05,
      "loss": 0.0002,
      "step": 1052
    },
    {
      "epoch": 0.7153532608695652,
      "grad_norm": 8.573890686035156,
      "learning_rate": 1.7322910269306645e-05,
      "loss": 0.2423,
      "step": 1053
    },
    {
      "epoch": 0.7160326086956522,
      "grad_norm": 7.725667953491211,
      "learning_rate": 1.7318063763363536e-05,
      "loss": 0.2608,
      "step": 1054
    },
    {
      "epoch": 0.7167119565217391,
      "grad_norm": 4.030701637268066,
      "learning_rate": 1.7313213553703494e-05,
      "loss": 0.1632,
      "step": 1055
    },
    {
      "epoch": 0.717391304347826,
      "grad_norm": 3.4749224185943604,
      "learning_rate": 1.730835964278124e-05,
      "loss": 0.0838,
      "step": 1056
    },
    {
      "epoch": 0.7180706521739131,
      "grad_norm": 0.146588534116745,
      "learning_rate": 1.7303502033053377e-05,
      "loss": 0.0019,
      "step": 1057
    },
    {
      "epoch": 0.71875,
      "grad_norm": 0.01631818152964115,
      "learning_rate": 1.7298640726978357e-05,
      "loss": 0.0002,
      "step": 1058
    },
    {
      "epoch": 0.7194293478260869,
      "grad_norm": 0.02353505603969097,
      "learning_rate": 1.729377572701653e-05,
      "loss": 0.0002,
      "step": 1059
    },
    {
      "epoch": 0.720108695652174,
      "grad_norm": 0.04919187352061272,
      "learning_rate": 1.728890703563009e-05,
      "loss": 0.0004,
      "step": 1060
    },
    {
      "epoch": 0.7207880434782609,
      "grad_norm": 7.189218044281006,
      "learning_rate": 1.728403465528312e-05,
      "loss": 0.398,
      "step": 1061
    },
    {
      "epoch": 0.7214673913043478,
      "grad_norm": 14.793405532836914,
      "learning_rate": 1.7279158588441558e-05,
      "loss": 0.4029,
      "step": 1062
    },
    {
      "epoch": 0.7221467391304348,
      "grad_norm": 2.880028486251831,
      "learning_rate": 1.7274278837573214e-05,
      "loss": 0.1441,
      "step": 1063
    },
    {
      "epoch": 0.7228260869565217,
      "grad_norm": 9.871789932250977,
      "learning_rate": 1.726939540514776e-05,
      "loss": 0.1317,
      "step": 1064
    },
    {
      "epoch": 0.7235054347826086,
      "grad_norm": 4.131043910980225,
      "learning_rate": 1.7264508293636726e-05,
      "loss": 0.1854,
      "step": 1065
    },
    {
      "epoch": 0.7241847826086957,
      "grad_norm": 2.7484304904937744,
      "learning_rate": 1.7259617505513515e-05,
      "loss": 0.0381,
      "step": 1066
    },
    {
      "epoch": 0.7248641304347826,
      "grad_norm": 3.5514676570892334,
      "learning_rate": 1.7254723043253384e-05,
      "loss": 0.1615,
      "step": 1067
    },
    {
      "epoch": 0.7255434782608695,
      "grad_norm": 1.898555874824524,
      "learning_rate": 1.7249824909333445e-05,
      "loss": 0.1908,
      "step": 1068
    },
    {
      "epoch": 0.7262228260869565,
      "grad_norm": 2.9497222900390625,
      "learning_rate": 1.7244923106232678e-05,
      "loss": 0.065,
      "step": 1069
    },
    {
      "epoch": 0.7269021739130435,
      "grad_norm": 0.4749796986579895,
      "learning_rate": 1.7240017636431914e-05,
      "loss": 0.0037,
      "step": 1070
    },
    {
      "epoch": 0.7275815217391305,
      "grad_norm": 0.004255442414432764,
      "learning_rate": 1.7235108502413844e-05,
      "loss": 0.0001,
      "step": 1071
    },
    {
      "epoch": 0.7282608695652174,
      "grad_norm": 2.8815500736236572,
      "learning_rate": 1.723019570666301e-05,
      "loss": 0.0419,
      "step": 1072
    },
    {
      "epoch": 0.7289402173913043,
      "grad_norm": 12.80208969116211,
      "learning_rate": 1.7225279251665803e-05,
      "loss": 0.4754,
      "step": 1073
    },
    {
      "epoch": 0.7296195652173914,
      "grad_norm": 0.27992454171180725,
      "learning_rate": 1.722035913991048e-05,
      "loss": 0.0024,
      "step": 1074
    },
    {
      "epoch": 0.7302989130434783,
      "grad_norm": 3.298454761505127,
      "learning_rate": 1.7215435373887133e-05,
      "loss": 0.062,
      "step": 1075
    },
    {
      "epoch": 0.7309782608695652,
      "grad_norm": 0.04041971266269684,
      "learning_rate": 1.721050795608771e-05,
      "loss": 0.0004,
      "step": 1076
    },
    {
      "epoch": 0.7316576086956522,
      "grad_norm": 2.9865522384643555,
      "learning_rate": 1.720557688900601e-05,
      "loss": 0.1318,
      "step": 1077
    },
    {
      "epoch": 0.7323369565217391,
      "grad_norm": 2.458894968032837,
      "learning_rate": 1.720064217513768e-05,
      "loss": 0.0835,
      "step": 1078
    },
    {
      "epoch": 0.733016304347826,
      "grad_norm": 0.02025603875517845,
      "learning_rate": 1.71957038169802e-05,
      "loss": 0.0003,
      "step": 1079
    },
    {
      "epoch": 0.7336956521739131,
      "grad_norm": 0.34355223178863525,
      "learning_rate": 1.719076181703291e-05,
      "loss": 0.0031,
      "step": 1080
    },
    {
      "epoch": 0.734375,
      "grad_norm": 3.8593909740448,
      "learning_rate": 1.718581617779698e-05,
      "loss": 0.0797,
      "step": 1081
    },
    {
      "epoch": 0.7350543478260869,
      "grad_norm": 11.646585464477539,
      "learning_rate": 1.7180866901775437e-05,
      "loss": 0.2034,
      "step": 1082
    },
    {
      "epoch": 0.735733695652174,
      "grad_norm": 1.746839165687561,
      "learning_rate": 1.7175913991473137e-05,
      "loss": 0.0389,
      "step": 1083
    },
    {
      "epoch": 0.7364130434782609,
      "grad_norm": 2.5142972469329834,
      "learning_rate": 1.7170957449396774e-05,
      "loss": 0.0823,
      "step": 1084
    },
    {
      "epoch": 0.7370923913043478,
      "grad_norm": 0.07023037225008011,
      "learning_rate": 1.716599727805489e-05,
      "loss": 0.0008,
      "step": 1085
    },
    {
      "epoch": 0.7377717391304348,
      "grad_norm": 0.021175816655158997,
      "learning_rate": 1.716103347995785e-05,
      "loss": 0.0003,
      "step": 1086
    },
    {
      "epoch": 0.7384510869565217,
      "grad_norm": 4.721290111541748,
      "learning_rate": 1.715606605761787e-05,
      "loss": 0.204,
      "step": 1087
    },
    {
      "epoch": 0.7391304347826086,
      "grad_norm": 0.005303564481437206,
      "learning_rate": 1.7151095013548996e-05,
      "loss": 0.0001,
      "step": 1088
    },
    {
      "epoch": 0.7398097826086957,
      "grad_norm": 2.2891249656677246,
      "learning_rate": 1.7146120350267094e-05,
      "loss": 0.0154,
      "step": 1089
    },
    {
      "epoch": 0.7404891304347826,
      "grad_norm": 5.8939619064331055,
      "learning_rate": 1.7141142070289876e-05,
      "loss": 0.175,
      "step": 1090
    },
    {
      "epoch": 0.7411684782608695,
      "grad_norm": 0.31334197521209717,
      "learning_rate": 1.7136160176136884e-05,
      "loss": 0.0042,
      "step": 1091
    },
    {
      "epoch": 0.7418478260869565,
      "grad_norm": 0.7516409158706665,
      "learning_rate": 1.713117467032948e-05,
      "loss": 0.0068,
      "step": 1092
    },
    {
      "epoch": 0.7425271739130435,
      "grad_norm": 0.11473438143730164,
      "learning_rate": 1.7126185555390858e-05,
      "loss": 0.0008,
      "step": 1093
    },
    {
      "epoch": 0.7432065217391305,
      "grad_norm": 2.5731911659240723,
      "learning_rate": 1.7121192833846046e-05,
      "loss": 0.2005,
      "step": 1094
    },
    {
      "epoch": 0.7438858695652174,
      "grad_norm": 1.5667989253997803,
      "learning_rate": 1.7116196508221886e-05,
      "loss": 0.0548,
      "step": 1095
    },
    {
      "epoch": 0.7445652173913043,
      "grad_norm": 0.004928696434944868,
      "learning_rate": 1.711119658104705e-05,
      "loss": 0.0001,
      "step": 1096
    },
    {
      "epoch": 0.7452445652173914,
      "grad_norm": 4.553735733032227,
      "learning_rate": 1.710619305485203e-05,
      "loss": 0.1432,
      "step": 1097
    },
    {
      "epoch": 0.7459239130434783,
      "grad_norm": 25.63762855529785,
      "learning_rate": 1.7101185932169147e-05,
      "loss": 0.2021,
      "step": 1098
    },
    {
      "epoch": 0.7466032608695652,
      "grad_norm": 0.013849059119820595,
      "learning_rate": 1.709617521553253e-05,
      "loss": 0.0002,
      "step": 1099
    },
    {
      "epoch": 0.7472826086956522,
      "grad_norm": 3.3248190879821777,
      "learning_rate": 1.7091160907478137e-05,
      "loss": 0.0413,
      "step": 1100
    },
    {
      "epoch": 0.7479619565217391,
      "grad_norm": 3.8051438331604004,
      "learning_rate": 1.7086143010543737e-05,
      "loss": 0.1275,
      "step": 1101
    },
    {
      "epoch": 0.748641304347826,
      "grad_norm": 0.7438082098960876,
      "learning_rate": 1.7081121527268925e-05,
      "loss": 0.0066,
      "step": 1102
    },
    {
      "epoch": 0.7493206521739131,
      "grad_norm": 8.951205253601074,
      "learning_rate": 1.7076096460195097e-05,
      "loss": 0.4037,
      "step": 1103
    },
    {
      "epoch": 0.75,
      "grad_norm": 14.387803077697754,
      "learning_rate": 1.7071067811865477e-05,
      "loss": 0.1715,
      "step": 1104
    },
    {
      "epoch": 0.7506793478260869,
      "grad_norm": 3.930302858352661,
      "learning_rate": 1.706603558482509e-05,
      "loss": 0.1642,
      "step": 1105
    },
    {
      "epoch": 0.751358695652174,
      "grad_norm": 0.009159103967249393,
      "learning_rate": 1.7060999781620776e-05,
      "loss": 0.0001,
      "step": 1106
    },
    {
      "epoch": 0.7520380434782609,
      "grad_norm": 2.675755023956299,
      "learning_rate": 1.7055960404801187e-05,
      "loss": 0.116,
      "step": 1107
    },
    {
      "epoch": 0.7527173913043478,
      "grad_norm": 4.903449058532715,
      "learning_rate": 1.7050917456916788e-05,
      "loss": 0.1475,
      "step": 1108
    },
    {
      "epoch": 0.7533967391304348,
      "grad_norm": 3.901665210723877,
      "learning_rate": 1.7045870940519838e-05,
      "loss": 0.1908,
      "step": 1109
    },
    {
      "epoch": 0.7540760869565217,
      "grad_norm": 3.904235363006592,
      "learning_rate": 1.7040820858164413e-05,
      "loss": 0.1858,
      "step": 1110
    },
    {
      "epoch": 0.7547554347826086,
      "grad_norm": 8.102553367614746,
      "learning_rate": 1.703576721240639e-05,
      "loss": 0.3167,
      "step": 1111
    },
    {
      "epoch": 0.7554347826086957,
      "grad_norm": 1.8930020332336426,
      "learning_rate": 1.7030710005803453e-05,
      "loss": 0.0872,
      "step": 1112
    },
    {
      "epoch": 0.7561141304347826,
      "grad_norm": 0.006936580408364534,
      "learning_rate": 1.7025649240915085e-05,
      "loss": 0.0002,
      "step": 1113
    },
    {
      "epoch": 0.7567934782608695,
      "grad_norm": 3.1609272956848145,
      "learning_rate": 1.7020584920302565e-05,
      "loss": 0.0574,
      "step": 1114
    },
    {
      "epoch": 0.7574728260869565,
      "grad_norm": 3.0434114933013916,
      "learning_rate": 1.701551704652898e-05,
      "loss": 0.1844,
      "step": 1115
    },
    {
      "epoch": 0.7581521739130435,
      "grad_norm": 0.7803290486335754,
      "learning_rate": 1.7010445622159214e-05,
      "loss": 0.0069,
      "step": 1116
    },
    {
      "epoch": 0.7588315217391305,
      "grad_norm": 0.3007705807685852,
      "learning_rate": 1.7005370649759942e-05,
      "loss": 0.0058,
      "step": 1117
    },
    {
      "epoch": 0.7595108695652174,
      "grad_norm": 0.06456691771745682,
      "learning_rate": 1.7000292131899644e-05,
      "loss": 0.0005,
      "step": 1118
    },
    {
      "epoch": 0.7601902173913043,
      "grad_norm": 0.00441835867241025,
      "learning_rate": 1.6995210071148582e-05,
      "loss": 0.0001,
      "step": 1119
    },
    {
      "epoch": 0.7608695652173914,
      "grad_norm": 2.1137638092041016,
      "learning_rate": 1.699012447007882e-05,
      "loss": 0.0743,
      "step": 1120
    },
    {
      "epoch": 0.7615489130434783,
      "grad_norm": 14.027073860168457,
      "learning_rate": 1.6985035331264218e-05,
      "loss": 0.3144,
      "step": 1121
    },
    {
      "epoch": 0.7622282608695652,
      "grad_norm": 14.166521072387695,
      "learning_rate": 1.6979942657280414e-05,
      "loss": 0.5755,
      "step": 1122
    },
    {
      "epoch": 0.7629076086956522,
      "grad_norm": 0.9569743275642395,
      "learning_rate": 1.6974846450704843e-05,
      "loss": 0.0114,
      "step": 1123
    },
    {
      "epoch": 0.7635869565217391,
      "grad_norm": 0.00341109000146389,
      "learning_rate": 1.696974671411673e-05,
      "loss": 0.0001,
      "step": 1124
    },
    {
      "epoch": 0.764266304347826,
      "grad_norm": 0.04378248751163483,
      "learning_rate": 1.6964643450097077e-05,
      "loss": 0.0004,
      "step": 1125
    },
    {
      "epoch": 0.7649456521739131,
      "grad_norm": 0.06767056882381439,
      "learning_rate": 1.6959536661228682e-05,
      "loss": 0.0005,
      "step": 1126
    },
    {
      "epoch": 0.765625,
      "grad_norm": 2.488598585128784,
      "learning_rate": 1.6954426350096118e-05,
      "loss": 0.0595,
      "step": 1127
    },
    {
      "epoch": 0.7663043478260869,
      "grad_norm": 0.5535913109779358,
      "learning_rate": 1.694931251928575e-05,
      "loss": 0.0037,
      "step": 1128
    },
    {
      "epoch": 0.766983695652174,
      "grad_norm": 0.07483649253845215,
      "learning_rate": 1.694419517138571e-05,
      "loss": 0.0005,
      "step": 1129
    },
    {
      "epoch": 0.7676630434782609,
      "grad_norm": 2.7964859008789062,
      "learning_rate": 1.693907430898593e-05,
      "loss": 0.1626,
      "step": 1130
    },
    {
      "epoch": 0.7683423913043478,
      "grad_norm": 0.015132089145481586,
      "learning_rate": 1.6933949934678104e-05,
      "loss": 0.0002,
      "step": 1131
    },
    {
      "epoch": 0.7690217391304348,
      "grad_norm": 3.101755142211914,
      "learning_rate": 1.6928822051055714e-05,
      "loss": 0.0201,
      "step": 1132
    },
    {
      "epoch": 0.7697010869565217,
      "grad_norm": 4.919325351715088,
      "learning_rate": 1.6923690660714e-05,
      "loss": 0.4635,
      "step": 1133
    },
    {
      "epoch": 0.7703804347826086,
      "grad_norm": 0.1900714784860611,
      "learning_rate": 1.691855576625001e-05,
      "loss": 0.0009,
      "step": 1134
    },
    {
      "epoch": 0.7710597826086957,
      "grad_norm": 0.2640787959098816,
      "learning_rate": 1.691341737026253e-05,
      "loss": 0.0022,
      "step": 1135
    },
    {
      "epoch": 0.7717391304347826,
      "grad_norm": 3.337005376815796,
      "learning_rate": 1.690827547535214e-05,
      "loss": 0.1988,
      "step": 1136
    },
    {
      "epoch": 0.7724184782608695,
      "grad_norm": 0.06314945220947266,
      "learning_rate": 1.6903130084121183e-05,
      "loss": 0.0009,
      "step": 1137
    },
    {
      "epoch": 0.7730978260869565,
      "grad_norm": 6.989785671234131,
      "learning_rate": 1.6897981199173775e-05,
      "loss": 0.1098,
      "step": 1138
    },
    {
      "epoch": 0.7737771739130435,
      "grad_norm": 1.0607659816741943,
      "learning_rate": 1.6892828823115798e-05,
      "loss": 0.0063,
      "step": 1139
    },
    {
      "epoch": 0.7744565217391305,
      "grad_norm": 4.712150573730469,
      "learning_rate": 1.68876729585549e-05,
      "loss": 0.2006,
      "step": 1140
    },
    {
      "epoch": 0.7751358695652174,
      "grad_norm": 0.5978155732154846,
      "learning_rate": 1.688251360810049e-05,
      "loss": 0.0044,
      "step": 1141
    },
    {
      "epoch": 0.7758152173913043,
      "grad_norm": 0.006875122897326946,
      "learning_rate": 1.6877350774363757e-05,
      "loss": 0.0001,
      "step": 1142
    },
    {
      "epoch": 0.7764945652173914,
      "grad_norm": 0.7245901226997375,
      "learning_rate": 1.6872184459957637e-05,
      "loss": 0.0077,
      "step": 1143
    },
    {
      "epoch": 0.7771739130434783,
      "grad_norm": 1.5674673318862915,
      "learning_rate": 1.6867014667496838e-05,
      "loss": 0.038,
      "step": 1144
    },
    {
      "epoch": 0.7778532608695652,
      "grad_norm": 0.006503838114440441,
      "learning_rate": 1.6861841399597816e-05,
      "loss": 0.0001,
      "step": 1145
    },
    {
      "epoch": 0.7785326086956522,
      "grad_norm": 15.202439308166504,
      "learning_rate": 1.6856664658878797e-05,
      "loss": 0.2209,
      "step": 1146
    },
    {
      "epoch": 0.7792119565217391,
      "grad_norm": 4.880453109741211,
      "learning_rate": 1.6851484447959767e-05,
      "loss": 0.1588,
      "step": 1147
    },
    {
      "epoch": 0.779891304347826,
      "grad_norm": 0.022006411105394363,
      "learning_rate": 1.6846300769462454e-05,
      "loss": 0.0002,
      "step": 1148
    },
    {
      "epoch": 0.7805706521739131,
      "grad_norm": 20.693571090698242,
      "learning_rate": 1.6841113626010358e-05,
      "loss": 0.1678,
      "step": 1149
    },
    {
      "epoch": 0.78125,
      "grad_norm": 8.097753524780273,
      "learning_rate": 1.6835923020228714e-05,
      "loss": 0.353,
      "step": 1150
    },
    {
      "epoch": 0.7819293478260869,
      "grad_norm": 0.007331556174904108,
      "learning_rate": 1.6830728954744528e-05,
      "loss": 0.0001,
      "step": 1151
    },
    {
      "epoch": 0.782608695652174,
      "grad_norm": 4.797691345214844,
      "learning_rate": 1.6825531432186545e-05,
      "loss": 0.1813,
      "step": 1152
    },
    {
      "epoch": 0.7832880434782609,
      "grad_norm": 0.011165675707161427,
      "learning_rate": 1.682033045518526e-05,
      "loss": 0.0002,
      "step": 1153
    },
    {
      "epoch": 0.7839673913043478,
      "grad_norm": 5.615592002868652,
      "learning_rate": 1.6815126026372922e-05,
      "loss": 0.1411,
      "step": 1154
    },
    {
      "epoch": 0.7846467391304348,
      "grad_norm": 0.1472175419330597,
      "learning_rate": 1.6809918148383525e-05,
      "loss": 0.001,
      "step": 1155
    },
    {
      "epoch": 0.7853260869565217,
      "grad_norm": 4.720834732055664,
      "learning_rate": 1.680470682385281e-05,
      "loss": 0.144,
      "step": 1156
    },
    {
      "epoch": 0.7860054347826086,
      "grad_norm": 2.792808771133423,
      "learning_rate": 1.679949205541826e-05,
      "loss": 0.1231,
      "step": 1157
    },
    {
      "epoch": 0.7866847826086957,
      "grad_norm": 5.159171104431152,
      "learning_rate": 1.6794273845719096e-05,
      "loss": 0.1856,
      "step": 1158
    },
    {
      "epoch": 0.7873641304347826,
      "grad_norm": 5.423820972442627,
      "learning_rate": 1.678905219739629e-05,
      "loss": 0.1944,
      "step": 1159
    },
    {
      "epoch": 0.7880434782608695,
      "grad_norm": 1.5016698837280273,
      "learning_rate": 1.6783827113092547e-05,
      "loss": 0.067,
      "step": 1160
    },
    {
      "epoch": 0.7887228260869565,
      "grad_norm": 7.982760429382324,
      "learning_rate": 1.6778598595452324e-05,
      "loss": 0.2733,
      "step": 1161
    },
    {
      "epoch": 0.7894021739130435,
      "grad_norm": 0.03432298079133034,
      "learning_rate": 1.6773366647121792e-05,
      "loss": 0.0004,
      "step": 1162
    },
    {
      "epoch": 0.7900815217391305,
      "grad_norm": 2.2823727130889893,
      "learning_rate": 1.676813127074888e-05,
      "loss": 0.1683,
      "step": 1163
    },
    {
      "epoch": 0.7907608695652174,
      "grad_norm": 2.949338674545288,
      "learning_rate": 1.6762892468983237e-05,
      "loss": 0.0901,
      "step": 1164
    },
    {
      "epoch": 0.7914402173913043,
      "grad_norm": 4.912231922149658,
      "learning_rate": 1.6757650244476267e-05,
      "loss": 0.1019,
      "step": 1165
    },
    {
      "epoch": 0.7921195652173914,
      "grad_norm": 1.6429691314697266,
      "learning_rate": 1.675240459988108e-05,
      "loss": 0.0882,
      "step": 1166
    },
    {
      "epoch": 0.7927989130434783,
      "grad_norm": 11.778715133666992,
      "learning_rate": 1.674715553785253e-05,
      "loss": 0.2361,
      "step": 1167
    },
    {
      "epoch": 0.7934782608695652,
      "grad_norm": 0.06545011699199677,
      "learning_rate": 1.6741903061047204e-05,
      "loss": 0.0007,
      "step": 1168
    },
    {
      "epoch": 0.7941576086956522,
      "grad_norm": 4.240870475769043,
      "learning_rate": 1.6736647172123414e-05,
      "loss": 0.1533,
      "step": 1169
    },
    {
      "epoch": 0.7948369565217391,
      "grad_norm": 15.38669490814209,
      "learning_rate": 1.673138787374119e-05,
      "loss": 0.3217,
      "step": 1170
    },
    {
      "epoch": 0.795516304347826,
      "grad_norm": 9.29895305633545,
      "learning_rate": 1.6726125168562295e-05,
      "loss": 0.1338,
      "step": 1171
    },
    {
      "epoch": 0.7961956521739131,
      "grad_norm": 0.007878685370087624,
      "learning_rate": 1.6720859059250225e-05,
      "loss": 0.0001,
      "step": 1172
    },
    {
      "epoch": 0.796875,
      "grad_norm": 2.6004321575164795,
      "learning_rate": 1.6715589548470187e-05,
      "loss": 0.1326,
      "step": 1173
    },
    {
      "epoch": 0.7975543478260869,
      "grad_norm": 0.017970897257328033,
      "learning_rate": 1.6710316638889107e-05,
      "loss": 0.0002,
      "step": 1174
    },
    {
      "epoch": 0.798233695652174,
      "grad_norm": 3.3570151329040527,
      "learning_rate": 1.6705040333175646e-05,
      "loss": 0.1375,
      "step": 1175
    },
    {
      "epoch": 0.7989130434782609,
      "grad_norm": 2.392174482345581,
      "learning_rate": 1.6699760634000166e-05,
      "loss": 0.1762,
      "step": 1176
    },
    {
      "epoch": 0.7995923913043478,
      "grad_norm": 1.2039214372634888,
      "learning_rate": 1.6694477544034762e-05,
      "loss": 0.0432,
      "step": 1177
    },
    {
      "epoch": 0.8002717391304348,
      "grad_norm": 9.069202423095703,
      "learning_rate": 1.6689191065953233e-05,
      "loss": 0.4014,
      "step": 1178
    },
    {
      "epoch": 0.8009510869565217,
      "grad_norm": 2.68400239944458,
      "learning_rate": 1.66839012024311e-05,
      "loss": 0.1343,
      "step": 1179
    },
    {
      "epoch": 0.8016304347826086,
      "grad_norm": 3.5989534854888916,
      "learning_rate": 1.6678607956145596e-05,
      "loss": 0.1661,
      "step": 1180
    },
    {
      "epoch": 0.8023097826086957,
      "grad_norm": 10.461862564086914,
      "learning_rate": 1.6673311329775664e-05,
      "loss": 0.4904,
      "step": 1181
    },
    {
      "epoch": 0.8029891304347826,
      "grad_norm": 9.910654067993164,
      "learning_rate": 1.6668011326001962e-05,
      "loss": 0.2774,
      "step": 1182
    },
    {
      "epoch": 0.8036684782608695,
      "grad_norm": 0.01894976943731308,
      "learning_rate": 1.666270794750685e-05,
      "loss": 0.0002,
      "step": 1183
    },
    {
      "epoch": 0.8043478260869565,
      "grad_norm": 0.34281307458877563,
      "learning_rate": 1.6657401196974405e-05,
      "loss": 0.0042,
      "step": 1184
    },
    {
      "epoch": 0.8050271739130435,
      "grad_norm": 2.854161024093628,
      "learning_rate": 1.6652091077090405e-05,
      "loss": 0.0736,
      "step": 1185
    },
    {
      "epoch": 0.8057065217391305,
      "grad_norm": 2.9185619354248047,
      "learning_rate": 1.664677759054233e-05,
      "loss": 0.0936,
      "step": 1186
    },
    {
      "epoch": 0.8063858695652174,
      "grad_norm": 0.026957767084240913,
      "learning_rate": 1.6641460740019374e-05,
      "loss": 0.0003,
      "step": 1187
    },
    {
      "epoch": 0.8070652173913043,
      "grad_norm": 6.094059944152832,
      "learning_rate": 1.6636140528212427e-05,
      "loss": 0.0459,
      "step": 1188
    },
    {
      "epoch": 0.8077445652173914,
      "grad_norm": 2.425330638885498,
      "learning_rate": 1.663081695781407e-05,
      "loss": 0.0253,
      "step": 1189
    },
    {
      "epoch": 0.8084239130434783,
      "grad_norm": 0.017145216464996338,
      "learning_rate": 1.662549003151861e-05,
      "loss": 0.0003,
      "step": 1190
    },
    {
      "epoch": 0.8091032608695652,
      "grad_norm": 2.324483871459961,
      "learning_rate": 1.662015975202203e-05,
      "loss": 0.0721,
      "step": 1191
    },
    {
      "epoch": 0.8097826086956522,
      "grad_norm": 2.5859220027923584,
      "learning_rate": 1.6614826122022015e-05,
      "loss": 0.0216,
      "step": 1192
    },
    {
      "epoch": 0.8104619565217391,
      "grad_norm": 3.126854419708252,
      "learning_rate": 1.6609489144217948e-05,
      "loss": 0.1106,
      "step": 1193
    },
    {
      "epoch": 0.811141304347826,
      "grad_norm": 1.8013042211532593,
      "learning_rate": 1.6604148821310912e-05,
      "loss": 0.0105,
      "step": 1194
    },
    {
      "epoch": 0.8118206521739131,
      "grad_norm": 2.4575212001800537,
      "learning_rate": 1.6598805156003673e-05,
      "loss": 0.0937,
      "step": 1195
    },
    {
      "epoch": 0.8125,
      "grad_norm": 3.2234318256378174,
      "learning_rate": 1.659345815100069e-05,
      "loss": 0.0192,
      "step": 1196
    },
    {
      "epoch": 0.8131793478260869,
      "grad_norm": 1.065696358680725,
      "learning_rate": 1.658810780900812e-05,
      "loss": 0.0104,
      "step": 1197
    },
    {
      "epoch": 0.813858695652174,
      "grad_norm": 0.013319156132638454,
      "learning_rate": 1.6582754132733804e-05,
      "loss": 0.0002,
      "step": 1198
    },
    {
      "epoch": 0.8145380434782609,
      "grad_norm": 0.05189032480120659,
      "learning_rate": 1.6577397124887266e-05,
      "loss": 0.0006,
      "step": 1199
    },
    {
      "epoch": 0.8152173913043478,
      "grad_norm": 4.2049384117126465,
      "learning_rate": 1.6572036788179728e-05,
      "loss": 0.0761,
      "step": 1200
    },
    {
      "epoch": 0.8158967391304348,
      "grad_norm": 6.290818214416504,
      "learning_rate": 1.656667312532408e-05,
      "loss": 0.2377,
      "step": 1201
    },
    {
      "epoch": 0.8165760869565217,
      "grad_norm": 3.6947503089904785,
      "learning_rate": 1.656130613903491e-05,
      "loss": 0.0879,
      "step": 1202
    },
    {
      "epoch": 0.8172554347826086,
      "grad_norm": 15.322870254516602,
      "learning_rate": 1.655593583202848e-05,
      "loss": 0.6028,
      "step": 1203
    },
    {
      "epoch": 0.8179347826086957,
      "grad_norm": 0.020406924188137054,
      "learning_rate": 1.655056220702274e-05,
      "loss": 0.0003,
      "step": 1204
    },
    {
      "epoch": 0.8186141304347826,
      "grad_norm": 4.576895236968994,
      "learning_rate": 1.654518526673731e-05,
      "loss": 0.2493,
      "step": 1205
    },
    {
      "epoch": 0.8192934782608695,
      "grad_norm": 1.8264999389648438,
      "learning_rate": 1.6539805013893493e-05,
      "loss": 0.044,
      "step": 1206
    },
    {
      "epoch": 0.8199728260869565,
      "grad_norm": 0.2979051172733307,
      "learning_rate": 1.653442145121427e-05,
      "loss": 0.0018,
      "step": 1207
    },
    {
      "epoch": 0.8206521739130435,
      "grad_norm": 0.2371481955051422,
      "learning_rate": 1.6529034581424293e-05,
      "loss": 0.0021,
      "step": 1208
    },
    {
      "epoch": 0.8213315217391305,
      "grad_norm": 7.194174766540527,
      "learning_rate": 1.6523644407249893e-05,
      "loss": 0.2822,
      "step": 1209
    },
    {
      "epoch": 0.8220108695652174,
      "grad_norm": 0.37182852625846863,
      "learning_rate": 1.6518250931419063e-05,
      "loss": 0.0037,
      "step": 1210
    },
    {
      "epoch": 0.8226902173913043,
      "grad_norm": 0.07815787196159363,
      "learning_rate": 1.6512854156661484e-05,
      "loss": 0.0007,
      "step": 1211
    },
    {
      "epoch": 0.8233695652173914,
      "grad_norm": 0.0032201455906033516,
      "learning_rate": 1.650745408570849e-05,
      "loss": 0.0001,
      "step": 1212
    },
    {
      "epoch": 0.8240489130434783,
      "grad_norm": 6.569381237030029,
      "learning_rate": 1.6502050721293094e-05,
      "loss": 0.0488,
      "step": 1213
    },
    {
      "epoch": 0.8247282608695652,
      "grad_norm": 0.007558899931609631,
      "learning_rate": 1.6496644066149967e-05,
      "loss": 0.0001,
      "step": 1214
    },
    {
      "epoch": 0.8254076086956522,
      "grad_norm": 0.012790814973413944,
      "learning_rate": 1.6491234123015454e-05,
      "loss": 0.0001,
      "step": 1215
    },
    {
      "epoch": 0.8260869565217391,
      "grad_norm": 0.007647894322872162,
      "learning_rate": 1.648582089462756e-05,
      "loss": 0.0001,
      "step": 1216
    },
    {
      "epoch": 0.826766304347826,
      "grad_norm": 0.011109848506748676,
      "learning_rate": 1.6480404383725952e-05,
      "loss": 0.0002,
      "step": 1217
    },
    {
      "epoch": 0.8274456521739131,
      "grad_norm": 6.7049455642700195,
      "learning_rate": 1.6474984593051965e-05,
      "loss": 0.1071,
      "step": 1218
    },
    {
      "epoch": 0.828125,
      "grad_norm": 21.318374633789062,
      "learning_rate": 1.6469561525348576e-05,
      "loss": 0.5211,
      "step": 1219
    },
    {
      "epoch": 0.8288043478260869,
      "grad_norm": 0.01985798589885235,
      "learning_rate": 1.6464135183360444e-05,
      "loss": 0.0004,
      "step": 1220
    },
    {
      "epoch": 0.829483695652174,
      "grad_norm": 0.034099992364645004,
      "learning_rate": 1.6458705569833866e-05,
      "loss": 0.0004,
      "step": 1221
    },
    {
      "epoch": 0.8301630434782609,
      "grad_norm": 3.660599946975708,
      "learning_rate": 1.645327268751681e-05,
      "loss": 0.1514,
      "step": 1222
    },
    {
      "epoch": 0.8308423913043478,
      "grad_norm": 0.5418680906295776,
      "learning_rate": 1.6447836539158887e-05,
      "loss": 0.0085,
      "step": 1223
    },
    {
      "epoch": 0.8315217391304348,
      "grad_norm": 7.382092475891113,
      "learning_rate": 1.6442397127511366e-05,
      "loss": 0.2254,
      "step": 1224
    },
    {
      "epoch": 0.8322010869565217,
      "grad_norm": 0.17234554886817932,
      "learning_rate": 1.6436954455327165e-05,
      "loss": 0.0021,
      "step": 1225
    },
    {
      "epoch": 0.8328804347826086,
      "grad_norm": 0.0058849225752055645,
      "learning_rate": 1.6431508525360858e-05,
      "loss": 0.0001,
      "step": 1226
    },
    {
      "epoch": 0.8335597826086957,
      "grad_norm": 4.991378307342529,
      "learning_rate": 1.6426059340368653e-05,
      "loss": 0.1763,
      "step": 1227
    },
    {
      "epoch": 0.8342391304347826,
      "grad_norm": 0.06262640655040741,
      "learning_rate": 1.6420606903108432e-05,
      "loss": 0.0006,
      "step": 1228
    },
    {
      "epoch": 0.8349184782608695,
      "grad_norm": 6.753287315368652,
      "learning_rate": 1.6415151216339697e-05,
      "loss": 0.2137,
      "step": 1229
    },
    {
      "epoch": 0.8355978260869565,
      "grad_norm": 5.8550896644592285,
      "learning_rate": 1.6409692282823604e-05,
      "loss": 0.1052,
      "step": 1230
    },
    {
      "epoch": 0.8362771739130435,
      "grad_norm": 0.7936115860939026,
      "learning_rate": 1.6404230105322953e-05,
      "loss": 0.0014,
      "step": 1231
    },
    {
      "epoch": 0.8369565217391305,
      "grad_norm": 3.6599526405334473,
      "learning_rate": 1.6398764686602188e-05,
      "loss": 0.0315,
      "step": 1232
    },
    {
      "epoch": 0.8376358695652174,
      "grad_norm": 2.1404731273651123,
      "learning_rate": 1.6393296029427395e-05,
      "loss": 0.05,
      "step": 1233
    },
    {
      "epoch": 0.8383152173913043,
      "grad_norm": 6.098732948303223,
      "learning_rate": 1.6387824136566287e-05,
      "loss": 0.2253,
      "step": 1234
    },
    {
      "epoch": 0.8389945652173914,
      "grad_norm": 0.002830777782946825,
      "learning_rate": 1.6382349010788223e-05,
      "loss": 0.0001,
      "step": 1235
    },
    {
      "epoch": 0.8396739130434783,
      "grad_norm": 7.19691801071167,
      "learning_rate": 1.63768706548642e-05,
      "loss": 0.1741,
      "step": 1236
    },
    {
      "epoch": 0.8403532608695652,
      "grad_norm": 4.127296447753906,
      "learning_rate": 1.637138907156685e-05,
      "loss": 0.2252,
      "step": 1237
    },
    {
      "epoch": 0.8410326086956522,
      "grad_norm": 3.8032565116882324,
      "learning_rate": 1.6365904263670436e-05,
      "loss": 0.1661,
      "step": 1238
    },
    {
      "epoch": 0.8417119565217391,
      "grad_norm": 1.7080070972442627,
      "learning_rate": 1.636041623395085e-05,
      "loss": 0.1364,
      "step": 1239
    },
    {
      "epoch": 0.842391304347826,
      "grad_norm": 3.5759339332580566,
      "learning_rate": 1.6354924985185614e-05,
      "loss": 0.0364,
      "step": 1240
    },
    {
      "epoch": 0.8430706521739131,
      "grad_norm": 9.352465629577637,
      "learning_rate": 1.634943052015389e-05,
      "loss": 0.1903,
      "step": 1241
    },
    {
      "epoch": 0.84375,
      "grad_norm": 0.015388302505016327,
      "learning_rate": 1.6343932841636455e-05,
      "loss": 0.0002,
      "step": 1242
    },
    {
      "epoch": 0.8444293478260869,
      "grad_norm": 3.5388286113739014,
      "learning_rate": 1.6338431952415722e-05,
      "loss": 0.1768,
      "step": 1243
    },
    {
      "epoch": 0.845108695652174,
      "grad_norm": 0.3708150088787079,
      "learning_rate": 1.6332927855275724e-05,
      "loss": 0.0072,
      "step": 1244
    },
    {
      "epoch": 0.8457880434782609,
      "grad_norm": 14.749564170837402,
      "learning_rate": 1.6327420553002113e-05,
      "loss": 0.5233,
      "step": 1245
    },
    {
      "epoch": 0.8464673913043478,
      "grad_norm": 0.013912818394601345,
      "learning_rate": 1.6321910048382174e-05,
      "loss": 0.0002,
      "step": 1246
    },
    {
      "epoch": 0.8471467391304348,
      "grad_norm": 5.279598712921143,
      "learning_rate": 1.6316396344204805e-05,
      "loss": 0.1101,
      "step": 1247
    },
    {
      "epoch": 0.8478260869565217,
      "grad_norm": 3.776071310043335,
      "learning_rate": 1.631087944326053e-05,
      "loss": 0.2148,
      "step": 1248
    },
    {
      "epoch": 0.8485054347826086,
      "grad_norm": 7.169015884399414,
      "learning_rate": 1.630535934834148e-05,
      "loss": 0.143,
      "step": 1249
    },
    {
      "epoch": 0.8491847826086957,
      "grad_norm": 0.14618875086307526,
      "learning_rate": 1.629983606224141e-05,
      "loss": 0.0011,
      "step": 1250
    },
    {
      "epoch": 0.8498641304347826,
      "grad_norm": 1.0521316528320312,
      "learning_rate": 1.6294309587755693e-05,
      "loss": 0.0155,
      "step": 1251
    },
    {
      "epoch": 0.8505434782608695,
      "grad_norm": 6.765789985656738,
      "learning_rate": 1.6288779927681307e-05,
      "loss": 0.1923,
      "step": 1252
    },
    {
      "epoch": 0.8512228260869565,
      "grad_norm": 4.810800552368164,
      "learning_rate": 1.6283247084816847e-05,
      "loss": 0.1956,
      "step": 1253
    },
    {
      "epoch": 0.8519021739130435,
      "grad_norm": 11.150030136108398,
      "learning_rate": 1.6277711061962525e-05,
      "loss": 0.1986,
      "step": 1254
    },
    {
      "epoch": 0.8525815217391305,
      "grad_norm": 0.03334292024374008,
      "learning_rate": 1.6272171861920148e-05,
      "loss": 0.0003,
      "step": 1255
    },
    {
      "epoch": 0.8532608695652174,
      "grad_norm": 0.41097578406333923,
      "learning_rate": 1.6266629487493144e-05,
      "loss": 0.0095,
      "step": 1256
    },
    {
      "epoch": 0.8539402173913043,
      "grad_norm": 3.566910743713379,
      "learning_rate": 1.6261083941486543e-05,
      "loss": 0.1601,
      "step": 1257
    },
    {
      "epoch": 0.8546195652173914,
      "grad_norm": 1.337583303451538,
      "learning_rate": 1.6255535226706975e-05,
      "loss": 0.0103,
      "step": 1258
    },
    {
      "epoch": 0.8552989130434783,
      "grad_norm": 2.342054843902588,
      "learning_rate": 1.6249983345962685e-05,
      "loss": 0.0601,
      "step": 1259
    },
    {
      "epoch": 0.8559782608695652,
      "grad_norm": 7.872633457183838,
      "learning_rate": 1.6244428302063506e-05,
      "loss": 0.1527,
      "step": 1260
    },
    {
      "epoch": 0.8566576086956522,
      "grad_norm": 2.4879062175750732,
      "learning_rate": 1.623887009782089e-05,
      "loss": 0.0386,
      "step": 1261
    },
    {
      "epoch": 0.8573369565217391,
      "grad_norm": 0.15408912301063538,
      "learning_rate": 1.6233308736047868e-05,
      "loss": 0.0012,
      "step": 1262
    },
    {
      "epoch": 0.858016304347826,
      "grad_norm": 0.12110697478055954,
      "learning_rate": 1.6227744219559086e-05,
      "loss": 0.0013,
      "step": 1263
    },
    {
      "epoch": 0.8586956521739131,
      "grad_norm": 3.410362958908081,
      "learning_rate": 1.622217655117078e-05,
      "loss": 0.0245,
      "step": 1264
    },
    {
      "epoch": 0.859375,
      "grad_norm": 0.538288414478302,
      "learning_rate": 1.6216605733700776e-05,
      "loss": 0.0031,
      "step": 1265
    },
    {
      "epoch": 0.8600543478260869,
      "grad_norm": 5.4630889892578125,
      "learning_rate": 1.6211031769968503e-05,
      "loss": 0.1332,
      "step": 1266
    },
    {
      "epoch": 0.860733695652174,
      "grad_norm": 2.8647408485412598,
      "learning_rate": 1.6205454662794977e-05,
      "loss": 0.1965,
      "step": 1267
    },
    {
      "epoch": 0.8614130434782609,
      "grad_norm": 5.350769519805908,
      "learning_rate": 1.6199874415002806e-05,
      "loss": 0.2218,
      "step": 1268
    },
    {
      "epoch": 0.8620923913043478,
      "grad_norm": 3.4774227142333984,
      "learning_rate": 1.6194291029416188e-05,
      "loss": 0.0674,
      "step": 1269
    },
    {
      "epoch": 0.8627717391304348,
      "grad_norm": 9.367063522338867,
      "learning_rate": 1.6188704508860905e-05,
      "loss": 0.5566,
      "step": 1270
    },
    {
      "epoch": 0.8634510869565217,
      "grad_norm": 0.11063416302204132,
      "learning_rate": 1.6183114856164338e-05,
      "loss": 0.0011,
      "step": 1271
    },
    {
      "epoch": 0.8641304347826086,
      "grad_norm": 0.0062730214558541775,
      "learning_rate": 1.6177522074155436e-05,
      "loss": 0.0002,
      "step": 1272
    },
    {
      "epoch": 0.8648097826086957,
      "grad_norm": 17.195886611938477,
      "learning_rate": 1.6171926165664745e-05,
      "loss": 0.7251,
      "step": 1273
    },
    {
      "epoch": 0.8654891304347826,
      "grad_norm": 7.881266117095947,
      "learning_rate": 1.6166327133524385e-05,
      "loss": 0.1154,
      "step": 1274
    },
    {
      "epoch": 0.8661684782608695,
      "grad_norm": 0.006201921962201595,
      "learning_rate": 1.6160724980568066e-05,
      "loss": 0.0001,
      "step": 1275
    },
    {
      "epoch": 0.8668478260869565,
      "grad_norm": 6.8911519050598145,
      "learning_rate": 1.6155119709631067e-05,
      "loss": 0.12,
      "step": 1276
    },
    {
      "epoch": 0.8675271739130435,
      "grad_norm": 0.02556048147380352,
      "learning_rate": 1.614951132355025e-05,
      "loss": 0.0004,
      "step": 1277
    },
    {
      "epoch": 0.8682065217391305,
      "grad_norm": 17.978662490844727,
      "learning_rate": 1.6143899825164058e-05,
      "loss": 0.9096,
      "step": 1278
    },
    {
      "epoch": 0.8688858695652174,
      "grad_norm": 4.10403299331665,
      "learning_rate": 1.61382852173125e-05,
      "loss": 0.0302,
      "step": 1279
    },
    {
      "epoch": 0.8695652173913043,
      "grad_norm": 0.03308641538023949,
      "learning_rate": 1.6132667502837164e-05,
      "loss": 0.0004,
      "step": 1280
    },
    {
      "epoch": 0.8702445652173914,
      "grad_norm": 0.2762182652950287,
      "learning_rate": 1.6127046684581212e-05,
      "loss": 0.003,
      "step": 1281
    },
    {
      "epoch": 0.8709239130434783,
      "grad_norm": 0.048279933631420135,
      "learning_rate": 1.6121422765389377e-05,
      "loss": 0.0003,
      "step": 1282
    },
    {
      "epoch": 0.8716032608695652,
      "grad_norm": 4.880821704864502,
      "learning_rate": 1.611579574810795e-05,
      "loss": 0.2015,
      "step": 1283
    },
    {
      "epoch": 0.8722826086956522,
      "grad_norm": 2.099346160888672,
      "learning_rate": 1.6110165635584807e-05,
      "loss": 0.0193,
      "step": 1284
    },
    {
      "epoch": 0.8729619565217391,
      "grad_norm": 4.2198591232299805,
      "learning_rate": 1.610453243066938e-05,
      "loss": 0.0923,
      "step": 1285
    },
    {
      "epoch": 0.873641304347826,
      "grad_norm": 8.331930160522461,
      "learning_rate": 1.609889613621267e-05,
      "loss": 0.1721,
      "step": 1286
    },
    {
      "epoch": 0.8743206521739131,
      "grad_norm": 0.1922997385263443,
      "learning_rate": 1.6093256755067236e-05,
      "loss": 0.0016,
      "step": 1287
    },
    {
      "epoch": 0.875,
      "grad_norm": 4.215078830718994,
      "learning_rate": 1.608761429008721e-05,
      "loss": 0.092,
      "step": 1288
    },
    {
      "epoch": 0.8756793478260869,
      "grad_norm": 2.4442641735076904,
      "learning_rate": 1.608196874412827e-05,
      "loss": 0.0614,
      "step": 1289
    },
    {
      "epoch": 0.876358695652174,
      "grad_norm": 7.1868977546691895,
      "learning_rate": 1.6076320120047667e-05,
      "loss": 0.3053,
      "step": 1290
    },
    {
      "epoch": 0.8770380434782609,
      "grad_norm": 0.22022157907485962,
      "learning_rate": 1.6070668420704203e-05,
      "loss": 0.0018,
      "step": 1291
    },
    {
      "epoch": 0.8777173913043478,
      "grad_norm": 0.7343658208847046,
      "learning_rate": 1.6065013648958238e-05,
      "loss": 0.0079,
      "step": 1292
    },
    {
      "epoch": 0.8783967391304348,
      "grad_norm": 2.709275722503662,
      "learning_rate": 1.6059355807671683e-05,
      "loss": 0.0984,
      "step": 1293
    },
    {
      "epoch": 0.8790760869565217,
      "grad_norm": 0.010153694078326225,
      "learning_rate": 1.6053694899708014e-05,
      "loss": 0.0002,
      "step": 1294
    },
    {
      "epoch": 0.8797554347826086,
      "grad_norm": 4.557705879211426,
      "learning_rate": 1.6048030927932242e-05,
      "loss": 0.147,
      "step": 1295
    },
    {
      "epoch": 0.8804347826086957,
      "grad_norm": 3.881136655807495,
      "learning_rate": 1.6042363895210948e-05,
      "loss": 0.1211,
      "step": 1296
    },
    {
      "epoch": 0.8811141304347826,
      "grad_norm": 13.885415077209473,
      "learning_rate": 1.603669380441224e-05,
      "loss": 0.0929,
      "step": 1297
    },
    {
      "epoch": 0.8817934782608695,
      "grad_norm": 6.643519878387451,
      "learning_rate": 1.60310206584058e-05,
      "loss": 0.1503,
      "step": 1298
    },
    {
      "epoch": 0.8824728260869565,
      "grad_norm": 2.598642587661743,
      "learning_rate": 1.6025344460062826e-05,
      "loss": 0.088,
      "step": 1299
    },
    {
      "epoch": 0.8831521739130435,
      "grad_norm": 0.06751960515975952,
      "learning_rate": 1.601966521225609e-05,
      "loss": 0.0005,
      "step": 1300
    },
    {
      "epoch": 0.8838315217391305,
      "grad_norm": 10.32369327545166,
      "learning_rate": 1.6013982917859884e-05,
      "loss": 0.4232,
      "step": 1301
    },
    {
      "epoch": 0.8845108695652174,
      "grad_norm": 9.193562507629395,
      "learning_rate": 1.6008297579750063e-05,
      "loss": 0.0524,
      "step": 1302
    },
    {
      "epoch": 0.8851902173913043,
      "grad_norm": 6.480647087097168,
      "learning_rate": 1.6002609200804003e-05,
      "loss": 0.2608,
      "step": 1303
    },
    {
      "epoch": 0.8858695652173914,
      "grad_norm": 0.006734566763043404,
      "learning_rate": 1.5996917783900633e-05,
      "loss": 0.0001,
      "step": 1304
    },
    {
      "epoch": 0.8865489130434783,
      "grad_norm": 3.119795560836792,
      "learning_rate": 1.59912233319204e-05,
      "loss": 0.0227,
      "step": 1305
    },
    {
      "epoch": 0.8872282608695652,
      "grad_norm": 0.03523558750748634,
      "learning_rate": 1.5985525847745322e-05,
      "loss": 0.0004,
      "step": 1306
    },
    {
      "epoch": 0.8879076086956522,
      "grad_norm": 0.0683199018239975,
      "learning_rate": 1.597982533425892e-05,
      "loss": 0.0007,
      "step": 1307
    },
    {
      "epoch": 0.8885869565217391,
      "grad_norm": 2.4387032985687256,
      "learning_rate": 1.597412179434626e-05,
      "loss": 0.0813,
      "step": 1308
    },
    {
      "epoch": 0.889266304347826,
      "grad_norm": 3.291825771331787,
      "learning_rate": 1.5968415230893933e-05,
      "loss": 0.1359,
      "step": 1309
    },
    {
      "epoch": 0.8899456521739131,
      "grad_norm": 1.7487306594848633,
      "learning_rate": 1.596270564679007e-05,
      "loss": 0.0155,
      "step": 1310
    },
    {
      "epoch": 0.890625,
      "grad_norm": 0.01513379905372858,
      "learning_rate": 1.5956993044924334e-05,
      "loss": 0.0002,
      "step": 1311
    },
    {
      "epoch": 0.8913043478260869,
      "grad_norm": 0.010354988276958466,
      "learning_rate": 1.59512774281879e-05,
      "loss": 0.0001,
      "step": 1312
    },
    {
      "epoch": 0.891983695652174,
      "grad_norm": 2.5996153354644775,
      "learning_rate": 1.5945558799473474e-05,
      "loss": 0.0159,
      "step": 1313
    },
    {
      "epoch": 0.8926630434782609,
      "grad_norm": 3.583008050918579,
      "learning_rate": 1.5939837161675297e-05,
      "loss": 0.1079,
      "step": 1314
    },
    {
      "epoch": 0.8933423913043478,
      "grad_norm": 0.09065516293048859,
      "learning_rate": 1.5934112517689116e-05,
      "loss": 0.0006,
      "step": 1315
    },
    {
      "epoch": 0.8940217391304348,
      "grad_norm": 2.712101697921753,
      "learning_rate": 1.5928384870412213e-05,
      "loss": 0.0995,
      "step": 1316
    },
    {
      "epoch": 0.8947010869565217,
      "grad_norm": 11.647645950317383,
      "learning_rate": 1.592265422274339e-05,
      "loss": 0.175,
      "step": 1317
    },
    {
      "epoch": 0.8953804347826086,
      "grad_norm": 3.2527387142181396,
      "learning_rate": 1.5916920577582956e-05,
      "loss": 0.202,
      "step": 1318
    },
    {
      "epoch": 0.8960597826086957,
      "grad_norm": 9.680343627929688,
      "learning_rate": 1.5911183937832746e-05,
      "loss": 0.3297,
      "step": 1319
    },
    {
      "epoch": 0.8967391304347826,
      "grad_norm": 1.4904168844223022,
      "learning_rate": 1.590544430639611e-05,
      "loss": 0.0274,
      "step": 1320
    },
    {
      "epoch": 0.8974184782608695,
      "grad_norm": 3.235474109649658,
      "learning_rate": 1.589970168617791e-05,
      "loss": 0.1195,
      "step": 1321
    },
    {
      "epoch": 0.8980978260869565,
      "grad_norm": 4.218188762664795,
      "learning_rate": 1.589395608008452e-05,
      "loss": 0.1726,
      "step": 1322
    },
    {
      "epoch": 0.8987771739130435,
      "grad_norm": 0.0033501137513667345,
      "learning_rate": 1.5888207491023824e-05,
      "loss": 0.0001,
      "step": 1323
    },
    {
      "epoch": 0.8994565217391305,
      "grad_norm": 0.5422161221504211,
      "learning_rate": 1.5882455921905228e-05,
      "loss": 0.0046,
      "step": 1324
    },
    {
      "epoch": 0.9001358695652174,
      "grad_norm": 0.20662708580493927,
      "learning_rate": 1.5876701375639626e-05,
      "loss": 0.002,
      "step": 1325
    },
    {
      "epoch": 0.9008152173913043,
      "grad_norm": 0.463724285364151,
      "learning_rate": 1.5870943855139437e-05,
      "loss": 0.0026,
      "step": 1326
    },
    {
      "epoch": 0.9014945652173914,
      "grad_norm": 1.5156137943267822,
      "learning_rate": 1.586518336331857e-05,
      "loss": 0.0104,
      "step": 1327
    },
    {
      "epoch": 0.9021739130434783,
      "grad_norm": 0.013759922236204147,
      "learning_rate": 1.585941990309245e-05,
      "loss": 0.0001,
      "step": 1328
    },
    {
      "epoch": 0.9028532608695652,
      "grad_norm": 3.4151787757873535,
      "learning_rate": 1.5853653477377996e-05,
      "loss": 0.173,
      "step": 1329
    },
    {
      "epoch": 0.9035326086956522,
      "grad_norm": 0.008232605643570423,
      "learning_rate": 1.5847884089093633e-05,
      "loss": 0.0001,
      "step": 1330
    },
    {
      "epoch": 0.9042119565217391,
      "grad_norm": 1.9652698040008545,
      "learning_rate": 1.5842111741159286e-05,
      "loss": 0.0297,
      "step": 1331
    },
    {
      "epoch": 0.904891304347826,
      "grad_norm": 11.751420974731445,
      "learning_rate": 1.5836336436496377e-05,
      "loss": 0.6801,
      "step": 1332
    },
    {
      "epoch": 0.9055706521739131,
      "grad_norm": 0.0166009608656168,
      "learning_rate": 1.583055817802782e-05,
      "loss": 0.0002,
      "step": 1333
    },
    {
      "epoch": 0.90625,
      "grad_norm": 7.520349979400635,
      "learning_rate": 1.5824776968678024e-05,
      "loss": 0.2074,
      "step": 1334
    },
    {
      "epoch": 0.9069293478260869,
      "grad_norm": 6.405848979949951,
      "learning_rate": 1.5818992811372898e-05,
      "loss": 0.2251,
      "step": 1335
    },
    {
      "epoch": 0.907608695652174,
      "grad_norm": 0.00842144712805748,
      "learning_rate": 1.5813205709039842e-05,
      "loss": 0.0001,
      "step": 1336
    },
    {
      "epoch": 0.9082880434782609,
      "grad_norm": 2.802276134490967,
      "learning_rate": 1.5807415664607737e-05,
      "loss": 0.0611,
      "step": 1337
    },
    {
      "epoch": 0.9089673913043478,
      "grad_norm": 3.107285976409912,
      "learning_rate": 1.5801622681006966e-05,
      "loss": 0.0997,
      "step": 1338
    },
    {
      "epoch": 0.9096467391304348,
      "grad_norm": 4.056421279907227,
      "learning_rate": 1.5795826761169393e-05,
      "loss": 0.1642,
      "step": 1339
    },
    {
      "epoch": 0.9103260869565217,
      "grad_norm": 3.4772775173187256,
      "learning_rate": 1.5790027908028366e-05,
      "loss": 0.1922,
      "step": 1340
    },
    {
      "epoch": 0.9110054347826086,
      "grad_norm": 0.04782328009605408,
      "learning_rate": 1.5784226124518724e-05,
      "loss": 0.0005,
      "step": 1341
    },
    {
      "epoch": 0.9116847826086957,
      "grad_norm": 3.2281432151794434,
      "learning_rate": 1.5778421413576778e-05,
      "loss": 0.1945,
      "step": 1342
    },
    {
      "epoch": 0.9123641304347826,
      "grad_norm": 5.913190841674805,
      "learning_rate": 1.5772613778140337e-05,
      "loss": 0.4489,
      "step": 1343
    },
    {
      "epoch": 0.9130434782608695,
      "grad_norm": 18.881946563720703,
      "learning_rate": 1.5766803221148676e-05,
      "loss": 0.0858,
      "step": 1344
    },
    {
      "epoch": 0.9137228260869565,
      "grad_norm": 0.13095861673355103,
      "learning_rate": 1.5760989745542547e-05,
      "loss": 0.0012,
      "step": 1345
    },
    {
      "epoch": 0.9144021739130435,
      "grad_norm": 22.444087982177734,
      "learning_rate": 1.57551733542642e-05,
      "loss": 0.2823,
      "step": 1346
    },
    {
      "epoch": 0.9150815217391305,
      "grad_norm": 2.006809949874878,
      "learning_rate": 1.5749354050257334e-05,
      "loss": 0.1174,
      "step": 1347
    },
    {
      "epoch": 0.9157608695652174,
      "grad_norm": 5.835620403289795,
      "learning_rate": 1.574353183646714e-05,
      "loss": 0.2712,
      "step": 1348
    },
    {
      "epoch": 0.9164402173913043,
      "grad_norm": 1.208159327507019,
      "learning_rate": 1.5737706715840276e-05,
      "loss": 0.0099,
      "step": 1349
    },
    {
      "epoch": 0.9171195652173914,
      "grad_norm": 6.292935371398926,
      "learning_rate": 1.5731878691324874e-05,
      "loss": 0.1373,
      "step": 1350
    },
    {
      "epoch": 0.9177989130434783,
      "grad_norm": 1.5513161420822144,
      "learning_rate": 1.5726047765870525e-05,
      "loss": 0.0086,
      "step": 1351
    },
    {
      "epoch": 0.9184782608695652,
      "grad_norm": 4.538267612457275,
      "learning_rate": 1.57202139424283e-05,
      "loss": 0.0658,
      "step": 1352
    },
    {
      "epoch": 0.9191576086956522,
      "grad_norm": 5.4983415603637695,
      "learning_rate": 1.5714377223950734e-05,
      "loss": 0.2123,
      "step": 1353
    },
    {
      "epoch": 0.9198369565217391,
      "grad_norm": 12.839144706726074,
      "learning_rate": 1.5708537613391826e-05,
      "loss": 0.4013,
      "step": 1354
    },
    {
      "epoch": 0.920516304347826,
      "grad_norm": 0.017009804025292397,
      "learning_rate": 1.570269511370704e-05,
      "loss": 0.0002,
      "step": 1355
    },
    {
      "epoch": 0.9211956521739131,
      "grad_norm": 2.6084752082824707,
      "learning_rate": 1.5696849727853297e-05,
      "loss": 0.176,
      "step": 1356
    },
    {
      "epoch": 0.921875,
      "grad_norm": 0.07881367951631546,
      "learning_rate": 1.5691001458788984e-05,
      "loss": 0.0006,
      "step": 1357
    },
    {
      "epoch": 0.9225543478260869,
      "grad_norm": 7.718589782714844,
      "learning_rate": 1.5685150309473947e-05,
      "loss": 0.2088,
      "step": 1358
    },
    {
      "epoch": 0.923233695652174,
      "grad_norm": 9.23873233795166,
      "learning_rate": 1.567929628286949e-05,
      "loss": 0.137,
      "step": 1359
    },
    {
      "epoch": 0.9239130434782609,
      "grad_norm": 2.223062038421631,
      "learning_rate": 1.5673439381938365e-05,
      "loss": 0.0457,
      "step": 1360
    },
    {
      "epoch": 0.9245923913043478,
      "grad_norm": 0.005545417778193951,
      "learning_rate": 1.5667579609644793e-05,
      "loss": 0.0001,
      "step": 1361
    },
    {
      "epoch": 0.9252717391304348,
      "grad_norm": 2.8608219623565674,
      "learning_rate": 1.5661716968954436e-05,
      "loss": 0.1291,
      "step": 1362
    },
    {
      "epoch": 0.9259510869565217,
      "grad_norm": 8.168438911437988,
      "learning_rate": 1.5655851462834414e-05,
      "loss": 0.3172,
      "step": 1363
    },
    {
      "epoch": 0.9266304347826086,
      "grad_norm": 4.699005603790283,
      "learning_rate": 1.56499830942533e-05,
      "loss": 0.1434,
      "step": 1364
    },
    {
      "epoch": 0.9273097826086957,
      "grad_norm": 3.6030755043029785,
      "learning_rate": 1.56441118661811e-05,
      "loss": 0.2123,
      "step": 1365
    },
    {
      "epoch": 0.9279891304347826,
      "grad_norm": 0.16000905632972717,
      "learning_rate": 1.563823778158929e-05,
      "loss": 0.0013,
      "step": 1366
    },
    {
      "epoch": 0.9286684782608695,
      "grad_norm": 12.810025215148926,
      "learning_rate": 1.563236084345078e-05,
      "loss": 0.2563,
      "step": 1367
    },
    {
      "epoch": 0.9293478260869565,
      "grad_norm": 5.620250225067139,
      "learning_rate": 1.5626481054739916e-05,
      "loss": 0.0658,
      "step": 1368
    },
    {
      "epoch": 0.9300271739130435,
      "grad_norm": 0.10696300864219666,
      "learning_rate": 1.56205984184325e-05,
      "loss": 0.0008,
      "step": 1369
    },
    {
      "epoch": 0.9307065217391305,
      "grad_norm": 5.196381092071533,
      "learning_rate": 1.5614712937505767e-05,
      "loss": 0.0608,
      "step": 1370
    },
    {
      "epoch": 0.9313858695652174,
      "grad_norm": 3.564013957977295,
      "learning_rate": 1.56088246149384e-05,
      "loss": 0.1177,
      "step": 1371
    },
    {
      "epoch": 0.9320652173913043,
      "grad_norm": 3.427672863006592,
      "learning_rate": 1.560293345371051e-05,
      "loss": 0.1136,
      "step": 1372
    },
    {
      "epoch": 0.9327445652173914,
      "grad_norm": 0.005687073804438114,
      "learning_rate": 1.559703945680366e-05,
      "loss": 0.0001,
      "step": 1373
    },
    {
      "epoch": 0.9334239130434783,
      "grad_norm": 0.00970435794442892,
      "learning_rate": 1.5591142627200825e-05,
      "loss": 0.0001,
      "step": 1374
    },
    {
      "epoch": 0.9341032608695652,
      "grad_norm": 0.1284162700176239,
      "learning_rate": 1.5585242967886432e-05,
      "loss": 0.001,
      "step": 1375
    },
    {
      "epoch": 0.9347826086956522,
      "grad_norm": 0.10837393254041672,
      "learning_rate": 1.5579340481846338e-05,
      "loss": 0.0009,
      "step": 1376
    },
    {
      "epoch": 0.9354619565217391,
      "grad_norm": 0.0064818477258086205,
      "learning_rate": 1.557343517206782e-05,
      "loss": 0.0001,
      "step": 1377
    },
    {
      "epoch": 0.936141304347826,
      "grad_norm": 3.308253526687622,
      "learning_rate": 1.5567527041539597e-05,
      "loss": 0.1608,
      "step": 1378
    },
    {
      "epoch": 0.9368206521739131,
      "grad_norm": 0.02472648210823536,
      "learning_rate": 1.556161609325181e-05,
      "loss": 0.0002,
      "step": 1379
    },
    {
      "epoch": 0.9375,
      "grad_norm": 9.764029502868652,
      "learning_rate": 1.5555702330196024e-05,
      "loss": 0.2878,
      "step": 1380
    },
    {
      "epoch": 0.9381793478260869,
      "grad_norm": 3.6967406272888184,
      "learning_rate": 1.5549785755365233e-05,
      "loss": 0.0944,
      "step": 1381
    },
    {
      "epoch": 0.938858695652174,
      "grad_norm": 4.412747383117676,
      "learning_rate": 1.5543866371753852e-05,
      "loss": 0.1578,
      "step": 1382
    },
    {
      "epoch": 0.9395380434782609,
      "grad_norm": 0.012648808769881725,
      "learning_rate": 1.553794418235771e-05,
      "loss": 0.0002,
      "step": 1383
    },
    {
      "epoch": 0.9402173913043478,
      "grad_norm": 0.03010539337992668,
      "learning_rate": 1.5532019190174074e-05,
      "loss": 0.0003,
      "step": 1384
    },
    {
      "epoch": 0.9408967391304348,
      "grad_norm": 5.495959758758545,
      "learning_rate": 1.5526091398201612e-05,
      "loss": 0.1119,
      "step": 1385
    },
    {
      "epoch": 0.9415760869565217,
      "grad_norm": 2.1214799880981445,
      "learning_rate": 1.552016080944042e-05,
      "loss": 0.0693,
      "step": 1386
    },
    {
      "epoch": 0.9422554347826086,
      "grad_norm": 4.912486553192139,
      "learning_rate": 1.5514227426892e-05,
      "loss": 0.1298,
      "step": 1387
    },
    {
      "epoch": 0.9429347826086957,
      "grad_norm": 0.01906687393784523,
      "learning_rate": 1.550829125355928e-05,
      "loss": 0.0003,
      "step": 1388
    },
    {
      "epoch": 0.9436141304347826,
      "grad_norm": 0.06884314119815826,
      "learning_rate": 1.550235229244659e-05,
      "loss": 0.0005,
      "step": 1389
    },
    {
      "epoch": 0.9442934782608695,
      "grad_norm": 4.5919671058654785,
      "learning_rate": 1.549641054655967e-05,
      "loss": 0.0253,
      "step": 1390
    },
    {
      "epoch": 0.9449728260869565,
      "grad_norm": 0.9511318206787109,
      "learning_rate": 1.5490466018905684e-05,
      "loss": 0.0304,
      "step": 1391
    },
    {
      "epoch": 0.9456521739130435,
      "grad_norm": 0.4235449731349945,
      "learning_rate": 1.5484518712493188e-05,
      "loss": 0.0032,
      "step": 1392
    },
    {
      "epoch": 0.9463315217391305,
      "grad_norm": 0.006372315809130669,
      "learning_rate": 1.547856863033215e-05,
      "loss": 0.0001,
      "step": 1393
    },
    {
      "epoch": 0.9470108695652174,
      "grad_norm": 5.4803385734558105,
      "learning_rate": 1.547261577543395e-05,
      "loss": 0.235,
      "step": 1394
    },
    {
      "epoch": 0.9476902173913043,
      "grad_norm": 0.19809593260288239,
      "learning_rate": 1.546666015081135e-05,
      "loss": 0.001,
      "step": 1395
    },
    {
      "epoch": 0.9483695652173914,
      "grad_norm": 0.016140209510922432,
      "learning_rate": 1.5460701759478538e-05,
      "loss": 0.0002,
      "step": 1396
    },
    {
      "epoch": 0.9490489130434783,
      "grad_norm": 1.0869321823120117,
      "learning_rate": 1.5454740604451092e-05,
      "loss": 0.0041,
      "step": 1397
    },
    {
      "epoch": 0.9497282608695652,
      "grad_norm": 2.0975091457366943,
      "learning_rate": 1.544877668874599e-05,
      "loss": 0.0164,
      "step": 1398
    },
    {
      "epoch": 0.9504076086956522,
      "grad_norm": 12.064363479614258,
      "learning_rate": 1.54428100153816e-05,
      "loss": 0.5842,
      "step": 1399
    },
    {
      "epoch": 0.9510869565217391,
      "grad_norm": 4.695302963256836,
      "learning_rate": 1.54368405873777e-05,
      "loss": 0.2242,
      "step": 1400
    },
    {
      "epoch": 0.951766304347826,
      "grad_norm": 0.7056177854537964,
      "learning_rate": 1.543086840775545e-05,
      "loss": 0.0047,
      "step": 1401
    },
    {
      "epoch": 0.9524456521739131,
      "grad_norm": 0.009909282438457012,
      "learning_rate": 1.542489347953741e-05,
      "loss": 0.0001,
      "step": 1402
    },
    {
      "epoch": 0.953125,
      "grad_norm": 0.006628815550357103,
      "learning_rate": 1.5418915805747518e-05,
      "loss": 0.0001,
      "step": 1403
    },
    {
      "epoch": 0.9538043478260869,
      "grad_norm": 1.569519281387329,
      "learning_rate": 1.5412935389411124e-05,
      "loss": 0.0338,
      "step": 1404
    },
    {
      "epoch": 0.954483695652174,
      "grad_norm": 4.988273620605469,
      "learning_rate": 1.5406952233554945e-05,
      "loss": 0.1294,
      "step": 1405
    },
    {
      "epoch": 0.9551630434782609,
      "grad_norm": 7.007875442504883,
      "learning_rate": 1.5400966341207095e-05,
      "loss": 0.0925,
      "step": 1406
    },
    {
      "epoch": 0.9558423913043478,
      "grad_norm": 2.684270143508911,
      "learning_rate": 1.5394977715397073e-05,
      "loss": 0.1276,
      "step": 1407
    },
    {
      "epoch": 0.9565217391304348,
      "grad_norm": 0.015098828822374344,
      "learning_rate": 1.538898635915576e-05,
      "loss": 0.0002,
      "step": 1408
    },
    {
      "epoch": 0.9572010869565217,
      "grad_norm": 0.26080888509750366,
      "learning_rate": 1.5382992275515406e-05,
      "loss": 0.0015,
      "step": 1409
    },
    {
      "epoch": 0.9578804347826086,
      "grad_norm": 1.8673917055130005,
      "learning_rate": 1.5376995467509673e-05,
      "loss": 0.068,
      "step": 1410
    },
    {
      "epoch": 0.9585597826086957,
      "grad_norm": 0.8817573189735413,
      "learning_rate": 1.5370995938173566e-05,
      "loss": 0.007,
      "step": 1411
    },
    {
      "epoch": 0.9592391304347826,
      "grad_norm": 0.28940075635910034,
      "learning_rate": 1.5364993690543495e-05,
      "loss": 0.0017,
      "step": 1412
    },
    {
      "epoch": 0.9599184782608695,
      "grad_norm": 3.350982189178467,
      "learning_rate": 1.5358988727657227e-05,
      "loss": 0.1988,
      "step": 1413
    },
    {
      "epoch": 0.9605978260869565,
      "grad_norm": 1.1216166019439697,
      "learning_rate": 1.5352981052553913e-05,
      "loss": 0.0129,
      "step": 1414
    },
    {
      "epoch": 0.9612771739130435,
      "grad_norm": 0.07850778847932816,
      "learning_rate": 1.5346970668274076e-05,
      "loss": 0.0007,
      "step": 1415
    },
    {
      "epoch": 0.9619565217391305,
      "grad_norm": 5.374345779418945,
      "learning_rate": 1.5340957577859605e-05,
      "loss": 0.0369,
      "step": 1416
    },
    {
      "epoch": 0.9626358695652174,
      "grad_norm": 0.10821686685085297,
      "learning_rate": 1.533494178435376e-05,
      "loss": 0.0013,
      "step": 1417
    },
    {
      "epoch": 0.9633152173913043,
      "grad_norm": 4.043907642364502,
      "learning_rate": 1.5328923290801177e-05,
      "loss": 0.129,
      "step": 1418
    },
    {
      "epoch": 0.9639945652173914,
      "grad_norm": 2.521387815475464,
      "learning_rate": 1.532290210024785e-05,
      "loss": 0.1145,
      "step": 1419
    },
    {
      "epoch": 0.9646739130434783,
      "grad_norm": 7.19654655456543,
      "learning_rate": 1.531687821574114e-05,
      "loss": 0.1814,
      "step": 1420
    },
    {
      "epoch": 0.9653532608695652,
      "grad_norm": 0.16714231669902802,
      "learning_rate": 1.531085164032977e-05,
      "loss": 0.0011,
      "step": 1421
    },
    {
      "epoch": 0.9660326086956522,
      "grad_norm": 3.4607417583465576,
      "learning_rate": 1.530482237706383e-05,
      "loss": 0.2353,
      "step": 1422
    },
    {
      "epoch": 0.9667119565217391,
      "grad_norm": 3.4830429553985596,
      "learning_rate": 1.529879042899477e-05,
      "loss": 0.2132,
      "step": 1423
    },
    {
      "epoch": 0.967391304347826,
      "grad_norm": 3.739295482635498,
      "learning_rate": 1.529275579917539e-05,
      "loss": 0.14,
      "step": 1424
    },
    {
      "epoch": 0.9680706521739131,
      "grad_norm": 19.183168411254883,
      "learning_rate": 1.5286718490659854e-05,
      "loss": 0.4788,
      "step": 1425
    },
    {
      "epoch": 0.96875,
      "grad_norm": 0.014388694427907467,
      "learning_rate": 1.528067850650368e-05,
      "loss": 0.0001,
      "step": 1426
    },
    {
      "epoch": 0.9694293478260869,
      "grad_norm": 5.064570426940918,
      "learning_rate": 1.5274635849763744e-05,
      "loss": 0.1016,
      "step": 1427
    },
    {
      "epoch": 0.970108695652174,
      "grad_norm": 3.202915668487549,
      "learning_rate": 1.526859052349827e-05,
      "loss": 0.1618,
      "step": 1428
    },
    {
      "epoch": 0.9707880434782609,
      "grad_norm": 10.172043800354004,
      "learning_rate": 1.526254253076684e-05,
      "loss": 0.1789,
      "step": 1429
    },
    {
      "epoch": 0.9714673913043478,
      "grad_norm": 4.946157455444336,
      "learning_rate": 1.525649187463037e-05,
      "loss": 0.0895,
      "step": 1430
    },
    {
      "epoch": 0.9721467391304348,
      "grad_norm": 6.561168193817139,
      "learning_rate": 1.5250438558151142e-05,
      "loss": 0.1626,
      "step": 1431
    },
    {
      "epoch": 0.9728260869565217,
      "grad_norm": 1.4505921602249146,
      "learning_rate": 1.5244382584392772e-05,
      "loss": 0.0954,
      "step": 1432
    },
    {
      "epoch": 0.9735054347826086,
      "grad_norm": 0.1935548633337021,
      "learning_rate": 1.523832395642023e-05,
      "loss": 0.0014,
      "step": 1433
    },
    {
      "epoch": 0.9741847826086957,
      "grad_norm": 16.883495330810547,
      "learning_rate": 1.5232262677299816e-05,
      "loss": 0.2762,
      "step": 1434
    },
    {
      "epoch": 0.9748641304347826,
      "grad_norm": 14.212903022766113,
      "learning_rate": 1.5226198750099194e-05,
      "loss": 0.6042,
      "step": 1435
    },
    {
      "epoch": 0.9755434782608695,
      "grad_norm": 0.4111306965351105,
      "learning_rate": 1.5220132177887345e-05,
      "loss": 0.0042,
      "step": 1436
    },
    {
      "epoch": 0.9762228260869565,
      "grad_norm": 1.7214993238449097,
      "learning_rate": 1.5214062963734599e-05,
      "loss": 0.0312,
      "step": 1437
    },
    {
      "epoch": 0.9769021739130435,
      "grad_norm": 2.085015296936035,
      "learning_rate": 1.5207991110712628e-05,
      "loss": 0.0932,
      "step": 1438
    },
    {
      "epoch": 0.9775815217391305,
      "grad_norm": 0.0049176705069839954,
      "learning_rate": 1.5201916621894425e-05,
      "loss": 0.0001,
      "step": 1439
    },
    {
      "epoch": 0.9782608695652174,
      "grad_norm": 0.04550231620669365,
      "learning_rate": 1.5195839500354337e-05,
      "loss": 0.0004,
      "step": 1440
    },
    {
      "epoch": 0.9789402173913043,
      "grad_norm": 0.14694960415363312,
      "learning_rate": 1.5189759749168027e-05,
      "loss": 0.0012,
      "step": 1441
    },
    {
      "epoch": 0.9796195652173914,
      "grad_norm": 0.006421320140361786,
      "learning_rate": 1.518367737141249e-05,
      "loss": 0.0001,
      "step": 1442
    },
    {
      "epoch": 0.9802989130434783,
      "grad_norm": 0.06050824373960495,
      "learning_rate": 1.517759237016606e-05,
      "loss": 0.0004,
      "step": 1443
    },
    {
      "epoch": 0.9809782608695652,
      "grad_norm": 0.5870195627212524,
      "learning_rate": 1.5171504748508394e-05,
      "loss": 0.0061,
      "step": 1444
    },
    {
      "epoch": 0.9816576086956522,
      "grad_norm": 0.1437949240207672,
      "learning_rate": 1.5165414509520473e-05,
      "loss": 0.0011,
      "step": 1445
    },
    {
      "epoch": 0.9823369565217391,
      "grad_norm": 0.011620125733315945,
      "learning_rate": 1.5159321656284602e-05,
      "loss": 0.0002,
      "step": 1446
    },
    {
      "epoch": 0.983016304347826,
      "grad_norm": 6.151699066162109,
      "learning_rate": 1.5153226191884417e-05,
      "loss": 0.1112,
      "step": 1447
    },
    {
      "epoch": 0.9836956521739131,
      "grad_norm": 1.8072712421417236,
      "learning_rate": 1.5147128119404863e-05,
      "loss": 0.0803,
      "step": 1448
    },
    {
      "epoch": 0.984375,
      "grad_norm": 3.437274932861328,
      "learning_rate": 1.5141027441932217e-05,
      "loss": 0.075,
      "step": 1449
    },
    {
      "epoch": 0.9850543478260869,
      "grad_norm": 3.0249032974243164,
      "learning_rate": 1.513492416255407e-05,
      "loss": 0.0214,
      "step": 1450
    },
    {
      "epoch": 0.985733695652174,
      "grad_norm": 0.0019451844273135066,
      "learning_rate": 1.5128818284359326e-05,
      "loss": 0.0001,
      "step": 1451
    },
    {
      "epoch": 0.9864130434782609,
      "grad_norm": 0.06347780674695969,
      "learning_rate": 1.5122709810438205e-05,
      "loss": 0.0005,
      "step": 1452
    },
    {
      "epoch": 0.9870923913043478,
      "grad_norm": 1.5245935916900635,
      "learning_rate": 1.5116598743882247e-05,
      "loss": 0.0498,
      "step": 1453
    },
    {
      "epoch": 0.9877717391304348,
      "grad_norm": 2.772524118423462,
      "learning_rate": 1.5110485087784302e-05,
      "loss": 0.0157,
      "step": 1454
    },
    {
      "epoch": 0.9884510869565217,
      "grad_norm": 0.27937087416648865,
      "learning_rate": 1.5104368845238525e-05,
      "loss": 0.0028,
      "step": 1455
    },
    {
      "epoch": 0.9891304347826086,
      "grad_norm": 0.019388342276215553,
      "learning_rate": 1.5098250019340385e-05,
      "loss": 0.0004,
      "step": 1456
    },
    {
      "epoch": 0.9898097826086957,
      "grad_norm": 0.00597785972058773,
      "learning_rate": 1.5092128613186658e-05,
      "loss": 0.0001,
      "step": 1457
    },
    {
      "epoch": 0.9904891304347826,
      "grad_norm": 4.986589431762695,
      "learning_rate": 1.5086004629875426e-05,
      "loss": 0.2042,
      "step": 1458
    },
    {
      "epoch": 0.9911684782608695,
      "grad_norm": 0.003293231362476945,
      "learning_rate": 1.507987807250607e-05,
      "loss": 0.0001,
      "step": 1459
    },
    {
      "epoch": 0.9918478260869565,
      "grad_norm": 7.522050380706787,
      "learning_rate": 1.5073748944179282e-05,
      "loss": 0.1217,
      "step": 1460
    },
    {
      "epoch": 0.9925271739130435,
      "grad_norm": 4.29258394241333,
      "learning_rate": 1.5067617247997053e-05,
      "loss": 0.1264,
      "step": 1461
    },
    {
      "epoch": 0.9932065217391305,
      "grad_norm": 0.05195072665810585,
      "learning_rate": 1.5061482987062668e-05,
      "loss": 0.0004,
      "step": 1462
    },
    {
      "epoch": 0.9938858695652174,
      "grad_norm": 0.019239505752921104,
      "learning_rate": 1.5055346164480717e-05,
      "loss": 0.0002,
      "step": 1463
    },
    {
      "epoch": 0.9945652173913043,
      "grad_norm": 9.546345710754395,
      "learning_rate": 1.5049206783357082e-05,
      "loss": 0.1083,
      "step": 1464
    },
    {
      "epoch": 0.9952445652173914,
      "grad_norm": 8.573846817016602,
      "learning_rate": 1.504306484679894e-05,
      "loss": 0.4133,
      "step": 1465
    },
    {
      "epoch": 0.9959239130434783,
      "grad_norm": 2.7695188522338867,
      "learning_rate": 1.5036920357914766e-05,
      "loss": 0.2113,
      "step": 1466
    },
    {
      "epoch": 0.9966032608695652,
      "grad_norm": 1.0249193906784058,
      "learning_rate": 1.5030773319814324e-05,
      "loss": 0.0257,
      "step": 1467
    },
    {
      "epoch": 0.9972826086956522,
      "grad_norm": 2.963571071624756,
      "learning_rate": 1.5024623735608663e-05,
      "loss": 0.1449,
      "step": 1468
    },
    {
      "epoch": 0.9979619565217391,
      "grad_norm": 0.03058844618499279,
      "learning_rate": 1.5018471608410128e-05,
      "loss": 0.0003,
      "step": 1469
    },
    {
      "epoch": 0.998641304347826,
      "grad_norm": 1.2278715372085571,
      "learning_rate": 1.501231694133235e-05,
      "loss": 0.0175,
      "step": 1470
    },
    {
      "epoch": 0.9993206521739131,
      "grad_norm": 3.445892333984375,
      "learning_rate": 1.500615973749024e-05,
      "loss": 0.1716,
      "step": 1471
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.01526703406125307,
      "learning_rate": 1.5000000000000002e-05,
      "loss": 0.0002,
      "step": 1472
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.43902439024390244,
      "eval_loss": 0.14645293354988098,
      "eval_runtime": 136.0987,
      "eval_samples_per_second": 1.205,
      "eval_steps_per_second": 1.205,
      "step": 1472
    },
    {
      "epoch": 1.000679347826087,
      "grad_norm": 0.015442684292793274,
      "learning_rate": 1.499383773197911e-05,
      "loss": 0.0002,
      "step": 1473
    },
    {
      "epoch": 1.0013586956521738,
      "grad_norm": 23.086410522460938,
      "learning_rate": 1.4987672936546331e-05,
      "loss": 0.3775,
      "step": 1474
    },
    {
      "epoch": 1.002038043478261,
      "grad_norm": 4.165894985198975,
      "learning_rate": 1.4981505616821705e-05,
      "loss": 0.0494,
      "step": 1475
    },
    {
      "epoch": 1.002717391304348,
      "grad_norm": 2.01476788520813,
      "learning_rate": 1.4975335775926547e-05,
      "loss": 0.0611,
      "step": 1476
    },
    {
      "epoch": 1.0033967391304348,
      "grad_norm": 7.1214518547058105,
      "learning_rate": 1.4969163416983457e-05,
      "loss": 0.1489,
      "step": 1477
    },
    {
      "epoch": 1.0040760869565217,
      "grad_norm": 3.620103597640991,
      "learning_rate": 1.4962988543116295e-05,
      "loss": 0.1837,
      "step": 1478
    },
    {
      "epoch": 1.0047554347826086,
      "grad_norm": 2.5072038173675537,
      "learning_rate": 1.495681115745021e-05,
      "loss": 0.1072,
      "step": 1479
    },
    {
      "epoch": 1.0054347826086956,
      "grad_norm": 4.495382785797119,
      "learning_rate": 1.4950631263111615e-05,
      "loss": 0.2952,
      "step": 1480
    },
    {
      "epoch": 1.0061141304347827,
      "grad_norm": 1.060097098350525,
      "learning_rate": 1.4944448863228187e-05,
      "loss": 0.0262,
      "step": 1481
    },
    {
      "epoch": 1.0067934782608696,
      "grad_norm": 0.04171852767467499,
      "learning_rate": 1.4938263960928878e-05,
      "loss": 0.0003,
      "step": 1482
    },
    {
      "epoch": 1.0074728260869565,
      "grad_norm": 3.0415098667144775,
      "learning_rate": 1.493207655934391e-05,
      "loss": 0.173,
      "step": 1483
    },
    {
      "epoch": 1.0081521739130435,
      "grad_norm": 3.9076833724975586,
      "learning_rate": 1.492588666160476e-05,
      "loss": 0.0708,
      "step": 1484
    },
    {
      "epoch": 1.0088315217391304,
      "grad_norm": 2.0882298946380615,
      "learning_rate": 1.4919694270844176e-05,
      "loss": 0.0357,
      "step": 1485
    },
    {
      "epoch": 1.0095108695652173,
      "grad_norm": 13.694387435913086,
      "learning_rate": 1.4913499390196162e-05,
      "loss": 0.3002,
      "step": 1486
    },
    {
      "epoch": 1.0101902173913044,
      "grad_norm": 0.017170293256640434,
      "learning_rate": 1.4907302022795987e-05,
      "loss": 0.0002,
      "step": 1487
    },
    {
      "epoch": 1.0108695652173914,
      "grad_norm": 0.003189832204952836,
      "learning_rate": 1.4901102171780175e-05,
      "loss": 0.0001,
      "step": 1488
    },
    {
      "epoch": 1.0115489130434783,
      "grad_norm": 0.13517315685749054,
      "learning_rate": 1.4894899840286507e-05,
      "loss": 0.001,
      "step": 1489
    },
    {
      "epoch": 1.0122282608695652,
      "grad_norm": 5.307467937469482,
      "learning_rate": 1.4888695031454028e-05,
      "loss": 0.0285,
      "step": 1490
    },
    {
      "epoch": 1.012907608695652,
      "grad_norm": 6.425926208496094,
      "learning_rate": 1.4882487748423025e-05,
      "loss": 0.3394,
      "step": 1491
    },
    {
      "epoch": 1.013586956521739,
      "grad_norm": 0.04941944032907486,
      "learning_rate": 1.4876277994335042e-05,
      "loss": 0.0004,
      "step": 1492
    },
    {
      "epoch": 1.0142663043478262,
      "grad_norm": 0.11626442521810532,
      "learning_rate": 1.4870065772332874e-05,
      "loss": 0.0008,
      "step": 1493
    },
    {
      "epoch": 1.014945652173913,
      "grad_norm": 3.6812517642974854,
      "learning_rate": 1.4863851085560563e-05,
      "loss": 0.2262,
      "step": 1494
    },
    {
      "epoch": 1.015625,
      "grad_norm": 0.05626283586025238,
      "learning_rate": 1.4857633937163402e-05,
      "loss": 0.0004,
      "step": 1495
    },
    {
      "epoch": 1.016304347826087,
      "grad_norm": 1.3909982442855835,
      "learning_rate": 1.485141433028793e-05,
      "loss": 0.0356,
      "step": 1496
    },
    {
      "epoch": 1.0169836956521738,
      "grad_norm": 1.5985581874847412,
      "learning_rate": 1.4845192268081924e-05,
      "loss": 0.0216,
      "step": 1497
    },
    {
      "epoch": 1.017663043478261,
      "grad_norm": 0.01585320197045803,
      "learning_rate": 1.4838967753694409e-05,
      "loss": 0.0001,
      "step": 1498
    },
    {
      "epoch": 1.018342391304348,
      "grad_norm": 5.990166664123535,
      "learning_rate": 1.483274079027565e-05,
      "loss": 0.112,
      "step": 1499
    },
    {
      "epoch": 1.0190217391304348,
      "grad_norm": 0.002935936441645026,
      "learning_rate": 1.4826511380977155e-05,
      "loss": 0.0001,
      "step": 1500
    },
    {
      "epoch": 1.0197010869565217,
      "grad_norm": 0.0031440621241927147,
      "learning_rate": 1.4820279528951662e-05,
      "loss": 0.0001,
      "step": 1501
    },
    {
      "epoch": 1.0203804347826086,
      "grad_norm": 2.612560272216797,
      "learning_rate": 1.4814045237353152e-05,
      "loss": 0.087,
      "step": 1502
    },
    {
      "epoch": 1.0210597826086956,
      "grad_norm": 14.611719131469727,
      "learning_rate": 1.4807808509336831e-05,
      "loss": 0.6255,
      "step": 1503
    },
    {
      "epoch": 1.0217391304347827,
      "grad_norm": 2.5104987621307373,
      "learning_rate": 1.4801569348059158e-05,
      "loss": 0.0689,
      "step": 1504
    },
    {
      "epoch": 1.0224184782608696,
      "grad_norm": 6.558987617492676,
      "learning_rate": 1.4795327756677799e-05,
      "loss": 0.1741,
      "step": 1505
    },
    {
      "epoch": 1.0230978260869565,
      "grad_norm": 0.12976473569869995,
      "learning_rate": 1.478908373835167e-05,
      "loss": 0.0008,
      "step": 1506
    },
    {
      "epoch": 1.0237771739130435,
      "grad_norm": 5.707356929779053,
      "learning_rate": 1.4782837296240905e-05,
      "loss": 0.2892,
      "step": 1507
    },
    {
      "epoch": 1.0244565217391304,
      "grad_norm": 0.0023402294609695673,
      "learning_rate": 1.4776588433506857e-05,
      "loss": 0.0,
      "step": 1508
    },
    {
      "epoch": 1.0251358695652173,
      "grad_norm": 7.1991119384765625,
      "learning_rate": 1.4770337153312131e-05,
      "loss": 0.1323,
      "step": 1509
    },
    {
      "epoch": 1.0258152173913044,
      "grad_norm": 9.42645263671875,
      "learning_rate": 1.4764083458820524e-05,
      "loss": 0.0972,
      "step": 1510
    },
    {
      "epoch": 1.0264945652173914,
      "grad_norm": 3.960550546646118,
      "learning_rate": 1.4757827353197076e-05,
      "loss": 0.1093,
      "step": 1511
    },
    {
      "epoch": 1.0271739130434783,
      "grad_norm": 0.010133652947843075,
      "learning_rate": 1.4751568839608036e-05,
      "loss": 0.0001,
      "step": 1512
    },
    {
      "epoch": 1.0278532608695652,
      "grad_norm": 3.53935170173645,
      "learning_rate": 1.4745307921220882e-05,
      "loss": 0.1132,
      "step": 1513
    },
    {
      "epoch": 1.028532608695652,
      "grad_norm": 3.950892925262451,
      "learning_rate": 1.47390446012043e-05,
      "loss": 0.1297,
      "step": 1514
    },
    {
      "epoch": 1.029211956521739,
      "grad_norm": 0.0043159713968634605,
      "learning_rate": 1.4732778882728193e-05,
      "loss": 0.0001,
      "step": 1515
    },
    {
      "epoch": 1.0298913043478262,
      "grad_norm": 0.22365976870059967,
      "learning_rate": 1.4726510768963682e-05,
      "loss": 0.0014,
      "step": 1516
    },
    {
      "epoch": 1.030570652173913,
      "grad_norm": 0.15149661898612976,
      "learning_rate": 1.4720240263083097e-05,
      "loss": 0.0014,
      "step": 1517
    },
    {
      "epoch": 1.03125,
      "grad_norm": 27.989765167236328,
      "learning_rate": 1.4713967368259981e-05,
      "loss": 0.3338,
      "step": 1518
    },
    {
      "epoch": 1.031929347826087,
      "grad_norm": 0.2718224823474884,
      "learning_rate": 1.4707692087669077e-05,
      "loss": 0.003,
      "step": 1519
    },
    {
      "epoch": 1.0326086956521738,
      "grad_norm": 2.4390528202056885,
      "learning_rate": 1.4701414424486353e-05,
      "loss": 0.0455,
      "step": 1520
    },
    {
      "epoch": 1.033288043478261,
      "grad_norm": 0.04750256985425949,
      "learning_rate": 1.4695134381888969e-05,
      "loss": 0.0004,
      "step": 1521
    },
    {
      "epoch": 1.033967391304348,
      "grad_norm": 1.520980715751648,
      "learning_rate": 1.468885196305529e-05,
      "loss": 0.0092,
      "step": 1522
    },
    {
      "epoch": 1.0346467391304348,
      "grad_norm": 2.2935354709625244,
      "learning_rate": 1.4682567171164891e-05,
      "loss": 0.16,
      "step": 1523
    },
    {
      "epoch": 1.0353260869565217,
      "grad_norm": 2.4518511295318604,
      "learning_rate": 1.4676280009398544e-05,
      "loss": 0.0683,
      "step": 1524
    },
    {
      "epoch": 1.0360054347826086,
      "grad_norm": 16.67848777770996,
      "learning_rate": 1.4669990480938217e-05,
      "loss": 0.2526,
      "step": 1525
    },
    {
      "epoch": 1.0366847826086956,
      "grad_norm": 3.617311954498291,
      "learning_rate": 1.466369858896708e-05,
      "loss": 0.1505,
      "step": 1526
    },
    {
      "epoch": 1.0373641304347827,
      "grad_norm": 2.1187517642974854,
      "learning_rate": 1.4657404336669498e-05,
      "loss": 0.0347,
      "step": 1527
    },
    {
      "epoch": 1.0380434782608696,
      "grad_norm": 21.40727424621582,
      "learning_rate": 1.4651107727231032e-05,
      "loss": 0.8909,
      "step": 1528
    },
    {
      "epoch": 1.0387228260869565,
      "grad_norm": 0.09724508225917816,
      "learning_rate": 1.464480876383843e-05,
      "loss": 0.0006,
      "step": 1529
    },
    {
      "epoch": 1.0394021739130435,
      "grad_norm": 3.929067611694336,
      "learning_rate": 1.4638507449679642e-05,
      "loss": 0.1538,
      "step": 1530
    },
    {
      "epoch": 1.0400815217391304,
      "grad_norm": 0.28417354822158813,
      "learning_rate": 1.46322037879438e-05,
      "loss": 0.0029,
      "step": 1531
    },
    {
      "epoch": 1.0407608695652173,
      "grad_norm": 5.576975345611572,
      "learning_rate": 1.4625897781821222e-05,
      "loss": 0.1985,
      "step": 1532
    },
    {
      "epoch": 1.0414402173913044,
      "grad_norm": 0.12298808991909027,
      "learning_rate": 1.4619589434503426e-05,
      "loss": 0.0012,
      "step": 1533
    },
    {
      "epoch": 1.0421195652173914,
      "grad_norm": 3.657367467880249,
      "learning_rate": 1.461327874918309e-05,
      "loss": 0.1347,
      "step": 1534
    },
    {
      "epoch": 1.0427989130434783,
      "grad_norm": 0.011868573725223541,
      "learning_rate": 1.4606965729054106e-05,
      "loss": 0.0001,
      "step": 1535
    },
    {
      "epoch": 1.0434782608695652,
      "grad_norm": 0.23739446699619293,
      "learning_rate": 1.4600650377311523e-05,
      "loss": 0.0014,
      "step": 1536
    },
    {
      "epoch": 1.044157608695652,
      "grad_norm": 2.9391977787017822,
      "learning_rate": 1.4594332697151581e-05,
      "loss": 0.2224,
      "step": 1537
    },
    {
      "epoch": 1.044836956521739,
      "grad_norm": 0.1220867782831192,
      "learning_rate": 1.4588012691771697e-05,
      "loss": 0.0007,
      "step": 1538
    },
    {
      "epoch": 1.0455163043478262,
      "grad_norm": 0.0017166233155876398,
      "learning_rate": 1.4581690364370466e-05,
      "loss": 0.0,
      "step": 1539
    },
    {
      "epoch": 1.046195652173913,
      "grad_norm": 0.6376268863677979,
      "learning_rate": 1.4575365718147655e-05,
      "loss": 0.006,
      "step": 1540
    },
    {
      "epoch": 1.046875,
      "grad_norm": 0.06624583899974823,
      "learning_rate": 1.4569038756304209e-05,
      "loss": 0.0005,
      "step": 1541
    },
    {
      "epoch": 1.047554347826087,
      "grad_norm": 2.5712366104125977,
      "learning_rate": 1.4562709482042237e-05,
      "loss": 0.0537,
      "step": 1542
    },
    {
      "epoch": 1.0482336956521738,
      "grad_norm": 0.6058169603347778,
      "learning_rate": 1.4556377898565026e-05,
      "loss": 0.0092,
      "step": 1543
    },
    {
      "epoch": 1.048913043478261,
      "grad_norm": 3.679365873336792,
      "learning_rate": 1.455004400907703e-05,
      "loss": 0.1797,
      "step": 1544
    },
    {
      "epoch": 1.049592391304348,
      "grad_norm": 3.5392866134643555,
      "learning_rate": 1.454370781678387e-05,
      "loss": 0.1219,
      "step": 1545
    },
    {
      "epoch": 1.0502717391304348,
      "grad_norm": 0.11696778982877731,
      "learning_rate": 1.4537369324892332e-05,
      "loss": 0.0007,
      "step": 1546
    },
    {
      "epoch": 1.0509510869565217,
      "grad_norm": 4.072417259216309,
      "learning_rate": 1.4531028536610361e-05,
      "loss": 0.1434,
      "step": 1547
    },
    {
      "epoch": 1.0516304347826086,
      "grad_norm": 4.323110103607178,
      "learning_rate": 1.4524685455147071e-05,
      "loss": 0.0814,
      "step": 1548
    },
    {
      "epoch": 1.0523097826086956,
      "grad_norm": 3.4391539096832275,
      "learning_rate": 1.4518340083712738e-05,
      "loss": 0.1722,
      "step": 1549
    },
    {
      "epoch": 1.0529891304347827,
      "grad_norm": 0.0034766155295073986,
      "learning_rate": 1.451199242551879e-05,
      "loss": 0.0001,
      "step": 1550
    },
    {
      "epoch": 1.0536684782608696,
      "grad_norm": 6.678549289703369,
      "learning_rate": 1.450564248377782e-05,
      "loss": 0.0426,
      "step": 1551
    },
    {
      "epoch": 1.0543478260869565,
      "grad_norm": 1.5289312601089478,
      "learning_rate": 1.4499290261703565e-05,
      "loss": 0.0276,
      "step": 1552
    },
    {
      "epoch": 1.0550271739130435,
      "grad_norm": 0.010154129937291145,
      "learning_rate": 1.4492935762510928e-05,
      "loss": 0.0001,
      "step": 1553
    },
    {
      "epoch": 1.0557065217391304,
      "grad_norm": 1.6098179817199707,
      "learning_rate": 1.448657898941596e-05,
      "loss": 0.0373,
      "step": 1554
    },
    {
      "epoch": 1.0563858695652173,
      "grad_norm": 6.157129287719727,
      "learning_rate": 1.448021994563586e-05,
      "loss": 0.1507,
      "step": 1555
    },
    {
      "epoch": 1.0570652173913044,
      "grad_norm": 3.4606099128723145,
      "learning_rate": 1.4473858634388984e-05,
      "loss": 0.1929,
      "step": 1556
    },
    {
      "epoch": 1.0577445652173914,
      "grad_norm": 0.033445440232753754,
      "learning_rate": 1.4467495058894829e-05,
      "loss": 0.0003,
      "step": 1557
    },
    {
      "epoch": 1.0584239130434783,
      "grad_norm": 7.676474571228027,
      "learning_rate": 1.4461129222374037e-05,
      "loss": 0.1991,
      "step": 1558
    },
    {
      "epoch": 1.0591032608695652,
      "grad_norm": 1.0154333114624023,
      "learning_rate": 1.4454761128048397e-05,
      "loss": 0.0078,
      "step": 1559
    },
    {
      "epoch": 1.059782608695652,
      "grad_norm": 2.9390532970428467,
      "learning_rate": 1.4448390779140844e-05,
      "loss": 0.1369,
      "step": 1560
    },
    {
      "epoch": 1.060461956521739,
      "grad_norm": 1.674701452255249,
      "learning_rate": 1.444201817887545e-05,
      "loss": 0.0058,
      "step": 1561
    },
    {
      "epoch": 1.0611413043478262,
      "grad_norm": 1.3620179891586304,
      "learning_rate": 1.4435643330477423e-05,
      "loss": 0.0074,
      "step": 1562
    },
    {
      "epoch": 1.061820652173913,
      "grad_norm": 0.009296800941228867,
      "learning_rate": 1.4429266237173116e-05,
      "loss": 0.0001,
      "step": 1563
    },
    {
      "epoch": 1.0625,
      "grad_norm": 0.06522279977798462,
      "learning_rate": 1.4422886902190014e-05,
      "loss": 0.0007,
      "step": 1564
    },
    {
      "epoch": 1.063179347826087,
      "grad_norm": 1.4501745700836182,
      "learning_rate": 1.441650532875674e-05,
      "loss": 0.0059,
      "step": 1565
    },
    {
      "epoch": 1.0638586956521738,
      "grad_norm": 5.832849025726318,
      "learning_rate": 1.4410121520103045e-05,
      "loss": 0.255,
      "step": 1566
    },
    {
      "epoch": 1.0645380434782608,
      "grad_norm": 2.030024528503418,
      "learning_rate": 1.4403735479459813e-05,
      "loss": 0.0381,
      "step": 1567
    },
    {
      "epoch": 1.065217391304348,
      "grad_norm": 0.0512150377035141,
      "learning_rate": 1.4397347210059059e-05,
      "loss": 0.0005,
      "step": 1568
    },
    {
      "epoch": 1.0658967391304348,
      "grad_norm": 15.794541358947754,
      "learning_rate": 1.4390956715133928e-05,
      "loss": 0.2331,
      "step": 1569
    },
    {
      "epoch": 1.0665760869565217,
      "grad_norm": 4.009235858917236,
      "learning_rate": 1.4384563997918685e-05,
      "loss": 0.2014,
      "step": 1570
    },
    {
      "epoch": 1.0672554347826086,
      "grad_norm": 0.011101662181317806,
      "learning_rate": 1.4378169061648727e-05,
      "loss": 0.0002,
      "step": 1571
    },
    {
      "epoch": 1.0679347826086956,
      "grad_norm": 0.8439016938209534,
      "learning_rate": 1.4371771909560566e-05,
      "loss": 0.0176,
      "step": 1572
    },
    {
      "epoch": 1.0686141304347827,
      "grad_norm": 13.383081436157227,
      "learning_rate": 1.4365372544891843e-05,
      "loss": 0.1827,
      "step": 1573
    },
    {
      "epoch": 1.0692934782608696,
      "grad_norm": 5.076871871948242,
      "learning_rate": 1.4358970970881315e-05,
      "loss": 0.0808,
      "step": 1574
    },
    {
      "epoch": 1.0699728260869565,
      "grad_norm": 15.975001335144043,
      "learning_rate": 1.4352567190768859e-05,
      "loss": 0.2364,
      "step": 1575
    },
    {
      "epoch": 1.0706521739130435,
      "grad_norm": 0.012239559553563595,
      "learning_rate": 1.4346161207795464e-05,
      "loss": 0.0001,
      "step": 1576
    },
    {
      "epoch": 1.0713315217391304,
      "grad_norm": 0.06524258852005005,
      "learning_rate": 1.4339753025203238e-05,
      "loss": 0.0005,
      "step": 1577
    },
    {
      "epoch": 1.0720108695652173,
      "grad_norm": 4.077610015869141,
      "learning_rate": 1.4333342646235407e-05,
      "loss": 0.1163,
      "step": 1578
    },
    {
      "epoch": 1.0726902173913044,
      "grad_norm": 13.692485809326172,
      "learning_rate": 1.4326930074136298e-05,
      "loss": 0.1216,
      "step": 1579
    },
    {
      "epoch": 1.0733695652173914,
      "grad_norm": 0.0029977173544466496,
      "learning_rate": 1.4320515312151352e-05,
      "loss": 0.0001,
      "step": 1580
    },
    {
      "epoch": 1.0740489130434783,
      "grad_norm": 0.0019045707304030657,
      "learning_rate": 1.4314098363527122e-05,
      "loss": 0.0,
      "step": 1581
    },
    {
      "epoch": 1.0747282608695652,
      "grad_norm": 3.936851978302002,
      "learning_rate": 1.4307679231511267e-05,
      "loss": 0.1323,
      "step": 1582
    },
    {
      "epoch": 1.075407608695652,
      "grad_norm": 0.013464424759149551,
      "learning_rate": 1.4301257919352545e-05,
      "loss": 0.0002,
      "step": 1583
    },
    {
      "epoch": 1.0760869565217392,
      "grad_norm": 0.12653006613254547,
      "learning_rate": 1.4294834430300822e-05,
      "loss": 0.0008,
      "step": 1584
    },
    {
      "epoch": 1.0767663043478262,
      "grad_norm": 0.21782323718070984,
      "learning_rate": 1.4288408767607065e-05,
      "loss": 0.0011,
      "step": 1585
    },
    {
      "epoch": 1.077445652173913,
      "grad_norm": 0.002473450032994151,
      "learning_rate": 1.4281980934523345e-05,
      "loss": 0.0,
      "step": 1586
    },
    {
      "epoch": 1.078125,
      "grad_norm": 5.80073356628418,
      "learning_rate": 1.4275550934302822e-05,
      "loss": 0.1578,
      "step": 1587
    },
    {
      "epoch": 1.078804347826087,
      "grad_norm": 16.998708724975586,
      "learning_rate": 1.4269118770199764e-05,
      "loss": 0.3913,
      "step": 1588
    },
    {
      "epoch": 1.0794836956521738,
      "grad_norm": 10.014002799987793,
      "learning_rate": 1.4262684445469527e-05,
      "loss": 0.0949,
      "step": 1589
    },
    {
      "epoch": 1.0801630434782608,
      "grad_norm": 0.002760649425908923,
      "learning_rate": 1.425624796336856e-05,
      "loss": 0.0001,
      "step": 1590
    },
    {
      "epoch": 1.080842391304348,
      "grad_norm": 9.426423072814941,
      "learning_rate": 1.4249809327154407e-05,
      "loss": 0.2918,
      "step": 1591
    },
    {
      "epoch": 1.0815217391304348,
      "grad_norm": 5.222172260284424,
      "learning_rate": 1.4243368540085702e-05,
      "loss": 0.1959,
      "step": 1592
    },
    {
      "epoch": 1.0822010869565217,
      "grad_norm": 0.004321719985455275,
      "learning_rate": 1.423692560542217e-05,
      "loss": 0.0001,
      "step": 1593
    },
    {
      "epoch": 1.0828804347826086,
      "grad_norm": 4.454862594604492,
      "learning_rate": 1.4230480526424611e-05,
      "loss": 0.1489,
      "step": 1594
    },
    {
      "epoch": 1.0835597826086956,
      "grad_norm": 0.0122299799695611,
      "learning_rate": 1.4224033306354927e-05,
      "loss": 0.0002,
      "step": 1595
    },
    {
      "epoch": 1.0842391304347827,
      "grad_norm": 7.12107515335083,
      "learning_rate": 1.4217583948476094e-05,
      "loss": 0.1727,
      "step": 1596
    },
    {
      "epoch": 1.0849184782608696,
      "grad_norm": 1.55582857131958,
      "learning_rate": 1.421113245605217e-05,
      "loss": 0.0208,
      "step": 1597
    },
    {
      "epoch": 1.0855978260869565,
      "grad_norm": 7.803342819213867,
      "learning_rate": 1.4204678832348292e-05,
      "loss": 0.3018,
      "step": 1598
    },
    {
      "epoch": 1.0862771739130435,
      "grad_norm": 0.013680513948202133,
      "learning_rate": 1.4198223080630686e-05,
      "loss": 0.0002,
      "step": 1599
    },
    {
      "epoch": 1.0869565217391304,
      "grad_norm": 9.960075378417969,
      "learning_rate": 1.4191765204166643e-05,
      "loss": 0.2418,
      "step": 1600
    },
    {
      "epoch": 1.0876358695652173,
      "grad_norm": 0.0398278646171093,
      "learning_rate": 1.4185305206224533e-05,
      "loss": 0.0002,
      "step": 1601
    },
    {
      "epoch": 1.0883152173913044,
      "grad_norm": 0.25480613112449646,
      "learning_rate": 1.4178843090073802e-05,
      "loss": 0.0024,
      "step": 1602
    },
    {
      "epoch": 1.0889945652173914,
      "grad_norm": 6.4980998039245605,
      "learning_rate": 1.4172378858984965e-05,
      "loss": 0.1736,
      "step": 1603
    },
    {
      "epoch": 1.0896739130434783,
      "grad_norm": 5.455694675445557,
      "learning_rate": 1.4165912516229614e-05,
      "loss": 0.1387,
      "step": 1604
    },
    {
      "epoch": 1.0903532608695652,
      "grad_norm": 6.181756019592285,
      "learning_rate": 1.4159444065080398e-05,
      "loss": 0.087,
      "step": 1605
    },
    {
      "epoch": 1.091032608695652,
      "grad_norm": 7.233175277709961,
      "learning_rate": 1.4152973508811046e-05,
      "loss": 0.1796,
      "step": 1606
    },
    {
      "epoch": 1.0917119565217392,
      "grad_norm": 6.454148769378662,
      "learning_rate": 1.4146500850696338e-05,
      "loss": 0.2752,
      "step": 1607
    },
    {
      "epoch": 1.0923913043478262,
      "grad_norm": 4.104693412780762,
      "learning_rate": 1.4140026094012136e-05,
      "loss": 0.1698,
      "step": 1608
    },
    {
      "epoch": 1.093070652173913,
      "grad_norm": 4.532145023345947,
      "learning_rate": 1.4133549242035347e-05,
      "loss": 0.0302,
      "step": 1609
    },
    {
      "epoch": 1.09375,
      "grad_norm": 9.353821754455566,
      "learning_rate": 1.4127070298043949e-05,
      "loss": 0.1118,
      "step": 1610
    },
    {
      "epoch": 1.094429347826087,
      "grad_norm": 0.0035111953038722277,
      "learning_rate": 1.4120589265316974e-05,
      "loss": 0.0001,
      "step": 1611
    },
    {
      "epoch": 1.0951086956521738,
      "grad_norm": 5.735478401184082,
      "learning_rate": 1.411410614713451e-05,
      "loss": 0.1933,
      "step": 1612
    },
    {
      "epoch": 1.0957880434782608,
      "grad_norm": 0.009311042726039886,
      "learning_rate": 1.4107620946777707e-05,
      "loss": 0.0001,
      "step": 1613
    },
    {
      "epoch": 1.096467391304348,
      "grad_norm": 14.590140342712402,
      "learning_rate": 1.4101133667528761e-05,
      "loss": 0.1809,
      "step": 1614
    },
    {
      "epoch": 1.0971467391304348,
      "grad_norm": 6.759785175323486,
      "learning_rate": 1.4094644312670926e-05,
      "loss": 0.2634,
      "step": 1615
    },
    {
      "epoch": 1.0978260869565217,
      "grad_norm": 5.21060848236084,
      "learning_rate": 1.4088152885488504e-05,
      "loss": 0.2427,
      "step": 1616
    },
    {
      "epoch": 1.0985054347826086,
      "grad_norm": 17.80339241027832,
      "learning_rate": 1.4081659389266846e-05,
      "loss": 0.4044,
      "step": 1617
    },
    {
      "epoch": 1.0991847826086956,
      "grad_norm": 4.774783611297607,
      "learning_rate": 1.407516382729235e-05,
      "loss": 0.1512,
      "step": 1618
    },
    {
      "epoch": 1.0998641304347827,
      "grad_norm": 0.035383619368076324,
      "learning_rate": 1.4068666202852461e-05,
      "loss": 0.0003,
      "step": 1619
    },
    {
      "epoch": 1.1005434782608696,
      "grad_norm": 4.430106163024902,
      "learning_rate": 1.4062166519235665e-05,
      "loss": 0.0787,
      "step": 1620
    },
    {
      "epoch": 1.1012228260869565,
      "grad_norm": 3.049375534057617,
      "learning_rate": 1.405566477973149e-05,
      "loss": 0.1339,
      "step": 1621
    },
    {
      "epoch": 1.1019021739130435,
      "grad_norm": 9.941679000854492,
      "learning_rate": 1.4049160987630513e-05,
      "loss": 0.3694,
      "step": 1622
    },
    {
      "epoch": 1.1025815217391304,
      "grad_norm": 0.0688285082578659,
      "learning_rate": 1.4042655146224333e-05,
      "loss": 0.0006,
      "step": 1623
    },
    {
      "epoch": 1.1032608695652173,
      "grad_norm": 0.0649188980460167,
      "learning_rate": 1.4036147258805604e-05,
      "loss": 0.0004,
      "step": 1624
    },
    {
      "epoch": 1.1039402173913044,
      "grad_norm": 2.5965423583984375,
      "learning_rate": 1.4029637328668004e-05,
      "loss": 0.1289,
      "step": 1625
    },
    {
      "epoch": 1.1046195652173914,
      "grad_norm": 0.035551805049180984,
      "learning_rate": 1.4023125359106253e-05,
      "loss": 0.0003,
      "step": 1626
    },
    {
      "epoch": 1.1052989130434783,
      "grad_norm": 1.9326398372650146,
      "learning_rate": 1.4016611353416094e-05,
      "loss": 0.0251,
      "step": 1627
    },
    {
      "epoch": 1.1059782608695652,
      "grad_norm": 0.172272726893425,
      "learning_rate": 1.4010095314894305e-05,
      "loss": 0.0003,
      "step": 1628
    },
    {
      "epoch": 1.106657608695652,
      "grad_norm": 6.9118971824646,
      "learning_rate": 1.40035772468387e-05,
      "loss": 0.4471,
      "step": 1629
    },
    {
      "epoch": 1.1073369565217392,
      "grad_norm": 5.147279262542725,
      "learning_rate": 1.3997057152548104e-05,
      "loss": 0.0414,
      "step": 1630
    },
    {
      "epoch": 1.1080163043478262,
      "grad_norm": 0.019243594259023666,
      "learning_rate": 1.3990535035322382e-05,
      "loss": 0.0002,
      "step": 1631
    },
    {
      "epoch": 1.108695652173913,
      "grad_norm": 2.2167162895202637,
      "learning_rate": 1.3984010898462417e-05,
      "loss": 0.1229,
      "step": 1632
    },
    {
      "epoch": 1.109375,
      "grad_norm": 1.383819580078125,
      "learning_rate": 1.3977484745270112e-05,
      "loss": 0.0564,
      "step": 1633
    },
    {
      "epoch": 1.110054347826087,
      "grad_norm": 8.277548789978027,
      "learning_rate": 1.3970956579048396e-05,
      "loss": 0.3306,
      "step": 1634
    },
    {
      "epoch": 1.1107336956521738,
      "grad_norm": 0.1899624466896057,
      "learning_rate": 1.3964426403101212e-05,
      "loss": 0.0009,
      "step": 1635
    },
    {
      "epoch": 1.1114130434782608,
      "grad_norm": 0.0765499398112297,
      "learning_rate": 1.3957894220733526e-05,
      "loss": 0.0006,
      "step": 1636
    },
    {
      "epoch": 1.112092391304348,
      "grad_norm": 0.3036348223686218,
      "learning_rate": 1.395136003525131e-05,
      "loss": 0.0048,
      "step": 1637
    },
    {
      "epoch": 1.1127717391304348,
      "grad_norm": 3.5616817474365234,
      "learning_rate": 1.3944823849961557e-05,
      "loss": 0.0552,
      "step": 1638
    },
    {
      "epoch": 1.1134510869565217,
      "grad_norm": 5.015310764312744,
      "learning_rate": 1.3938285668172273e-05,
      "loss": 0.1791,
      "step": 1639
    },
    {
      "epoch": 1.1141304347826086,
      "grad_norm": 0.005014651920646429,
      "learning_rate": 1.3931745493192473e-05,
      "loss": 0.0001,
      "step": 1640
    },
    {
      "epoch": 1.1148097826086956,
      "grad_norm": 0.0032333913259208202,
      "learning_rate": 1.3925203328332173e-05,
      "loss": 0.0,
      "step": 1641
    },
    {
      "epoch": 1.1154891304347827,
      "grad_norm": 1.9375211000442505,
      "learning_rate": 1.391865917690241e-05,
      "loss": 0.0523,
      "step": 1642
    },
    {
      "epoch": 1.1161684782608696,
      "grad_norm": 3.1326873302459717,
      "learning_rate": 1.3912113042215215e-05,
      "loss": 0.1414,
      "step": 1643
    },
    {
      "epoch": 1.1168478260869565,
      "grad_norm": 0.010932368226349354,
      "learning_rate": 1.3905564927583625e-05,
      "loss": 0.0002,
      "step": 1644
    },
    {
      "epoch": 1.1175271739130435,
      "grad_norm": 0.00579966651275754,
      "learning_rate": 1.3899014836321687e-05,
      "loss": 0.0001,
      "step": 1645
    },
    {
      "epoch": 1.1182065217391304,
      "grad_norm": 9.595108985900879,
      "learning_rate": 1.3892462771744435e-05,
      "loss": 0.3633,
      "step": 1646
    },
    {
      "epoch": 1.1188858695652173,
      "grad_norm": 1.8328601121902466,
      "learning_rate": 1.3885908737167918e-05,
      "loss": 0.0183,
      "step": 1647
    },
    {
      "epoch": 1.1195652173913044,
      "grad_norm": 1.5818819999694824,
      "learning_rate": 1.3879352735909163e-05,
      "loss": 0.0565,
      "step": 1648
    },
    {
      "epoch": 1.1202445652173914,
      "grad_norm": 3.6093263626098633,
      "learning_rate": 1.3872794771286212e-05,
      "loss": 0.077,
      "step": 1649
    },
    {
      "epoch": 1.1209239130434783,
      "grad_norm": 2.5623080730438232,
      "learning_rate": 1.3866234846618083e-05,
      "loss": 0.0214,
      "step": 1650
    },
    {
      "epoch": 1.1216032608695652,
      "grad_norm": 0.003642481518909335,
      "learning_rate": 1.38596729652248e-05,
      "loss": 0.0001,
      "step": 1651
    },
    {
      "epoch": 1.122282608695652,
      "grad_norm": 0.5189990997314453,
      "learning_rate": 1.3853109130427369e-05,
      "loss": 0.0048,
      "step": 1652
    },
    {
      "epoch": 1.1229619565217392,
      "grad_norm": 4.7744059562683105,
      "learning_rate": 1.3846543345547787e-05,
      "loss": 0.1731,
      "step": 1653
    },
    {
      "epoch": 1.1236413043478262,
      "grad_norm": 0.01402159221470356,
      "learning_rate": 1.3839975613909036e-05,
      "loss": 0.0003,
      "step": 1654
    },
    {
      "epoch": 1.124320652173913,
      "grad_norm": 2.3273749351501465,
      "learning_rate": 1.3833405938835089e-05,
      "loss": 0.139,
      "step": 1655
    },
    {
      "epoch": 1.125,
      "grad_norm": 3.468278169631958,
      "learning_rate": 1.3826834323650899e-05,
      "loss": 0.1456,
      "step": 1656
    },
    {
      "epoch": 1.125679347826087,
      "grad_norm": 2.294477939605713,
      "learning_rate": 1.3820260771682398e-05,
      "loss": 0.0935,
      "step": 1657
    },
    {
      "epoch": 1.1263586956521738,
      "grad_norm": 1.1553130149841309,
      "learning_rate": 1.3813685286256503e-05,
      "loss": 0.0231,
      "step": 1658
    },
    {
      "epoch": 1.1270380434782608,
      "grad_norm": 0.012131440453231335,
      "learning_rate": 1.3807107870701102e-05,
      "loss": 0.0001,
      "step": 1659
    },
    {
      "epoch": 1.127717391304348,
      "grad_norm": 0.5374065637588501,
      "learning_rate": 1.3800528528345074e-05,
      "loss": 0.0101,
      "step": 1660
    },
    {
      "epoch": 1.1283967391304348,
      "grad_norm": 19.02620506286621,
      "learning_rate": 1.3793947262518259e-05,
      "loss": 0.5297,
      "step": 1661
    },
    {
      "epoch": 1.1290760869565217,
      "grad_norm": 1.829671859741211,
      "learning_rate": 1.3787364076551478e-05,
      "loss": 0.0368,
      "step": 1662
    },
    {
      "epoch": 1.1297554347826086,
      "grad_norm": 0.015405605547130108,
      "learning_rate": 1.3780778973776518e-05,
      "loss": 0.0001,
      "step": 1663
    },
    {
      "epoch": 1.1304347826086956,
      "grad_norm": 4.643617153167725,
      "learning_rate": 1.3774191957526144e-05,
      "loss": 0.212,
      "step": 1664
    },
    {
      "epoch": 1.1311141304347827,
      "grad_norm": 0.003610177431255579,
      "learning_rate": 1.3767603031134087e-05,
      "loss": 0.0001,
      "step": 1665
    },
    {
      "epoch": 1.1317934782608696,
      "grad_norm": 3.244861364364624,
      "learning_rate": 1.3761012197935037e-05,
      "loss": 0.1958,
      "step": 1666
    },
    {
      "epoch": 1.1324728260869565,
      "grad_norm": 17.82714080810547,
      "learning_rate": 1.3754419461264658e-05,
      "loss": 0.6378,
      "step": 1667
    },
    {
      "epoch": 1.1331521739130435,
      "grad_norm": 2.7874972820281982,
      "learning_rate": 1.3747824824459577e-05,
      "loss": 0.0434,
      "step": 1668
    },
    {
      "epoch": 1.1338315217391304,
      "grad_norm": 0.13613469898700714,
      "learning_rate": 1.3741228290857378e-05,
      "loss": 0.001,
      "step": 1669
    },
    {
      "epoch": 1.1345108695652173,
      "grad_norm": 24.375638961791992,
      "learning_rate": 1.3734629863796607e-05,
      "loss": 0.6176,
      "step": 1670
    },
    {
      "epoch": 1.1351902173913044,
      "grad_norm": 3.0331766605377197,
      "learning_rate": 1.3728029546616769e-05,
      "loss": 0.0365,
      "step": 1671
    },
    {
      "epoch": 1.1358695652173914,
      "grad_norm": 0.6451007723808289,
      "learning_rate": 1.3721427342658322e-05,
      "loss": 0.0041,
      "step": 1672
    },
    {
      "epoch": 1.1365489130434783,
      "grad_norm": 0.003761675674468279,
      "learning_rate": 1.3714823255262687e-05,
      "loss": 0.0001,
      "step": 1673
    },
    {
      "epoch": 1.1372282608695652,
      "grad_norm": 1.1490267515182495,
      "learning_rate": 1.3708217287772227e-05,
      "loss": 0.0076,
      "step": 1674
    },
    {
      "epoch": 1.137907608695652,
      "grad_norm": 0.6335837841033936,
      "learning_rate": 1.3701609443530269e-05,
      "loss": 0.0113,
      "step": 1675
    },
    {
      "epoch": 1.1385869565217392,
      "grad_norm": 0.0059587047435343266,
      "learning_rate": 1.3694999725881075e-05,
      "loss": 0.0001,
      "step": 1676
    },
    {
      "epoch": 1.1392663043478262,
      "grad_norm": 4.941709518432617,
      "learning_rate": 1.3688388138169873e-05,
      "loss": 0.2085,
      "step": 1677
    },
    {
      "epoch": 1.139945652173913,
      "grad_norm": 5.346026420593262,
      "learning_rate": 1.3681774683742824e-05,
      "loss": 0.0865,
      "step": 1678
    },
    {
      "epoch": 1.140625,
      "grad_norm": 2.0844810009002686,
      "learning_rate": 1.3675159365947038e-05,
      "loss": 0.1734,
      "step": 1679
    },
    {
      "epoch": 1.141304347826087,
      "grad_norm": 15.563840866088867,
      "learning_rate": 1.3668542188130567e-05,
      "loss": 0.1227,
      "step": 1680
    },
    {
      "epoch": 1.1419836956521738,
      "grad_norm": 0.004511096049100161,
      "learning_rate": 1.3661923153642407e-05,
      "loss": 0.0001,
      "step": 1681
    },
    {
      "epoch": 1.1426630434782608,
      "grad_norm": 17.237035751342773,
      "learning_rate": 1.3655302265832492e-05,
      "loss": 0.1487,
      "step": 1682
    },
    {
      "epoch": 1.143342391304348,
      "grad_norm": 3.945833206176758,
      "learning_rate": 1.3648679528051689e-05,
      "loss": 0.257,
      "step": 1683
    },
    {
      "epoch": 1.1440217391304348,
      "grad_norm": 0.6627120971679688,
      "learning_rate": 1.3642054943651814e-05,
      "loss": 0.0075,
      "step": 1684
    },
    {
      "epoch": 1.1447010869565217,
      "grad_norm": 0.003022650023922324,
      "learning_rate": 1.3635428515985602e-05,
      "loss": 0.0001,
      "step": 1685
    },
    {
      "epoch": 1.1453804347826086,
      "grad_norm": 5.110558986663818,
      "learning_rate": 1.3628800248406738e-05,
      "loss": 0.0291,
      "step": 1686
    },
    {
      "epoch": 1.1460597826086956,
      "grad_norm": 1.1768220663070679,
      "learning_rate": 1.3622170144269819e-05,
      "loss": 0.0109,
      "step": 1687
    },
    {
      "epoch": 1.1467391304347827,
      "grad_norm": 7.966223239898682,
      "learning_rate": 1.3615538206930387e-05,
      "loss": 0.1401,
      "step": 1688
    },
    {
      "epoch": 1.1474184782608696,
      "grad_norm": 0.27497154474258423,
      "learning_rate": 1.3608904439744905e-05,
      "loss": 0.0019,
      "step": 1689
    },
    {
      "epoch": 1.1480978260869565,
      "grad_norm": 9.816134452819824,
      "learning_rate": 1.3602268846070763e-05,
      "loss": 0.272,
      "step": 1690
    },
    {
      "epoch": 1.1487771739130435,
      "grad_norm": 0.003102431772276759,
      "learning_rate": 1.3595631429266276e-05,
      "loss": 0.0001,
      "step": 1691
    },
    {
      "epoch": 1.1494565217391304,
      "grad_norm": 2.245997428894043,
      "learning_rate": 1.3588992192690683e-05,
      "loss": 0.0083,
      "step": 1692
    },
    {
      "epoch": 1.1501358695652173,
      "grad_norm": 3.427326202392578,
      "learning_rate": 1.3582351139704137e-05,
      "loss": 0.1505,
      "step": 1693
    },
    {
      "epoch": 1.1508152173913044,
      "grad_norm": 2.953315258026123,
      "learning_rate": 1.357570827366772e-05,
      "loss": 0.0329,
      "step": 1694
    },
    {
      "epoch": 1.1514945652173914,
      "grad_norm": 0.027908707037568092,
      "learning_rate": 1.3569063597943428e-05,
      "loss": 0.0003,
      "step": 1695
    },
    {
      "epoch": 1.1521739130434783,
      "grad_norm": 3.407172918319702,
      "learning_rate": 1.356241711589417e-05,
      "loss": 0.0599,
      "step": 1696
    },
    {
      "epoch": 1.1528532608695652,
      "grad_norm": 4.068121910095215,
      "learning_rate": 1.3555768830883768e-05,
      "loss": 0.204,
      "step": 1697
    },
    {
      "epoch": 1.153532608695652,
      "grad_norm": 4.814074993133545,
      "learning_rate": 1.3549118746276968e-05,
      "loss": 0.2803,
      "step": 1698
    },
    {
      "epoch": 1.1542119565217392,
      "grad_norm": 2.527845859527588,
      "learning_rate": 1.3542466865439412e-05,
      "loss": 0.0126,
      "step": 1699
    },
    {
      "epoch": 1.1548913043478262,
      "grad_norm": 0.017833907157182693,
      "learning_rate": 1.3535813191737663e-05,
      "loss": 0.0003,
      "step": 1700
    },
    {
      "epoch": 1.155570652173913,
      "grad_norm": 0.002720573917031288,
      "learning_rate": 1.3529157728539179e-05,
      "loss": 0.0,
      "step": 1701
    },
    {
      "epoch": 1.15625,
      "grad_norm": 0.22829394042491913,
      "learning_rate": 1.3522500479212337e-05,
      "loss": 0.0014,
      "step": 1702
    },
    {
      "epoch": 1.156929347826087,
      "grad_norm": 8.484386444091797,
      "learning_rate": 1.3515841447126408e-05,
      "loss": 0.4615,
      "step": 1703
    },
    {
      "epoch": 1.1576086956521738,
      "grad_norm": 5.555764675140381,
      "learning_rate": 1.350918063565157e-05,
      "loss": 0.2442,
      "step": 1704
    },
    {
      "epoch": 1.1582880434782608,
      "grad_norm": 0.006466820370405912,
      "learning_rate": 1.3502518048158901e-05,
      "loss": 0.0001,
      "step": 1705
    },
    {
      "epoch": 1.158967391304348,
      "grad_norm": 0.41968515515327454,
      "learning_rate": 1.3495853688020377e-05,
      "loss": 0.0027,
      "step": 1706
    },
    {
      "epoch": 1.1596467391304348,
      "grad_norm": 0.029862070456147194,
      "learning_rate": 1.3489187558608871e-05,
      "loss": 0.0003,
      "step": 1707
    },
    {
      "epoch": 1.1603260869565217,
      "grad_norm": 5.587708473205566,
      "learning_rate": 1.3482519663298156e-05,
      "loss": 0.19,
      "step": 1708
    },
    {
      "epoch": 1.1610054347826086,
      "grad_norm": 0.05275585874915123,
      "learning_rate": 1.3475850005462887e-05,
      "loss": 0.0006,
      "step": 1709
    },
    {
      "epoch": 1.1616847826086956,
      "grad_norm": 0.003731018863618374,
      "learning_rate": 1.3469178588478621e-05,
      "loss": 0.0001,
      "step": 1710
    },
    {
      "epoch": 1.1623641304347827,
      "grad_norm": 4.150568962097168,
      "learning_rate": 1.346250541572181e-05,
      "loss": 0.0759,
      "step": 1711
    },
    {
      "epoch": 1.1630434782608696,
      "grad_norm": 0.6025072932243347,
      "learning_rate": 1.3455830490569782e-05,
      "loss": 0.0035,
      "step": 1712
    },
    {
      "epoch": 1.1637228260869565,
      "grad_norm": 8.815125465393066,
      "learning_rate": 1.3449153816400758e-05,
      "loss": 0.2651,
      "step": 1713
    },
    {
      "epoch": 1.1644021739130435,
      "grad_norm": 1.7245980501174927,
      "learning_rate": 1.3442475396593842e-05,
      "loss": 0.0746,
      "step": 1714
    },
    {
      "epoch": 1.1650815217391304,
      "grad_norm": 3.211346387863159,
      "learning_rate": 1.3435795234529026e-05,
      "loss": 0.1402,
      "step": 1715
    },
    {
      "epoch": 1.1657608695652173,
      "grad_norm": 0.01882142759859562,
      "learning_rate": 1.3429113333587181e-05,
      "loss": 0.0002,
      "step": 1716
    },
    {
      "epoch": 1.1664402173913044,
      "grad_norm": 0.5033212900161743,
      "learning_rate": 1.3422429697150055e-05,
      "loss": 0.0034,
      "step": 1717
    },
    {
      "epoch": 1.1671195652173914,
      "grad_norm": 2.4074809551239014,
      "learning_rate": 1.341574432860028e-05,
      "loss": 0.0521,
      "step": 1718
    },
    {
      "epoch": 1.1677989130434783,
      "grad_norm": 1.894115924835205,
      "learning_rate": 1.3409057231321363e-05,
      "loss": 0.0119,
      "step": 1719
    },
    {
      "epoch": 1.1684782608695652,
      "grad_norm": 1.8398678302764893,
      "learning_rate": 1.3402368408697681e-05,
      "loss": 0.0835,
      "step": 1720
    },
    {
      "epoch": 1.169157608695652,
      "grad_norm": 6.260182857513428,
      "learning_rate": 1.3395677864114493e-05,
      "loss": 0.3064,
      "step": 1721
    },
    {
      "epoch": 1.1698369565217392,
      "grad_norm": 2.434089422225952,
      "learning_rate": 1.3388985600957922e-05,
      "loss": 0.019,
      "step": 1722
    },
    {
      "epoch": 1.1705163043478262,
      "grad_norm": 19.095556259155273,
      "learning_rate": 1.338229162261496e-05,
      "loss": 1.2341,
      "step": 1723
    },
    {
      "epoch": 1.171195652173913,
      "grad_norm": 7.637264728546143,
      "learning_rate": 1.337559593247348e-05,
      "loss": 0.1693,
      "step": 1724
    },
    {
      "epoch": 1.171875,
      "grad_norm": 1.968718409538269,
      "learning_rate": 1.3368898533922202e-05,
      "loss": 0.0455,
      "step": 1725
    },
    {
      "epoch": 1.172554347826087,
      "grad_norm": 3.573232889175415,
      "learning_rate": 1.3362199430350726e-05,
      "loss": 0.1312,
      "step": 1726
    },
    {
      "epoch": 1.1732336956521738,
      "grad_norm": 12.0181884765625,
      "learning_rate": 1.3355498625149506e-05,
      "loss": 0.151,
      "step": 1727
    },
    {
      "epoch": 1.1739130434782608,
      "grad_norm": 3.599600076675415,
      "learning_rate": 1.3348796121709862e-05,
      "loss": 0.037,
      "step": 1728
    },
    {
      "epoch": 1.174592391304348,
      "grad_norm": 0.018731193616986275,
      "learning_rate": 1.3342091923423975e-05,
      "loss": 0.0002,
      "step": 1729
    },
    {
      "epoch": 1.1752717391304348,
      "grad_norm": 0.00560136279091239,
      "learning_rate": 1.3335386033684877e-05,
      "loss": 0.0001,
      "step": 1730
    },
    {
      "epoch": 1.1759510869565217,
      "grad_norm": 5.690821647644043,
      "learning_rate": 1.3328678455886461e-05,
      "loss": 0.1059,
      "step": 1731
    },
    {
      "epoch": 1.1766304347826086,
      "grad_norm": 2.571718692779541,
      "learning_rate": 1.3321969193423472e-05,
      "loss": 0.0841,
      "step": 1732
    },
    {
      "epoch": 1.1773097826086956,
      "grad_norm": 3.962747097015381,
      "learning_rate": 1.3315258249691514e-05,
      "loss": 0.1295,
      "step": 1733
    },
    {
      "epoch": 1.1779891304347827,
      "grad_norm": 1.5480905771255493,
      "learning_rate": 1.3308545628087029e-05,
      "loss": 0.0292,
      "step": 1734
    },
    {
      "epoch": 1.1786684782608696,
      "grad_norm": 0.02807030640542507,
      "learning_rate": 1.3301831332007322e-05,
      "loss": 0.0003,
      "step": 1735
    },
    {
      "epoch": 1.1793478260869565,
      "grad_norm": 4.480740070343018,
      "learning_rate": 1.3295115364850535e-05,
      "loss": 0.1071,
      "step": 1736
    },
    {
      "epoch": 1.1800271739130435,
      "grad_norm": 0.034677065908908844,
      "learning_rate": 1.3288397730015666e-05,
      "loss": 0.0005,
      "step": 1737
    },
    {
      "epoch": 1.1807065217391304,
      "grad_norm": 2.354872703552246,
      "learning_rate": 1.3281678430902545e-05,
      "loss": 0.0998,
      "step": 1738
    },
    {
      "epoch": 1.1813858695652173,
      "grad_norm": 4.587540149688721,
      "learning_rate": 1.3274957470911856e-05,
      "loss": 0.2201,
      "step": 1739
    },
    {
      "epoch": 1.1820652173913044,
      "grad_norm": 6.719797134399414,
      "learning_rate": 1.3268234853445113e-05,
      "loss": 0.1349,
      "step": 1740
    },
    {
      "epoch": 1.1827445652173914,
      "grad_norm": 5.505187034606934,
      "learning_rate": 1.3261510581904675e-05,
      "loss": 0.0403,
      "step": 1741
    },
    {
      "epoch": 1.1834239130434783,
      "grad_norm": 5.343483924865723,
      "learning_rate": 1.3254784659693739e-05,
      "loss": 0.15,
      "step": 1742
    },
    {
      "epoch": 1.1841032608695652,
      "grad_norm": 8.583279609680176,
      "learning_rate": 1.3248057090216336e-05,
      "loss": 0.209,
      "step": 1743
    },
    {
      "epoch": 1.184782608695652,
      "grad_norm": 2.057082414627075,
      "learning_rate": 1.3241327876877328e-05,
      "loss": 0.0532,
      "step": 1744
    },
    {
      "epoch": 1.1854619565217392,
      "grad_norm": 0.06885503232479095,
      "learning_rate": 1.3234597023082409e-05,
      "loss": 0.0003,
      "step": 1745
    },
    {
      "epoch": 1.1861413043478262,
      "grad_norm": 7.921818256378174,
      "learning_rate": 1.3227864532238113e-05,
      "loss": 0.0218,
      "step": 1746
    },
    {
      "epoch": 1.186820652173913,
      "grad_norm": 0.08491700142621994,
      "learning_rate": 1.3221130407751788e-05,
      "loss": 0.0006,
      "step": 1747
    },
    {
      "epoch": 1.1875,
      "grad_norm": 0.029553769156336784,
      "learning_rate": 1.3214394653031616e-05,
      "loss": 0.0003,
      "step": 1748
    },
    {
      "epoch": 1.188179347826087,
      "grad_norm": 0.0056425780057907104,
      "learning_rate": 1.3207657271486607e-05,
      "loss": 0.0001,
      "step": 1749
    },
    {
      "epoch": 1.1888586956521738,
      "grad_norm": 0.19825595617294312,
      "learning_rate": 1.3200918266526593e-05,
      "loss": 0.0016,
      "step": 1750
    },
    {
      "epoch": 1.1895380434782608,
      "grad_norm": 0.00457899970933795,
      "learning_rate": 1.3194177641562218e-05,
      "loss": 0.0001,
      "step": 1751
    },
    {
      "epoch": 1.190217391304348,
      "grad_norm": 0.0026947096921503544,
      "learning_rate": 1.318743540000496e-05,
      "loss": 0.0,
      "step": 1752
    },
    {
      "epoch": 1.1908967391304348,
      "grad_norm": 6.135365962982178,
      "learning_rate": 1.3180691545267105e-05,
      "loss": 0.191,
      "step": 1753
    },
    {
      "epoch": 1.1915760869565217,
      "grad_norm": 6.290278911590576,
      "learning_rate": 1.3173946080761764e-05,
      "loss": 0.098,
      "step": 1754
    },
    {
      "epoch": 1.1922554347826086,
      "grad_norm": 0.38112568855285645,
      "learning_rate": 1.316719900990285e-05,
      "loss": 0.0022,
      "step": 1755
    },
    {
      "epoch": 1.1929347826086956,
      "grad_norm": 2.368340015411377,
      "learning_rate": 1.3160450336105108e-05,
      "loss": 0.047,
      "step": 1756
    },
    {
      "epoch": 1.1936141304347827,
      "grad_norm": 14.167957305908203,
      "learning_rate": 1.3153700062784073e-05,
      "loss": 0.1849,
      "step": 1757
    },
    {
      "epoch": 1.1942934782608696,
      "grad_norm": 0.025177421048283577,
      "learning_rate": 1.3146948193356105e-05,
      "loss": 0.0003,
      "step": 1758
    },
    {
      "epoch": 1.1949728260869565,
      "grad_norm": 0.003108817618340254,
      "learning_rate": 1.3140194731238367e-05,
      "loss": 0.0001,
      "step": 1759
    },
    {
      "epoch": 1.1956521739130435,
      "grad_norm": 0.007757726591080427,
      "learning_rate": 1.3133439679848824e-05,
      "loss": 0.0001,
      "step": 1760
    },
    {
      "epoch": 1.1963315217391304,
      "grad_norm": 2.3769283294677734,
      "learning_rate": 1.3126683042606251e-05,
      "loss": 0.0608,
      "step": 1761
    },
    {
      "epoch": 1.1970108695652173,
      "grad_norm": 2.0749213695526123,
      "learning_rate": 1.3119924822930223e-05,
      "loss": 0.0566,
      "step": 1762
    },
    {
      "epoch": 1.1976902173913044,
      "grad_norm": 2.9464831352233887,
      "learning_rate": 1.3113165024241117e-05,
      "loss": 0.0978,
      "step": 1763
    },
    {
      "epoch": 1.1983695652173914,
      "grad_norm": 0.41475769877433777,
      "learning_rate": 1.3106403649960109e-05,
      "loss": 0.0027,
      "step": 1764
    },
    {
      "epoch": 1.1990489130434783,
      "grad_norm": 0.07036662846803665,
      "learning_rate": 1.3099640703509169e-05,
      "loss": 0.001,
      "step": 1765
    },
    {
      "epoch": 1.1997282608695652,
      "grad_norm": 0.0023163931909948587,
      "learning_rate": 1.309287618831107e-05,
      "loss": 0.0,
      "step": 1766
    },
    {
      "epoch": 1.200407608695652,
      "grad_norm": 4.270255088806152,
      "learning_rate": 1.3086110107789371e-05,
      "loss": 0.1305,
      "step": 1767
    },
    {
      "epoch": 1.2010869565217392,
      "grad_norm": 5.96523904800415,
      "learning_rate": 1.307934246536843e-05,
      "loss": 0.084,
      "step": 1768
    },
    {
      "epoch": 1.2017663043478262,
      "grad_norm": 5.318070888519287,
      "learning_rate": 1.307257326447339e-05,
      "loss": 0.1003,
      "step": 1769
    },
    {
      "epoch": 1.202445652173913,
      "grad_norm": 0.009479076601564884,
      "learning_rate": 1.3065802508530186e-05,
      "loss": 0.0001,
      "step": 1770
    },
    {
      "epoch": 1.203125,
      "grad_norm": 2.607269048690796,
      "learning_rate": 1.3059030200965536e-05,
      "loss": 0.0569,
      "step": 1771
    },
    {
      "epoch": 1.203804347826087,
      "grad_norm": 0.053905364125967026,
      "learning_rate": 1.3052256345206953e-05,
      "loss": 0.0006,
      "step": 1772
    },
    {
      "epoch": 1.2044836956521738,
      "grad_norm": 5.457691192626953,
      "learning_rate": 1.304548094468272e-05,
      "loss": 0.2074,
      "step": 1773
    },
    {
      "epoch": 1.2051630434782608,
      "grad_norm": 0.5891343951225281,
      "learning_rate": 1.3038704002821914e-05,
      "loss": 0.0089,
      "step": 1774
    },
    {
      "epoch": 1.205842391304348,
      "grad_norm": 14.299212455749512,
      "learning_rate": 1.3031925523054383e-05,
      "loss": 0.3417,
      "step": 1775
    },
    {
      "epoch": 1.2065217391304348,
      "grad_norm": 0.0040407683700323105,
      "learning_rate": 1.302514550881076e-05,
      "loss": 0.0001,
      "step": 1776
    },
    {
      "epoch": 1.2072010869565217,
      "grad_norm": 4.308060169219971,
      "learning_rate": 1.3018363963522449e-05,
      "loss": 0.0649,
      "step": 1777
    },
    {
      "epoch": 1.2078804347826086,
      "grad_norm": 0.006537371315062046,
      "learning_rate": 1.3011580890621635e-05,
      "loss": 0.0001,
      "step": 1778
    },
    {
      "epoch": 1.2085597826086956,
      "grad_norm": 0.01098616048693657,
      "learning_rate": 1.3004796293541269e-05,
      "loss": 0.0002,
      "step": 1779
    },
    {
      "epoch": 1.2092391304347827,
      "grad_norm": 0.8111585378646851,
      "learning_rate": 1.2998010175715081e-05,
      "loss": 0.0099,
      "step": 1780
    },
    {
      "epoch": 1.2099184782608696,
      "grad_norm": 10.506061553955078,
      "learning_rate": 1.2991222540577566e-05,
      "loss": 0.0739,
      "step": 1781
    },
    {
      "epoch": 1.2105978260869565,
      "grad_norm": 0.027899015694856644,
      "learning_rate": 1.2984433391563984e-05,
      "loss": 0.0002,
      "step": 1782
    },
    {
      "epoch": 1.2112771739130435,
      "grad_norm": 0.00205056625418365,
      "learning_rate": 1.2977642732110369e-05,
      "loss": 0.0,
      "step": 1783
    },
    {
      "epoch": 1.2119565217391304,
      "grad_norm": 4.355540752410889,
      "learning_rate": 1.2970850565653515e-05,
      "loss": 0.1032,
      "step": 1784
    },
    {
      "epoch": 1.2126358695652173,
      "grad_norm": 9.451065063476562,
      "learning_rate": 1.2964056895630976e-05,
      "loss": 0.1669,
      "step": 1785
    },
    {
      "epoch": 1.2133152173913044,
      "grad_norm": 11.464850425720215,
      "learning_rate": 1.2957261725481074e-05,
      "loss": 0.9077,
      "step": 1786
    },
    {
      "epoch": 1.2139945652173914,
      "grad_norm": 0.0429808534681797,
      "learning_rate": 1.2950465058642884e-05,
      "loss": 0.0004,
      "step": 1787
    },
    {
      "epoch": 1.2146739130434783,
      "grad_norm": 0.014205030165612698,
      "learning_rate": 1.294366689855624e-05,
      "loss": 0.0001,
      "step": 1788
    },
    {
      "epoch": 1.2153532608695652,
      "grad_norm": 0.0017704892670735717,
      "learning_rate": 1.2936867248661736e-05,
      "loss": 0.0,
      "step": 1789
    },
    {
      "epoch": 1.216032608695652,
      "grad_norm": 11.637412071228027,
      "learning_rate": 1.2930066112400712e-05,
      "loss": 0.3107,
      "step": 1790
    },
    {
      "epoch": 1.2167119565217392,
      "grad_norm": 0.06014661118388176,
      "learning_rate": 1.292326349321527e-05,
      "loss": 0.0004,
      "step": 1791
    },
    {
      "epoch": 1.2173913043478262,
      "grad_norm": 0.013766930438578129,
      "learning_rate": 1.291645939454825e-05,
      "loss": 0.0003,
      "step": 1792
    },
    {
      "epoch": 1.218070652173913,
      "grad_norm": 5.558853626251221,
      "learning_rate": 1.2909653819843255e-05,
      "loss": 0.0639,
      "step": 1793
    },
    {
      "epoch": 1.21875,
      "grad_norm": 0.002159481169655919,
      "learning_rate": 1.2902846772544625e-05,
      "loss": 0.0,
      "step": 1794
    },
    {
      "epoch": 1.219429347826087,
      "grad_norm": 9.82470417022705,
      "learning_rate": 1.2896038256097447e-05,
      "loss": 0.2342,
      "step": 1795
    },
    {
      "epoch": 1.2201086956521738,
      "grad_norm": 0.014546157792210579,
      "learning_rate": 1.2889228273947559e-05,
      "loss": 0.0001,
      "step": 1796
    },
    {
      "epoch": 1.2207880434782608,
      "grad_norm": 3.8130433559417725,
      "learning_rate": 1.2882416829541526e-05,
      "loss": 0.0476,
      "step": 1797
    },
    {
      "epoch": 1.221467391304348,
      "grad_norm": 0.12014325708150864,
      "learning_rate": 1.2875603926326667e-05,
      "loss": 0.0014,
      "step": 1798
    },
    {
      "epoch": 1.2221467391304348,
      "grad_norm": 0.0029414105229079723,
      "learning_rate": 1.2868789567751034e-05,
      "loss": 0.0001,
      "step": 1799
    },
    {
      "epoch": 1.2228260869565217,
      "grad_norm": 0.0029504369013011456,
      "learning_rate": 1.2861973757263416e-05,
      "loss": 0.0,
      "step": 1800
    },
    {
      "epoch": 1.2235054347826086,
      "grad_norm": 0.005980391055345535,
      "learning_rate": 1.2855156498313333e-05,
      "loss": 0.0001,
      "step": 1801
    },
    {
      "epoch": 1.2241847826086956,
      "grad_norm": 2.0154871940612793,
      "learning_rate": 1.2848337794351045e-05,
      "loss": 0.0246,
      "step": 1802
    },
    {
      "epoch": 1.2248641304347827,
      "grad_norm": 5.608510494232178,
      "learning_rate": 1.2841517648827538e-05,
      "loss": 0.117,
      "step": 1803
    },
    {
      "epoch": 1.2255434782608696,
      "grad_norm": 3.967928647994995,
      "learning_rate": 1.283469606519453e-05,
      "loss": 0.0695,
      "step": 1804
    },
    {
      "epoch": 1.2262228260869565,
      "grad_norm": 0.07784061133861542,
      "learning_rate": 1.2827873046904467e-05,
      "loss": 0.0004,
      "step": 1805
    },
    {
      "epoch": 1.2269021739130435,
      "grad_norm": 4.919301509857178,
      "learning_rate": 1.282104859741052e-05,
      "loss": 0.0254,
      "step": 1806
    },
    {
      "epoch": 1.2275815217391304,
      "grad_norm": 25.29270362854004,
      "learning_rate": 1.2814222720166582e-05,
      "loss": 0.3649,
      "step": 1807
    },
    {
      "epoch": 1.2282608695652173,
      "grad_norm": 15.365514755249023,
      "learning_rate": 1.2807395418627278e-05,
      "loss": 0.8145,
      "step": 1808
    },
    {
      "epoch": 1.2289402173913044,
      "grad_norm": 6.657712459564209,
      "learning_rate": 1.2800566696247943e-05,
      "loss": 0.1421,
      "step": 1809
    },
    {
      "epoch": 1.2296195652173914,
      "grad_norm": 0.00406479649245739,
      "learning_rate": 1.279373655648463e-05,
      "loss": 0.0001,
      "step": 1810
    },
    {
      "epoch": 1.2302989130434783,
      "grad_norm": 0.009792041964828968,
      "learning_rate": 1.2786905002794123e-05,
      "loss": 0.0001,
      "step": 1811
    },
    {
      "epoch": 1.2309782608695652,
      "grad_norm": 1.7670810222625732,
      "learning_rate": 1.2780072038633913e-05,
      "loss": 0.0201,
      "step": 1812
    },
    {
      "epoch": 1.231657608695652,
      "grad_norm": 0.0025559826754033566,
      "learning_rate": 1.2773237667462199e-05,
      "loss": 0.0,
      "step": 1813
    },
    {
      "epoch": 1.2323369565217392,
      "grad_norm": 6.713651657104492,
      "learning_rate": 1.2766401892737901e-05,
      "loss": 0.2384,
      "step": 1814
    },
    {
      "epoch": 1.2330163043478262,
      "grad_norm": 3.3508265018463135,
      "learning_rate": 1.2759564717920649e-05,
      "loss": 0.1713,
      "step": 1815
    },
    {
      "epoch": 1.233695652173913,
      "grad_norm": 0.020621662959456444,
      "learning_rate": 1.2752726146470775e-05,
      "loss": 0.0002,
      "step": 1816
    },
    {
      "epoch": 1.234375,
      "grad_norm": 3.7970046997070312,
      "learning_rate": 1.2745886181849325e-05,
      "loss": 0.0585,
      "step": 1817
    },
    {
      "epoch": 1.235054347826087,
      "grad_norm": 0.020184120163321495,
      "learning_rate": 1.2739044827518043e-05,
      "loss": 0.0004,
      "step": 1818
    },
    {
      "epoch": 1.2357336956521738,
      "grad_norm": 0.046375833451747894,
      "learning_rate": 1.2732202086939387e-05,
      "loss": 0.0006,
      "step": 1819
    },
    {
      "epoch": 1.2364130434782608,
      "grad_norm": 6.253995418548584,
      "learning_rate": 1.2725357963576506e-05,
      "loss": 0.1209,
      "step": 1820
    },
    {
      "epoch": 1.237092391304348,
      "grad_norm": 0.013148978352546692,
      "learning_rate": 1.271851246089325e-05,
      "loss": 0.0001,
      "step": 1821
    },
    {
      "epoch": 1.2377717391304348,
      "grad_norm": 0.012231368571519852,
      "learning_rate": 1.2711665582354175e-05,
      "loss": 0.0002,
      "step": 1822
    },
    {
      "epoch": 1.2384510869565217,
      "grad_norm": 0.01313357800245285,
      "learning_rate": 1.2704817331424526e-05,
      "loss": 0.0002,
      "step": 1823
    },
    {
      "epoch": 1.2391304347826086,
      "grad_norm": 7.418666362762451,
      "learning_rate": 1.2697967711570243e-05,
      "loss": 0.2415,
      "step": 1824
    },
    {
      "epoch": 1.2398097826086956,
      "grad_norm": 1.417590856552124,
      "learning_rate": 1.2691116726257963e-05,
      "loss": 0.025,
      "step": 1825
    },
    {
      "epoch": 1.2404891304347827,
      "grad_norm": 0.007995883002877235,
      "learning_rate": 1.2684264378955014e-05,
      "loss": 0.0001,
      "step": 1826
    },
    {
      "epoch": 1.2411684782608696,
      "grad_norm": 12.026870727539062,
      "learning_rate": 1.2677410673129406e-05,
      "loss": 0.3132,
      "step": 1827
    },
    {
      "epoch": 1.2418478260869565,
      "grad_norm": 3.860698699951172,
      "learning_rate": 1.2670555612249845e-05,
      "loss": 0.1107,
      "step": 1828
    },
    {
      "epoch": 1.2425271739130435,
      "grad_norm": 3.507427215576172,
      "learning_rate": 1.2663699199785715e-05,
      "loss": 0.0756,
      "step": 1829
    },
    {
      "epoch": 1.2432065217391304,
      "grad_norm": 0.00899704173207283,
      "learning_rate": 1.2656841439207093e-05,
      "loss": 0.0001,
      "step": 1830
    },
    {
      "epoch": 1.2438858695652173,
      "grad_norm": 6.736767768859863,
      "learning_rate": 1.264998233398473e-05,
      "loss": 0.3082,
      "step": 1831
    },
    {
      "epoch": 1.2445652173913044,
      "grad_norm": 4.522645950317383,
      "learning_rate": 1.2643121887590064e-05,
      "loss": 0.1432,
      "step": 1832
    },
    {
      "epoch": 1.2452445652173914,
      "grad_norm": 0.9570327997207642,
      "learning_rate": 1.2636260103495209e-05,
      "loss": 0.0135,
      "step": 1833
    },
    {
      "epoch": 1.2459239130434783,
      "grad_norm": 10.506107330322266,
      "learning_rate": 1.2629396985172954e-05,
      "loss": 0.3515,
      "step": 1834
    },
    {
      "epoch": 1.2466032608695652,
      "grad_norm": 0.003613840788602829,
      "learning_rate": 1.2622532536096767e-05,
      "loss": 0.0001,
      "step": 1835
    },
    {
      "epoch": 1.247282608695652,
      "grad_norm": 0.005265049170702696,
      "learning_rate": 1.2615666759740788e-05,
      "loss": 0.0001,
      "step": 1836
    },
    {
      "epoch": 1.2479619565217392,
      "grad_norm": 7.59357213973999,
      "learning_rate": 1.2608799659579827e-05,
      "loss": 0.2289,
      "step": 1837
    },
    {
      "epoch": 1.2486413043478262,
      "grad_norm": 0.01077038049697876,
      "learning_rate": 1.2601931239089366e-05,
      "loss": 0.0002,
      "step": 1838
    },
    {
      "epoch": 1.249320652173913,
      "grad_norm": 4.408677101135254,
      "learning_rate": 1.2595061501745556e-05,
      "loss": 0.1159,
      "step": 1839
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.026187753304839134,
      "learning_rate": 1.2588190451025209e-05,
      "loss": 0.0001,
      "step": 1840
    },
    {
      "epoch": 1.250679347826087,
      "grad_norm": 0.0016751312650740147,
      "learning_rate": 1.258131809040581e-05,
      "loss": 0.0,
      "step": 1841
    },
    {
      "epoch": 1.2513586956521738,
      "grad_norm": 0.041673220694065094,
      "learning_rate": 1.2574444423365503e-05,
      "loss": 0.0003,
      "step": 1842
    },
    {
      "epoch": 1.2520380434782608,
      "grad_norm": 6.699699401855469,
      "learning_rate": 1.2567569453383092e-05,
      "loss": 0.1794,
      "step": 1843
    },
    {
      "epoch": 1.252717391304348,
      "grad_norm": 0.5242273807525635,
      "learning_rate": 1.256069318393804e-05,
      "loss": 0.003,
      "step": 1844
    },
    {
      "epoch": 1.2533967391304348,
      "grad_norm": 13.734987258911133,
      "learning_rate": 1.255381561851047e-05,
      "loss": 0.1173,
      "step": 1845
    },
    {
      "epoch": 1.2540760869565217,
      "grad_norm": 5.5967278480529785,
      "learning_rate": 1.2546936760581162e-05,
      "loss": 0.0962,
      "step": 1846
    },
    {
      "epoch": 1.2547554347826086,
      "grad_norm": 0.9839407801628113,
      "learning_rate": 1.2540056613631547e-05,
      "loss": 0.0063,
      "step": 1847
    },
    {
      "epoch": 1.2554347826086958,
      "grad_norm": 14.351702690124512,
      "learning_rate": 1.2533175181143704e-05,
      "loss": 0.7282,
      "step": 1848
    },
    {
      "epoch": 1.2561141304347827,
      "grad_norm": 0.007128981873393059,
      "learning_rate": 1.2526292466600378e-05,
      "loss": 0.0001,
      "step": 1849
    },
    {
      "epoch": 1.2567934782608696,
      "grad_norm": 18.060270309448242,
      "learning_rate": 1.2519408473484947e-05,
      "loss": 0.565,
      "step": 1850
    },
    {
      "epoch": 1.2574728260869565,
      "grad_norm": 1.3987340927124023,
      "learning_rate": 1.2512523205281444e-05,
      "loss": 0.0331,
      "step": 1851
    },
    {
      "epoch": 1.2581521739130435,
      "grad_norm": 0.03298868611454964,
      "learning_rate": 1.2505636665474545e-05,
      "loss": 0.0003,
      "step": 1852
    },
    {
      "epoch": 1.2588315217391304,
      "grad_norm": 27.94749641418457,
      "learning_rate": 1.2498748857549567e-05,
      "loss": 0.4602,
      "step": 1853
    },
    {
      "epoch": 1.2595108695652173,
      "grad_norm": 11.298770904541016,
      "learning_rate": 1.2491859784992477e-05,
      "loss": 0.4225,
      "step": 1854
    },
    {
      "epoch": 1.2601902173913042,
      "grad_norm": 0.009049613028764725,
      "learning_rate": 1.2484969451289874e-05,
      "loss": 0.0001,
      "step": 1855
    },
    {
      "epoch": 1.2608695652173914,
      "grad_norm": 5.676522731781006,
      "learning_rate": 1.2478077859929e-05,
      "loss": 0.2639,
      "step": 1856
    },
    {
      "epoch": 1.2615489130434783,
      "grad_norm": 8.516944885253906,
      "learning_rate": 1.2471185014397728e-05,
      "loss": 0.4457,
      "step": 1857
    },
    {
      "epoch": 1.2622282608695652,
      "grad_norm": 0.003825993277132511,
      "learning_rate": 1.2464290918184573e-05,
      "loss": 0.0001,
      "step": 1858
    },
    {
      "epoch": 1.262907608695652,
      "grad_norm": 0.08187572658061981,
      "learning_rate": 1.2457395574778679e-05,
      "loss": 0.0005,
      "step": 1859
    },
    {
      "epoch": 1.2635869565217392,
      "grad_norm": 17.446279525756836,
      "learning_rate": 1.245049898766982e-05,
      "loss": 0.5199,
      "step": 1860
    },
    {
      "epoch": 1.2642663043478262,
      "grad_norm": 0.028503868728876114,
      "learning_rate": 1.24436011603484e-05,
      "loss": 0.0002,
      "step": 1861
    },
    {
      "epoch": 1.264945652173913,
      "grad_norm": 4.075013637542725,
      "learning_rate": 1.2436702096305455e-05,
      "loss": 0.1198,
      "step": 1862
    },
    {
      "epoch": 1.265625,
      "grad_norm": 1.6190909147262573,
      "learning_rate": 1.242980179903264e-05,
      "loss": 0.0174,
      "step": 1863
    },
    {
      "epoch": 1.266304347826087,
      "grad_norm": 6.85167121887207,
      "learning_rate": 1.2422900272022242e-05,
      "loss": 0.0841,
      "step": 1864
    },
    {
      "epoch": 1.2669836956521738,
      "grad_norm": 0.03445519506931305,
      "learning_rate": 1.2415997518767163e-05,
      "loss": 0.0003,
      "step": 1865
    },
    {
      "epoch": 1.2676630434782608,
      "grad_norm": 7.656400680541992,
      "learning_rate": 1.2409093542760925e-05,
      "loss": 0.1235,
      "step": 1866
    },
    {
      "epoch": 1.268342391304348,
      "grad_norm": 0.003952934872359037,
      "learning_rate": 1.2402188347497684e-05,
      "loss": 0.0001,
      "step": 1867
    },
    {
      "epoch": 1.2690217391304348,
      "grad_norm": 5.04925537109375,
      "learning_rate": 1.239528193647219e-05,
      "loss": 0.1734,
      "step": 1868
    },
    {
      "epoch": 1.2697010869565217,
      "grad_norm": 11.628913879394531,
      "learning_rate": 1.2388374313179828e-05,
      "loss": 0.1463,
      "step": 1869
    },
    {
      "epoch": 1.2703804347826086,
      "grad_norm": 0.5360386371612549,
      "learning_rate": 1.2381465481116582e-05,
      "loss": 0.0044,
      "step": 1870
    },
    {
      "epoch": 1.2710597826086958,
      "grad_norm": 0.002907796995714307,
      "learning_rate": 1.2374555443779057e-05,
      "loss": 0.0001,
      "step": 1871
    },
    {
      "epoch": 1.2717391304347827,
      "grad_norm": 0.1974596381187439,
      "learning_rate": 1.2367644204664468e-05,
      "loss": 0.002,
      "step": 1872
    },
    {
      "epoch": 1.2724184782608696,
      "grad_norm": 9.024429321289062,
      "learning_rate": 1.2360731767270634e-05,
      "loss": 0.2624,
      "step": 1873
    },
    {
      "epoch": 1.2730978260869565,
      "grad_norm": 0.007691664155572653,
      "learning_rate": 1.2353818135095978e-05,
      "loss": 0.0001,
      "step": 1874
    },
    {
      "epoch": 1.2737771739130435,
      "grad_norm": 11.280048370361328,
      "learning_rate": 1.2346903311639537e-05,
      "loss": 0.5632,
      "step": 1875
    },
    {
      "epoch": 1.2744565217391304,
      "grad_norm": 0.02314738556742668,
      "learning_rate": 1.2339987300400941e-05,
      "loss": 0.0002,
      "step": 1876
    },
    {
      "epoch": 1.2751358695652173,
      "grad_norm": 1.6443877220153809,
      "learning_rate": 1.2333070104880431e-05,
      "loss": 0.0391,
      "step": 1877
    },
    {
      "epoch": 1.2758152173913042,
      "grad_norm": 34.154666900634766,
      "learning_rate": 1.2326151728578839e-05,
      "loss": 0.4144,
      "step": 1878
    },
    {
      "epoch": 1.2764945652173914,
      "grad_norm": 4.415376663208008,
      "learning_rate": 1.2319232174997593e-05,
      "loss": 0.0513,
      "step": 1879
    },
    {
      "epoch": 1.2771739130434783,
      "grad_norm": 0.004836303181946278,
      "learning_rate": 1.2312311447638731e-05,
      "loss": 0.0001,
      "step": 1880
    },
    {
      "epoch": 1.2778532608695652,
      "grad_norm": 1.8570106029510498,
      "learning_rate": 1.230538955000487e-05,
      "loss": 0.0131,
      "step": 1881
    },
    {
      "epoch": 1.278532608695652,
      "grad_norm": 3.422037363052368,
      "learning_rate": 1.2298466485599223e-05,
      "loss": 0.0629,
      "step": 1882
    },
    {
      "epoch": 1.2792119565217392,
      "grad_norm": 6.8280181884765625,
      "learning_rate": 1.2291542257925597e-05,
      "loss": 0.2521,
      "step": 1883
    },
    {
      "epoch": 1.2798913043478262,
      "grad_norm": 0.05152333155274391,
      "learning_rate": 1.228461687048839e-05,
      "loss": 0.0003,
      "step": 1884
    },
    {
      "epoch": 1.280570652173913,
      "grad_norm": 0.00788226816803217,
      "learning_rate": 1.2277690326792579e-05,
      "loss": 0.0001,
      "step": 1885
    },
    {
      "epoch": 1.28125,
      "grad_norm": 3.8865973949432373,
      "learning_rate": 1.2270762630343734e-05,
      "loss": 0.0882,
      "step": 1886
    },
    {
      "epoch": 1.281929347826087,
      "grad_norm": 1.9726213216781616,
      "learning_rate": 1.2263833784647998e-05,
      "loss": 0.014,
      "step": 1887
    },
    {
      "epoch": 1.2826086956521738,
      "grad_norm": 2.3486509323120117,
      "learning_rate": 1.2256903793212107e-05,
      "loss": 0.0508,
      "step": 1888
    },
    {
      "epoch": 1.2832880434782608,
      "grad_norm": 0.41652411222457886,
      "learning_rate": 1.2249972659543375e-05,
      "loss": 0.0027,
      "step": 1889
    },
    {
      "epoch": 1.283967391304348,
      "grad_norm": 4.938397407531738,
      "learning_rate": 1.2243040387149682e-05,
      "loss": 0.0671,
      "step": 1890
    },
    {
      "epoch": 1.2846467391304348,
      "grad_norm": 12.765387535095215,
      "learning_rate": 1.2236106979539501e-05,
      "loss": 0.3675,
      "step": 1891
    },
    {
      "epoch": 1.2853260869565217,
      "grad_norm": 9.093751907348633,
      "learning_rate": 1.2229172440221867e-05,
      "loss": 0.2213,
      "step": 1892
    },
    {
      "epoch": 1.2860054347826086,
      "grad_norm": 4.506013870239258,
      "learning_rate": 1.2222236772706402e-05,
      "loss": 0.1792,
      "step": 1893
    },
    {
      "epoch": 1.2866847826086958,
      "grad_norm": 0.04630458354949951,
      "learning_rate": 1.2215299980503282e-05,
      "loss": 0.0004,
      "step": 1894
    },
    {
      "epoch": 1.2873641304347827,
      "grad_norm": 0.10755900293588638,
      "learning_rate": 1.220836206712326e-05,
      "loss": 0.0008,
      "step": 1895
    },
    {
      "epoch": 1.2880434782608696,
      "grad_norm": 14.94509220123291,
      "learning_rate": 1.2201423036077657e-05,
      "loss": 0.3807,
      "step": 1896
    },
    {
      "epoch": 1.2887228260869565,
      "grad_norm": 5.828987121582031,
      "learning_rate": 1.2194482890878363e-05,
      "loss": 0.1513,
      "step": 1897
    },
    {
      "epoch": 1.2894021739130435,
      "grad_norm": 4.2720561027526855,
      "learning_rate": 1.2187541635037824e-05,
      "loss": 0.1196,
      "step": 1898
    },
    {
      "epoch": 1.2900815217391304,
      "grad_norm": 1.8748259544372559,
      "learning_rate": 1.2180599272069058e-05,
      "loss": 0.0256,
      "step": 1899
    },
    {
      "epoch": 1.2907608695652173,
      "grad_norm": 3.7237699031829834,
      "learning_rate": 1.2173655805485627e-05,
      "loss": 0.0704,
      "step": 1900
    },
    {
      "epoch": 1.2914402173913042,
      "grad_norm": 0.00562876695767045,
      "learning_rate": 1.2166711238801671e-05,
      "loss": 0.0001,
      "step": 1901
    },
    {
      "epoch": 1.2921195652173914,
      "grad_norm": 0.18227972090244293,
      "learning_rate": 1.2159765575531877e-05,
      "loss": 0.0016,
      "step": 1902
    },
    {
      "epoch": 1.2927989130434783,
      "grad_norm": 0.7556204795837402,
      "learning_rate": 1.2152818819191483e-05,
      "loss": 0.014,
      "step": 1903
    },
    {
      "epoch": 1.2934782608695652,
      "grad_norm": 2.997357130050659,
      "learning_rate": 1.2145870973296288e-05,
      "loss": 0.0304,
      "step": 1904
    },
    {
      "epoch": 1.294157608695652,
      "grad_norm": 8.627342224121094,
      "learning_rate": 1.213892204136264e-05,
      "loss": 0.3426,
      "step": 1905
    },
    {
      "epoch": 1.2948369565217392,
      "grad_norm": 15.629996299743652,
      "learning_rate": 1.2131972026907433e-05,
      "loss": 0.5607,
      "step": 1906
    },
    {
      "epoch": 1.2955163043478262,
      "grad_norm": 0.9237052202224731,
      "learning_rate": 1.2125020933448117e-05,
      "loss": 0.0172,
      "step": 1907
    },
    {
      "epoch": 1.296195652173913,
      "grad_norm": 9.80202865600586,
      "learning_rate": 1.2118068764502677e-05,
      "loss": 0.1176,
      "step": 1908
    },
    {
      "epoch": 1.296875,
      "grad_norm": 4.403525352478027,
      "learning_rate": 1.2111115523589651e-05,
      "loss": 0.1148,
      "step": 1909
    },
    {
      "epoch": 1.297554347826087,
      "grad_norm": 9.924792289733887,
      "learning_rate": 1.210416121422812e-05,
      "loss": 0.229,
      "step": 1910
    },
    {
      "epoch": 1.2982336956521738,
      "grad_norm": 9.810341835021973,
      "learning_rate": 1.20972058399377e-05,
      "loss": 0.3847,
      "step": 1911
    },
    {
      "epoch": 1.2989130434782608,
      "grad_norm": 6.545526027679443,
      "learning_rate": 1.2090249404238548e-05,
      "loss": 0.1507,
      "step": 1912
    },
    {
      "epoch": 1.299592391304348,
      "grad_norm": 0.01595310866832733,
      "learning_rate": 1.2083291910651356e-05,
      "loss": 0.0002,
      "step": 1913
    },
    {
      "epoch": 1.3002717391304348,
      "grad_norm": 0.00380860548466444,
      "learning_rate": 1.2076333362697358e-05,
      "loss": 0.0001,
      "step": 1914
    },
    {
      "epoch": 1.3009510869565217,
      "grad_norm": 2.4099621772766113,
      "learning_rate": 1.206937376389832e-05,
      "loss": 0.0267,
      "step": 1915
    },
    {
      "epoch": 1.3016304347826086,
      "grad_norm": 2.551196575164795,
      "learning_rate": 1.2062413117776535e-05,
      "loss": 0.0225,
      "step": 1916
    },
    {
      "epoch": 1.3023097826086958,
      "grad_norm": 0.026631822809576988,
      "learning_rate": 1.2055451427854825e-05,
      "loss": 0.0005,
      "step": 1917
    },
    {
      "epoch": 1.3029891304347827,
      "grad_norm": 0.007477866485714912,
      "learning_rate": 1.2048488697656548e-05,
      "loss": 0.0001,
      "step": 1918
    },
    {
      "epoch": 1.3036684782608696,
      "grad_norm": 5.131917953491211,
      "learning_rate": 1.2041524930705586e-05,
      "loss": 0.2546,
      "step": 1919
    },
    {
      "epoch": 1.3043478260869565,
      "grad_norm": 0.025710992515087128,
      "learning_rate": 1.2034560130526341e-05,
      "loss": 0.0002,
      "step": 1920
    },
    {
      "epoch": 1.3050271739130435,
      "grad_norm": 2.7351694107055664,
      "learning_rate": 1.2027594300643742e-05,
      "loss": 0.0153,
      "step": 1921
    },
    {
      "epoch": 1.3057065217391304,
      "grad_norm": 10.17860221862793,
      "learning_rate": 1.2020627444583235e-05,
      "loss": 0.0901,
      "step": 1922
    },
    {
      "epoch": 1.3063858695652173,
      "grad_norm": 0.07073204219341278,
      "learning_rate": 1.2013659565870795e-05,
      "loss": 0.0005,
      "step": 1923
    },
    {
      "epoch": 1.3070652173913042,
      "grad_norm": 0.003238529898226261,
      "learning_rate": 1.2006690668032902e-05,
      "loss": 0.0001,
      "step": 1924
    },
    {
      "epoch": 1.3077445652173914,
      "grad_norm": 1.6534532308578491,
      "learning_rate": 1.1999720754596565e-05,
      "loss": 0.0219,
      "step": 1925
    },
    {
      "epoch": 1.3084239130434783,
      "grad_norm": 0.009520214982330799,
      "learning_rate": 1.199274982908929e-05,
      "loss": 0.0002,
      "step": 1926
    },
    {
      "epoch": 1.3091032608695652,
      "grad_norm": 0.05418645590543747,
      "learning_rate": 1.1985777895039114e-05,
      "loss": 0.0005,
      "step": 1927
    },
    {
      "epoch": 1.309782608695652,
      "grad_norm": 20.04592514038086,
      "learning_rate": 1.1978804955974573e-05,
      "loss": 0.8293,
      "step": 1928
    },
    {
      "epoch": 1.3104619565217392,
      "grad_norm": 10.342062950134277,
      "learning_rate": 1.1971831015424713e-05,
      "loss": 0.2832,
      "step": 1929
    },
    {
      "epoch": 1.3111413043478262,
      "grad_norm": 0.003654196858406067,
      "learning_rate": 1.1964856076919087e-05,
      "loss": 0.0001,
      "step": 1930
    },
    {
      "epoch": 1.311820652173913,
      "grad_norm": 0.6576586365699768,
      "learning_rate": 1.1957880143987757e-05,
      "loss": 0.0042,
      "step": 1931
    },
    {
      "epoch": 1.3125,
      "grad_norm": 19.361249923706055,
      "learning_rate": 1.1950903220161286e-05,
      "loss": 0.2603,
      "step": 1932
    },
    {
      "epoch": 1.313179347826087,
      "grad_norm": 1.3657625913619995,
      "learning_rate": 1.1943925308970732e-05,
      "loss": 0.0083,
      "step": 1933
    },
    {
      "epoch": 1.3138586956521738,
      "grad_norm": 0.09111951291561127,
      "learning_rate": 1.1936946413947666e-05,
      "loss": 0.001,
      "step": 1934
    },
    {
      "epoch": 1.3145380434782608,
      "grad_norm": 0.17729142308235168,
      "learning_rate": 1.1929966538624143e-05,
      "loss": 0.0012,
      "step": 1935
    },
    {
      "epoch": 1.315217391304348,
      "grad_norm": 0.036300405859947205,
      "learning_rate": 1.1922985686532726e-05,
      "loss": 0.0003,
      "step": 1936
    },
    {
      "epoch": 1.3158967391304348,
      "grad_norm": 0.004013833124190569,
      "learning_rate": 1.1916003861206467e-05,
      "loss": 0.0001,
      "step": 1937
    },
    {
      "epoch": 1.3165760869565217,
      "grad_norm": 0.010419638827443123,
      "learning_rate": 1.1909021066178906e-05,
      "loss": 0.0001,
      "step": 1938
    },
    {
      "epoch": 1.3172554347826086,
      "grad_norm": 0.002425922779366374,
      "learning_rate": 1.1902037304984079e-05,
      "loss": 0.0,
      "step": 1939
    },
    {
      "epoch": 1.3179347826086958,
      "grad_norm": 4.358849048614502,
      "learning_rate": 1.1895052581156516e-05,
      "loss": 0.097,
      "step": 1940
    },
    {
      "epoch": 1.3186141304347827,
      "grad_norm": 0.0020211408846080303,
      "learning_rate": 1.1888066898231223e-05,
      "loss": 0.0,
      "step": 1941
    },
    {
      "epoch": 1.3192934782608696,
      "grad_norm": 7.245133876800537,
      "learning_rate": 1.1881080259743701e-05,
      "loss": 0.1564,
      "step": 1942
    },
    {
      "epoch": 1.3199728260869565,
      "grad_norm": 7.243581771850586,
      "learning_rate": 1.1874092669229924e-05,
      "loss": 0.155,
      "step": 1943
    },
    {
      "epoch": 1.3206521739130435,
      "grad_norm": 0.016083480790257454,
      "learning_rate": 1.1867104130226363e-05,
      "loss": 0.0002,
      "step": 1944
    },
    {
      "epoch": 1.3213315217391304,
      "grad_norm": 0.03364970162510872,
      "learning_rate": 1.1860114646269955e-05,
      "loss": 0.0006,
      "step": 1945
    },
    {
      "epoch": 1.3220108695652173,
      "grad_norm": 4.857770919799805,
      "learning_rate": 1.1853124220898123e-05,
      "loss": 0.2265,
      "step": 1946
    },
    {
      "epoch": 1.3226902173913042,
      "grad_norm": 3.0432708263397217,
      "learning_rate": 1.184613285764876e-05,
      "loss": 0.0187,
      "step": 1947
    },
    {
      "epoch": 1.3233695652173914,
      "grad_norm": 2.0657505989074707,
      "learning_rate": 1.1839140560060242e-05,
      "loss": 0.0415,
      "step": 1948
    },
    {
      "epoch": 1.3240489130434783,
      "grad_norm": 5.498228073120117,
      "learning_rate": 1.1832147331671416e-05,
      "loss": 0.0981,
      "step": 1949
    },
    {
      "epoch": 1.3247282608695652,
      "grad_norm": 0.0040071578696370125,
      "learning_rate": 1.1825153176021591e-05,
      "loss": 0.0001,
      "step": 1950
    },
    {
      "epoch": 1.325407608695652,
      "grad_norm": 9.864995002746582,
      "learning_rate": 1.1818158096650554e-05,
      "loss": 0.4126,
      "step": 1951
    },
    {
      "epoch": 1.3260869565217392,
      "grad_norm": 12.793861389160156,
      "learning_rate": 1.1811162097098559e-05,
      "loss": 0.1679,
      "step": 1952
    },
    {
      "epoch": 1.3267663043478262,
      "grad_norm": 0.587598979473114,
      "learning_rate": 1.1804165180906326e-05,
      "loss": 0.0068,
      "step": 1953
    },
    {
      "epoch": 1.327445652173913,
      "grad_norm": 0.4172724187374115,
      "learning_rate": 1.1797167351615032e-05,
      "loss": 0.0034,
      "step": 1954
    },
    {
      "epoch": 1.328125,
      "grad_norm": 6.407911777496338,
      "learning_rate": 1.1790168612766331e-05,
      "loss": 0.1208,
      "step": 1955
    },
    {
      "epoch": 1.328804347826087,
      "grad_norm": 6.381159782409668,
      "learning_rate": 1.1783168967902314e-05,
      "loss": 0.1209,
      "step": 1956
    },
    {
      "epoch": 1.3294836956521738,
      "grad_norm": 8.365281105041504,
      "learning_rate": 1.1776168420565555e-05,
      "loss": 0.1559,
      "step": 1957
    },
    {
      "epoch": 1.3301630434782608,
      "grad_norm": 0.10377766191959381,
      "learning_rate": 1.1769166974299071e-05,
      "loss": 0.0008,
      "step": 1958
    },
    {
      "epoch": 1.330842391304348,
      "grad_norm": 5.640632152557373,
      "learning_rate": 1.1762164632646334e-05,
      "loss": 0.1291,
      "step": 1959
    },
    {
      "epoch": 1.3315217391304348,
      "grad_norm": 0.008271165192127228,
      "learning_rate": 1.1755161399151277e-05,
      "loss": 0.0001,
      "step": 1960
    },
    {
      "epoch": 1.3322010869565217,
      "grad_norm": 0.009315317496657372,
      "learning_rate": 1.1748157277358272e-05,
      "loss": 0.0001,
      "step": 1961
    },
    {
      "epoch": 1.3328804347826086,
      "grad_norm": 0.23801566660404205,
      "learning_rate": 1.1741152270812155e-05,
      "loss": 0.0013,
      "step": 1962
    },
    {
      "epoch": 1.3335597826086958,
      "grad_norm": 4.417314052581787,
      "learning_rate": 1.17341463830582e-05,
      "loss": 0.1807,
      "step": 1963
    },
    {
      "epoch": 1.3342391304347827,
      "grad_norm": 14.808277130126953,
      "learning_rate": 1.1727139617642132e-05,
      "loss": 0.5965,
      "step": 1964
    },
    {
      "epoch": 1.3349184782608696,
      "grad_norm": 11.00629997253418,
      "learning_rate": 1.1720131978110115e-05,
      "loss": 0.4901,
      "step": 1965
    },
    {
      "epoch": 1.3355978260869565,
      "grad_norm": 1.2663354873657227,
      "learning_rate": 1.1713123468008757e-05,
      "loss": 0.011,
      "step": 1966
    },
    {
      "epoch": 1.3362771739130435,
      "grad_norm": 0.17444148659706116,
      "learning_rate": 1.1706114090885112e-05,
      "loss": 0.0012,
      "step": 1967
    },
    {
      "epoch": 1.3369565217391304,
      "grad_norm": 0.005931726656854153,
      "learning_rate": 1.1699103850286668e-05,
      "loss": 0.0001,
      "step": 1968
    },
    {
      "epoch": 1.3376358695652173,
      "grad_norm": 5.517638206481934,
      "learning_rate": 1.1692092749761348e-05,
      "loss": 0.082,
      "step": 1969
    },
    {
      "epoch": 1.3383152173913042,
      "grad_norm": 14.891495704650879,
      "learning_rate": 1.1685080792857516e-05,
      "loss": 0.4123,
      "step": 1970
    },
    {
      "epoch": 1.3389945652173914,
      "grad_norm": 0.007995921187102795,
      "learning_rate": 1.1678067983123965e-05,
      "loss": 0.0001,
      "step": 1971
    },
    {
      "epoch": 1.3396739130434783,
      "grad_norm": 2.7162327766418457,
      "learning_rate": 1.167105432410992e-05,
      "loss": 0.0125,
      "step": 1972
    },
    {
      "epoch": 1.3403532608695652,
      "grad_norm": 0.2552129030227661,
      "learning_rate": 1.1664039819365037e-05,
      "loss": 0.0013,
      "step": 1973
    },
    {
      "epoch": 1.341032608695652,
      "grad_norm": 0.6955382227897644,
      "learning_rate": 1.1657024472439402e-05,
      "loss": 0.0042,
      "step": 1974
    },
    {
      "epoch": 1.3417119565217392,
      "grad_norm": 0.004812710452824831,
      "learning_rate": 1.1650008286883526e-05,
      "loss": 0.0001,
      "step": 1975
    },
    {
      "epoch": 1.3423913043478262,
      "grad_norm": 6.678188800811768,
      "learning_rate": 1.1642991266248338e-05,
      "loss": 0.1985,
      "step": 1976
    },
    {
      "epoch": 1.343070652173913,
      "grad_norm": 2.8937814235687256,
      "learning_rate": 1.16359734140852e-05,
      "loss": 0.047,
      "step": 1977
    },
    {
      "epoch": 1.34375,
      "grad_norm": 5.1912922859191895,
      "learning_rate": 1.162895473394589e-05,
      "loss": 0.1247,
      "step": 1978
    },
    {
      "epoch": 1.344429347826087,
      "grad_norm": 1.2069268226623535,
      "learning_rate": 1.16219352293826e-05,
      "loss": 0.007,
      "step": 1979
    },
    {
      "epoch": 1.3451086956521738,
      "grad_norm": 0.18405331671237946,
      "learning_rate": 1.1614914903947952e-05,
      "loss": 0.0009,
      "step": 1980
    },
    {
      "epoch": 1.3457880434782608,
      "grad_norm": 9.490435600280762,
      "learning_rate": 1.1607893761194967e-05,
      "loss": 0.3208,
      "step": 1981
    },
    {
      "epoch": 1.346467391304348,
      "grad_norm": 0.008474992588162422,
      "learning_rate": 1.1600871804677094e-05,
      "loss": 0.0001,
      "step": 1982
    },
    {
      "epoch": 1.3471467391304348,
      "grad_norm": 0.9683520197868347,
      "learning_rate": 1.1593849037948189e-05,
      "loss": 0.0127,
      "step": 1983
    },
    {
      "epoch": 1.3478260869565217,
      "grad_norm": 3.9884414672851562,
      "learning_rate": 1.1586825464562515e-05,
      "loss": 0.0488,
      "step": 1984
    },
    {
      "epoch": 1.3485054347826086,
      "grad_norm": 0.004746672697365284,
      "learning_rate": 1.1579801088074747e-05,
      "loss": 0.0001,
      "step": 1985
    },
    {
      "epoch": 1.3491847826086958,
      "grad_norm": 3.4824931621551514,
      "learning_rate": 1.157277591203996e-05,
      "loss": 0.1508,
      "step": 1986
    },
    {
      "epoch": 1.3498641304347827,
      "grad_norm": 0.00537850521504879,
      "learning_rate": 1.1565749940013647e-05,
      "loss": 0.0001,
      "step": 1987
    },
    {
      "epoch": 1.3505434782608696,
      "grad_norm": 4.09273099899292,
      "learning_rate": 1.155872317555169e-05,
      "loss": 0.0579,
      "step": 1988
    },
    {
      "epoch": 1.3512228260869565,
      "grad_norm": 13.200532913208008,
      "learning_rate": 1.1551695622210377e-05,
      "loss": 0.1406,
      "step": 1989
    },
    {
      "epoch": 1.3519021739130435,
      "grad_norm": 1.7059831619262695,
      "learning_rate": 1.15446672835464e-05,
      "loss": 0.0127,
      "step": 1990
    },
    {
      "epoch": 1.3525815217391304,
      "grad_norm": 7.732605457305908,
      "learning_rate": 1.1537638163116838e-05,
      "loss": 0.3008,
      "step": 1991
    },
    {
      "epoch": 1.3532608695652173,
      "grad_norm": 0.009580043144524097,
      "learning_rate": 1.153060826447918e-05,
      "loss": 0.0001,
      "step": 1992
    },
    {
      "epoch": 1.3539402173913042,
      "grad_norm": 2.6792948246002197,
      "learning_rate": 1.1523577591191292e-05,
      "loss": 0.1161,
      "step": 1993
    },
    {
      "epoch": 1.3546195652173914,
      "grad_norm": 4.779118061065674,
      "learning_rate": 1.1516546146811452e-05,
      "loss": 0.1001,
      "step": 1994
    },
    {
      "epoch": 1.3552989130434783,
      "grad_norm": 2.413613796234131,
      "learning_rate": 1.1509513934898303e-05,
      "loss": 0.0714,
      "step": 1995
    },
    {
      "epoch": 1.3559782608695652,
      "grad_norm": 5.684939384460449,
      "learning_rate": 1.1502480959010902e-05,
      "loss": 0.1057,
      "step": 1996
    },
    {
      "epoch": 1.356657608695652,
      "grad_norm": 16.608253479003906,
      "learning_rate": 1.1495447222708677e-05,
      "loss": 0.4174,
      "step": 1997
    },
    {
      "epoch": 1.3573369565217392,
      "grad_norm": 0.004729577340185642,
      "learning_rate": 1.1488412729551449e-05,
      "loss": 0.0001,
      "step": 1998
    },
    {
      "epoch": 1.3580163043478262,
      "grad_norm": 18.768953323364258,
      "learning_rate": 1.1481377483099407e-05,
      "loss": 0.6987,
      "step": 1999
    },
    {
      "epoch": 1.358695652173913,
      "grad_norm": 0.045744650065898895,
      "learning_rate": 1.1474341486913146e-05,
      "loss": 0.0004,
      "step": 2000
    },
    {
      "epoch": 1.359375,
      "grad_norm": 8.517630577087402,
      "learning_rate": 1.1467304744553618e-05,
      "loss": 0.2486,
      "step": 2001
    },
    {
      "epoch": 1.360054347826087,
      "grad_norm": 0.018564380705356598,
      "learning_rate": 1.1460267259582165e-05,
      "loss": 0.0002,
      "step": 2002
    },
    {
      "epoch": 1.3607336956521738,
      "grad_norm": 0.03132694959640503,
      "learning_rate": 1.14532290355605e-05,
      "loss": 0.0004,
      "step": 2003
    },
    {
      "epoch": 1.3614130434782608,
      "grad_norm": 0.012886225245893002,
      "learning_rate": 1.144619007605071e-05,
      "loss": 0.0001,
      "step": 2004
    },
    {
      "epoch": 1.362092391304348,
      "grad_norm": 3.513162851333618,
      "learning_rate": 1.1439150384615261e-05,
      "loss": 0.2557,
      "step": 2005
    },
    {
      "epoch": 1.3627717391304348,
      "grad_norm": 4.25804328918457,
      "learning_rate": 1.1432109964816978e-05,
      "loss": 0.12,
      "step": 2006
    },
    {
      "epoch": 1.3634510869565217,
      "grad_norm": 0.02052994817495346,
      "learning_rate": 1.1425068820219063e-05,
      "loss": 0.0002,
      "step": 2007
    },
    {
      "epoch": 1.3641304347826086,
      "grad_norm": 1.9474499225616455,
      "learning_rate": 1.1418026954385082e-05,
      "loss": 0.0256,
      "step": 2008
    },
    {
      "epoch": 1.3648097826086958,
      "grad_norm": 4.694637298583984,
      "learning_rate": 1.1410984370878967e-05,
      "loss": 0.1373,
      "step": 2009
    },
    {
      "epoch": 1.3654891304347827,
      "grad_norm": 3.3195948600769043,
      "learning_rate": 1.1403941073265014e-05,
      "loss": 0.1189,
      "step": 2010
    },
    {
      "epoch": 1.3661684782608696,
      "grad_norm": 2.4898886680603027,
      "learning_rate": 1.1396897065107876e-05,
      "loss": 0.0466,
      "step": 2011
    },
    {
      "epoch": 1.3668478260869565,
      "grad_norm": 7.193469524383545,
      "learning_rate": 1.1389852349972568e-05,
      "loss": 0.107,
      "step": 2012
    },
    {
      "epoch": 1.3675271739130435,
      "grad_norm": 0.4494907259941101,
      "learning_rate": 1.1382806931424468e-05,
      "loss": 0.0023,
      "step": 2013
    },
    {
      "epoch": 1.3682065217391304,
      "grad_norm": 5.533039093017578,
      "learning_rate": 1.1375760813029304e-05,
      "loss": 0.2636,
      "step": 2014
    },
    {
      "epoch": 1.3688858695652173,
      "grad_norm": 0.5064757466316223,
      "learning_rate": 1.1368713998353158e-05,
      "loss": 0.002,
      "step": 2015
    },
    {
      "epoch": 1.3695652173913042,
      "grad_norm": 8.341775894165039,
      "learning_rate": 1.1361666490962468e-05,
      "loss": 0.2907,
      "step": 2016
    },
    {
      "epoch": 1.3702445652173914,
      "grad_norm": 0.04044529050588608,
      "learning_rate": 1.1354618294424018e-05,
      "loss": 0.0004,
      "step": 2017
    },
    {
      "epoch": 1.3709239130434783,
      "grad_norm": 0.0631803423166275,
      "learning_rate": 1.1347569412304945e-05,
      "loss": 0.0005,
      "step": 2018
    },
    {
      "epoch": 1.3716032608695652,
      "grad_norm": 2.688544511795044,
      "learning_rate": 1.1340519848172735e-05,
      "loss": 0.0465,
      "step": 2019
    },
    {
      "epoch": 1.372282608695652,
      "grad_norm": 14.578460693359375,
      "learning_rate": 1.133346960559521e-05,
      "loss": 0.4035,
      "step": 2020
    },
    {
      "epoch": 1.3729619565217392,
      "grad_norm": 0.08479128032922745,
      "learning_rate": 1.1326418688140544e-05,
      "loss": 0.0007,
      "step": 2021
    },
    {
      "epoch": 1.3736413043478262,
      "grad_norm": 5.463860988616943,
      "learning_rate": 1.1319367099377248e-05,
      "loss": 0.1711,
      "step": 2022
    },
    {
      "epoch": 1.374320652173913,
      "grad_norm": 6.9892144203186035,
      "learning_rate": 1.1312314842874176e-05,
      "loss": 0.2725,
      "step": 2023
    },
    {
      "epoch": 1.375,
      "grad_norm": 5.066526412963867,
      "learning_rate": 1.130526192220052e-05,
      "loss": 0.2048,
      "step": 2024
    },
    {
      "epoch": 1.375679347826087,
      "grad_norm": 0.23889462649822235,
      "learning_rate": 1.1298208340925798e-05,
      "loss": 0.0016,
      "step": 2025
    },
    {
      "epoch": 1.3763586956521738,
      "grad_norm": 7.162306308746338,
      "learning_rate": 1.1291154102619878e-05,
      "loss": 0.2093,
      "step": 2026
    },
    {
      "epoch": 1.3770380434782608,
      "grad_norm": 6.6917829513549805,
      "learning_rate": 1.1284099210852955e-05,
      "loss": 0.2267,
      "step": 2027
    },
    {
      "epoch": 1.377717391304348,
      "grad_norm": 7.7365241050720215,
      "learning_rate": 1.1277043669195549e-05,
      "loss": 0.0648,
      "step": 2028
    },
    {
      "epoch": 1.3783967391304348,
      "grad_norm": 0.01034559216350317,
      "learning_rate": 1.1269987481218511e-05,
      "loss": 0.0001,
      "step": 2029
    },
    {
      "epoch": 1.3790760869565217,
      "grad_norm": 11.974832534790039,
      "learning_rate": 1.1262930650493025e-05,
      "loss": 0.7721,
      "step": 2030
    },
    {
      "epoch": 1.3797554347826086,
      "grad_norm": 1.8325755596160889,
      "learning_rate": 1.1255873180590595e-05,
      "loss": 0.012,
      "step": 2031
    },
    {
      "epoch": 1.3804347826086958,
      "grad_norm": 0.09875951707363129,
      "learning_rate": 1.1248815075083051e-05,
      "loss": 0.0012,
      "step": 2032
    },
    {
      "epoch": 1.3811141304347827,
      "grad_norm": 1.212649941444397,
      "learning_rate": 1.1241756337542542e-05,
      "loss": 0.0083,
      "step": 2033
    },
    {
      "epoch": 1.3817934782608696,
      "grad_norm": 13.322366714477539,
      "learning_rate": 1.1234696971541534e-05,
      "loss": 0.2437,
      "step": 2034
    },
    {
      "epoch": 1.3824728260869565,
      "grad_norm": 0.0066612656228244305,
      "learning_rate": 1.1227636980652826e-05,
      "loss": 0.0001,
      "step": 2035
    },
    {
      "epoch": 1.3831521739130435,
      "grad_norm": 0.7457560896873474,
      "learning_rate": 1.1220576368449513e-05,
      "loss": 0.0028,
      "step": 2036
    },
    {
      "epoch": 1.3838315217391304,
      "grad_norm": 3.9196598529815674,
      "learning_rate": 1.121351513850502e-05,
      "loss": 0.2511,
      "step": 2037
    },
    {
      "epoch": 1.3845108695652173,
      "grad_norm": 4.256882667541504,
      "learning_rate": 1.1206453294393074e-05,
      "loss": 0.1051,
      "step": 2038
    },
    {
      "epoch": 1.3851902173913042,
      "grad_norm": 6.57553768157959,
      "learning_rate": 1.1199390839687722e-05,
      "loss": 0.2558,
      "step": 2039
    },
    {
      "epoch": 1.3858695652173914,
      "grad_norm": 3.379612922668457,
      "learning_rate": 1.1192327777963313e-05,
      "loss": 0.1479,
      "step": 2040
    },
    {
      "epoch": 1.3865489130434783,
      "grad_norm": 3.7625107765197754,
      "learning_rate": 1.1185264112794505e-05,
      "loss": 0.113,
      "step": 2041
    },
    {
      "epoch": 1.3872282608695652,
      "grad_norm": 7.316278457641602,
      "learning_rate": 1.1178199847756266e-05,
      "loss": 0.3254,
      "step": 2042
    },
    {
      "epoch": 1.387907608695652,
      "grad_norm": 3.761453628540039,
      "learning_rate": 1.1171134986423859e-05,
      "loss": 0.1042,
      "step": 2043
    },
    {
      "epoch": 1.3885869565217392,
      "grad_norm": 0.2539519965648651,
      "learning_rate": 1.116406953237286e-05,
      "loss": 0.0015,
      "step": 2044
    },
    {
      "epoch": 1.3892663043478262,
      "grad_norm": 4.307644367218018,
      "learning_rate": 1.1157003489179132e-05,
      "loss": 0.1246,
      "step": 2045
    },
    {
      "epoch": 1.389945652173913,
      "grad_norm": 3.151712417602539,
      "learning_rate": 1.1149936860418846e-05,
      "loss": 0.1037,
      "step": 2046
    },
    {
      "epoch": 1.390625,
      "grad_norm": 0.008539185859262943,
      "learning_rate": 1.1142869649668467e-05,
      "loss": 0.0001,
      "step": 2047
    },
    {
      "epoch": 1.391304347826087,
      "grad_norm": 5.954404830932617,
      "learning_rate": 1.113580186050475e-05,
      "loss": 0.2317,
      "step": 2048
    },
    {
      "epoch": 1.3919836956521738,
      "grad_norm": 3.709535837173462,
      "learning_rate": 1.1128733496504751e-05,
      "loss": 0.1134,
      "step": 2049
    },
    {
      "epoch": 1.3926630434782608,
      "grad_norm": 13.4635009765625,
      "learning_rate": 1.1121664561245808e-05,
      "loss": 0.1171,
      "step": 2050
    },
    {
      "epoch": 1.393342391304348,
      "grad_norm": 0.07530864328145981,
      "learning_rate": 1.1114595058305555e-05,
      "loss": 0.0004,
      "step": 2051
    },
    {
      "epoch": 1.3940217391304348,
      "grad_norm": 8.551669120788574,
      "learning_rate": 1.1107524991261913e-05,
      "loss": 0.9884,
      "step": 2052
    },
    {
      "epoch": 1.3947010869565217,
      "grad_norm": 6.639787197113037,
      "learning_rate": 1.1100454363693083e-05,
      "loss": 0.229,
      "step": 2053
    },
    {
      "epoch": 1.3953804347826086,
      "grad_norm": 2.864471197128296,
      "learning_rate": 1.1093383179177553e-05,
      "loss": 0.0655,
      "step": 2054
    },
    {
      "epoch": 1.3960597826086958,
      "grad_norm": 2.4963605403900146,
      "learning_rate": 1.108631144129409e-05,
      "loss": 0.1517,
      "step": 2055
    },
    {
      "epoch": 1.3967391304347827,
      "grad_norm": 5.465577125549316,
      "learning_rate": 1.1079239153621753e-05,
      "loss": 0.2445,
      "step": 2056
    },
    {
      "epoch": 1.3974184782608696,
      "grad_norm": 3.1363284587860107,
      "learning_rate": 1.1072166319739861e-05,
      "loss": 0.0645,
      "step": 2057
    },
    {
      "epoch": 1.3980978260869565,
      "grad_norm": 0.0111074885353446,
      "learning_rate": 1.1065092943228024e-05,
      "loss": 0.0002,
      "step": 2058
    },
    {
      "epoch": 1.3987771739130435,
      "grad_norm": 0.06053765118122101,
      "learning_rate": 1.1058019027666119e-05,
      "loss": 0.0004,
      "step": 2059
    },
    {
      "epoch": 1.3994565217391304,
      "grad_norm": 0.19915153086185455,
      "learning_rate": 1.1050944576634298e-05,
      "loss": 0.0019,
      "step": 2060
    },
    {
      "epoch": 1.4001358695652173,
      "grad_norm": 16.262319564819336,
      "learning_rate": 1.1043869593712984e-05,
      "loss": 0.1728,
      "step": 2061
    },
    {
      "epoch": 1.4008152173913042,
      "grad_norm": 12.401257514953613,
      "learning_rate": 1.1036794082482868e-05,
      "loss": 0.3762,
      "step": 2062
    },
    {
      "epoch": 1.4014945652173914,
      "grad_norm": 0.0022652377374470234,
      "learning_rate": 1.1029718046524916e-05,
      "loss": 0.0001,
      "step": 2063
    },
    {
      "epoch": 1.4021739130434783,
      "grad_norm": 14.061663627624512,
      "learning_rate": 1.1022641489420342e-05,
      "loss": 0.4101,
      "step": 2064
    },
    {
      "epoch": 1.4028532608695652,
      "grad_norm": 0.02915647253394127,
      "learning_rate": 1.1015564414750646e-05,
      "loss": 0.0004,
      "step": 2065
    },
    {
      "epoch": 1.403532608695652,
      "grad_norm": 2.458639621734619,
      "learning_rate": 1.1008486826097572e-05,
      "loss": 0.0214,
      "step": 2066
    },
    {
      "epoch": 1.4042119565217392,
      "grad_norm": 3.5635762214660645,
      "learning_rate": 1.1001408727043135e-05,
      "loss": 0.0596,
      "step": 2067
    },
    {
      "epoch": 1.4048913043478262,
      "grad_norm": 1.1263521909713745,
      "learning_rate": 1.0994330121169602e-05,
      "loss": 0.0086,
      "step": 2068
    },
    {
      "epoch": 1.405570652173913,
      "grad_norm": 0.05268017202615738,
      "learning_rate": 1.0987251012059501e-05,
      "loss": 0.0003,
      "step": 2069
    },
    {
      "epoch": 1.40625,
      "grad_norm": 0.003549338551238179,
      "learning_rate": 1.098017140329561e-05,
      "loss": 0.0001,
      "step": 2070
    },
    {
      "epoch": 1.406929347826087,
      "grad_norm": 6.270216464996338,
      "learning_rate": 1.0973091298460958e-05,
      "loss": 0.1342,
      "step": 2071
    },
    {
      "epoch": 1.4076086956521738,
      "grad_norm": 1.4348104000091553,
      "learning_rate": 1.0966010701138841e-05,
      "loss": 0.0415,
      "step": 2072
    },
    {
      "epoch": 1.4082880434782608,
      "grad_norm": 2.4525623321533203,
      "learning_rate": 1.0958929614912782e-05,
      "loss": 0.1062,
      "step": 2073
    },
    {
      "epoch": 1.408967391304348,
      "grad_norm": 3.2356643676757812,
      "learning_rate": 1.0951848043366571e-05,
      "loss": 0.1507,
      "step": 2074
    },
    {
      "epoch": 1.4096467391304348,
      "grad_norm": 1.1139681339263916,
      "learning_rate": 1.094476599008423e-05,
      "loss": 0.011,
      "step": 2075
    },
    {
      "epoch": 1.4103260869565217,
      "grad_norm": 4.585526943206787,
      "learning_rate": 1.0937683458650029e-05,
      "loss": 0.1119,
      "step": 2076
    },
    {
      "epoch": 1.4110054347826086,
      "grad_norm": 12.110434532165527,
      "learning_rate": 1.0930600452648476e-05,
      "loss": 0.1767,
      "step": 2077
    },
    {
      "epoch": 1.4116847826086958,
      "grad_norm": 0.10523346066474915,
      "learning_rate": 1.0923516975664336e-05,
      "loss": 0.0007,
      "step": 2078
    },
    {
      "epoch": 1.4123641304347827,
      "grad_norm": 0.861425518989563,
      "learning_rate": 1.0916433031282592e-05,
      "loss": 0.0246,
      "step": 2079
    },
    {
      "epoch": 1.4130434782608696,
      "grad_norm": 0.03464595600962639,
      "learning_rate": 1.0909348623088472e-05,
      "loss": 0.0003,
      "step": 2080
    },
    {
      "epoch": 1.4137228260869565,
      "grad_norm": 0.004238128662109375,
      "learning_rate": 1.0902263754667438e-05,
      "loss": 0.0001,
      "step": 2081
    },
    {
      "epoch": 1.4144021739130435,
      "grad_norm": 0.13924434781074524,
      "learning_rate": 1.0895178429605189e-05,
      "loss": 0.0007,
      "step": 2082
    },
    {
      "epoch": 1.4150815217391304,
      "grad_norm": 2.4249439239501953,
      "learning_rate": 1.088809265148765e-05,
      "loss": 0.0389,
      "step": 2083
    },
    {
      "epoch": 1.4157608695652173,
      "grad_norm": 0.004701605066657066,
      "learning_rate": 1.0881006423900975e-05,
      "loss": 0.0001,
      "step": 2084
    },
    {
      "epoch": 1.4164402173913042,
      "grad_norm": 0.003736754646524787,
      "learning_rate": 1.0873919750431548e-05,
      "loss": 0.0001,
      "step": 2085
    },
    {
      "epoch": 1.4171195652173914,
      "grad_norm": 0.00673974584788084,
      "learning_rate": 1.0866832634665977e-05,
      "loss": 0.0001,
      "step": 2086
    },
    {
      "epoch": 1.4177989130434783,
      "grad_norm": 0.1038813665509224,
      "learning_rate": 1.0859745080191098e-05,
      "loss": 0.0007,
      "step": 2087
    },
    {
      "epoch": 1.4184782608695652,
      "grad_norm": 0.0060816677287220955,
      "learning_rate": 1.0852657090593961e-05,
      "loss": 0.0001,
      "step": 2088
    },
    {
      "epoch": 1.419157608695652,
      "grad_norm": 6.20821475982666,
      "learning_rate": 1.0845568669461845e-05,
      "loss": 0.1331,
      "step": 2089
    },
    {
      "epoch": 1.4198369565217392,
      "grad_norm": 4.029661655426025,
      "learning_rate": 1.0838479820382242e-05,
      "loss": 0.0779,
      "step": 2090
    },
    {
      "epoch": 1.4205163043478262,
      "grad_norm": 0.20745687186717987,
      "learning_rate": 1.083139054694286e-05,
      "loss": 0.0011,
      "step": 2091
    },
    {
      "epoch": 1.421195652173913,
      "grad_norm": 0.002627696143463254,
      "learning_rate": 1.0824300852731631e-05,
      "loss": 0.0001,
      "step": 2092
    },
    {
      "epoch": 1.421875,
      "grad_norm": 0.0038600272964686155,
      "learning_rate": 1.0817210741336684e-05,
      "loss": 0.0001,
      "step": 2093
    },
    {
      "epoch": 1.422554347826087,
      "grad_norm": 0.00873279757797718,
      "learning_rate": 1.0810120216346368e-05,
      "loss": 0.0002,
      "step": 2094
    },
    {
      "epoch": 1.4232336956521738,
      "grad_norm": 4.073683738708496,
      "learning_rate": 1.0803029281349248e-05,
      "loss": 0.1424,
      "step": 2095
    },
    {
      "epoch": 1.4239130434782608,
      "grad_norm": 0.1665305346250534,
      "learning_rate": 1.0795937939934088e-05,
      "loss": 0.0016,
      "step": 2096
    },
    {
      "epoch": 1.424592391304348,
      "grad_norm": 15.038280487060547,
      "learning_rate": 1.0788846195689856e-05,
      "loss": 0.403,
      "step": 2097
    },
    {
      "epoch": 1.4252717391304348,
      "grad_norm": 4.628468990325928,
      "learning_rate": 1.0781754052205729e-05,
      "loss": 0.2124,
      "step": 2098
    },
    {
      "epoch": 1.4259510869565217,
      "grad_norm": 2.160653591156006,
      "learning_rate": 1.0774661513071084e-05,
      "loss": 0.0723,
      "step": 2099
    },
    {
      "epoch": 1.4266304347826086,
      "grad_norm": 13.239887237548828,
      "learning_rate": 1.0767568581875494e-05,
      "loss": 0.1622,
      "step": 2100
    },
    {
      "epoch": 1.4273097826086958,
      "grad_norm": 0.08977167308330536,
      "learning_rate": 1.0760475262208742e-05,
      "loss": 0.0006,
      "step": 2101
    },
    {
      "epoch": 1.4279891304347827,
      "grad_norm": 15.927724838256836,
      "learning_rate": 1.0753381557660801e-05,
      "loss": 0.5201,
      "step": 2102
    },
    {
      "epoch": 1.4286684782608696,
      "grad_norm": 2.515693426132202,
      "learning_rate": 1.0746287471821833e-05,
      "loss": 0.059,
      "step": 2103
    },
    {
      "epoch": 1.4293478260869565,
      "grad_norm": 0.07345636188983917,
      "learning_rate": 1.0739193008282203e-05,
      "loss": 0.0008,
      "step": 2104
    },
    {
      "epoch": 1.4300271739130435,
      "grad_norm": 5.7835469245910645,
      "learning_rate": 1.0732098170632458e-05,
      "loss": 0.206,
      "step": 2105
    },
    {
      "epoch": 1.4307065217391304,
      "grad_norm": 0.020962856709957123,
      "learning_rate": 1.072500296246334e-05,
      "loss": 0.0003,
      "step": 2106
    },
    {
      "epoch": 1.4313858695652173,
      "grad_norm": 3.987239122390747,
      "learning_rate": 1.0717907387365779e-05,
      "loss": 0.022,
      "step": 2107
    },
    {
      "epoch": 1.4320652173913042,
      "grad_norm": 5.213222026824951,
      "learning_rate": 1.0710811448930888e-05,
      "loss": 0.0288,
      "step": 2108
    },
    {
      "epoch": 1.4327445652173914,
      "grad_norm": 8.531034469604492,
      "learning_rate": 1.0703715150749967e-05,
      "loss": 0.1518,
      "step": 2109
    },
    {
      "epoch": 1.4334239130434783,
      "grad_norm": 0.005745685193687677,
      "learning_rate": 1.0696618496414495e-05,
      "loss": 0.0001,
      "step": 2110
    },
    {
      "epoch": 1.4341032608695652,
      "grad_norm": 2.352047920227051,
      "learning_rate": 1.0689521489516128e-05,
      "loss": 0.0582,
      "step": 2111
    },
    {
      "epoch": 1.434782608695652,
      "grad_norm": 2.449075937271118,
      "learning_rate": 1.0682424133646712e-05,
      "loss": 0.0245,
      "step": 2112
    },
    {
      "epoch": 1.4354619565217392,
      "grad_norm": 4.2301106452941895,
      "learning_rate": 1.0675326432398257e-05,
      "loss": 0.045,
      "step": 2113
    },
    {
      "epoch": 1.4361413043478262,
      "grad_norm": 6.26568078994751,
      "learning_rate": 1.0668228389362955e-05,
      "loss": 0.1248,
      "step": 2114
    },
    {
      "epoch": 1.436820652173913,
      "grad_norm": 6.560178279876709,
      "learning_rate": 1.0661130008133169e-05,
      "loss": 0.148,
      "step": 2115
    },
    {
      "epoch": 1.4375,
      "grad_norm": 4.483260631561279,
      "learning_rate": 1.0654031292301432e-05,
      "loss": 0.0351,
      "step": 2116
    },
    {
      "epoch": 1.438179347826087,
      "grad_norm": 0.04187982156872749,
      "learning_rate": 1.0646932245460448e-05,
      "loss": 0.0003,
      "step": 2117
    },
    {
      "epoch": 1.4388586956521738,
      "grad_norm": 3.7994678020477295,
      "learning_rate": 1.0639832871203094e-05,
      "loss": 0.1475,
      "step": 2118
    },
    {
      "epoch": 1.4395380434782608,
      "grad_norm": 0.005871691275388002,
      "learning_rate": 1.0632733173122395e-05,
      "loss": 0.0001,
      "step": 2119
    },
    {
      "epoch": 1.440217391304348,
      "grad_norm": 5.268579006195068,
      "learning_rate": 1.062563315481156e-05,
      "loss": 0.2214,
      "step": 2120
    },
    {
      "epoch": 1.4408967391304348,
      "grad_norm": 8.651220321655273,
      "learning_rate": 1.0618532819863953e-05,
      "loss": 0.2749,
      "step": 2121
    },
    {
      "epoch": 1.4415760869565217,
      "grad_norm": 19.43470573425293,
      "learning_rate": 1.0611432171873092e-05,
      "loss": 0.0874,
      "step": 2122
    },
    {
      "epoch": 1.4422554347826086,
      "grad_norm": 3.5534582138061523,
      "learning_rate": 1.0604331214432663e-05,
      "loss": 0.2208,
      "step": 2123
    },
    {
      "epoch": 1.4429347826086958,
      "grad_norm": 6.71231746673584,
      "learning_rate": 1.0597229951136498e-05,
      "loss": 0.1676,
      "step": 2124
    },
    {
      "epoch": 1.4436141304347827,
      "grad_norm": 3.420278549194336,
      "learning_rate": 1.0590128385578597e-05,
      "loss": 0.0106,
      "step": 2125
    },
    {
      "epoch": 1.4442934782608696,
      "grad_norm": 12.284109115600586,
      "learning_rate": 1.0583026521353102e-05,
      "loss": 0.4388,
      "step": 2126
    },
    {
      "epoch": 1.4449728260869565,
      "grad_norm": 6.835472583770752,
      "learning_rate": 1.057592436205431e-05,
      "loss": 0.0964,
      "step": 2127
    },
    {
      "epoch": 1.4456521739130435,
      "grad_norm": 3.246255397796631,
      "learning_rate": 1.056882191127667e-05,
      "loss": 0.113,
      "step": 2128
    },
    {
      "epoch": 1.4463315217391304,
      "grad_norm": 5.3970136642456055,
      "learning_rate": 1.0561719172614769e-05,
      "loss": 0.2601,
      "step": 2129
    },
    {
      "epoch": 1.4470108695652173,
      "grad_norm": 4.37814474105835,
      "learning_rate": 1.0554616149663355e-05,
      "loss": 0.1144,
      "step": 2130
    },
    {
      "epoch": 1.4476902173913042,
      "grad_norm": 11.801986694335938,
      "learning_rate": 1.0547512846017307e-05,
      "loss": 0.2107,
      "step": 2131
    },
    {
      "epoch": 1.4483695652173914,
      "grad_norm": 2.456998825073242,
      "learning_rate": 1.0540409265271652e-05,
      "loss": 0.0786,
      "step": 2132
    },
    {
      "epoch": 1.4490489130434783,
      "grad_norm": 0.01427109818905592,
      "learning_rate": 1.0533305411021555e-05,
      "loss": 0.0002,
      "step": 2133
    },
    {
      "epoch": 1.4497282608695652,
      "grad_norm": 4.353374004364014,
      "learning_rate": 1.052620128686232e-05,
      "loss": 0.1083,
      "step": 2134
    },
    {
      "epoch": 1.450407608695652,
      "grad_norm": 6.354180335998535,
      "learning_rate": 1.0519096896389387e-05,
      "loss": 0.1609,
      "step": 2135
    },
    {
      "epoch": 1.4510869565217392,
      "grad_norm": 0.005884840618818998,
      "learning_rate": 1.0511992243198335e-05,
      "loss": 0.0001,
      "step": 2136
    },
    {
      "epoch": 1.4517663043478262,
      "grad_norm": 0.003961862064898014,
      "learning_rate": 1.0504887330884865e-05,
      "loss": 0.0001,
      "step": 2137
    },
    {
      "epoch": 1.452445652173913,
      "grad_norm": 1.9080828428268433,
      "learning_rate": 1.0497782163044825e-05,
      "loss": 0.0975,
      "step": 2138
    },
    {
      "epoch": 1.453125,
      "grad_norm": 5.835447788238525,
      "learning_rate": 1.0490676743274181e-05,
      "loss": 0.2102,
      "step": 2139
    },
    {
      "epoch": 1.453804347826087,
      "grad_norm": 3.9091293811798096,
      "learning_rate": 1.048357107516903e-05,
      "loss": 0.1389,
      "step": 2140
    },
    {
      "epoch": 1.4544836956521738,
      "grad_norm": 1.0191420316696167,
      "learning_rate": 1.0476465162325595e-05,
      "loss": 0.0075,
      "step": 2141
    },
    {
      "epoch": 1.4551630434782608,
      "grad_norm": 0.021375050768256187,
      "learning_rate": 1.0469359008340216e-05,
      "loss": 0.0003,
      "step": 2142
    },
    {
      "epoch": 1.455842391304348,
      "grad_norm": 0.008776566945016384,
      "learning_rate": 1.0462252616809367e-05,
      "loss": 0.0001,
      "step": 2143
    },
    {
      "epoch": 1.4565217391304348,
      "grad_norm": 0.033183060586452484,
      "learning_rate": 1.0455145991329639e-05,
      "loss": 0.0005,
      "step": 2144
    },
    {
      "epoch": 1.4572010869565217,
      "grad_norm": 1.5674033164978027,
      "learning_rate": 1.0448039135497732e-05,
      "loss": 0.0098,
      "step": 2145
    },
    {
      "epoch": 1.4578804347826086,
      "grad_norm": 0.021408192813396454,
      "learning_rate": 1.0440932052910468e-05,
      "loss": 0.0002,
      "step": 2146
    },
    {
      "epoch": 1.4585597826086958,
      "grad_norm": 1.9575272798538208,
      "learning_rate": 1.0433824747164794e-05,
      "loss": 0.0203,
      "step": 2147
    },
    {
      "epoch": 1.4592391304347827,
      "grad_norm": 2.690918207168579,
      "learning_rate": 1.0426717221857756e-05,
      "loss": 0.0181,
      "step": 2148
    },
    {
      "epoch": 1.4599184782608696,
      "grad_norm": 4.995519161224365,
      "learning_rate": 1.0419609480586515e-05,
      "loss": 0.275,
      "step": 2149
    },
    {
      "epoch": 1.4605978260869565,
      "grad_norm": 4.23380708694458,
      "learning_rate": 1.0412501526948343e-05,
      "loss": 0.1359,
      "step": 2150
    },
    {
      "epoch": 1.4612771739130435,
      "grad_norm": 0.008335241116583347,
      "learning_rate": 1.0405393364540618e-05,
      "loss": 0.0002,
      "step": 2151
    },
    {
      "epoch": 1.4619565217391304,
      "grad_norm": 6.241193771362305,
      "learning_rate": 1.039828499696083e-05,
      "loss": 0.1057,
      "step": 2152
    },
    {
      "epoch": 1.4626358695652173,
      "grad_norm": 1.4841636419296265,
      "learning_rate": 1.0391176427806564e-05,
      "loss": 0.0088,
      "step": 2153
    },
    {
      "epoch": 1.4633152173913042,
      "grad_norm": 3.517411231994629,
      "learning_rate": 1.0384067660675508e-05,
      "loss": 0.1624,
      "step": 2154
    },
    {
      "epoch": 1.4639945652173914,
      "grad_norm": 3.0831384658813477,
      "learning_rate": 1.0376958699165451e-05,
      "loss": 0.0702,
      "step": 2155
    },
    {
      "epoch": 1.4646739130434783,
      "grad_norm": 0.14546950161457062,
      "learning_rate": 1.036984954687429e-05,
      "loss": 0.001,
      "step": 2156
    },
    {
      "epoch": 1.4653532608695652,
      "grad_norm": 1.2096527814865112,
      "learning_rate": 1.0362740207400006e-05,
      "loss": 0.0123,
      "step": 2157
    },
    {
      "epoch": 1.466032608695652,
      "grad_norm": 0.13446709513664246,
      "learning_rate": 1.0355630684340678e-05,
      "loss": 0.0013,
      "step": 2158
    },
    {
      "epoch": 1.4667119565217392,
      "grad_norm": 10.589296340942383,
      "learning_rate": 1.034852098129448e-05,
      "loss": 0.0917,
      "step": 2159
    },
    {
      "epoch": 1.4673913043478262,
      "grad_norm": 5.313881874084473,
      "learning_rate": 1.034141110185968e-05,
      "loss": 0.2585,
      "step": 2160
    },
    {
      "epoch": 1.468070652173913,
      "grad_norm": 0.010315196588635445,
      "learning_rate": 1.0334301049634624e-05,
      "loss": 0.0001,
      "step": 2161
    },
    {
      "epoch": 1.46875,
      "grad_norm": 0.0020088700111955404,
      "learning_rate": 1.0327190828217763e-05,
      "loss": 0.0001,
      "step": 2162
    },
    {
      "epoch": 1.469429347826087,
      "grad_norm": 8.293930053710938,
      "learning_rate": 1.0320080441207616e-05,
      "loss": 0.0706,
      "step": 2163
    },
    {
      "epoch": 1.4701086956521738,
      "grad_norm": 0.08955423533916473,
      "learning_rate": 1.0312969892202793e-05,
      "loss": 0.0012,
      "step": 2164
    },
    {
      "epoch": 1.4707880434782608,
      "grad_norm": 0.005265784449875355,
      "learning_rate": 1.0305859184801991e-05,
      "loss": 0.0001,
      "step": 2165
    },
    {
      "epoch": 1.471467391304348,
      "grad_norm": 6.482354640960693,
      "learning_rate": 1.0298748322603982e-05,
      "loss": 0.2604,
      "step": 2166
    },
    {
      "epoch": 1.4721467391304348,
      "grad_norm": 0.04320283979177475,
      "learning_rate": 1.0291637309207613e-05,
      "loss": 0.0005,
      "step": 2167
    },
    {
      "epoch": 1.4728260869565217,
      "grad_norm": 7.542062282562256,
      "learning_rate": 1.0284526148211815e-05,
      "loss": 0.128,
      "step": 2168
    },
    {
      "epoch": 1.4735054347826086,
      "grad_norm": 5.100317001342773,
      "learning_rate": 1.027741484321559e-05,
      "loss": 0.2079,
      "step": 2169
    },
    {
      "epoch": 1.4741847826086958,
      "grad_norm": 3.6142477989196777,
      "learning_rate": 1.0270303397818011e-05,
      "loss": 0.0785,
      "step": 2170
    },
    {
      "epoch": 1.4748641304347827,
      "grad_norm": 0.0047898124903440475,
      "learning_rate": 1.0263191815618227e-05,
      "loss": 0.0001,
      "step": 2171
    },
    {
      "epoch": 1.4755434782608696,
      "grad_norm": 0.010678267106413841,
      "learning_rate": 1.0256080100215448e-05,
      "loss": 0.0001,
      "step": 2172
    },
    {
      "epoch": 1.4762228260869565,
      "grad_norm": 3.5178463459014893,
      "learning_rate": 1.0248968255208964e-05,
      "loss": 0.0584,
      "step": 2173
    },
    {
      "epoch": 1.4769021739130435,
      "grad_norm": 0.008327462710440159,
      "learning_rate": 1.024185628419812e-05,
      "loss": 0.0001,
      "step": 2174
    },
    {
      "epoch": 1.4775815217391304,
      "grad_norm": 0.01616562530398369,
      "learning_rate": 1.0234744190782326e-05,
      "loss": 0.0002,
      "step": 2175
    },
    {
      "epoch": 1.4782608695652173,
      "grad_norm": 0.007200869731605053,
      "learning_rate": 1.0227631978561057e-05,
      "loss": 0.0002,
      "step": 2176
    },
    {
      "epoch": 1.4789402173913042,
      "grad_norm": 1.9634748697280884,
      "learning_rate": 1.022051965113385e-05,
      "loss": 0.0556,
      "step": 2177
    },
    {
      "epoch": 1.4796195652173914,
      "grad_norm": 0.052887704223394394,
      "learning_rate": 1.0213407212100296e-05,
      "loss": 0.0005,
      "step": 2178
    },
    {
      "epoch": 1.4802989130434783,
      "grad_norm": 21.482133865356445,
      "learning_rate": 1.0206294665060046e-05,
      "loss": 0.527,
      "step": 2179
    },
    {
      "epoch": 1.4809782608695652,
      "grad_norm": 0.007965666241943836,
      "learning_rate": 1.0199182013612797e-05,
      "loss": 0.0001,
      "step": 2180
    },
    {
      "epoch": 1.481657608695652,
      "grad_norm": 0.45650193095207214,
      "learning_rate": 1.0192069261358313e-05,
      "loss": 0.0037,
      "step": 2181
    },
    {
      "epoch": 1.4823369565217392,
      "grad_norm": 12.75452995300293,
      "learning_rate": 1.0184956411896396e-05,
      "loss": 0.3658,
      "step": 2182
    },
    {
      "epoch": 1.4830163043478262,
      "grad_norm": 3.814375638961792,
      "learning_rate": 1.0177843468826909e-05,
      "loss": 0.0898,
      "step": 2183
    },
    {
      "epoch": 1.483695652173913,
      "grad_norm": 4.43428373336792,
      "learning_rate": 1.017073043574975e-05,
      "loss": 0.1689,
      "step": 2184
    },
    {
      "epoch": 1.484375,
      "grad_norm": 9.201244354248047,
      "learning_rate": 1.0163617316264869e-05,
      "loss": 0.2154,
      "step": 2185
    },
    {
      "epoch": 1.485054347826087,
      "grad_norm": 3.3892359733581543,
      "learning_rate": 1.0156504113972263e-05,
      "loss": 0.0313,
      "step": 2186
    },
    {
      "epoch": 1.4857336956521738,
      "grad_norm": 4.8921895027160645,
      "learning_rate": 1.0149390832471965e-05,
      "loss": 0.0913,
      "step": 2187
    },
    {
      "epoch": 1.4864130434782608,
      "grad_norm": 4.889744758605957,
      "learning_rate": 1.0142277475364053e-05,
      "loss": 0.2285,
      "step": 2188
    },
    {
      "epoch": 1.487092391304348,
      "grad_norm": 0.004792809020727873,
      "learning_rate": 1.0135164046248633e-05,
      "loss": 0.0001,
      "step": 2189
    },
    {
      "epoch": 1.4877717391304348,
      "grad_norm": 3.998953104019165,
      "learning_rate": 1.0128050548725865e-05,
      "loss": 0.1009,
      "step": 2190
    },
    {
      "epoch": 1.4884510869565217,
      "grad_norm": 0.9770722389221191,
      "learning_rate": 1.012093698639593e-05,
      "loss": 0.0125,
      "step": 2191
    },
    {
      "epoch": 1.4891304347826086,
      "grad_norm": 3.238006591796875,
      "learning_rate": 1.0113823362859042e-05,
      "loss": 0.0591,
      "step": 2192
    },
    {
      "epoch": 1.4898097826086958,
      "grad_norm": 12.800353050231934,
      "learning_rate": 1.0106709681715456e-05,
      "loss": 0.4247,
      "step": 2193
    },
    {
      "epoch": 1.4904891304347827,
      "grad_norm": 0.006786454003304243,
      "learning_rate": 1.0099595946565446e-05,
      "loss": 0.0001,
      "step": 2194
    },
    {
      "epoch": 1.4911684782608696,
      "grad_norm": 2.5745222568511963,
      "learning_rate": 1.0092482161009314e-05,
      "loss": 0.0322,
      "step": 2195
    },
    {
      "epoch": 1.4918478260869565,
      "grad_norm": 23.19304847717285,
      "learning_rate": 1.0085368328647395e-05,
      "loss": 0.5682,
      "step": 2196
    },
    {
      "epoch": 1.4925271739130435,
      "grad_norm": 0.06251955777406693,
      "learning_rate": 1.0078254453080042e-05,
      "loss": 0.0005,
      "step": 2197
    },
    {
      "epoch": 1.4932065217391304,
      "grad_norm": 0.009239320643246174,
      "learning_rate": 1.0071140537907626e-05,
      "loss": 0.0002,
      "step": 2198
    },
    {
      "epoch": 1.4938858695652173,
      "grad_norm": 0.2054019421339035,
      "learning_rate": 1.0064026586730553e-05,
      "loss": 0.0016,
      "step": 2199
    },
    {
      "epoch": 1.4945652173913042,
      "grad_norm": 7.1111979484558105,
      "learning_rate": 1.0056912603149229e-05,
      "loss": 0.1159,
      "step": 2200
    },
    {
      "epoch": 1.4952445652173914,
      "grad_norm": 5.811014175415039,
      "learning_rate": 1.004979859076409e-05,
      "loss": 0.1692,
      "step": 2201
    },
    {
      "epoch": 1.4959239130434783,
      "grad_norm": 4.771520137786865,
      "learning_rate": 1.0042684553175575e-05,
      "loss": 0.1947,
      "step": 2202
    },
    {
      "epoch": 1.4966032608695652,
      "grad_norm": 2.6211984157562256,
      "learning_rate": 1.003557049398415e-05,
      "loss": 0.0387,
      "step": 2203
    },
    {
      "epoch": 1.497282608695652,
      "grad_norm": 5.572290897369385,
      "learning_rate": 1.0028456416790278e-05,
      "loss": 0.2262,
      "step": 2204
    },
    {
      "epoch": 1.4979619565217392,
      "grad_norm": 1.9198912382125854,
      "learning_rate": 1.0021342325194441e-05,
      "loss": 0.0404,
      "step": 2205
    },
    {
      "epoch": 1.4986413043478262,
      "grad_norm": 11.978669166564941,
      "learning_rate": 1.0014228222797117e-05,
      "loss": 0.4807,
      "step": 2206
    },
    {
      "epoch": 1.499320652173913,
      "grad_norm": 3.904503583908081,
      "learning_rate": 1.0007114113198809e-05,
      "loss": 0.0412,
      "step": 2207
    },
    {
      "epoch": 1.5,
      "grad_norm": 7.586369037628174,
      "learning_rate": 1e-05,
      "loss": 0.246,
      "step": 2208
    },
    {
      "epoch": 1.500679347826087,
      "grad_norm": 0.008423859253525734,
      "learning_rate": 9.992885886801194e-06,
      "loss": 0.0001,
      "step": 2209
    },
    {
      "epoch": 1.5013586956521738,
      "grad_norm": 0.012203779071569443,
      "learning_rate": 9.985771777202884e-06,
      "loss": 0.0001,
      "step": 2210
    },
    {
      "epoch": 1.5020380434782608,
      "grad_norm": 0.1770390272140503,
      "learning_rate": 9.978657674805564e-06,
      "loss": 0.0017,
      "step": 2211
    },
    {
      "epoch": 1.5027173913043477,
      "grad_norm": 6.475362777709961,
      "learning_rate": 9.971543583209727e-06,
      "loss": 0.1629,
      "step": 2212
    },
    {
      "epoch": 1.5033967391304348,
      "grad_norm": 1.2574033737182617,
      "learning_rate": 9.964429506015851e-06,
      "loss": 0.0068,
      "step": 2213
    },
    {
      "epoch": 1.5040760869565217,
      "grad_norm": 3.248176097869873,
      "learning_rate": 9.957315446824425e-06,
      "loss": 0.0636,
      "step": 2214
    },
    {
      "epoch": 1.5047554347826086,
      "grad_norm": 8.331107139587402,
      "learning_rate": 9.950201409235913e-06,
      "loss": 0.104,
      "step": 2215
    },
    {
      "epoch": 1.5054347826086958,
      "grad_norm": 9.568364143371582,
      "learning_rate": 9.943087396850773e-06,
      "loss": 0.7059,
      "step": 2216
    },
    {
      "epoch": 1.5061141304347827,
      "grad_norm": 4.656234264373779,
      "learning_rate": 9.93597341326945e-06,
      "loss": 0.1694,
      "step": 2217
    },
    {
      "epoch": 1.5067934782608696,
      "grad_norm": 0.6075297594070435,
      "learning_rate": 9.928859462092375e-06,
      "loss": 0.0047,
      "step": 2218
    },
    {
      "epoch": 1.5074728260869565,
      "grad_norm": 2.7031939029693604,
      "learning_rate": 9.921745546919963e-06,
      "loss": 0.0997,
      "step": 2219
    },
    {
      "epoch": 1.5081521739130435,
      "grad_norm": 4.2550530433654785,
      "learning_rate": 9.91463167135261e-06,
      "loss": 0.1466,
      "step": 2220
    },
    {
      "epoch": 1.5088315217391304,
      "grad_norm": 8.137892723083496,
      "learning_rate": 9.907517838990689e-06,
      "loss": 0.7956,
      "step": 2221
    },
    {
      "epoch": 1.5095108695652173,
      "grad_norm": 0.003267318243160844,
      "learning_rate": 9.900404053434559e-06,
      "loss": 0.0001,
      "step": 2222
    },
    {
      "epoch": 1.5101902173913042,
      "grad_norm": 5.494597434997559,
      "learning_rate": 9.893290318284546e-06,
      "loss": 0.1999,
      "step": 2223
    },
    {
      "epoch": 1.5108695652173914,
      "grad_norm": 7.5369343757629395,
      "learning_rate": 9.886176637140959e-06,
      "loss": 0.1508,
      "step": 2224
    },
    {
      "epoch": 1.5115489130434783,
      "grad_norm": 5.594879150390625,
      "learning_rate": 9.879063013604073e-06,
      "loss": 0.1115,
      "step": 2225
    },
    {
      "epoch": 1.5122282608695652,
      "grad_norm": 4.141956806182861,
      "learning_rate": 9.871949451274137e-06,
      "loss": 0.1892,
      "step": 2226
    },
    {
      "epoch": 1.5129076086956523,
      "grad_norm": 3.6561689376831055,
      "learning_rate": 9.86483595375137e-06,
      "loss": 0.1394,
      "step": 2227
    },
    {
      "epoch": 1.5135869565217392,
      "grad_norm": 2.146336078643799,
      "learning_rate": 9.857722524635954e-06,
      "loss": 0.0223,
      "step": 2228
    },
    {
      "epoch": 1.5142663043478262,
      "grad_norm": 17.902376174926758,
      "learning_rate": 9.850609167528038e-06,
      "loss": 0.2668,
      "step": 2229
    },
    {
      "epoch": 1.514945652173913,
      "grad_norm": 3.3559114933013916,
      "learning_rate": 9.843495886027738e-06,
      "loss": 0.1121,
      "step": 2230
    },
    {
      "epoch": 1.515625,
      "grad_norm": 2.844583749771118,
      "learning_rate": 9.836382683735133e-06,
      "loss": 0.127,
      "step": 2231
    },
    {
      "epoch": 1.516304347826087,
      "grad_norm": 0.287515789270401,
      "learning_rate": 9.829269564250254e-06,
      "loss": 0.0028,
      "step": 2232
    },
    {
      "epoch": 1.5169836956521738,
      "grad_norm": 2.6991658210754395,
      "learning_rate": 9.822156531173094e-06,
      "loss": 0.0231,
      "step": 2233
    },
    {
      "epoch": 1.5176630434782608,
      "grad_norm": 0.01198993157595396,
      "learning_rate": 9.815043588103606e-06,
      "loss": 0.0001,
      "step": 2234
    },
    {
      "epoch": 1.5183423913043477,
      "grad_norm": 2.6702632904052734,
      "learning_rate": 9.807930738641692e-06,
      "loss": 0.1791,
      "step": 2235
    },
    {
      "epoch": 1.5190217391304348,
      "grad_norm": 8.60867977142334,
      "learning_rate": 9.800817986387207e-06,
      "loss": 0.9408,
      "step": 2236
    },
    {
      "epoch": 1.5197010869565217,
      "grad_norm": 3.7756943702697754,
      "learning_rate": 9.79370533493996e-06,
      "loss": 0.1468,
      "step": 2237
    },
    {
      "epoch": 1.5203804347826086,
      "grad_norm": 3.7059805393218994,
      "learning_rate": 9.786592787899707e-06,
      "loss": 0.1478,
      "step": 2238
    },
    {
      "epoch": 1.5210597826086958,
      "grad_norm": 4.380974292755127,
      "learning_rate": 9.77948034886615e-06,
      "loss": 0.1704,
      "step": 2239
    },
    {
      "epoch": 1.5217391304347827,
      "grad_norm": 2.3519699573516846,
      "learning_rate": 9.772368021438943e-06,
      "loss": 0.0238,
      "step": 2240
    },
    {
      "epoch": 1.5224184782608696,
      "grad_norm": 0.006207972299307585,
      "learning_rate": 9.765255809217676e-06,
      "loss": 0.0001,
      "step": 2241
    },
    {
      "epoch": 1.5230978260869565,
      "grad_norm": 0.07907664775848389,
      "learning_rate": 9.758143715801884e-06,
      "loss": 0.0007,
      "step": 2242
    },
    {
      "epoch": 1.5237771739130435,
      "grad_norm": 0.07724542170763016,
      "learning_rate": 9.75103174479104e-06,
      "loss": 0.0006,
      "step": 2243
    },
    {
      "epoch": 1.5244565217391304,
      "grad_norm": 3.0602993965148926,
      "learning_rate": 9.743919899784555e-06,
      "loss": 0.0977,
      "step": 2244
    },
    {
      "epoch": 1.5251358695652173,
      "grad_norm": 8.763042449951172,
      "learning_rate": 9.736808184381778e-06,
      "loss": 0.2484,
      "step": 2245
    },
    {
      "epoch": 1.5258152173913042,
      "grad_norm": 0.003987515345215797,
      "learning_rate": 9.729696602181994e-06,
      "loss": 0.0001,
      "step": 2246
    },
    {
      "epoch": 1.5264945652173914,
      "grad_norm": 0.007664697244763374,
      "learning_rate": 9.72258515678441e-06,
      "loss": 0.0001,
      "step": 2247
    },
    {
      "epoch": 1.5271739130434783,
      "grad_norm": 0.0043327054008841515,
      "learning_rate": 9.715473851788187e-06,
      "loss": 0.0001,
      "step": 2248
    },
    {
      "epoch": 1.5278532608695652,
      "grad_norm": 0.08312518149614334,
      "learning_rate": 9.708362690792388e-06,
      "loss": 0.0008,
      "step": 2249
    },
    {
      "epoch": 1.5285326086956523,
      "grad_norm": 0.1524142026901245,
      "learning_rate": 9.701251677396021e-06,
      "loss": 0.0012,
      "step": 2250
    },
    {
      "epoch": 1.5292119565217392,
      "grad_norm": 0.01121122669428587,
      "learning_rate": 9.69414081519801e-06,
      "loss": 0.0002,
      "step": 2251
    },
    {
      "epoch": 1.5298913043478262,
      "grad_norm": 0.031762637197971344,
      "learning_rate": 9.687030107797209e-06,
      "loss": 0.0004,
      "step": 2252
    },
    {
      "epoch": 1.530570652173913,
      "grad_norm": 0.01271028071641922,
      "learning_rate": 9.679919558792388e-06,
      "loss": 0.0002,
      "step": 2253
    },
    {
      "epoch": 1.53125,
      "grad_norm": 1.947582483291626,
      "learning_rate": 9.67280917178224e-06,
      "loss": 0.0168,
      "step": 2254
    },
    {
      "epoch": 1.531929347826087,
      "grad_norm": 4.137321472167969,
      "learning_rate": 9.665698950365377e-06,
      "loss": 0.1587,
      "step": 2255
    },
    {
      "epoch": 1.5326086956521738,
      "grad_norm": 5.64631986618042,
      "learning_rate": 9.658588898140322e-06,
      "loss": 0.3358,
      "step": 2256
    },
    {
      "epoch": 1.5332880434782608,
      "grad_norm": 0.0075171575881540775,
      "learning_rate": 9.65147901870552e-06,
      "loss": 0.0001,
      "step": 2257
    },
    {
      "epoch": 1.5339673913043477,
      "grad_norm": 14.076655387878418,
      "learning_rate": 9.644369315659324e-06,
      "loss": 0.3075,
      "step": 2258
    },
    {
      "epoch": 1.5346467391304348,
      "grad_norm": 2.9600818157196045,
      "learning_rate": 9.637259792599997e-06,
      "loss": 0.0604,
      "step": 2259
    },
    {
      "epoch": 1.5353260869565217,
      "grad_norm": 6.423228740692139,
      "learning_rate": 9.630150453125711e-06,
      "loss": 0.1169,
      "step": 2260
    },
    {
      "epoch": 1.5360054347826086,
      "grad_norm": 4.937028884887695,
      "learning_rate": 9.62304130083455e-06,
      "loss": 0.2133,
      "step": 2261
    },
    {
      "epoch": 1.5366847826086958,
      "grad_norm": 2.111708879470825,
      "learning_rate": 9.615932339324497e-06,
      "loss": 0.0455,
      "step": 2262
    },
    {
      "epoch": 1.5373641304347827,
      "grad_norm": 3.579566240310669,
      "learning_rate": 9.608823572193443e-06,
      "loss": 0.0933,
      "step": 2263
    },
    {
      "epoch": 1.5380434782608696,
      "grad_norm": 0.18202504515647888,
      "learning_rate": 9.601715003039174e-06,
      "loss": 0.0012,
      "step": 2264
    },
    {
      "epoch": 1.5387228260869565,
      "grad_norm": 4.988954544067383,
      "learning_rate": 9.59460663545938e-06,
      "loss": 0.147,
      "step": 2265
    },
    {
      "epoch": 1.5394021739130435,
      "grad_norm": 0.14273783564567566,
      "learning_rate": 9.587498473051659e-06,
      "loss": 0.0011,
      "step": 2266
    },
    {
      "epoch": 1.5400815217391304,
      "grad_norm": 1.9261659383773804,
      "learning_rate": 9.580390519413487e-06,
      "loss": 0.0263,
      "step": 2267
    },
    {
      "epoch": 1.5407608695652173,
      "grad_norm": 4.374185085296631,
      "learning_rate": 9.573282778142246e-06,
      "loss": 0.0952,
      "step": 2268
    },
    {
      "epoch": 1.5414402173913042,
      "grad_norm": 0.009259641170501709,
      "learning_rate": 9.566175252835208e-06,
      "loss": 0.0002,
      "step": 2269
    },
    {
      "epoch": 1.5421195652173914,
      "grad_norm": 7.293357849121094,
      "learning_rate": 9.559067947089533e-06,
      "loss": 0.1654,
      "step": 2270
    },
    {
      "epoch": 1.5427989130434783,
      "grad_norm": 13.073391914367676,
      "learning_rate": 9.551960864502275e-06,
      "loss": 0.6368,
      "step": 2271
    },
    {
      "epoch": 1.5434782608695652,
      "grad_norm": 0.13428014516830444,
      "learning_rate": 9.544854008670366e-06,
      "loss": 0.0007,
      "step": 2272
    },
    {
      "epoch": 1.5441576086956523,
      "grad_norm": 2.1930088996887207,
      "learning_rate": 9.537747383190631e-06,
      "loss": 0.0163,
      "step": 2273
    },
    {
      "epoch": 1.5448369565217392,
      "grad_norm": 5.664251327514648,
      "learning_rate": 9.530640991659785e-06,
      "loss": 0.1167,
      "step": 2274
    },
    {
      "epoch": 1.5455163043478262,
      "grad_norm": 0.007948193699121475,
      "learning_rate": 9.523534837674408e-06,
      "loss": 0.0002,
      "step": 2275
    },
    {
      "epoch": 1.546195652173913,
      "grad_norm": 0.008423494175076485,
      "learning_rate": 9.516428924830971e-06,
      "loss": 0.0001,
      "step": 2276
    },
    {
      "epoch": 1.546875,
      "grad_norm": 0.018311847001314163,
      "learning_rate": 9.50932325672582e-06,
      "loss": 0.0002,
      "step": 2277
    },
    {
      "epoch": 1.547554347826087,
      "grad_norm": 9.835155487060547,
      "learning_rate": 9.502217836955178e-06,
      "loss": 0.6019,
      "step": 2278
    },
    {
      "epoch": 1.5482336956521738,
      "grad_norm": 2.373418092727661,
      "learning_rate": 9.495112669115138e-06,
      "loss": 0.0859,
      "step": 2279
    },
    {
      "epoch": 1.5489130434782608,
      "grad_norm": 2.7819061279296875,
      "learning_rate": 9.488007756801672e-06,
      "loss": 0.0111,
      "step": 2280
    },
    {
      "epoch": 1.5495923913043477,
      "grad_norm": 0.01724400371313095,
      "learning_rate": 9.480903103610618e-06,
      "loss": 0.0002,
      "step": 2281
    },
    {
      "epoch": 1.5502717391304348,
      "grad_norm": 0.04364718869328499,
      "learning_rate": 9.473798713137684e-06,
      "loss": 0.0004,
      "step": 2282
    },
    {
      "epoch": 1.5509510869565217,
      "grad_norm": 8.825448036193848,
      "learning_rate": 9.466694588978448e-06,
      "loss": 0.2745,
      "step": 2283
    },
    {
      "epoch": 1.5516304347826086,
      "grad_norm": 5.393798828125,
      "learning_rate": 9.459590734728351e-06,
      "loss": 0.083,
      "step": 2284
    },
    {
      "epoch": 1.5523097826086958,
      "grad_norm": 2.4397575855255127,
      "learning_rate": 9.452487153982696e-06,
      "loss": 0.0892,
      "step": 2285
    },
    {
      "epoch": 1.5529891304347827,
      "grad_norm": 4.356871604919434,
      "learning_rate": 9.445383850336648e-06,
      "loss": 0.0663,
      "step": 2286
    },
    {
      "epoch": 1.5536684782608696,
      "grad_norm": 6.124781608581543,
      "learning_rate": 9.438280827385233e-06,
      "loss": 0.2111,
      "step": 2287
    },
    {
      "epoch": 1.5543478260869565,
      "grad_norm": 0.007612711749970913,
      "learning_rate": 9.431178088723334e-06,
      "loss": 0.0001,
      "step": 2288
    },
    {
      "epoch": 1.5550271739130435,
      "grad_norm": 0.6160715818405151,
      "learning_rate": 9.424075637945692e-06,
      "loss": 0.004,
      "step": 2289
    },
    {
      "epoch": 1.5557065217391304,
      "grad_norm": 5.802586555480957,
      "learning_rate": 9.416973478646898e-06,
      "loss": 0.1261,
      "step": 2290
    },
    {
      "epoch": 1.5563858695652173,
      "grad_norm": 3.301442861557007,
      "learning_rate": 9.409871614421403e-06,
      "loss": 0.0675,
      "step": 2291
    },
    {
      "epoch": 1.5570652173913042,
      "grad_norm": 1.2573045492172241,
      "learning_rate": 9.402770048863502e-06,
      "loss": 0.007,
      "step": 2292
    },
    {
      "epoch": 1.5577445652173914,
      "grad_norm": 2.76936936378479,
      "learning_rate": 9.395668785567339e-06,
      "loss": 0.1303,
      "step": 2293
    },
    {
      "epoch": 1.5584239130434783,
      "grad_norm": 3.9493775367736816,
      "learning_rate": 9.38856782812691e-06,
      "loss": 0.1205,
      "step": 2294
    },
    {
      "epoch": 1.5591032608695652,
      "grad_norm": 0.11043673753738403,
      "learning_rate": 9.381467180136049e-06,
      "loss": 0.0013,
      "step": 2295
    },
    {
      "epoch": 1.5597826086956523,
      "grad_norm": 0.006087025627493858,
      "learning_rate": 9.374366845188441e-06,
      "loss": 0.0001,
      "step": 2296
    },
    {
      "epoch": 1.5604619565217392,
      "grad_norm": 13.696266174316406,
      "learning_rate": 9.367266826877608e-06,
      "loss": 0.2693,
      "step": 2297
    },
    {
      "epoch": 1.5611413043478262,
      "grad_norm": 10.971282005310059,
      "learning_rate": 9.360167128796913e-06,
      "loss": 0.6422,
      "step": 2298
    },
    {
      "epoch": 1.561820652173913,
      "grad_norm": 4.39501428604126,
      "learning_rate": 9.353067754539552e-06,
      "loss": 0.1173,
      "step": 2299
    },
    {
      "epoch": 1.5625,
      "grad_norm": 4.242394924163818,
      "learning_rate": 9.34596870769857e-06,
      "loss": 0.1792,
      "step": 2300
    },
    {
      "epoch": 1.563179347826087,
      "grad_norm": 0.06180492788553238,
      "learning_rate": 9.338869991866833e-06,
      "loss": 0.0006,
      "step": 2301
    },
    {
      "epoch": 1.5638586956521738,
      "grad_norm": 0.0037342547439038754,
      "learning_rate": 9.331771610637048e-06,
      "loss": 0.0001,
      "step": 2302
    },
    {
      "epoch": 1.5645380434782608,
      "grad_norm": 0.045416392385959625,
      "learning_rate": 9.324673567601747e-06,
      "loss": 0.0003,
      "step": 2303
    },
    {
      "epoch": 1.5652173913043477,
      "grad_norm": 0.007005492225289345,
      "learning_rate": 9.317575866353293e-06,
      "loss": 0.0002,
      "step": 2304
    },
    {
      "epoch": 1.5658967391304348,
      "grad_norm": 0.0023807089310139418,
      "learning_rate": 9.310478510483875e-06,
      "loss": 0.0001,
      "step": 2305
    },
    {
      "epoch": 1.5665760869565217,
      "grad_norm": 0.026040660217404366,
      "learning_rate": 9.30338150358551e-06,
      "loss": 0.0002,
      "step": 2306
    },
    {
      "epoch": 1.5672554347826086,
      "grad_norm": 2.1657848358154297,
      "learning_rate": 9.296284849250038e-06,
      "loss": 0.0851,
      "step": 2307
    },
    {
      "epoch": 1.5679347826086958,
      "grad_norm": 2.2089152336120605,
      "learning_rate": 9.289188551069112e-06,
      "loss": 0.1609,
      "step": 2308
    },
    {
      "epoch": 1.5686141304347827,
      "grad_norm": 6.1733927726745605,
      "learning_rate": 9.282092612634223e-06,
      "loss": 0.1128,
      "step": 2309
    },
    {
      "epoch": 1.5692934782608696,
      "grad_norm": 0.008485137484967709,
      "learning_rate": 9.274997037536663e-06,
      "loss": 0.0002,
      "step": 2310
    },
    {
      "epoch": 1.5699728260869565,
      "grad_norm": 7.208725929260254,
      "learning_rate": 9.267901829367546e-06,
      "loss": 0.0549,
      "step": 2311
    },
    {
      "epoch": 1.5706521739130435,
      "grad_norm": 4.877036094665527,
      "learning_rate": 9.260806991717802e-06,
      "loss": 0.1044,
      "step": 2312
    },
    {
      "epoch": 1.5713315217391304,
      "grad_norm": 0.004586894530802965,
      "learning_rate": 9.253712528178169e-06,
      "loss": 0.0001,
      "step": 2313
    },
    {
      "epoch": 1.5720108695652173,
      "grad_norm": 4.284517765045166,
      "learning_rate": 9.246618442339202e-06,
      "loss": 0.1692,
      "step": 2314
    },
    {
      "epoch": 1.5726902173913042,
      "grad_norm": 2.0181946754455566,
      "learning_rate": 9.23952473779126e-06,
      "loss": 0.0461,
      "step": 2315
    },
    {
      "epoch": 1.5733695652173914,
      "grad_norm": 2.7666473388671875,
      "learning_rate": 9.232431418124507e-06,
      "loss": 0.0171,
      "step": 2316
    },
    {
      "epoch": 1.5740489130434783,
      "grad_norm": 0.20213483273983002,
      "learning_rate": 9.225338486928921e-06,
      "loss": 0.0017,
      "step": 2317
    },
    {
      "epoch": 1.5747282608695652,
      "grad_norm": 7.162048816680908,
      "learning_rate": 9.218245947794275e-06,
      "loss": 0.2937,
      "step": 2318
    },
    {
      "epoch": 1.5754076086956523,
      "grad_norm": 4.754650592803955,
      "learning_rate": 9.211153804310146e-06,
      "loss": 0.2665,
      "step": 2319
    },
    {
      "epoch": 1.5760869565217392,
      "grad_norm": 0.008927376009523869,
      "learning_rate": 9.204062060065915e-06,
      "loss": 0.0001,
      "step": 2320
    },
    {
      "epoch": 1.5767663043478262,
      "grad_norm": 5.460582733154297,
      "learning_rate": 9.196970718650753e-06,
      "loss": 0.094,
      "step": 2321
    },
    {
      "epoch": 1.577445652173913,
      "grad_norm": 13.123541831970215,
      "learning_rate": 9.189879783653633e-06,
      "loss": 0.4336,
      "step": 2322
    },
    {
      "epoch": 1.578125,
      "grad_norm": 5.250144004821777,
      "learning_rate": 9.182789258663321e-06,
      "loss": 0.2012,
      "step": 2323
    },
    {
      "epoch": 1.578804347826087,
      "grad_norm": 0.17135091125965118,
      "learning_rate": 9.175699147268374e-06,
      "loss": 0.0012,
      "step": 2324
    },
    {
      "epoch": 1.5794836956521738,
      "grad_norm": 0.002557773143053055,
      "learning_rate": 9.16860945305714e-06,
      "loss": 0.0001,
      "step": 2325
    },
    {
      "epoch": 1.5801630434782608,
      "grad_norm": 0.20733828842639923,
      "learning_rate": 9.16152017961776e-06,
      "loss": 0.002,
      "step": 2326
    },
    {
      "epoch": 1.5808423913043477,
      "grad_norm": 4.268035411834717,
      "learning_rate": 9.154431330538156e-06,
      "loss": 0.1082,
      "step": 2327
    },
    {
      "epoch": 1.5815217391304348,
      "grad_norm": 6.929776191711426,
      "learning_rate": 9.14734290940604e-06,
      "loss": 0.3244,
      "step": 2328
    },
    {
      "epoch": 1.5822010869565217,
      "grad_norm": 5.432803153991699,
      "learning_rate": 9.140254919808907e-06,
      "loss": 0.1415,
      "step": 2329
    },
    {
      "epoch": 1.5828804347826086,
      "grad_norm": 4.743430137634277,
      "learning_rate": 9.133167365334027e-06,
      "loss": 0.2824,
      "step": 2330
    },
    {
      "epoch": 1.5835597826086958,
      "grad_norm": 13.165960311889648,
      "learning_rate": 9.126080249568457e-06,
      "loss": 0.2803,
      "step": 2331
    },
    {
      "epoch": 1.5842391304347827,
      "grad_norm": 3.838646173477173,
      "learning_rate": 9.118993576099032e-06,
      "loss": 0.0437,
      "step": 2332
    },
    {
      "epoch": 1.5849184782608696,
      "grad_norm": 2.4184138774871826,
      "learning_rate": 9.111907348512356e-06,
      "loss": 0.1327,
      "step": 2333
    },
    {
      "epoch": 1.5855978260869565,
      "grad_norm": 6.650803089141846,
      "learning_rate": 9.104821570394811e-06,
      "loss": 0.1785,
      "step": 2334
    },
    {
      "epoch": 1.5862771739130435,
      "grad_norm": 8.20974349975586,
      "learning_rate": 9.097736245332562e-06,
      "loss": 0.1503,
      "step": 2335
    },
    {
      "epoch": 1.5869565217391304,
      "grad_norm": 2.479282855987549,
      "learning_rate": 9.090651376911532e-06,
      "loss": 0.1029,
      "step": 2336
    },
    {
      "epoch": 1.5876358695652173,
      "grad_norm": 6.3209004402160645,
      "learning_rate": 9.083566968717412e-06,
      "loss": 0.0488,
      "step": 2337
    },
    {
      "epoch": 1.5883152173913042,
      "grad_norm": 2.9246368408203125,
      "learning_rate": 9.076483024335667e-06,
      "loss": 0.1472,
      "step": 2338
    },
    {
      "epoch": 1.5889945652173914,
      "grad_norm": 2.836864709854126,
      "learning_rate": 9.069399547351526e-06,
      "loss": 0.1043,
      "step": 2339
    },
    {
      "epoch": 1.5896739130434783,
      "grad_norm": 2.1189844608306885,
      "learning_rate": 9.062316541349978e-06,
      "loss": 0.0699,
      "step": 2340
    },
    {
      "epoch": 1.5903532608695652,
      "grad_norm": 0.06981975585222244,
      "learning_rate": 9.055234009915777e-06,
      "loss": 0.0006,
      "step": 2341
    },
    {
      "epoch": 1.5910326086956523,
      "grad_norm": 7.15220308303833,
      "learning_rate": 9.048151956633432e-06,
      "loss": 0.1794,
      "step": 2342
    },
    {
      "epoch": 1.5917119565217392,
      "grad_norm": 0.503734290599823,
      "learning_rate": 9.04107038508722e-06,
      "loss": 0.0033,
      "step": 2343
    },
    {
      "epoch": 1.5923913043478262,
      "grad_norm": 4.16574764251709,
      "learning_rate": 9.033989298861162e-06,
      "loss": 0.255,
      "step": 2344
    },
    {
      "epoch": 1.593070652173913,
      "grad_norm": 1.1288070678710938,
      "learning_rate": 9.026908701539043e-06,
      "loss": 0.0266,
      "step": 2345
    },
    {
      "epoch": 1.59375,
      "grad_norm": 0.5760046243667603,
      "learning_rate": 9.019828596704394e-06,
      "loss": 0.0049,
      "step": 2346
    },
    {
      "epoch": 1.594429347826087,
      "grad_norm": 0.2118552029132843,
      "learning_rate": 9.012748987940502e-06,
      "loss": 0.0021,
      "step": 2347
    },
    {
      "epoch": 1.5951086956521738,
      "grad_norm": 7.210508346557617,
      "learning_rate": 9.005669878830399e-06,
      "loss": 0.2801,
      "step": 2348
    },
    {
      "epoch": 1.5957880434782608,
      "grad_norm": 4.151697635650635,
      "learning_rate": 8.998591272956866e-06,
      "loss": 0.1415,
      "step": 2349
    },
    {
      "epoch": 1.5964673913043477,
      "grad_norm": 2.653074264526367,
      "learning_rate": 8.99151317390243e-06,
      "loss": 0.1197,
      "step": 2350
    },
    {
      "epoch": 1.5971467391304348,
      "grad_norm": 7.214731216430664,
      "learning_rate": 8.984435585249355e-06,
      "loss": 0.1757,
      "step": 2351
    },
    {
      "epoch": 1.5978260869565217,
      "grad_norm": 0.11242121458053589,
      "learning_rate": 8.977358510579658e-06,
      "loss": 0.0008,
      "step": 2352
    },
    {
      "epoch": 1.5985054347826086,
      "grad_norm": 0.08723133057355881,
      "learning_rate": 8.970281953475088e-06,
      "loss": 0.0007,
      "step": 2353
    },
    {
      "epoch": 1.5991847826086958,
      "grad_norm": 0.025401879101991653,
      "learning_rate": 8.963205917517133e-06,
      "loss": 0.0003,
      "step": 2354
    },
    {
      "epoch": 1.5998641304347827,
      "grad_norm": 0.014855654910206795,
      "learning_rate": 8.95613040628702e-06,
      "loss": 0.0002,
      "step": 2355
    },
    {
      "epoch": 1.6005434782608696,
      "grad_norm": 2.932211399078369,
      "learning_rate": 8.949055423365708e-06,
      "loss": 0.0357,
      "step": 2356
    },
    {
      "epoch": 1.6012228260869565,
      "grad_norm": 0.006037063896656036,
      "learning_rate": 8.941980972333886e-06,
      "loss": 0.0001,
      "step": 2357
    },
    {
      "epoch": 1.6019021739130435,
      "grad_norm": 0.8240282535552979,
      "learning_rate": 8.93490705677198e-06,
      "loss": 0.0163,
      "step": 2358
    },
    {
      "epoch": 1.6025815217391304,
      "grad_norm": 2.8607656955718994,
      "learning_rate": 8.927833680260139e-06,
      "loss": 0.0685,
      "step": 2359
    },
    {
      "epoch": 1.6032608695652173,
      "grad_norm": 4.116784572601318,
      "learning_rate": 8.920760846378248e-06,
      "loss": 0.1947,
      "step": 2360
    },
    {
      "epoch": 1.6039402173913042,
      "grad_norm": 0.02995932102203369,
      "learning_rate": 8.91368855870591e-06,
      "loss": 0.0003,
      "step": 2361
    },
    {
      "epoch": 1.6046195652173914,
      "grad_norm": 8.709585189819336,
      "learning_rate": 8.906616820822452e-06,
      "loss": 0.2316,
      "step": 2362
    },
    {
      "epoch": 1.6052989130434783,
      "grad_norm": 6.064743518829346,
      "learning_rate": 8.899545636306922e-06,
      "loss": 0.1919,
      "step": 2363
    },
    {
      "epoch": 1.6059782608695652,
      "grad_norm": 1.4077566862106323,
      "learning_rate": 8.89247500873809e-06,
      "loss": 0.022,
      "step": 2364
    },
    {
      "epoch": 1.6066576086956523,
      "grad_norm": 0.1770849972963333,
      "learning_rate": 8.885404941694448e-06,
      "loss": 0.002,
      "step": 2365
    },
    {
      "epoch": 1.6073369565217392,
      "grad_norm": 0.0039414712227880955,
      "learning_rate": 8.878335438754195e-06,
      "loss": 0.0001,
      "step": 2366
    },
    {
      "epoch": 1.6080163043478262,
      "grad_norm": 1.0361075401306152,
      "learning_rate": 8.871266503495255e-06,
      "loss": 0.0088,
      "step": 2367
    },
    {
      "epoch": 1.608695652173913,
      "grad_norm": 3.8854429721832275,
      "learning_rate": 8.86419813949525e-06,
      "loss": 0.1134,
      "step": 2368
    },
    {
      "epoch": 1.609375,
      "grad_norm": 0.004383291117846966,
      "learning_rate": 8.857130350331535e-06,
      "loss": 0.0001,
      "step": 2369
    },
    {
      "epoch": 1.610054347826087,
      "grad_norm": 0.06605640053749084,
      "learning_rate": 8.850063139581156e-06,
      "loss": 0.0005,
      "step": 2370
    },
    {
      "epoch": 1.6107336956521738,
      "grad_norm": 0.04672033339738846,
      "learning_rate": 8.84299651082087e-06,
      "loss": 0.0004,
      "step": 2371
    },
    {
      "epoch": 1.6114130434782608,
      "grad_norm": 31.64481544494629,
      "learning_rate": 8.835930467627142e-06,
      "loss": 0.35,
      "step": 2372
    },
    {
      "epoch": 1.6120923913043477,
      "grad_norm": 0.02335023693740368,
      "learning_rate": 8.828865013576143e-06,
      "loss": 0.0002,
      "step": 2373
    },
    {
      "epoch": 1.6127717391304348,
      "grad_norm": 0.21224895119667053,
      "learning_rate": 8.821800152243738e-06,
      "loss": 0.0014,
      "step": 2374
    },
    {
      "epoch": 1.6134510869565217,
      "grad_norm": 2.3153724670410156,
      "learning_rate": 8.814735887205499e-06,
      "loss": 0.0553,
      "step": 2375
    },
    {
      "epoch": 1.6141304347826086,
      "grad_norm": 6.115016937255859,
      "learning_rate": 8.807672222036692e-06,
      "loss": 0.049,
      "step": 2376
    },
    {
      "epoch": 1.6148097826086958,
      "grad_norm": 1.7623482942581177,
      "learning_rate": 8.800609160312281e-06,
      "loss": 0.012,
      "step": 2377
    },
    {
      "epoch": 1.6154891304347827,
      "grad_norm": 0.06944316625595093,
      "learning_rate": 8.793546705606928e-06,
      "loss": 0.0006,
      "step": 2378
    },
    {
      "epoch": 1.6161684782608696,
      "grad_norm": 0.005284635350108147,
      "learning_rate": 8.786484861494984e-06,
      "loss": 0.0001,
      "step": 2379
    },
    {
      "epoch": 1.6168478260869565,
      "grad_norm": 7.6617536544799805,
      "learning_rate": 8.77942363155049e-06,
      "loss": 0.1541,
      "step": 2380
    },
    {
      "epoch": 1.6175271739130435,
      "grad_norm": 0.10750170797109604,
      "learning_rate": 8.77236301934718e-06,
      "loss": 0.0012,
      "step": 2381
    },
    {
      "epoch": 1.6182065217391304,
      "grad_norm": 0.08844984322786331,
      "learning_rate": 8.765303028458468e-06,
      "loss": 0.0006,
      "step": 2382
    },
    {
      "epoch": 1.6188858695652173,
      "grad_norm": 0.006850891280919313,
      "learning_rate": 8.758243662457464e-06,
      "loss": 0.0001,
      "step": 2383
    },
    {
      "epoch": 1.6195652173913042,
      "grad_norm": 3.270702362060547,
      "learning_rate": 8.751184924916954e-06,
      "loss": 0.1496,
      "step": 2384
    },
    {
      "epoch": 1.6202445652173914,
      "grad_norm": 0.12293729186058044,
      "learning_rate": 8.744126819409405e-06,
      "loss": 0.0009,
      "step": 2385
    },
    {
      "epoch": 1.6209239130434783,
      "grad_norm": 3.8011703491210938,
      "learning_rate": 8.737069349506977e-06,
      "loss": 0.2084,
      "step": 2386
    },
    {
      "epoch": 1.6216032608695652,
      "grad_norm": 3.6700031757354736,
      "learning_rate": 8.73001251878149e-06,
      "loss": 0.1411,
      "step": 2387
    },
    {
      "epoch": 1.6222826086956523,
      "grad_norm": 0.005023847334086895,
      "learning_rate": 8.722956330804456e-06,
      "loss": 0.0001,
      "step": 2388
    },
    {
      "epoch": 1.6229619565217392,
      "grad_norm": 1.4264367818832397,
      "learning_rate": 8.715900789147048e-06,
      "loss": 0.0098,
      "step": 2389
    },
    {
      "epoch": 1.6236413043478262,
      "grad_norm": 0.0055765719152987,
      "learning_rate": 8.708845897380123e-06,
      "loss": 0.0001,
      "step": 2390
    },
    {
      "epoch": 1.624320652173913,
      "grad_norm": 18.740734100341797,
      "learning_rate": 8.701791659074206e-06,
      "loss": 0.3377,
      "step": 2391
    },
    {
      "epoch": 1.625,
      "grad_norm": 3.5385971069335938,
      "learning_rate": 8.694738077799487e-06,
      "loss": 0.1513,
      "step": 2392
    },
    {
      "epoch": 1.625679347826087,
      "grad_norm": 0.027478720992803574,
      "learning_rate": 8.687685157125829e-06,
      "loss": 0.0002,
      "step": 2393
    },
    {
      "epoch": 1.6263586956521738,
      "grad_norm": 0.005968582350760698,
      "learning_rate": 8.680632900622752e-06,
      "loss": 0.0001,
      "step": 2394
    },
    {
      "epoch": 1.6270380434782608,
      "grad_norm": 4.184354305267334,
      "learning_rate": 8.673581311859456e-06,
      "loss": 0.0787,
      "step": 2395
    },
    {
      "epoch": 1.6277173913043477,
      "grad_norm": 0.0018924034666270018,
      "learning_rate": 8.666530394404791e-06,
      "loss": 0.0,
      "step": 2396
    },
    {
      "epoch": 1.6283967391304348,
      "grad_norm": 14.179801940917969,
      "learning_rate": 8.659480151827267e-06,
      "loss": 0.2062,
      "step": 2397
    },
    {
      "epoch": 1.6290760869565217,
      "grad_norm": 0.04561672732234001,
      "learning_rate": 8.652430587695056e-06,
      "loss": 0.0004,
      "step": 2398
    },
    {
      "epoch": 1.6297554347826086,
      "grad_norm": 0.05675074830651283,
      "learning_rate": 8.645381705575985e-06,
      "loss": 0.0004,
      "step": 2399
    },
    {
      "epoch": 1.6304347826086958,
      "grad_norm": 10.360827445983887,
      "learning_rate": 8.638333509037537e-06,
      "loss": 0.0929,
      "step": 2400
    },
    {
      "epoch": 1.6311141304347827,
      "grad_norm": 0.004403450060635805,
      "learning_rate": 8.631286001646845e-06,
      "loss": 0.0001,
      "step": 2401
    },
    {
      "epoch": 1.6317934782608696,
      "grad_norm": 6.828993797302246,
      "learning_rate": 8.6242391869707e-06,
      "loss": 0.179,
      "step": 2402
    },
    {
      "epoch": 1.6324728260869565,
      "grad_norm": 6.081562042236328,
      "learning_rate": 8.617193068575534e-06,
      "loss": 0.1621,
      "step": 2403
    },
    {
      "epoch": 1.6331521739130435,
      "grad_norm": 0.0025435653515160084,
      "learning_rate": 8.610147650027433e-06,
      "loss": 0.0001,
      "step": 2404
    },
    {
      "epoch": 1.6338315217391304,
      "grad_norm": 3.4256136417388916,
      "learning_rate": 8.603102934892127e-06,
      "loss": 0.1441,
      "step": 2405
    },
    {
      "epoch": 1.6345108695652173,
      "grad_norm": 0.008997626602649689,
      "learning_rate": 8.59605892673499e-06,
      "loss": 0.0001,
      "step": 2406
    },
    {
      "epoch": 1.6351902173913042,
      "grad_norm": 0.0048005711287260056,
      "learning_rate": 8.589015629121034e-06,
      "loss": 0.0001,
      "step": 2407
    },
    {
      "epoch": 1.6358695652173914,
      "grad_norm": 6.342529296875,
      "learning_rate": 8.58197304561492e-06,
      "loss": 0.26,
      "step": 2408
    },
    {
      "epoch": 1.6365489130434783,
      "grad_norm": 0.069004125893116,
      "learning_rate": 8.57493117978094e-06,
      "loss": 0.0011,
      "step": 2409
    },
    {
      "epoch": 1.6372282608695652,
      "grad_norm": 0.015120414085686207,
      "learning_rate": 8.567890035183025e-06,
      "loss": 0.0002,
      "step": 2410
    },
    {
      "epoch": 1.6379076086956523,
      "grad_norm": 0.02992890402674675,
      "learning_rate": 8.56084961538474e-06,
      "loss": 0.0003,
      "step": 2411
    },
    {
      "epoch": 1.6385869565217392,
      "grad_norm": 6.28720235824585,
      "learning_rate": 8.55380992394929e-06,
      "loss": 0.1635,
      "step": 2412
    },
    {
      "epoch": 1.6392663043478262,
      "grad_norm": 4.156796455383301,
      "learning_rate": 8.546770964439502e-06,
      "loss": 0.1242,
      "step": 2413
    },
    {
      "epoch": 1.639945652173913,
      "grad_norm": 0.0020597672555595636,
      "learning_rate": 8.539732740417838e-06,
      "loss": 0.0001,
      "step": 2414
    },
    {
      "epoch": 1.640625,
      "grad_norm": 4.075844764709473,
      "learning_rate": 8.532695255446384e-06,
      "loss": 0.139,
      "step": 2415
    },
    {
      "epoch": 1.641304347826087,
      "grad_norm": 13.876058578491211,
      "learning_rate": 8.525658513086857e-06,
      "loss": 0.2667,
      "step": 2416
    },
    {
      "epoch": 1.6419836956521738,
      "grad_norm": 0.4967133104801178,
      "learning_rate": 8.518622516900594e-06,
      "loss": 0.0051,
      "step": 2417
    },
    {
      "epoch": 1.6426630434782608,
      "grad_norm": 1.9926156997680664,
      "learning_rate": 8.511587270448556e-06,
      "loss": 0.0535,
      "step": 2418
    },
    {
      "epoch": 1.6433423913043477,
      "grad_norm": 2.8034985065460205,
      "learning_rate": 8.504552777291326e-06,
      "loss": 0.0389,
      "step": 2419
    },
    {
      "epoch": 1.6440217391304348,
      "grad_norm": 0.013126612640917301,
      "learning_rate": 8.497519040989096e-06,
      "loss": 0.0002,
      "step": 2420
    },
    {
      "epoch": 1.6447010869565217,
      "grad_norm": 8.963179588317871,
      "learning_rate": 8.490486065101698e-06,
      "loss": 0.1769,
      "step": 2421
    },
    {
      "epoch": 1.6453804347826086,
      "grad_norm": 0.00584840914234519,
      "learning_rate": 8.483453853188552e-06,
      "loss": 0.0001,
      "step": 2422
    },
    {
      "epoch": 1.6460597826086958,
      "grad_norm": 2.500333309173584,
      "learning_rate": 8.47642240880871e-06,
      "loss": 0.0472,
      "step": 2423
    },
    {
      "epoch": 1.6467391304347827,
      "grad_norm": 0.6485122442245483,
      "learning_rate": 8.469391735520824e-06,
      "loss": 0.007,
      "step": 2424
    },
    {
      "epoch": 1.6474184782608696,
      "grad_norm": 3.210108518600464,
      "learning_rate": 8.462361836883165e-06,
      "loss": 0.1149,
      "step": 2425
    },
    {
      "epoch": 1.6480978260869565,
      "grad_norm": 8.060760498046875,
      "learning_rate": 8.455332716453605e-06,
      "loss": 0.2984,
      "step": 2426
    },
    {
      "epoch": 1.6487771739130435,
      "grad_norm": 3.682588577270508,
      "learning_rate": 8.448304377789628e-06,
      "loss": 0.0561,
      "step": 2427
    },
    {
      "epoch": 1.6494565217391304,
      "grad_norm": 16.45244598388672,
      "learning_rate": 8.441276824448312e-06,
      "loss": 0.6154,
      "step": 2428
    },
    {
      "epoch": 1.6501358695652173,
      "grad_norm": 0.041698019951581955,
      "learning_rate": 8.434250059986355e-06,
      "loss": 0.0005,
      "step": 2429
    },
    {
      "epoch": 1.6508152173913042,
      "grad_norm": 2.098637580871582,
      "learning_rate": 8.42722408796004e-06,
      "loss": 0.1439,
      "step": 2430
    },
    {
      "epoch": 1.6514945652173914,
      "grad_norm": 13.417693138122559,
      "learning_rate": 8.420198911925257e-06,
      "loss": 0.5775,
      "step": 2431
    },
    {
      "epoch": 1.6521739130434783,
      "grad_norm": 1.7484092712402344,
      "learning_rate": 8.413174535437486e-06,
      "loss": 0.044,
      "step": 2432
    },
    {
      "epoch": 1.6528532608695652,
      "grad_norm": 0.02023334987461567,
      "learning_rate": 8.406150962051813e-06,
      "loss": 0.0002,
      "step": 2433
    },
    {
      "epoch": 1.6535326086956523,
      "grad_norm": 2.978811025619507,
      "learning_rate": 8.399128195322908e-06,
      "loss": 0.1359,
      "step": 2434
    },
    {
      "epoch": 1.6542119565217392,
      "grad_norm": 3.9524433612823486,
      "learning_rate": 8.392106238805038e-06,
      "loss": 0.1006,
      "step": 2435
    },
    {
      "epoch": 1.6548913043478262,
      "grad_norm": 0.25910624861717224,
      "learning_rate": 8.385085096052053e-06,
      "loss": 0.0024,
      "step": 2436
    },
    {
      "epoch": 1.655570652173913,
      "grad_norm": 0.005303273908793926,
      "learning_rate": 8.3780647706174e-06,
      "loss": 0.0001,
      "step": 2437
    },
    {
      "epoch": 1.65625,
      "grad_norm": 0.059578996151685715,
      "learning_rate": 8.371045266054114e-06,
      "loss": 0.0005,
      "step": 2438
    },
    {
      "epoch": 1.656929347826087,
      "grad_norm": 0.03116718679666519,
      "learning_rate": 8.364026585914802e-06,
      "loss": 0.0004,
      "step": 2439
    },
    {
      "epoch": 1.6576086956521738,
      "grad_norm": 3.1701552867889404,
      "learning_rate": 8.357008733751664e-06,
      "loss": 0.1756,
      "step": 2440
    },
    {
      "epoch": 1.6582880434782608,
      "grad_norm": 3.2436726093292236,
      "learning_rate": 8.349991713116478e-06,
      "loss": 0.2115,
      "step": 2441
    },
    {
      "epoch": 1.6589673913043477,
      "grad_norm": 1.6079325675964355,
      "learning_rate": 8.342975527560601e-06,
      "loss": 0.0482,
      "step": 2442
    },
    {
      "epoch": 1.6596467391304348,
      "grad_norm": 2.8516030311584473,
      "learning_rate": 8.335960180634965e-06,
      "loss": 0.057,
      "step": 2443
    },
    {
      "epoch": 1.6603260869565217,
      "grad_norm": 0.02296283282339573,
      "learning_rate": 8.328945675890085e-06,
      "loss": 0.0003,
      "step": 2444
    },
    {
      "epoch": 1.6610054347826086,
      "grad_norm": 3.46232008934021,
      "learning_rate": 8.32193201687604e-06,
      "loss": 0.1455,
      "step": 2445
    },
    {
      "epoch": 1.6616847826086958,
      "grad_norm": 1.6461862325668335,
      "learning_rate": 8.314919207142486e-06,
      "loss": 0.0276,
      "step": 2446
    },
    {
      "epoch": 1.6623641304347827,
      "grad_norm": 7.21177339553833,
      "learning_rate": 8.307907250238654e-06,
      "loss": 0.1045,
      "step": 2447
    },
    {
      "epoch": 1.6630434782608696,
      "grad_norm": 2.2594053745269775,
      "learning_rate": 8.300896149713334e-06,
      "loss": 0.0989,
      "step": 2448
    },
    {
      "epoch": 1.6637228260869565,
      "grad_norm": 3.3850698471069336,
      "learning_rate": 8.29388590911489e-06,
      "loss": 0.04,
      "step": 2449
    },
    {
      "epoch": 1.6644021739130435,
      "grad_norm": 6.18388557434082,
      "learning_rate": 8.286876531991246e-06,
      "loss": 0.1816,
      "step": 2450
    },
    {
      "epoch": 1.6650815217391304,
      "grad_norm": 3.5466859340667725,
      "learning_rate": 8.27986802188989e-06,
      "loss": 0.0918,
      "step": 2451
    },
    {
      "epoch": 1.6657608695652173,
      "grad_norm": 0.003235548734664917,
      "learning_rate": 8.272860382357873e-06,
      "loss": 0.0001,
      "step": 2452
    },
    {
      "epoch": 1.6664402173913042,
      "grad_norm": 0.07854785770177841,
      "learning_rate": 8.265853616941803e-06,
      "loss": 0.0007,
      "step": 2453
    },
    {
      "epoch": 1.6671195652173914,
      "grad_norm": 7.613321304321289,
      "learning_rate": 8.258847729187845e-06,
      "loss": 0.2548,
      "step": 2454
    },
    {
      "epoch": 1.6677989130434783,
      "grad_norm": 0.005262942984700203,
      "learning_rate": 8.25184272264173e-06,
      "loss": 0.0001,
      "step": 2455
    },
    {
      "epoch": 1.6684782608695652,
      "grad_norm": 0.11253141611814499,
      "learning_rate": 8.244838600848727e-06,
      "loss": 0.0008,
      "step": 2456
    },
    {
      "epoch": 1.6691576086956523,
      "grad_norm": 0.03110526315867901,
      "learning_rate": 8.237835367353668e-06,
      "loss": 0.0003,
      "step": 2457
    },
    {
      "epoch": 1.6698369565217392,
      "grad_norm": 4.37169075012207,
      "learning_rate": 8.230833025700932e-06,
      "loss": 0.2658,
      "step": 2458
    },
    {
      "epoch": 1.6705163043478262,
      "grad_norm": 1.985293984413147,
      "learning_rate": 8.223831579434449e-06,
      "loss": 0.0239,
      "step": 2459
    },
    {
      "epoch": 1.671195652173913,
      "grad_norm": 3.232490301132202,
      "learning_rate": 8.216831032097689e-06,
      "loss": 0.1972,
      "step": 2460
    },
    {
      "epoch": 1.671875,
      "grad_norm": 1.1289769411087036,
      "learning_rate": 8.209831387233675e-06,
      "loss": 0.0171,
      "step": 2461
    },
    {
      "epoch": 1.672554347826087,
      "grad_norm": 3.316617012023926,
      "learning_rate": 8.202832648384971e-06,
      "loss": 0.0566,
      "step": 2462
    },
    {
      "epoch": 1.6732336956521738,
      "grad_norm": 1.2982374429702759,
      "learning_rate": 8.195834819093677e-06,
      "loss": 0.0886,
      "step": 2463
    },
    {
      "epoch": 1.6739130434782608,
      "grad_norm": 14.8184175491333,
      "learning_rate": 8.188837902901441e-06,
      "loss": 0.4124,
      "step": 2464
    },
    {
      "epoch": 1.6745923913043477,
      "grad_norm": 0.14165158569812775,
      "learning_rate": 8.181841903349448e-06,
      "loss": 0.0009,
      "step": 2465
    },
    {
      "epoch": 1.6752717391304348,
      "grad_norm": 3.8129465579986572,
      "learning_rate": 8.174846823978412e-06,
      "loss": 0.1937,
      "step": 2466
    },
    {
      "epoch": 1.6759510869565217,
      "grad_norm": 5.060399055480957,
      "learning_rate": 8.167852668328588e-06,
      "loss": 0.0453,
      "step": 2467
    },
    {
      "epoch": 1.6766304347826086,
      "grad_norm": 8.257225036621094,
      "learning_rate": 8.16085943993976e-06,
      "loss": 0.1898,
      "step": 2468
    },
    {
      "epoch": 1.6773097826086958,
      "grad_norm": 3.4775898456573486,
      "learning_rate": 8.153867142351242e-06,
      "loss": 0.109,
      "step": 2469
    },
    {
      "epoch": 1.6779891304347827,
      "grad_norm": 6.6532883644104,
      "learning_rate": 8.146875779101882e-06,
      "loss": 0.3289,
      "step": 2470
    },
    {
      "epoch": 1.6786684782608696,
      "grad_norm": 5.351710796356201,
      "learning_rate": 8.139885353730048e-06,
      "loss": 0.0462,
      "step": 2471
    },
    {
      "epoch": 1.6793478260869565,
      "grad_norm": 4.468601226806641,
      "learning_rate": 8.132895869773638e-06,
      "loss": 0.1216,
      "step": 2472
    },
    {
      "epoch": 1.6800271739130435,
      "grad_norm": 3.074103593826294,
      "learning_rate": 8.125907330770075e-06,
      "loss": 0.1552,
      "step": 2473
    },
    {
      "epoch": 1.6807065217391304,
      "grad_norm": 1.6246135234832764,
      "learning_rate": 8.1189197402563e-06,
      "loss": 0.0147,
      "step": 2474
    },
    {
      "epoch": 1.6813858695652173,
      "grad_norm": 10.648722648620605,
      "learning_rate": 8.111933101768779e-06,
      "loss": 0.4421,
      "step": 2475
    },
    {
      "epoch": 1.6820652173913042,
      "grad_norm": 2.669276237487793,
      "learning_rate": 8.104947418843487e-06,
      "loss": 0.0861,
      "step": 2476
    },
    {
      "epoch": 1.6827445652173914,
      "grad_norm": 0.02966723032295704,
      "learning_rate": 8.097962695015923e-06,
      "loss": 0.0003,
      "step": 2477
    },
    {
      "epoch": 1.6834239130434783,
      "grad_norm": 13.347302436828613,
      "learning_rate": 8.0909789338211e-06,
      "loss": 0.5471,
      "step": 2478
    },
    {
      "epoch": 1.6841032608695652,
      "grad_norm": 0.009201319888234138,
      "learning_rate": 8.08399613879354e-06,
      "loss": 0.0001,
      "step": 2479
    },
    {
      "epoch": 1.6847826086956523,
      "grad_norm": 7.973750591278076,
      "learning_rate": 8.077014313467274e-06,
      "loss": 0.0861,
      "step": 2480
    },
    {
      "epoch": 1.6854619565217392,
      "grad_norm": 2.705488920211792,
      "learning_rate": 8.070033461375857e-06,
      "loss": 0.0808,
      "step": 2481
    },
    {
      "epoch": 1.6861413043478262,
      "grad_norm": 5.135571479797363,
      "learning_rate": 8.063053586052336e-06,
      "loss": 0.0658,
      "step": 2482
    },
    {
      "epoch": 1.686820652173913,
      "grad_norm": 0.17954058945178986,
      "learning_rate": 8.05607469102927e-06,
      "loss": 0.0017,
      "step": 2483
    },
    {
      "epoch": 1.6875,
      "grad_norm": 4.47128963470459,
      "learning_rate": 8.04909677983872e-06,
      "loss": 0.1241,
      "step": 2484
    },
    {
      "epoch": 1.688179347826087,
      "grad_norm": 0.09690799564123154,
      "learning_rate": 8.042119856012246e-06,
      "loss": 0.001,
      "step": 2485
    },
    {
      "epoch": 1.6888586956521738,
      "grad_norm": 11.64760971069336,
      "learning_rate": 8.035143923080917e-06,
      "loss": 0.1782,
      "step": 2486
    },
    {
      "epoch": 1.6895380434782608,
      "grad_norm": 0.07623245567083359,
      "learning_rate": 8.028168984575292e-06,
      "loss": 0.0008,
      "step": 2487
    },
    {
      "epoch": 1.6902173913043477,
      "grad_norm": 0.004322786815464497,
      "learning_rate": 8.021195044025432e-06,
      "loss": 0.0001,
      "step": 2488
    },
    {
      "epoch": 1.6908967391304348,
      "grad_norm": 2.1987383365631104,
      "learning_rate": 8.014222104960888e-06,
      "loss": 0.0633,
      "step": 2489
    },
    {
      "epoch": 1.6915760869565217,
      "grad_norm": 7.293490409851074,
      "learning_rate": 8.00725017091071e-06,
      "loss": 0.2717,
      "step": 2490
    },
    {
      "epoch": 1.6922554347826086,
      "grad_norm": 4.878210544586182,
      "learning_rate": 8.000279245403439e-06,
      "loss": 0.1441,
      "step": 2491
    },
    {
      "epoch": 1.6929347826086958,
      "grad_norm": 0.12328153103590012,
      "learning_rate": 7.9933093319671e-06,
      "loss": 0.0011,
      "step": 2492
    },
    {
      "epoch": 1.6936141304347827,
      "grad_norm": 4.279863357543945,
      "learning_rate": 7.98634043412921e-06,
      "loss": 0.1359,
      "step": 2493
    },
    {
      "epoch": 1.6942934782608696,
      "grad_norm": 0.09359601885080338,
      "learning_rate": 7.979372555416768e-06,
      "loss": 0.0007,
      "step": 2494
    },
    {
      "epoch": 1.6949728260869565,
      "grad_norm": 4.373041152954102,
      "learning_rate": 7.972405699356263e-06,
      "loss": 0.1924,
      "step": 2495
    },
    {
      "epoch": 1.6956521739130435,
      "grad_norm": 2.4375219345092773,
      "learning_rate": 7.965439869473664e-06,
      "loss": 0.0217,
      "step": 2496
    },
    {
      "epoch": 1.6963315217391304,
      "grad_norm": 0.005376516375690699,
      "learning_rate": 7.958475069294417e-06,
      "loss": 0.0001,
      "step": 2497
    },
    {
      "epoch": 1.6970108695652173,
      "grad_norm": 0.002561497502028942,
      "learning_rate": 7.951511302343454e-06,
      "loss": 0.0001,
      "step": 2498
    },
    {
      "epoch": 1.6976902173913042,
      "grad_norm": 4.6464457511901855,
      "learning_rate": 7.944548572145178e-06,
      "loss": 0.1103,
      "step": 2499
    },
    {
      "epoch": 1.6983695652173914,
      "grad_norm": 0.034682415425777435,
      "learning_rate": 7.93758688222347e-06,
      "loss": 0.0003,
      "step": 2500
    },
    {
      "epoch": 1.6990489130434783,
      "grad_norm": 3.221383571624756,
      "learning_rate": 7.930626236101684e-06,
      "loss": 0.107,
      "step": 2501
    },
    {
      "epoch": 1.6997282608695652,
      "grad_norm": 3.3027961254119873,
      "learning_rate": 7.923666637302643e-06,
      "loss": 0.0899,
      "step": 2502
    },
    {
      "epoch": 1.7004076086956523,
      "grad_norm": 0.8545565605163574,
      "learning_rate": 7.916708089348649e-06,
      "loss": 0.0093,
      "step": 2503
    },
    {
      "epoch": 1.7010869565217392,
      "grad_norm": 3.478724479675293,
      "learning_rate": 7.909750595761459e-06,
      "loss": 0.0999,
      "step": 2504
    },
    {
      "epoch": 1.7017663043478262,
      "grad_norm": 13.528555870056152,
      "learning_rate": 7.902794160062303e-06,
      "loss": 0.1463,
      "step": 2505
    },
    {
      "epoch": 1.702445652173913,
      "grad_norm": 2.4974465370178223,
      "learning_rate": 7.895838785771881e-06,
      "loss": 0.1246,
      "step": 2506
    },
    {
      "epoch": 1.703125,
      "grad_norm": 1.8596183061599731,
      "learning_rate": 7.888884476410348e-06,
      "loss": 0.0559,
      "step": 2507
    },
    {
      "epoch": 1.703804347826087,
      "grad_norm": 2.193190813064575,
      "learning_rate": 7.881931235497324e-06,
      "loss": 0.0793,
      "step": 2508
    },
    {
      "epoch": 1.7044836956521738,
      "grad_norm": 0.06583044677972794,
      "learning_rate": 7.874979066551886e-06,
      "loss": 0.0004,
      "step": 2509
    },
    {
      "epoch": 1.7051630434782608,
      "grad_norm": 0.3599301874637604,
      "learning_rate": 7.868027973092568e-06,
      "loss": 0.0038,
      "step": 2510
    },
    {
      "epoch": 1.7058423913043477,
      "grad_norm": 0.3038685619831085,
      "learning_rate": 7.861077958637365e-06,
      "loss": 0.0019,
      "step": 2511
    },
    {
      "epoch": 1.7065217391304348,
      "grad_norm": 0.009154523722827435,
      "learning_rate": 7.854129026703716e-06,
      "loss": 0.0001,
      "step": 2512
    },
    {
      "epoch": 1.7072010869565217,
      "grad_norm": 0.0563897080719471,
      "learning_rate": 7.847181180808522e-06,
      "loss": 0.0005,
      "step": 2513
    },
    {
      "epoch": 1.7078804347826086,
      "grad_norm": 6.0565409660339355,
      "learning_rate": 7.84023442446813e-06,
      "loss": 0.1326,
      "step": 2514
    },
    {
      "epoch": 1.7085597826086958,
      "grad_norm": 9.168556213378906,
      "learning_rate": 7.833288761198329e-06,
      "loss": 0.3141,
      "step": 2515
    },
    {
      "epoch": 1.7092391304347827,
      "grad_norm": 0.7114868760108948,
      "learning_rate": 7.826344194514374e-06,
      "loss": 0.0048,
      "step": 2516
    },
    {
      "epoch": 1.7099184782608696,
      "grad_norm": 2.1172003746032715,
      "learning_rate": 7.819400727930947e-06,
      "loss": 0.0638,
      "step": 2517
    },
    {
      "epoch": 1.7105978260869565,
      "grad_norm": 0.0035451140720397234,
      "learning_rate": 7.812458364962177e-06,
      "loss": 0.0001,
      "step": 2518
    },
    {
      "epoch": 1.7112771739130435,
      "grad_norm": 0.019403288140892982,
      "learning_rate": 7.80551710912164e-06,
      "loss": 0.0002,
      "step": 2519
    },
    {
      "epoch": 1.7119565217391304,
      "grad_norm": 22.104707717895508,
      "learning_rate": 7.798576963922347e-06,
      "loss": 0.6809,
      "step": 2520
    },
    {
      "epoch": 1.7126358695652173,
      "grad_norm": 0.011369148269295692,
      "learning_rate": 7.791637932876746e-06,
      "loss": 0.0001,
      "step": 2521
    },
    {
      "epoch": 1.7133152173913042,
      "grad_norm": 3.6553943157196045,
      "learning_rate": 7.784700019496725e-06,
      "loss": 0.136,
      "step": 2522
    },
    {
      "epoch": 1.7139945652173914,
      "grad_norm": 9.600797653198242,
      "learning_rate": 7.7777632272936e-06,
      "loss": 0.2828,
      "step": 2523
    },
    {
      "epoch": 1.7146739130434783,
      "grad_norm": 0.0028647147119045258,
      "learning_rate": 7.770827559778131e-06,
      "loss": 0.0001,
      "step": 2524
    },
    {
      "epoch": 1.7153532608695652,
      "grad_norm": 3.588517427444458,
      "learning_rate": 7.7638930204605e-06,
      "loss": 0.1608,
      "step": 2525
    },
    {
      "epoch": 1.7160326086956523,
      "grad_norm": 12.519503593444824,
      "learning_rate": 7.75695961285032e-06,
      "loss": 0.284,
      "step": 2526
    },
    {
      "epoch": 1.7167119565217392,
      "grad_norm": 4.357614040374756,
      "learning_rate": 7.75002734045663e-06,
      "loss": 0.1201,
      "step": 2527
    },
    {
      "epoch": 1.7173913043478262,
      "grad_norm": 5.5322370529174805,
      "learning_rate": 7.743096206787894e-06,
      "loss": 0.1191,
      "step": 2528
    },
    {
      "epoch": 1.718070652173913,
      "grad_norm": 1.1947808265686035,
      "learning_rate": 7.736166215352004e-06,
      "loss": 0.0111,
      "step": 2529
    },
    {
      "epoch": 1.71875,
      "grad_norm": 0.11630158871412277,
      "learning_rate": 7.72923736965627e-06,
      "loss": 0.0006,
      "step": 2530
    },
    {
      "epoch": 1.719429347826087,
      "grad_norm": 0.0264310110360384,
      "learning_rate": 7.722309673207423e-06,
      "loss": 0.0003,
      "step": 2531
    },
    {
      "epoch": 1.7201086956521738,
      "grad_norm": 1.3613262176513672,
      "learning_rate": 7.71538312951161e-06,
      "loss": 0.0295,
      "step": 2532
    },
    {
      "epoch": 1.7207880434782608,
      "grad_norm": 4.051445007324219,
      "learning_rate": 7.708457742074403e-06,
      "loss": 0.1409,
      "step": 2533
    },
    {
      "epoch": 1.7214673913043477,
      "grad_norm": 0.028936879709362984,
      "learning_rate": 7.701533514400779e-06,
      "loss": 0.0004,
      "step": 2534
    },
    {
      "epoch": 1.7221467391304348,
      "grad_norm": 1.206533670425415,
      "learning_rate": 7.694610449995133e-06,
      "loss": 0.0471,
      "step": 2535
    },
    {
      "epoch": 1.7228260869565217,
      "grad_norm": 0.4878798723220825,
      "learning_rate": 7.687688552361272e-06,
      "loss": 0.0099,
      "step": 2536
    },
    {
      "epoch": 1.7235054347826086,
      "grad_norm": 2.8030683994293213,
      "learning_rate": 7.680767825002409e-06,
      "loss": 0.1307,
      "step": 2537
    },
    {
      "epoch": 1.7241847826086958,
      "grad_norm": 0.004052731674164534,
      "learning_rate": 7.673848271421166e-06,
      "loss": 0.0001,
      "step": 2538
    },
    {
      "epoch": 1.7248641304347827,
      "grad_norm": 2.866241693496704,
      "learning_rate": 7.666929895119574e-06,
      "loss": 0.0789,
      "step": 2539
    },
    {
      "epoch": 1.7255434782608696,
      "grad_norm": 0.42197269201278687,
      "learning_rate": 7.660012699599062e-06,
      "loss": 0.0047,
      "step": 2540
    },
    {
      "epoch": 1.7262228260869565,
      "grad_norm": 2.2666330337524414,
      "learning_rate": 7.653096688360465e-06,
      "loss": 0.0974,
      "step": 2541
    },
    {
      "epoch": 1.7269021739130435,
      "grad_norm": 5.183717727661133,
      "learning_rate": 7.646181864904024e-06,
      "loss": 0.157,
      "step": 2542
    },
    {
      "epoch": 1.7275815217391304,
      "grad_norm": 0.6186248064041138,
      "learning_rate": 7.639268232729369e-06,
      "loss": 0.0047,
      "step": 2543
    },
    {
      "epoch": 1.7282608695652173,
      "grad_norm": 3.8482165336608887,
      "learning_rate": 7.632355795335533e-06,
      "loss": 0.0146,
      "step": 2544
    },
    {
      "epoch": 1.7289402173913042,
      "grad_norm": 0.04562303051352501,
      "learning_rate": 7.6254445562209444e-06,
      "loss": 0.0005,
      "step": 2545
    },
    {
      "epoch": 1.7296195652173914,
      "grad_norm": 0.029075630009174347,
      "learning_rate": 7.6185345188834215e-06,
      "loss": 0.0002,
      "step": 2546
    },
    {
      "epoch": 1.7302989130434783,
      "grad_norm": 0.09237857908010483,
      "learning_rate": 7.611625686820177e-06,
      "loss": 0.0019,
      "step": 2547
    },
    {
      "epoch": 1.7309782608695652,
      "grad_norm": 1.4332259893417358,
      "learning_rate": 7.6047180635278135e-06,
      "loss": 0.0345,
      "step": 2548
    },
    {
      "epoch": 1.7316576086956523,
      "grad_norm": 0.039671964943408966,
      "learning_rate": 7.597811652502318e-06,
      "loss": 0.0007,
      "step": 2549
    },
    {
      "epoch": 1.7323369565217392,
      "grad_norm": 2.8879199028015137,
      "learning_rate": 7.590906457239073e-06,
      "loss": 0.0494,
      "step": 2550
    },
    {
      "epoch": 1.7330163043478262,
      "grad_norm": 1.0443220138549805,
      "learning_rate": 7.584002481232841e-06,
      "loss": 0.0097,
      "step": 2551
    },
    {
      "epoch": 1.733695652173913,
      "grad_norm": 0.0021806831937283278,
      "learning_rate": 7.577099727977762e-06,
      "loss": 0.0,
      "step": 2552
    },
    {
      "epoch": 1.734375,
      "grad_norm": 0.004155511502176523,
      "learning_rate": 7.570198200967363e-06,
      "loss": 0.0001,
      "step": 2553
    },
    {
      "epoch": 1.735054347826087,
      "grad_norm": 7.028497219085693,
      "learning_rate": 7.563297903694549e-06,
      "loss": 0.2324,
      "step": 2554
    },
    {
      "epoch": 1.7357336956521738,
      "grad_norm": 1.3728803396224976,
      "learning_rate": 7.556398839651603e-06,
      "loss": 0.0314,
      "step": 2555
    },
    {
      "epoch": 1.7364130434782608,
      "grad_norm": 2.161558151245117,
      "learning_rate": 7.549501012330184e-06,
      "loss": 0.071,
      "step": 2556
    },
    {
      "epoch": 1.7370923913043477,
      "grad_norm": 0.15214352309703827,
      "learning_rate": 7.5426044252213245e-06,
      "loss": 0.001,
      "step": 2557
    },
    {
      "epoch": 1.7377717391304348,
      "grad_norm": 0.4216844141483307,
      "learning_rate": 7.5357090818154275e-06,
      "loss": 0.0024,
      "step": 2558
    },
    {
      "epoch": 1.7384510869565217,
      "grad_norm": 7.062535285949707,
      "learning_rate": 7.528814985602273e-06,
      "loss": 0.2778,
      "step": 2559
    },
    {
      "epoch": 1.7391304347826086,
      "grad_norm": 0.0055152615532279015,
      "learning_rate": 7.521922140071003e-06,
      "loss": 0.0001,
      "step": 2560
    },
    {
      "epoch": 1.7398097826086958,
      "grad_norm": 0.9788030385971069,
      "learning_rate": 7.515030548710127e-06,
      "loss": 0.014,
      "step": 2561
    },
    {
      "epoch": 1.7404891304347827,
      "grad_norm": 18.269933700561523,
      "learning_rate": 7.508140215007526e-06,
      "loss": 0.3638,
      "step": 2562
    },
    {
      "epoch": 1.7411684782608696,
      "grad_norm": 7.407528400421143,
      "learning_rate": 7.501251142450436e-06,
      "loss": 0.0379,
      "step": 2563
    },
    {
      "epoch": 1.7418478260869565,
      "grad_norm": 6.935262680053711,
      "learning_rate": 7.4943633345254585e-06,
      "loss": 0.032,
      "step": 2564
    },
    {
      "epoch": 1.7425271739130435,
      "grad_norm": 5.823368072509766,
      "learning_rate": 7.4874767947185586e-06,
      "loss": 0.1738,
      "step": 2565
    },
    {
      "epoch": 1.7432065217391304,
      "grad_norm": 5.181666851043701,
      "learning_rate": 7.480591526515053e-06,
      "loss": 0.1302,
      "step": 2566
    },
    {
      "epoch": 1.7438858695652173,
      "grad_norm": 0.005306266713887453,
      "learning_rate": 7.473707533399624e-06,
      "loss": 0.0001,
      "step": 2567
    },
    {
      "epoch": 1.7445652173913042,
      "grad_norm": 9.581507682800293,
      "learning_rate": 7.466824818856296e-06,
      "loss": 0.2452,
      "step": 2568
    },
    {
      "epoch": 1.7452445652173914,
      "grad_norm": 0.02157672680914402,
      "learning_rate": 7.459943386368458e-06,
      "loss": 0.0002,
      "step": 2569
    },
    {
      "epoch": 1.7459239130434783,
      "grad_norm": 2.760681629180908,
      "learning_rate": 7.453063239418842e-06,
      "loss": 0.0477,
      "step": 2570
    },
    {
      "epoch": 1.7466032608695652,
      "grad_norm": 3.609179973602295,
      "learning_rate": 7.446184381489533e-06,
      "loss": 0.1469,
      "step": 2571
    },
    {
      "epoch": 1.7472826086956523,
      "grad_norm": 3.0897369384765625,
      "learning_rate": 7.439306816061964e-06,
      "loss": 0.0365,
      "step": 2572
    },
    {
      "epoch": 1.7479619565217392,
      "grad_norm": 4.255665302276611,
      "learning_rate": 7.432430546616913e-06,
      "loss": 0.0629,
      "step": 2573
    },
    {
      "epoch": 1.7486413043478262,
      "grad_norm": 4.446691513061523,
      "learning_rate": 7.4255555766345025e-06,
      "loss": 0.198,
      "step": 2574
    },
    {
      "epoch": 1.749320652173913,
      "grad_norm": 6.560807228088379,
      "learning_rate": 7.4186819095941895e-06,
      "loss": 0.0533,
      "step": 2575
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.0018965249182656407,
      "learning_rate": 7.411809548974792e-06,
      "loss": 0.0,
      "step": 2576
    },
    {
      "epoch": 1.750679347826087,
      "grad_norm": 6.855086326599121,
      "learning_rate": 7.404938498254448e-06,
      "loss": 0.1328,
      "step": 2577
    },
    {
      "epoch": 1.7513586956521738,
      "grad_norm": 0.37962114810943604,
      "learning_rate": 7.398068760910637e-06,
      "loss": 0.0021,
      "step": 2578
    },
    {
      "epoch": 1.7520380434782608,
      "grad_norm": 4.205981254577637,
      "learning_rate": 7.391200340420176e-06,
      "loss": 0.0337,
      "step": 2579
    },
    {
      "epoch": 1.7527173913043477,
      "grad_norm": 3.021826982498169,
      "learning_rate": 7.384333240259216e-06,
      "loss": 0.1487,
      "step": 2580
    },
    {
      "epoch": 1.7533967391304348,
      "grad_norm": 0.002631358103826642,
      "learning_rate": 7.3774674639032365e-06,
      "loss": 0.0001,
      "step": 2581
    },
    {
      "epoch": 1.7540760869565217,
      "grad_norm": 4.120438098907471,
      "learning_rate": 7.370603014827049e-06,
      "loss": 0.1282,
      "step": 2582
    },
    {
      "epoch": 1.7547554347826086,
      "grad_norm": 0.0051670377142727375,
      "learning_rate": 7.363739896504795e-06,
      "loss": 0.0001,
      "step": 2583
    },
    {
      "epoch": 1.7554347826086958,
      "grad_norm": 11.576454162597656,
      "learning_rate": 7.356878112409936e-06,
      "loss": 0.8314,
      "step": 2584
    },
    {
      "epoch": 1.7561141304347827,
      "grad_norm": 7.400044918060303,
      "learning_rate": 7.350017666015272e-06,
      "loss": 0.1312,
      "step": 2585
    },
    {
      "epoch": 1.7567934782608696,
      "grad_norm": 16.448637008666992,
      "learning_rate": 7.34315856079291e-06,
      "loss": 0.1878,
      "step": 2586
    },
    {
      "epoch": 1.7574728260869565,
      "grad_norm": 3.592146635055542,
      "learning_rate": 7.336300800214289e-06,
      "loss": 0.0679,
      "step": 2587
    },
    {
      "epoch": 1.7581521739130435,
      "grad_norm": 7.647045612335205,
      "learning_rate": 7.32944438775016e-06,
      "loss": 0.4165,
      "step": 2588
    },
    {
      "epoch": 1.7588315217391304,
      "grad_norm": 6.474480628967285,
      "learning_rate": 7.322589326870597e-06,
      "loss": 0.1183,
      "step": 2589
    },
    {
      "epoch": 1.7595108695652173,
      "grad_norm": 6.8902153968811035,
      "learning_rate": 7.315735621044989e-06,
      "loss": 0.1011,
      "step": 2590
    },
    {
      "epoch": 1.7601902173913042,
      "grad_norm": 2.5456793308258057,
      "learning_rate": 7.3088832737420375e-06,
      "loss": 0.064,
      "step": 2591
    },
    {
      "epoch": 1.7608695652173914,
      "grad_norm": 0.00957421027123928,
      "learning_rate": 7.3020322884297565e-06,
      "loss": 0.0001,
      "step": 2592
    },
    {
      "epoch": 1.7615489130434783,
      "grad_norm": 0.045116640627384186,
      "learning_rate": 7.295182668575475e-06,
      "loss": 0.0003,
      "step": 2593
    },
    {
      "epoch": 1.7622282608695652,
      "grad_norm": 4.310995578765869,
      "learning_rate": 7.288334417645827e-06,
      "loss": 0.1409,
      "step": 2594
    },
    {
      "epoch": 1.7629076086956523,
      "grad_norm": 3.739720344543457,
      "learning_rate": 7.281487539106752e-06,
      "loss": 0.0788,
      "step": 2595
    },
    {
      "epoch": 1.7635869565217392,
      "grad_norm": 3.793739080429077,
      "learning_rate": 7.274642036423498e-06,
      "loss": 0.0187,
      "step": 2596
    },
    {
      "epoch": 1.7642663043478262,
      "grad_norm": 1.1116520166397095,
      "learning_rate": 7.267797913060617e-06,
      "loss": 0.0075,
      "step": 2597
    },
    {
      "epoch": 1.764945652173913,
      "grad_norm": 7.272366046905518,
      "learning_rate": 7.260955172481959e-06,
      "loss": 0.2558,
      "step": 2598
    },
    {
      "epoch": 1.765625,
      "grad_norm": 0.07689565420150757,
      "learning_rate": 7.25411381815068e-06,
      "loss": 0.0005,
      "step": 2599
    },
    {
      "epoch": 1.766304347826087,
      "grad_norm": 6.416024684906006,
      "learning_rate": 7.2472738535292295e-06,
      "loss": 0.2656,
      "step": 2600
    },
    {
      "epoch": 1.7669836956521738,
      "grad_norm": 0.004022662062197924,
      "learning_rate": 7.240435282079352e-06,
      "loss": 0.0001,
      "step": 2601
    },
    {
      "epoch": 1.7676630434782608,
      "grad_norm": 10.035117149353027,
      "learning_rate": 7.2335981072621e-06,
      "loss": 0.235,
      "step": 2602
    },
    {
      "epoch": 1.7683423913043477,
      "grad_norm": 6.4007439613342285,
      "learning_rate": 7.226762332537803e-06,
      "loss": 0.1279,
      "step": 2603
    },
    {
      "epoch": 1.7690217391304348,
      "grad_norm": 4.540153980255127,
      "learning_rate": 7.219927961366091e-06,
      "loss": 0.1114,
      "step": 2604
    },
    {
      "epoch": 1.7697010869565217,
      "grad_norm": 1.3581212759017944,
      "learning_rate": 7.213094997205878e-06,
      "loss": 0.0049,
      "step": 2605
    },
    {
      "epoch": 1.7703804347826086,
      "grad_norm": 3.7083747386932373,
      "learning_rate": 7.2062634435153725e-06,
      "loss": 0.0996,
      "step": 2606
    },
    {
      "epoch": 1.7710597826086958,
      "grad_norm": 6.476611614227295,
      "learning_rate": 7.199433303752064e-06,
      "loss": 0.1087,
      "step": 2607
    },
    {
      "epoch": 1.7717391304347827,
      "grad_norm": 0.590914249420166,
      "learning_rate": 7.192604581372727e-06,
      "loss": 0.0029,
      "step": 2608
    },
    {
      "epoch": 1.7724184782608696,
      "grad_norm": 0.022917337715625763,
      "learning_rate": 7.185777279833421e-06,
      "loss": 0.0002,
      "step": 2609
    },
    {
      "epoch": 1.7730978260869565,
      "grad_norm": 3.17582631111145,
      "learning_rate": 7.178951402589482e-06,
      "loss": 0.1241,
      "step": 2610
    },
    {
      "epoch": 1.7737771739130435,
      "grad_norm": 25.996580123901367,
      "learning_rate": 7.172126953095535e-06,
      "loss": 0.5359,
      "step": 2611
    },
    {
      "epoch": 1.7744565217391304,
      "grad_norm": 1.8330005407333374,
      "learning_rate": 7.165303934805472e-06,
      "loss": 0.0438,
      "step": 2612
    },
    {
      "epoch": 1.7751358695652173,
      "grad_norm": 0.0035457885824143887,
      "learning_rate": 7.158482351172465e-06,
      "loss": 0.0001,
      "step": 2613
    },
    {
      "epoch": 1.7758152173913042,
      "grad_norm": 1.4186286926269531,
      "learning_rate": 7.151662205648959e-06,
      "loss": 0.0044,
      "step": 2614
    },
    {
      "epoch": 1.7764945652173914,
      "grad_norm": 3.844168186187744,
      "learning_rate": 7.144843501686671e-06,
      "loss": 0.0547,
      "step": 2615
    },
    {
      "epoch": 1.7771739130434783,
      "grad_norm": 0.011992787942290306,
      "learning_rate": 7.1380262427365885e-06,
      "loss": 0.0002,
      "step": 2616
    },
    {
      "epoch": 1.7778532608695652,
      "grad_norm": 0.19839544594287872,
      "learning_rate": 7.131210432248969e-06,
      "loss": 0.0008,
      "step": 2617
    },
    {
      "epoch": 1.7785326086956523,
      "grad_norm": 0.893557071685791,
      "learning_rate": 7.124396073673334e-06,
      "loss": 0.0049,
      "step": 2618
    },
    {
      "epoch": 1.7792119565217392,
      "grad_norm": 7.3344292640686035,
      "learning_rate": 7.117583170458478e-06,
      "loss": 0.0721,
      "step": 2619
    },
    {
      "epoch": 1.7798913043478262,
      "grad_norm": 9.454258918762207,
      "learning_rate": 7.110771726052446e-06,
      "loss": 0.1592,
      "step": 2620
    },
    {
      "epoch": 1.780570652173913,
      "grad_norm": 1.9449363946914673,
      "learning_rate": 7.103961743902554e-06,
      "loss": 0.0443,
      "step": 2621
    },
    {
      "epoch": 1.78125,
      "grad_norm": 4.084854602813721,
      "learning_rate": 7.097153227455379e-06,
      "loss": 0.1203,
      "step": 2622
    },
    {
      "epoch": 1.781929347826087,
      "grad_norm": 10.917096138000488,
      "learning_rate": 7.090346180156747e-06,
      "loss": 0.2736,
      "step": 2623
    },
    {
      "epoch": 1.7826086956521738,
      "grad_norm": 4.7161102294921875,
      "learning_rate": 7.0835406054517505e-06,
      "loss": 0.2045,
      "step": 2624
    },
    {
      "epoch": 1.7832880434782608,
      "grad_norm": 0.015053789131343365,
      "learning_rate": 7.076736506784734e-06,
      "loss": 0.0001,
      "step": 2625
    },
    {
      "epoch": 1.7839673913043477,
      "grad_norm": 0.7460417151451111,
      "learning_rate": 7.06993388759929e-06,
      "loss": 0.0091,
      "step": 2626
    },
    {
      "epoch": 1.7846467391304348,
      "grad_norm": 3.4539473056793213,
      "learning_rate": 7.063132751338265e-06,
      "loss": 0.1659,
      "step": 2627
    },
    {
      "epoch": 1.7853260869565217,
      "grad_norm": 0.14583395421504974,
      "learning_rate": 7.056333101443761e-06,
      "loss": 0.0014,
      "step": 2628
    },
    {
      "epoch": 1.7860054347826086,
      "grad_norm": 0.024924354627728462,
      "learning_rate": 7.049534941357118e-06,
      "loss": 0.0002,
      "step": 2629
    },
    {
      "epoch": 1.7866847826086958,
      "grad_norm": 0.0019933979492634535,
      "learning_rate": 7.042738274518928e-06,
      "loss": 0.0,
      "step": 2630
    },
    {
      "epoch": 1.7873641304347827,
      "grad_norm": 0.0028190005104988813,
      "learning_rate": 7.035943104369026e-06,
      "loss": 0.0,
      "step": 2631
    },
    {
      "epoch": 1.7880434782608696,
      "grad_norm": 16.610633850097656,
      "learning_rate": 7.0291494343464896e-06,
      "loss": 0.4923,
      "step": 2632
    },
    {
      "epoch": 1.7887228260869565,
      "grad_norm": 4.337887763977051,
      "learning_rate": 7.0223572678896345e-06,
      "loss": 0.1058,
      "step": 2633
    },
    {
      "epoch": 1.7894021739130435,
      "grad_norm": 20.279428482055664,
      "learning_rate": 7.01556660843602e-06,
      "loss": 0.5729,
      "step": 2634
    },
    {
      "epoch": 1.7900815217391304,
      "grad_norm": 3.8602089881896973,
      "learning_rate": 7.008777459422436e-06,
      "loss": 0.1285,
      "step": 2635
    },
    {
      "epoch": 1.7907608695652173,
      "grad_norm": 4.925927639007568,
      "learning_rate": 7.001989824284919e-06,
      "loss": 0.1615,
      "step": 2636
    },
    {
      "epoch": 1.7914402173913042,
      "grad_norm": 4.826350688934326,
      "learning_rate": 6.995203706458731e-06,
      "loss": 0.1936,
      "step": 2637
    },
    {
      "epoch": 1.7921195652173914,
      "grad_norm": 12.455083847045898,
      "learning_rate": 6.988419109378367e-06,
      "loss": 0.5489,
      "step": 2638
    },
    {
      "epoch": 1.7927989130434783,
      "grad_norm": 8.727665901184082,
      "learning_rate": 6.981636036477553e-06,
      "loss": 0.3942,
      "step": 2639
    },
    {
      "epoch": 1.7934782608695652,
      "grad_norm": 0.050533972680568695,
      "learning_rate": 6.974854491189243e-06,
      "loss": 0.0003,
      "step": 2640
    },
    {
      "epoch": 1.7941576086956523,
      "grad_norm": 0.22127200663089752,
      "learning_rate": 6.968074476945621e-06,
      "loss": 0.0035,
      "step": 2641
    },
    {
      "epoch": 1.7948369565217392,
      "grad_norm": 0.013168908655643463,
      "learning_rate": 6.96129599717809e-06,
      "loss": 0.0001,
      "step": 2642
    },
    {
      "epoch": 1.7955163043478262,
      "grad_norm": 13.360793113708496,
      "learning_rate": 6.9545190553172836e-06,
      "loss": 0.2479,
      "step": 2643
    },
    {
      "epoch": 1.796195652173913,
      "grad_norm": 4.340803623199463,
      "learning_rate": 6.947743654793049e-06,
      "loss": 0.0979,
      "step": 2644
    },
    {
      "epoch": 1.796875,
      "grad_norm": 0.005166147835552692,
      "learning_rate": 6.940969799034465e-06,
      "loss": 0.0001,
      "step": 2645
    },
    {
      "epoch": 1.797554347826087,
      "grad_norm": 1.029064655303955,
      "learning_rate": 6.934197491469818e-06,
      "loss": 0.0047,
      "step": 2646
    },
    {
      "epoch": 1.7982336956521738,
      "grad_norm": 0.009958470240235329,
      "learning_rate": 6.927426735526612e-06,
      "loss": 0.0001,
      "step": 2647
    },
    {
      "epoch": 1.7989130434782608,
      "grad_norm": 11.180792808532715,
      "learning_rate": 6.920657534631573e-06,
      "loss": 0.5289,
      "step": 2648
    },
    {
      "epoch": 1.7995923913043477,
      "grad_norm": 0.003635471686720848,
      "learning_rate": 6.913889892210631e-06,
      "loss": 0.0001,
      "step": 2649
    },
    {
      "epoch": 1.8002717391304348,
      "grad_norm": 3.9015934467315674,
      "learning_rate": 6.907123811688934e-06,
      "loss": 0.1064,
      "step": 2650
    },
    {
      "epoch": 1.8009510869565217,
      "grad_norm": 3.1442835330963135,
      "learning_rate": 6.900359296490834e-06,
      "loss": 0.1165,
      "step": 2651
    },
    {
      "epoch": 1.8016304347826086,
      "grad_norm": 1.861140489578247,
      "learning_rate": 6.893596350039896e-06,
      "loss": 0.0097,
      "step": 2652
    },
    {
      "epoch": 1.8023097826086958,
      "grad_norm": 6.074560642242432,
      "learning_rate": 6.886834975758885e-06,
      "loss": 0.1049,
      "step": 2653
    },
    {
      "epoch": 1.8029891304347827,
      "grad_norm": 0.024711430072784424,
      "learning_rate": 6.880075177069779e-06,
      "loss": 0.0001,
      "step": 2654
    },
    {
      "epoch": 1.8036684782608696,
      "grad_norm": 1.4672633409500122,
      "learning_rate": 6.873316957393752e-06,
      "loss": 0.0295,
      "step": 2655
    },
    {
      "epoch": 1.8043478260869565,
      "grad_norm": 0.8406170010566711,
      "learning_rate": 6.866560320151179e-06,
      "loss": 0.0094,
      "step": 2656
    },
    {
      "epoch": 1.8050271739130435,
      "grad_norm": 1.643936038017273,
      "learning_rate": 6.859805268761637e-06,
      "loss": 0.03,
      "step": 2657
    },
    {
      "epoch": 1.8057065217391304,
      "grad_norm": 11.241524696350098,
      "learning_rate": 6.853051806643898e-06,
      "loss": 0.576,
      "step": 2658
    },
    {
      "epoch": 1.8063858695652173,
      "grad_norm": 0.0036327410489320755,
      "learning_rate": 6.84629993721593e-06,
      "loss": 0.0001,
      "step": 2659
    },
    {
      "epoch": 1.8070652173913042,
      "grad_norm": 5.1919169425964355,
      "learning_rate": 6.839549663894897e-06,
      "loss": 0.1464,
      "step": 2660
    },
    {
      "epoch": 1.8077445652173914,
      "grad_norm": 15.265547752380371,
      "learning_rate": 6.832800990097148e-06,
      "loss": 0.4497,
      "step": 2661
    },
    {
      "epoch": 1.8084239130434783,
      "grad_norm": 3.823897361755371,
      "learning_rate": 6.826053919238238e-06,
      "loss": 0.2162,
      "step": 2662
    },
    {
      "epoch": 1.8091032608695652,
      "grad_norm": 3.21089243888855,
      "learning_rate": 6.819308454732896e-06,
      "loss": 0.1625,
      "step": 2663
    },
    {
      "epoch": 1.8097826086956523,
      "grad_norm": 1.1997532844543457,
      "learning_rate": 6.812564599995042e-06,
      "loss": 0.025,
      "step": 2664
    },
    {
      "epoch": 1.8104619565217392,
      "grad_norm": 0.30260515213012695,
      "learning_rate": 6.805822358437784e-06,
      "loss": 0.0019,
      "step": 2665
    },
    {
      "epoch": 1.8111413043478262,
      "grad_norm": 9.998534202575684,
      "learning_rate": 6.799081733473411e-06,
      "loss": 0.3133,
      "step": 2666
    },
    {
      "epoch": 1.811820652173913,
      "grad_norm": 0.0024729508440941572,
      "learning_rate": 6.7923427285133945e-06,
      "loss": 0.0001,
      "step": 2667
    },
    {
      "epoch": 1.8125,
      "grad_norm": 6.22900390625,
      "learning_rate": 6.785605346968387e-06,
      "loss": 0.1848,
      "step": 2668
    },
    {
      "epoch": 1.813179347826087,
      "grad_norm": 4.2418999671936035,
      "learning_rate": 6.778869592248217e-06,
      "loss": 0.1437,
      "step": 2669
    },
    {
      "epoch": 1.8138586956521738,
      "grad_norm": 9.302461624145508,
      "learning_rate": 6.772135467761889e-06,
      "loss": 0.2831,
      "step": 2670
    },
    {
      "epoch": 1.8145380434782608,
      "grad_norm": 1.0051767826080322,
      "learning_rate": 6.765402976917591e-06,
      "loss": 0.0061,
      "step": 2671
    },
    {
      "epoch": 1.8152173913043477,
      "grad_norm": 0.01641073077917099,
      "learning_rate": 6.758672123122675e-06,
      "loss": 0.0002,
      "step": 2672
    },
    {
      "epoch": 1.8158967391304348,
      "grad_norm": 1.4190006256103516,
      "learning_rate": 6.7519429097836675e-06,
      "loss": 0.018,
      "step": 2673
    },
    {
      "epoch": 1.8165760869565217,
      "grad_norm": 2.0864405632019043,
      "learning_rate": 6.745215340306264e-06,
      "loss": 0.0887,
      "step": 2674
    },
    {
      "epoch": 1.8172554347826086,
      "grad_norm": 6.372984409332275,
      "learning_rate": 6.738489418095329e-06,
      "loss": 0.1078,
      "step": 2675
    },
    {
      "epoch": 1.8179347826086958,
      "grad_norm": 3.02618670463562,
      "learning_rate": 6.731765146554891e-06,
      "loss": 0.0844,
      "step": 2676
    },
    {
      "epoch": 1.8186141304347827,
      "grad_norm": 0.04096728190779686,
      "learning_rate": 6.72504252908815e-06,
      "loss": 0.0004,
      "step": 2677
    },
    {
      "epoch": 1.8192934782608696,
      "grad_norm": 14.163195610046387,
      "learning_rate": 6.718321569097459e-06,
      "loss": 0.7229,
      "step": 2678
    },
    {
      "epoch": 1.8199728260869565,
      "grad_norm": 0.07434120774269104,
      "learning_rate": 6.711602269984339e-06,
      "loss": 0.0005,
      "step": 2679
    },
    {
      "epoch": 1.8206521739130435,
      "grad_norm": 4.523995876312256,
      "learning_rate": 6.704884635149467e-06,
      "loss": 0.1367,
      "step": 2680
    },
    {
      "epoch": 1.8213315217391304,
      "grad_norm": 6.9923553466796875,
      "learning_rate": 6.698168667992681e-06,
      "loss": 0.2403,
      "step": 2681
    },
    {
      "epoch": 1.8220108695652173,
      "grad_norm": 3.237809896469116,
      "learning_rate": 6.691454371912974e-06,
      "loss": 0.0384,
      "step": 2682
    },
    {
      "epoch": 1.8226902173913042,
      "grad_norm": 0.003318357514217496,
      "learning_rate": 6.68474175030849e-06,
      "loss": 0.0001,
      "step": 2683
    },
    {
      "epoch": 1.8233695652173914,
      "grad_norm": 11.47435474395752,
      "learning_rate": 6.67803080657653e-06,
      "loss": 0.6019,
      "step": 2684
    },
    {
      "epoch": 1.8240489130434783,
      "grad_norm": 0.03112349845468998,
      "learning_rate": 6.6713215441135424e-06,
      "loss": 0.0003,
      "step": 2685
    },
    {
      "epoch": 1.8247282608695652,
      "grad_norm": 15.807125091552734,
      "learning_rate": 6.664613966315127e-06,
      "loss": 0.39,
      "step": 2686
    },
    {
      "epoch": 1.8254076086956523,
      "grad_norm": 4.288735866546631,
      "learning_rate": 6.657908076576028e-06,
      "loss": 0.1045,
      "step": 2687
    },
    {
      "epoch": 1.8260869565217392,
      "grad_norm": 0.09133842587471008,
      "learning_rate": 6.651203878290139e-06,
      "loss": 0.0008,
      "step": 2688
    },
    {
      "epoch": 1.8267663043478262,
      "grad_norm": 4.177285671234131,
      "learning_rate": 6.644501374850496e-06,
      "loss": 0.0814,
      "step": 2689
    },
    {
      "epoch": 1.827445652173913,
      "grad_norm": 0.005682783666998148,
      "learning_rate": 6.637800569649278e-06,
      "loss": 0.0001,
      "step": 2690
    },
    {
      "epoch": 1.828125,
      "grad_norm": 2.8745229244232178,
      "learning_rate": 6.631101466077801e-06,
      "loss": 0.0501,
      "step": 2691
    },
    {
      "epoch": 1.828804347826087,
      "grad_norm": 0.4333714544773102,
      "learning_rate": 6.624404067526524e-06,
      "loss": 0.0037,
      "step": 2692
    },
    {
      "epoch": 1.8294836956521738,
      "grad_norm": 5.2313761711120605,
      "learning_rate": 6.617708377385041e-06,
      "loss": 0.0796,
      "step": 2693
    },
    {
      "epoch": 1.8301630434782608,
      "grad_norm": 4.489380836486816,
      "learning_rate": 6.6110143990420824e-06,
      "loss": 0.11,
      "step": 2694
    },
    {
      "epoch": 1.8308423913043477,
      "grad_norm": 0.002102125668898225,
      "learning_rate": 6.604322135885513e-06,
      "loss": 0.0,
      "step": 2695
    },
    {
      "epoch": 1.8315217391304348,
      "grad_norm": 0.036095961928367615,
      "learning_rate": 6.597631591302319e-06,
      "loss": 0.0003,
      "step": 2696
    },
    {
      "epoch": 1.8322010869565217,
      "grad_norm": 0.004348674323409796,
      "learning_rate": 6.5909427686786386e-06,
      "loss": 0.0001,
      "step": 2697
    },
    {
      "epoch": 1.8328804347826086,
      "grad_norm": 7.656761169433594,
      "learning_rate": 6.584255671399722e-06,
      "loss": 0.0705,
      "step": 2698
    },
    {
      "epoch": 1.8335597826086958,
      "grad_norm": 0.02910781465470791,
      "learning_rate": 6.577570302849947e-06,
      "loss": 0.0002,
      "step": 2699
    },
    {
      "epoch": 1.8342391304347827,
      "grad_norm": 4.747783660888672,
      "learning_rate": 6.570886666412823e-06,
      "loss": 0.1144,
      "step": 2700
    },
    {
      "epoch": 1.8349184782608696,
      "grad_norm": 13.055370330810547,
      "learning_rate": 6.564204765470978e-06,
      "loss": 0.4508,
      "step": 2701
    },
    {
      "epoch": 1.8355978260869565,
      "grad_norm": 0.014705772511661053,
      "learning_rate": 6.557524603406162e-06,
      "loss": 0.0001,
      "step": 2702
    },
    {
      "epoch": 1.8362771739130435,
      "grad_norm": 6.966563701629639,
      "learning_rate": 6.550846183599249e-06,
      "loss": 0.0433,
      "step": 2703
    },
    {
      "epoch": 1.8369565217391304,
      "grad_norm": 12.280735969543457,
      "learning_rate": 6.544169509430219e-06,
      "loss": 0.1435,
      "step": 2704
    },
    {
      "epoch": 1.8376358695652173,
      "grad_norm": 6.529881477355957,
      "learning_rate": 6.53749458427819e-06,
      "loss": 0.2288,
      "step": 2705
    },
    {
      "epoch": 1.8383152173913042,
      "grad_norm": 0.12696439027786255,
      "learning_rate": 6.5308214115213785e-06,
      "loss": 0.0009,
      "step": 2706
    },
    {
      "epoch": 1.8389945652173914,
      "grad_norm": 0.07562077045440674,
      "learning_rate": 6.524149994537117e-06,
      "loss": 0.0004,
      "step": 2707
    },
    {
      "epoch": 1.8396739130434783,
      "grad_norm": 0.007141538895666599,
      "learning_rate": 6.5174803367018495e-06,
      "loss": 0.0001,
      "step": 2708
    },
    {
      "epoch": 1.8403532608695652,
      "grad_norm": 1.3091275691986084,
      "learning_rate": 6.510812441391131e-06,
      "loss": 0.0162,
      "step": 2709
    },
    {
      "epoch": 1.8410326086956523,
      "grad_norm": 14.449644088745117,
      "learning_rate": 6.504146311979627e-06,
      "loss": 0.3569,
      "step": 2710
    },
    {
      "epoch": 1.8417119565217392,
      "grad_norm": 6.1119818687438965,
      "learning_rate": 6.497481951841102e-06,
      "loss": 0.3515,
      "step": 2711
    },
    {
      "epoch": 1.8423913043478262,
      "grad_norm": 6.975770473480225,
      "learning_rate": 6.490819364348434e-06,
      "loss": 0.2835,
      "step": 2712
    },
    {
      "epoch": 1.843070652173913,
      "grad_norm": 8.670361518859863,
      "learning_rate": 6.484158552873594e-06,
      "loss": 0.2477,
      "step": 2713
    },
    {
      "epoch": 1.84375,
      "grad_norm": 12.035648345947266,
      "learning_rate": 6.4774995207876654e-06,
      "loss": 0.0569,
      "step": 2714
    },
    {
      "epoch": 1.844429347826087,
      "grad_norm": 10.308927536010742,
      "learning_rate": 6.470842271460823e-06,
      "loss": 0.3519,
      "step": 2715
    },
    {
      "epoch": 1.8451086956521738,
      "grad_norm": 0.2951275408267975,
      "learning_rate": 6.464186808262341e-06,
      "loss": 0.0017,
      "step": 2716
    },
    {
      "epoch": 1.8457880434782608,
      "grad_norm": 4.043630599975586,
      "learning_rate": 6.45753313456059e-06,
      "loss": 0.1385,
      "step": 2717
    },
    {
      "epoch": 1.8464673913043477,
      "grad_norm": 5.6732258796691895,
      "learning_rate": 6.450881253723035e-06,
      "loss": 0.2422,
      "step": 2718
    },
    {
      "epoch": 1.8471467391304348,
      "grad_norm": 0.01547796931117773,
      "learning_rate": 6.444231169116233e-06,
      "loss": 0.0002,
      "step": 2719
    },
    {
      "epoch": 1.8478260869565217,
      "grad_norm": 0.12389663606882095,
      "learning_rate": 6.437582884105835e-06,
      "loss": 0.0011,
      "step": 2720
    },
    {
      "epoch": 1.8485054347826086,
      "grad_norm": 3.347794771194458,
      "learning_rate": 6.430936402056577e-06,
      "loss": 0.1384,
      "step": 2721
    },
    {
      "epoch": 1.8491847826086958,
      "grad_norm": 21.890052795410156,
      "learning_rate": 6.42429172633228e-06,
      "loss": 0.1159,
      "step": 2722
    },
    {
      "epoch": 1.8498641304347827,
      "grad_norm": 6.148390293121338,
      "learning_rate": 6.417648860295864e-06,
      "loss": 0.0721,
      "step": 2723
    },
    {
      "epoch": 1.8505434782608696,
      "grad_norm": 0.003852379508316517,
      "learning_rate": 6.41100780730932e-06,
      "loss": 0.0001,
      "step": 2724
    },
    {
      "epoch": 1.8512228260869565,
      "grad_norm": 10.389286994934082,
      "learning_rate": 6.4043685707337255e-06,
      "loss": 0.0739,
      "step": 2725
    },
    {
      "epoch": 1.8519021739130435,
      "grad_norm": 4.358552932739258,
      "learning_rate": 6.397731153929239e-06,
      "loss": 0.1727,
      "step": 2726
    },
    {
      "epoch": 1.8525815217391304,
      "grad_norm": 4.49854850769043,
      "learning_rate": 6.391095560255098e-06,
      "loss": 0.2251,
      "step": 2727
    },
    {
      "epoch": 1.8532608695652173,
      "grad_norm": 0.27532312273979187,
      "learning_rate": 6.384461793069616e-06,
      "loss": 0.0017,
      "step": 2728
    },
    {
      "epoch": 1.8539402173913042,
      "grad_norm": 7.631682395935059,
      "learning_rate": 6.377829855730185e-06,
      "loss": 0.2505,
      "step": 2729
    },
    {
      "epoch": 1.8546195652173914,
      "grad_norm": 0.554280698299408,
      "learning_rate": 6.371199751593264e-06,
      "loss": 0.0035,
      "step": 2730
    },
    {
      "epoch": 1.8552989130434783,
      "grad_norm": 0.07047778367996216,
      "learning_rate": 6.3645714840143965e-06,
      "loss": 0.0005,
      "step": 2731
    },
    {
      "epoch": 1.8559782608695652,
      "grad_norm": 2.3465611934661865,
      "learning_rate": 6.3579450563481895e-06,
      "loss": 0.0346,
      "step": 2732
    },
    {
      "epoch": 1.8566576086956523,
      "grad_norm": 7.699043273925781,
      "learning_rate": 6.351320471948313e-06,
      "loss": 0.1921,
      "step": 2733
    },
    {
      "epoch": 1.8573369565217392,
      "grad_norm": 0.011751201935112476,
      "learning_rate": 6.3446977341675135e-06,
      "loss": 0.0002,
      "step": 2734
    },
    {
      "epoch": 1.8580163043478262,
      "grad_norm": 6.018198490142822,
      "learning_rate": 6.338076846357597e-06,
      "loss": 0.2572,
      "step": 2735
    },
    {
      "epoch": 1.858695652173913,
      "grad_norm": 1.4250481128692627,
      "learning_rate": 6.331457811869437e-06,
      "loss": 0.0145,
      "step": 2736
    },
    {
      "epoch": 1.859375,
      "grad_norm": 6.915332317352295,
      "learning_rate": 6.3248406340529665e-06,
      "loss": 0.2924,
      "step": 2737
    },
    {
      "epoch": 1.860054347826087,
      "grad_norm": 0.0016615198692306876,
      "learning_rate": 6.31822531625718e-06,
      "loss": 0.0,
      "step": 2738
    },
    {
      "epoch": 1.8607336956521738,
      "grad_norm": 3.045163869857788,
      "learning_rate": 6.311611861830129e-06,
      "loss": 0.1262,
      "step": 2739
    },
    {
      "epoch": 1.8614130434782608,
      "grad_norm": 0.003292346140369773,
      "learning_rate": 6.305000274118926e-06,
      "loss": 0.0001,
      "step": 2740
    },
    {
      "epoch": 1.8620923913043477,
      "grad_norm": 3.863529682159424,
      "learning_rate": 6.298390556469735e-06,
      "loss": 0.2148,
      "step": 2741
    },
    {
      "epoch": 1.8627717391304348,
      "grad_norm": 1.5153833627700806,
      "learning_rate": 6.291782712227776e-06,
      "loss": 0.0723,
      "step": 2742
    },
    {
      "epoch": 1.8634510869565217,
      "grad_norm": 2.0471792221069336,
      "learning_rate": 6.285176744737318e-06,
      "loss": 0.0532,
      "step": 2743
    },
    {
      "epoch": 1.8641304347826086,
      "grad_norm": 0.013633590191602707,
      "learning_rate": 6.278572657341682e-06,
      "loss": 0.0001,
      "step": 2744
    },
    {
      "epoch": 1.8648097826086958,
      "grad_norm": 3.812065362930298,
      "learning_rate": 6.271970453383235e-06,
      "loss": 0.0917,
      "step": 2745
    },
    {
      "epoch": 1.8654891304347827,
      "grad_norm": 1.4982357025146484,
      "learning_rate": 6.265370136203396e-06,
      "loss": 0.0076,
      "step": 2746
    },
    {
      "epoch": 1.8661684782608696,
      "grad_norm": 2.9132072925567627,
      "learning_rate": 6.258771709142623e-06,
      "loss": 0.0899,
      "step": 2747
    },
    {
      "epoch": 1.8668478260869565,
      "grad_norm": 0.008716835640370846,
      "learning_rate": 6.2521751755404226e-06,
      "loss": 0.0001,
      "step": 2748
    },
    {
      "epoch": 1.8675271739130435,
      "grad_norm": 0.05877775698900223,
      "learning_rate": 6.245580538735341e-06,
      "loss": 0.0005,
      "step": 2749
    },
    {
      "epoch": 1.8682065217391304,
      "grad_norm": 4.379317283630371,
      "learning_rate": 6.238987802064964e-06,
      "loss": 0.0411,
      "step": 2750
    },
    {
      "epoch": 1.8688858695652173,
      "grad_norm": 2.896345376968384,
      "learning_rate": 6.232396968865916e-06,
      "loss": 0.043,
      "step": 2751
    },
    {
      "epoch": 1.8695652173913042,
      "grad_norm": 3.0305988788604736,
      "learning_rate": 6.225808042473857e-06,
      "loss": 0.1334,
      "step": 2752
    },
    {
      "epoch": 1.8702445652173914,
      "grad_norm": 5.155493259429932,
      "learning_rate": 6.219221026223485e-06,
      "loss": 0.2243,
      "step": 2753
    },
    {
      "epoch": 1.8709239130434783,
      "grad_norm": 0.011717539280653,
      "learning_rate": 6.212635923448526e-06,
      "loss": 0.0001,
      "step": 2754
    },
    {
      "epoch": 1.8716032608695652,
      "grad_norm": 6.953956604003906,
      "learning_rate": 6.2060527374817455e-06,
      "loss": 0.092,
      "step": 2755
    },
    {
      "epoch": 1.8722826086956523,
      "grad_norm": 0.017672214657068253,
      "learning_rate": 6.199471471654928e-06,
      "loss": 0.0002,
      "step": 2756
    },
    {
      "epoch": 1.8729619565217392,
      "grad_norm": 0.014330698177218437,
      "learning_rate": 6.192892129298898e-06,
      "loss": 0.0002,
      "step": 2757
    },
    {
      "epoch": 1.8736413043478262,
      "grad_norm": 20.415254592895508,
      "learning_rate": 6.1863147137435e-06,
      "loss": 0.2427,
      "step": 2758
    },
    {
      "epoch": 1.874320652173913,
      "grad_norm": 0.002886667614802718,
      "learning_rate": 6.179739228317605e-06,
      "loss": 0.0001,
      "step": 2759
    },
    {
      "epoch": 1.875,
      "grad_norm": 7.215925216674805,
      "learning_rate": 6.173165676349103e-06,
      "loss": 0.2069,
      "step": 2760
    },
    {
      "epoch": 1.875679347826087,
      "grad_norm": 0.9589666128158569,
      "learning_rate": 6.166594061164912e-06,
      "loss": 0.0078,
      "step": 2761
    },
    {
      "epoch": 1.8763586956521738,
      "grad_norm": 4.5291666984558105,
      "learning_rate": 6.160024386090966e-06,
      "loss": 0.0861,
      "step": 2762
    },
    {
      "epoch": 1.8770380434782608,
      "grad_norm": 2.881518840789795,
      "learning_rate": 6.1534566544522175e-06,
      "loss": 0.0413,
      "step": 2763
    },
    {
      "epoch": 1.8777173913043477,
      "grad_norm": 0.19780083000659943,
      "learning_rate": 6.146890869572637e-06,
      "loss": 0.0014,
      "step": 2764
    },
    {
      "epoch": 1.8783967391304348,
      "grad_norm": 0.007493575103580952,
      "learning_rate": 6.140327034775202e-06,
      "loss": 0.0001,
      "step": 2765
    },
    {
      "epoch": 1.8790760869565217,
      "grad_norm": 0.06888635456562042,
      "learning_rate": 6.133765153381918e-06,
      "loss": 0.0004,
      "step": 2766
    },
    {
      "epoch": 1.8797554347826086,
      "grad_norm": 5.936429977416992,
      "learning_rate": 6.127205228713791e-06,
      "loss": 0.1224,
      "step": 2767
    },
    {
      "epoch": 1.8804347826086958,
      "grad_norm": 1.3103468418121338,
      "learning_rate": 6.120647264090839e-06,
      "loss": 0.015,
      "step": 2768
    },
    {
      "epoch": 1.8811141304347827,
      "grad_norm": 2.6327500343322754,
      "learning_rate": 6.114091262832087e-06,
      "loss": 0.0681,
      "step": 2769
    },
    {
      "epoch": 1.8817934782608696,
      "grad_norm": 3.172738790512085,
      "learning_rate": 6.107537228255568e-06,
      "loss": 0.1486,
      "step": 2770
    },
    {
      "epoch": 1.8824728260869565,
      "grad_norm": 5.739631652832031,
      "learning_rate": 6.100985163678319e-06,
      "loss": 0.0895,
      "step": 2771
    },
    {
      "epoch": 1.8831521739130435,
      "grad_norm": 0.024737035855650902,
      "learning_rate": 6.094435072416379e-06,
      "loss": 0.0002,
      "step": 2772
    },
    {
      "epoch": 1.8838315217391304,
      "grad_norm": 0.7251911759376526,
      "learning_rate": 6.08788695778479e-06,
      "loss": 0.0045,
      "step": 2773
    },
    {
      "epoch": 1.8845108695652173,
      "grad_norm": 8.79443359375,
      "learning_rate": 6.0813408230975935e-06,
      "loss": 0.2549,
      "step": 2774
    },
    {
      "epoch": 1.8851902173913042,
      "grad_norm": 0.15472817420959473,
      "learning_rate": 6.074796671667829e-06,
      "loss": 0.0012,
      "step": 2775
    },
    {
      "epoch": 1.8858695652173914,
      "grad_norm": 0.02035357616841793,
      "learning_rate": 6.0682545068075315e-06,
      "loss": 0.0002,
      "step": 2776
    },
    {
      "epoch": 1.8865489130434783,
      "grad_norm": 10.871750831604004,
      "learning_rate": 6.0617143318277286e-06,
      "loss": 0.253,
      "step": 2777
    },
    {
      "epoch": 1.8872282608695652,
      "grad_norm": 0.003092620987445116,
      "learning_rate": 6.055176150038445e-06,
      "loss": 0.0001,
      "step": 2778
    },
    {
      "epoch": 1.8879076086956523,
      "grad_norm": 0.010741215199232101,
      "learning_rate": 6.048639964748695e-06,
      "loss": 0.0001,
      "step": 2779
    },
    {
      "epoch": 1.8885869565217392,
      "grad_norm": 4.434147357940674,
      "learning_rate": 6.042105779266479e-06,
      "loss": 0.1442,
      "step": 2780
    },
    {
      "epoch": 1.8892663043478262,
      "grad_norm": 8.895551681518555,
      "learning_rate": 6.035573596898789e-06,
      "loss": 0.0789,
      "step": 2781
    },
    {
      "epoch": 1.889945652173913,
      "grad_norm": 1.838424801826477,
      "learning_rate": 6.029043420951606e-06,
      "loss": 0.0215,
      "step": 2782
    },
    {
      "epoch": 1.890625,
      "grad_norm": 0.0019171229796484113,
      "learning_rate": 6.02251525472989e-06,
      "loss": 0.0,
      "step": 2783
    },
    {
      "epoch": 1.891304347826087,
      "grad_norm": 9.305395126342773,
      "learning_rate": 6.015989101537586e-06,
      "loss": 0.2984,
      "step": 2784
    },
    {
      "epoch": 1.8919836956521738,
      "grad_norm": 18.69133186340332,
      "learning_rate": 6.009464964677621e-06,
      "loss": 0.6096,
      "step": 2785
    },
    {
      "epoch": 1.8926630434782608,
      "grad_norm": 0.1199147030711174,
      "learning_rate": 6.002942847451898e-06,
      "loss": 0.0008,
      "step": 2786
    },
    {
      "epoch": 1.8933423913043477,
      "grad_norm": 2.633166551589966,
      "learning_rate": 5.996422753161304e-06,
      "loss": 0.0937,
      "step": 2787
    },
    {
      "epoch": 1.8940217391304348,
      "grad_norm": 0.20974840223789215,
      "learning_rate": 5.989904685105696e-06,
      "loss": 0.0013,
      "step": 2788
    },
    {
      "epoch": 1.8947010869565217,
      "grad_norm": 0.07578311860561371,
      "learning_rate": 5.98338864658391e-06,
      "loss": 0.0007,
      "step": 2789
    },
    {
      "epoch": 1.8953804347826086,
      "grad_norm": 0.1165102943778038,
      "learning_rate": 5.976874640893751e-06,
      "loss": 0.0006,
      "step": 2790
    },
    {
      "epoch": 1.8960597826086958,
      "grad_norm": 0.003074966138228774,
      "learning_rate": 5.970362671331995e-06,
      "loss": 0.0001,
      "step": 2791
    },
    {
      "epoch": 1.8967391304347827,
      "grad_norm": 9.53536319732666,
      "learning_rate": 5.963852741194397e-06,
      "loss": 0.1873,
      "step": 2792
    },
    {
      "epoch": 1.8974184782608696,
      "grad_norm": 1.7335450649261475,
      "learning_rate": 5.957344853775668e-06,
      "loss": 0.0407,
      "step": 2793
    },
    {
      "epoch": 1.8980978260869565,
      "grad_norm": 0.005532523151487112,
      "learning_rate": 5.950839012369491e-06,
      "loss": 0.0001,
      "step": 2794
    },
    {
      "epoch": 1.8987771739130435,
      "grad_norm": 0.003279435448348522,
      "learning_rate": 5.944335220268512e-06,
      "loss": 0.0001,
      "step": 2795
    },
    {
      "epoch": 1.8994565217391304,
      "grad_norm": 17.358802795410156,
      "learning_rate": 5.937833480764339e-06,
      "loss": 0.3075,
      "step": 2796
    },
    {
      "epoch": 1.9001358695652173,
      "grad_norm": 4.152987003326416,
      "learning_rate": 5.931333797147543e-06,
      "loss": 0.1748,
      "step": 2797
    },
    {
      "epoch": 1.9008152173913042,
      "grad_norm": 6.470384120941162,
      "learning_rate": 5.924836172707653e-06,
      "loss": 0.3189,
      "step": 2798
    },
    {
      "epoch": 1.9014945652173914,
      "grad_norm": 9.35305118560791,
      "learning_rate": 5.918340610733154e-06,
      "loss": 0.09,
      "step": 2799
    },
    {
      "epoch": 1.9021739130434783,
      "grad_norm": 0.032442107796669006,
      "learning_rate": 5.911847114511497e-06,
      "loss": 0.0002,
      "step": 2800
    },
    {
      "epoch": 1.9028532608695652,
      "grad_norm": 6.405269622802734,
      "learning_rate": 5.905355687329075e-06,
      "loss": 0.2529,
      "step": 2801
    },
    {
      "epoch": 1.9035326086956523,
      "grad_norm": 0.5229997038841248,
      "learning_rate": 5.898866332471241e-06,
      "loss": 0.0033,
      "step": 2802
    },
    {
      "epoch": 1.9042119565217392,
      "grad_norm": 9.997830390930176,
      "learning_rate": 5.892379053222297e-06,
      "loss": 0.218,
      "step": 2803
    },
    {
      "epoch": 1.9048913043478262,
      "grad_norm": 1.2530298233032227,
      "learning_rate": 5.8858938528654915e-06,
      "loss": 0.0228,
      "step": 2804
    },
    {
      "epoch": 1.905570652173913,
      "grad_norm": 4.811936855316162,
      "learning_rate": 5.87941073468303e-06,
      "loss": 0.0408,
      "step": 2805
    },
    {
      "epoch": 1.90625,
      "grad_norm": 3.1354568004608154,
      "learning_rate": 5.872929701956054e-06,
      "loss": 0.1979,
      "step": 2806
    },
    {
      "epoch": 1.906929347826087,
      "grad_norm": 2.660416841506958,
      "learning_rate": 5.866450757964656e-06,
      "loss": 0.0781,
      "step": 2807
    },
    {
      "epoch": 1.9076086956521738,
      "grad_norm": 7.469629764556885,
      "learning_rate": 5.859973905987866e-06,
      "loss": 0.3618,
      "step": 2808
    },
    {
      "epoch": 1.9082880434782608,
      "grad_norm": 0.013907022774219513,
      "learning_rate": 5.853499149303662e-06,
      "loss": 0.0002,
      "step": 2809
    },
    {
      "epoch": 1.9089673913043477,
      "grad_norm": 0.0015347037697210908,
      "learning_rate": 5.8470264911889575e-06,
      "loss": 0.0,
      "step": 2810
    },
    {
      "epoch": 1.9096467391304348,
      "grad_norm": 1.1508978605270386,
      "learning_rate": 5.840555934919604e-06,
      "loss": 0.007,
      "step": 2811
    },
    {
      "epoch": 1.9103260869565217,
      "grad_norm": 3.921877861022949,
      "learning_rate": 5.83408748377039e-06,
      "loss": 0.0855,
      "step": 2812
    },
    {
      "epoch": 1.9110054347826086,
      "grad_norm": 4.514632225036621,
      "learning_rate": 5.827621141015034e-06,
      "loss": 0.0373,
      "step": 2813
    },
    {
      "epoch": 1.9116847826086958,
      "grad_norm": 0.00746467849239707,
      "learning_rate": 5.821156909926202e-06,
      "loss": 0.0001,
      "step": 2814
    },
    {
      "epoch": 1.9123641304347827,
      "grad_norm": 0.11537756025791168,
      "learning_rate": 5.814694793775469e-06,
      "loss": 0.0009,
      "step": 2815
    },
    {
      "epoch": 1.9130434782608696,
      "grad_norm": 6.490163803100586,
      "learning_rate": 5.8082347958333625e-06,
      "loss": 0.1462,
      "step": 2816
    },
    {
      "epoch": 1.9137228260869565,
      "grad_norm": 18.78474998474121,
      "learning_rate": 5.801776919369317e-06,
      "loss": 0.3,
      "step": 2817
    },
    {
      "epoch": 1.9144021739130435,
      "grad_norm": 0.0467756949365139,
      "learning_rate": 5.7953211676517085e-06,
      "loss": 0.0004,
      "step": 2818
    },
    {
      "epoch": 1.9150815217391304,
      "grad_norm": 0.00917901936918497,
      "learning_rate": 5.788867543947832e-06,
      "loss": 0.0001,
      "step": 2819
    },
    {
      "epoch": 1.9157608695652173,
      "grad_norm": 4.1013712882995605,
      "learning_rate": 5.782416051523909e-06,
      "loss": 0.2011,
      "step": 2820
    },
    {
      "epoch": 1.9164402173913042,
      "grad_norm": 3.006469964981079,
      "learning_rate": 5.7759666936450745e-06,
      "loss": 0.0536,
      "step": 2821
    },
    {
      "epoch": 1.9171195652173914,
      "grad_norm": 0.2041993886232376,
      "learning_rate": 5.769519473575391e-06,
      "loss": 0.0012,
      "step": 2822
    },
    {
      "epoch": 1.9177989130434783,
      "grad_norm": 1.4268327951431274,
      "learning_rate": 5.763074394577835e-06,
      "loss": 0.0073,
      "step": 2823
    },
    {
      "epoch": 1.9184782608695652,
      "grad_norm": 4.786184787750244,
      "learning_rate": 5.756631459914302e-06,
      "loss": 0.1362,
      "step": 2824
    },
    {
      "epoch": 1.9191576086956523,
      "grad_norm": 2.1413047313690186,
      "learning_rate": 5.750190672845596e-06,
      "loss": 0.0147,
      "step": 2825
    },
    {
      "epoch": 1.9198369565217392,
      "grad_norm": 4.751951694488525,
      "learning_rate": 5.743752036631443e-06,
      "loss": 0.2089,
      "step": 2826
    },
    {
      "epoch": 1.9205163043478262,
      "grad_norm": 8.863801956176758,
      "learning_rate": 5.7373155545304785e-06,
      "loss": 0.1234,
      "step": 2827
    },
    {
      "epoch": 1.921195652173913,
      "grad_norm": 0.636947751045227,
      "learning_rate": 5.730881229800238e-06,
      "loss": 0.0035,
      "step": 2828
    },
    {
      "epoch": 1.921875,
      "grad_norm": 2.7817959785461426,
      "learning_rate": 5.724449065697182e-06,
      "loss": 0.1351,
      "step": 2829
    },
    {
      "epoch": 1.922554347826087,
      "grad_norm": 0.03310428932309151,
      "learning_rate": 5.718019065476659e-06,
      "loss": 0.0003,
      "step": 2830
    },
    {
      "epoch": 1.9232336956521738,
      "grad_norm": 2.24236798286438,
      "learning_rate": 5.71159123239294e-06,
      "loss": 0.0705,
      "step": 2831
    },
    {
      "epoch": 1.9239130434782608,
      "grad_norm": 6.2523040771484375,
      "learning_rate": 5.7051655696991825e-06,
      "loss": 0.1894,
      "step": 2832
    },
    {
      "epoch": 1.9245923913043477,
      "grad_norm": 0.7069312334060669,
      "learning_rate": 5.698742080647462e-06,
      "loss": 0.0059,
      "step": 2833
    },
    {
      "epoch": 1.9252717391304348,
      "grad_norm": 17.067190170288086,
      "learning_rate": 5.692320768488735e-06,
      "loss": 0.3659,
      "step": 2834
    },
    {
      "epoch": 1.9259510869565217,
      "grad_norm": 1.7069748640060425,
      "learning_rate": 5.6859016364728795e-06,
      "loss": 0.0636,
      "step": 2835
    },
    {
      "epoch": 1.9266304347826086,
      "grad_norm": 2.887843132019043,
      "learning_rate": 5.679484687848649e-06,
      "loss": 0.0577,
      "step": 2836
    },
    {
      "epoch": 1.9273097826086958,
      "grad_norm": 1.6764631271362305,
      "learning_rate": 5.673069925863706e-06,
      "loss": 0.0146,
      "step": 2837
    },
    {
      "epoch": 1.9279891304347827,
      "grad_norm": 1.9058382511138916,
      "learning_rate": 5.666657353764594e-06,
      "loss": 0.0289,
      "step": 2838
    },
    {
      "epoch": 1.9286684782608696,
      "grad_norm": 3.5675277709960938,
      "learning_rate": 5.660246974796764e-06,
      "loss": 0.0461,
      "step": 2839
    },
    {
      "epoch": 1.9293478260869565,
      "grad_norm": 20.21151351928711,
      "learning_rate": 5.653838792204538e-06,
      "loss": 0.0716,
      "step": 2840
    },
    {
      "epoch": 1.9300271739130435,
      "grad_norm": 6.970007419586182,
      "learning_rate": 5.647432809231147e-06,
      "loss": 0.1219,
      "step": 2841
    },
    {
      "epoch": 1.9307065217391304,
      "grad_norm": 1.2254197597503662,
      "learning_rate": 5.641029029118685e-06,
      "loss": 0.0256,
      "step": 2842
    },
    {
      "epoch": 1.9313858695652173,
      "grad_norm": 0.37047386169433594,
      "learning_rate": 5.634627455108158e-06,
      "loss": 0.0021,
      "step": 2843
    },
    {
      "epoch": 1.9320652173913042,
      "grad_norm": 0.00869323592633009,
      "learning_rate": 5.628228090439434e-06,
      "loss": 0.0001,
      "step": 2844
    },
    {
      "epoch": 1.9327445652173914,
      "grad_norm": 1.8822317123413086,
      "learning_rate": 5.621830938351276e-06,
      "loss": 0.0449,
      "step": 2845
    },
    {
      "epoch": 1.9334239130434783,
      "grad_norm": 0.8101195096969604,
      "learning_rate": 5.615436002081316e-06,
      "loss": 0.0085,
      "step": 2846
    },
    {
      "epoch": 1.9341032608695652,
      "grad_norm": 6.545107841491699,
      "learning_rate": 5.609043284866076e-06,
      "loss": 0.0857,
      "step": 2847
    },
    {
      "epoch": 1.9347826086956523,
      "grad_norm": 3.6143016815185547,
      "learning_rate": 5.602652789940941e-06,
      "loss": 0.0621,
      "step": 2848
    },
    {
      "epoch": 1.9354619565217392,
      "grad_norm": 10.611001014709473,
      "learning_rate": 5.596264520540191e-06,
      "loss": 0.3037,
      "step": 2849
    },
    {
      "epoch": 1.9361413043478262,
      "grad_norm": 6.376399040222168,
      "learning_rate": 5.589878479896959e-06,
      "loss": 0.2278,
      "step": 2850
    },
    {
      "epoch": 1.936820652173913,
      "grad_norm": 0.7404183149337769,
      "learning_rate": 5.583494671243262e-06,
      "loss": 0.0151,
      "step": 2851
    },
    {
      "epoch": 1.9375,
      "grad_norm": 1.5165250301361084,
      "learning_rate": 5.5771130978099896e-06,
      "loss": 0.0298,
      "step": 2852
    },
    {
      "epoch": 1.938179347826087,
      "grad_norm": 28.9543514251709,
      "learning_rate": 5.5707337628268864e-06,
      "loss": 0.1794,
      "step": 2853
    },
    {
      "epoch": 1.9388586956521738,
      "grad_norm": 0.04425022006034851,
      "learning_rate": 5.564356669522581e-06,
      "loss": 0.0003,
      "step": 2854
    },
    {
      "epoch": 1.9395380434782608,
      "grad_norm": 8.916367530822754,
      "learning_rate": 5.557981821124554e-06,
      "loss": 0.1798,
      "step": 2855
    },
    {
      "epoch": 1.9402173913043477,
      "grad_norm": 2.3493995666503906,
      "learning_rate": 5.55160922085916e-06,
      "loss": 0.0407,
      "step": 2856
    },
    {
      "epoch": 1.9408967391304348,
      "grad_norm": 2.4708504676818848,
      "learning_rate": 5.545238871951606e-06,
      "loss": 0.0536,
      "step": 2857
    },
    {
      "epoch": 1.9415760869565217,
      "grad_norm": 0.01775096356868744,
      "learning_rate": 5.538870777625969e-06,
      "loss": 0.0001,
      "step": 2858
    },
    {
      "epoch": 1.9422554347826086,
      "grad_norm": 14.396418571472168,
      "learning_rate": 5.532504941105176e-06,
      "loss": 0.1688,
      "step": 2859
    },
    {
      "epoch": 1.9429347826086958,
      "grad_norm": 0.041338659822940826,
      "learning_rate": 5.526141365611018e-06,
      "loss": 0.0002,
      "step": 2860
    },
    {
      "epoch": 1.9436141304347827,
      "grad_norm": 0.004027632065117359,
      "learning_rate": 5.5197800543641385e-06,
      "loss": 0.0,
      "step": 2861
    },
    {
      "epoch": 1.9442934782608696,
      "grad_norm": 6.655297756195068,
      "learning_rate": 5.513421010584044e-06,
      "loss": 0.0695,
      "step": 2862
    },
    {
      "epoch": 1.9449728260869565,
      "grad_norm": 0.0018759854137897491,
      "learning_rate": 5.507064237489075e-06,
      "loss": 0.0,
      "step": 2863
    },
    {
      "epoch": 1.9456521739130435,
      "grad_norm": 0.01120887789875269,
      "learning_rate": 5.50070973829644e-06,
      "loss": 0.0001,
      "step": 2864
    },
    {
      "epoch": 1.9463315217391304,
      "grad_norm": 1.3777130842208862,
      "learning_rate": 5.494357516222184e-06,
      "loss": 0.017,
      "step": 2865
    },
    {
      "epoch": 1.9470108695652173,
      "grad_norm": 2.5011682510375977,
      "learning_rate": 5.488007574481213e-06,
      "loss": 0.1066,
      "step": 2866
    },
    {
      "epoch": 1.9476902173913042,
      "grad_norm": 0.23252494633197784,
      "learning_rate": 5.481659916287264e-06,
      "loss": 0.0016,
      "step": 2867
    },
    {
      "epoch": 1.9483695652173914,
      "grad_norm": 1.8310221433639526,
      "learning_rate": 5.4753145448529284e-06,
      "loss": 0.0241,
      "step": 2868
    },
    {
      "epoch": 1.9490489130434783,
      "grad_norm": 0.45260775089263916,
      "learning_rate": 5.468971463389639e-06,
      "loss": 0.004,
      "step": 2869
    },
    {
      "epoch": 1.9497282608695652,
      "grad_norm": 8.900426864624023,
      "learning_rate": 5.462630675107672e-06,
      "loss": 0.1545,
      "step": 2870
    },
    {
      "epoch": 1.9504076086956523,
      "grad_norm": 10.184578895568848,
      "learning_rate": 5.45629218321613e-06,
      "loss": 0.2328,
      "step": 2871
    },
    {
      "epoch": 1.9510869565217392,
      "grad_norm": 2.2480790615081787,
      "learning_rate": 5.449955990922973e-06,
      "loss": 0.0422,
      "step": 2872
    },
    {
      "epoch": 1.9517663043478262,
      "grad_norm": 2.683558225631714,
      "learning_rate": 5.4436221014349754e-06,
      "loss": 0.0461,
      "step": 2873
    },
    {
      "epoch": 1.952445652173913,
      "grad_norm": 8.161307334899902,
      "learning_rate": 5.437290517957767e-06,
      "loss": 0.0704,
      "step": 2874
    },
    {
      "epoch": 1.953125,
      "grad_norm": 4.140202522277832,
      "learning_rate": 5.430961243695794e-06,
      "loss": 0.1744,
      "step": 2875
    },
    {
      "epoch": 1.953804347826087,
      "grad_norm": 6.648980617523193,
      "learning_rate": 5.424634281852348e-06,
      "loss": 0.2211,
      "step": 2876
    },
    {
      "epoch": 1.9544836956521738,
      "grad_norm": 4.548921585083008,
      "learning_rate": 5.418309635629536e-06,
      "loss": 0.0295,
      "step": 2877
    },
    {
      "epoch": 1.9551630434782608,
      "grad_norm": 6.809443473815918,
      "learning_rate": 5.4119873082283035e-06,
      "loss": 0.167,
      "step": 2878
    },
    {
      "epoch": 1.9558423913043477,
      "grad_norm": 0.03881537914276123,
      "learning_rate": 5.405667302848419e-06,
      "loss": 0.0004,
      "step": 2879
    },
    {
      "epoch": 1.9565217391304348,
      "grad_norm": 0.005253975745290518,
      "learning_rate": 5.399349622688479e-06,
      "loss": 0.0001,
      "step": 2880
    },
    {
      "epoch": 1.9572010869565217,
      "grad_norm": 12.642784118652344,
      "learning_rate": 5.393034270945895e-06,
      "loss": 0.2648,
      "step": 2881
    },
    {
      "epoch": 1.9578804347826086,
      "grad_norm": 20.204017639160156,
      "learning_rate": 5.386721250816911e-06,
      "loss": 0.5355,
      "step": 2882
    },
    {
      "epoch": 1.9585597826086958,
      "grad_norm": 4.182158470153809,
      "learning_rate": 5.3804105654965784e-06,
      "loss": 0.2184,
      "step": 2883
    },
    {
      "epoch": 1.9592391304347827,
      "grad_norm": 3.094672203063965,
      "learning_rate": 5.374102218178781e-06,
      "loss": 0.1794,
      "step": 2884
    },
    {
      "epoch": 1.9599184782608696,
      "grad_norm": 11.173582077026367,
      "learning_rate": 5.367796212056202e-06,
      "loss": 0.3318,
      "step": 2885
    },
    {
      "epoch": 1.9605978260869565,
      "grad_norm": 0.8914089202880859,
      "learning_rate": 5.3614925503203586e-06,
      "loss": 0.0066,
      "step": 2886
    },
    {
      "epoch": 1.9612771739130435,
      "grad_norm": 3.875246286392212,
      "learning_rate": 5.355191236161572e-06,
      "loss": 0.0465,
      "step": 2887
    },
    {
      "epoch": 1.9619565217391304,
      "grad_norm": 14.315381050109863,
      "learning_rate": 5.348892272768972e-06,
      "loss": 0.1915,
      "step": 2888
    },
    {
      "epoch": 1.9626358695652173,
      "grad_norm": 6.7381672859191895,
      "learning_rate": 5.3425956633305075e-06,
      "loss": 0.0987,
      "step": 2889
    },
    {
      "epoch": 1.9633152173913042,
      "grad_norm": 4.4950337409973145,
      "learning_rate": 5.336301411032923e-06,
      "loss": 0.2325,
      "step": 2890
    },
    {
      "epoch": 1.9639945652173914,
      "grad_norm": 4.531582832336426,
      "learning_rate": 5.330009519061789e-06,
      "loss": 0.2325,
      "step": 2891
    },
    {
      "epoch": 1.9646739130434783,
      "grad_norm": 4.97646427154541,
      "learning_rate": 5.323719990601459e-06,
      "loss": 0.2389,
      "step": 2892
    },
    {
      "epoch": 1.9653532608695652,
      "grad_norm": 2.931668996810913,
      "learning_rate": 5.317432828835114e-06,
      "loss": 0.0822,
      "step": 2893
    },
    {
      "epoch": 1.9660326086956523,
      "grad_norm": 2.2589409351348877,
      "learning_rate": 5.311148036944709e-06,
      "loss": 0.0538,
      "step": 2894
    },
    {
      "epoch": 1.9667119565217392,
      "grad_norm": 0.012872407212853432,
      "learning_rate": 5.304865618111034e-06,
      "loss": 0.0001,
      "step": 2895
    },
    {
      "epoch": 1.9673913043478262,
      "grad_norm": 4.442212104797363,
      "learning_rate": 5.298585575513649e-06,
      "loss": 0.1526,
      "step": 2896
    },
    {
      "epoch": 1.968070652173913,
      "grad_norm": 4.225610256195068,
      "learning_rate": 5.292307912330925e-06,
      "loss": 0.1911,
      "step": 2897
    },
    {
      "epoch": 1.96875,
      "grad_norm": 0.3824557065963745,
      "learning_rate": 5.286032631740023e-06,
      "loss": 0.0025,
      "step": 2898
    },
    {
      "epoch": 1.969429347826087,
      "grad_norm": 3.622748374938965,
      "learning_rate": 5.2797597369169075e-06,
      "loss": 0.1432,
      "step": 2899
    },
    {
      "epoch": 1.9701086956521738,
      "grad_norm": 0.00804605707526207,
      "learning_rate": 5.273489231036321e-06,
      "loss": 0.0002,
      "step": 2900
    },
    {
      "epoch": 1.9707880434782608,
      "grad_norm": 0.0056015197187662125,
      "learning_rate": 5.267221117271812e-06,
      "loss": 0.0001,
      "step": 2901
    },
    {
      "epoch": 1.9714673913043477,
      "grad_norm": 11.187681198120117,
      "learning_rate": 5.260955398795704e-06,
      "loss": 0.1784,
      "step": 2902
    },
    {
      "epoch": 1.9721467391304348,
      "grad_norm": 3.3744099140167236,
      "learning_rate": 5.254692078779118e-06,
      "loss": 0.0635,
      "step": 2903
    },
    {
      "epoch": 1.9728260869565217,
      "grad_norm": 16.242359161376953,
      "learning_rate": 5.248431160391963e-06,
      "loss": 0.4206,
      "step": 2904
    },
    {
      "epoch": 1.9735054347826086,
      "grad_norm": 0.003887329949066043,
      "learning_rate": 5.242172646802927e-06,
      "loss": 0.0001,
      "step": 2905
    },
    {
      "epoch": 1.9741847826086958,
      "grad_norm": 0.003049412975087762,
      "learning_rate": 5.235916541179477e-06,
      "loss": 0.0001,
      "step": 2906
    },
    {
      "epoch": 1.9748641304347827,
      "grad_norm": 0.02706819586455822,
      "learning_rate": 5.229662846687873e-06,
      "loss": 0.0003,
      "step": 2907
    },
    {
      "epoch": 1.9755434782608696,
      "grad_norm": 0.005207757465541363,
      "learning_rate": 5.223411566493141e-06,
      "loss": 0.0001,
      "step": 2908
    },
    {
      "epoch": 1.9762228260869565,
      "grad_norm": 0.059256039559841156,
      "learning_rate": 5.217162703759102e-06,
      "loss": 0.0004,
      "step": 2909
    },
    {
      "epoch": 1.9769021739130435,
      "grad_norm": 0.0076368702575564384,
      "learning_rate": 5.2109162616483325e-06,
      "loss": 0.0001,
      "step": 2910
    },
    {
      "epoch": 1.9775815217391304,
      "grad_norm": 0.018061436712741852,
      "learning_rate": 5.2046722433222e-06,
      "loss": 0.0002,
      "step": 2911
    },
    {
      "epoch": 1.9782608695652173,
      "grad_norm": 0.05641765147447586,
      "learning_rate": 5.198430651940846e-06,
      "loss": 0.0003,
      "step": 2912
    },
    {
      "epoch": 1.9789402173913042,
      "grad_norm": 3.3876850605010986,
      "learning_rate": 5.192191490663168e-06,
      "loss": 0.0999,
      "step": 2913
    },
    {
      "epoch": 1.9796195652173914,
      "grad_norm": 4.783834934234619,
      "learning_rate": 5.1859547626468545e-06,
      "loss": 0.1511,
      "step": 2914
    },
    {
      "epoch": 1.9802989130434783,
      "grad_norm": 0.0023006736300885677,
      "learning_rate": 5.179720471048341e-06,
      "loss": 0.0001,
      "step": 2915
    },
    {
      "epoch": 1.9809782608695652,
      "grad_norm": 0.004467957187443972,
      "learning_rate": 5.1734886190228496e-06,
      "loss": 0.0001,
      "step": 2916
    },
    {
      "epoch": 1.9816576086956523,
      "grad_norm": 2.4976296424865723,
      "learning_rate": 5.1672592097243515e-06,
      "loss": 0.1032,
      "step": 2917
    },
    {
      "epoch": 1.9823369565217392,
      "grad_norm": 3.049182415008545,
      "learning_rate": 5.161032246305597e-06,
      "loss": 0.0448,
      "step": 2918
    },
    {
      "epoch": 1.9830163043478262,
      "grad_norm": 1.603494644165039,
      "learning_rate": 5.154807731918081e-06,
      "loss": 0.0263,
      "step": 2919
    },
    {
      "epoch": 1.983695652173913,
      "grad_norm": 0.5490929484367371,
      "learning_rate": 5.148585669712074e-06,
      "loss": 0.0042,
      "step": 2920
    },
    {
      "epoch": 1.984375,
      "grad_norm": 4.456130504608154,
      "learning_rate": 5.142366062836599e-06,
      "loss": 0.1287,
      "step": 2921
    },
    {
      "epoch": 1.985054347826087,
      "grad_norm": 0.10792739689350128,
      "learning_rate": 5.136148914439441e-06,
      "loss": 0.0007,
      "step": 2922
    },
    {
      "epoch": 1.9857336956521738,
      "grad_norm": 2.8352396488189697,
      "learning_rate": 5.1299342276671295e-06,
      "loss": 0.1153,
      "step": 2923
    },
    {
      "epoch": 1.9864130434782608,
      "grad_norm": 6.833130836486816,
      "learning_rate": 5.123722005664964e-06,
      "loss": 0.3709,
      "step": 2924
    },
    {
      "epoch": 1.9870923913043477,
      "grad_norm": 6.179580211639404,
      "learning_rate": 5.117512251576978e-06,
      "loss": 0.2702,
      "step": 2925
    },
    {
      "epoch": 1.9877717391304348,
      "grad_norm": 0.06089547276496887,
      "learning_rate": 5.111304968545976e-06,
      "loss": 0.0007,
      "step": 2926
    },
    {
      "epoch": 1.9884510869565217,
      "grad_norm": 2.0223026275634766,
      "learning_rate": 5.105100159713494e-06,
      "loss": 0.0109,
      "step": 2927
    },
    {
      "epoch": 1.9891304347826086,
      "grad_norm": 0.6069810390472412,
      "learning_rate": 5.098897828219831e-06,
      "loss": 0.0043,
      "step": 2928
    },
    {
      "epoch": 1.9898097826086958,
      "grad_norm": 3.169977903366089,
      "learning_rate": 5.092697977204016e-06,
      "loss": 0.025,
      "step": 2929
    },
    {
      "epoch": 1.9904891304347827,
      "grad_norm": 6.086213111877441,
      "learning_rate": 5.086500609803841e-06,
      "loss": 0.2024,
      "step": 2930
    },
    {
      "epoch": 1.9911684782608696,
      "grad_norm": 3.171619176864624,
      "learning_rate": 5.0803057291558255e-06,
      "loss": 0.1034,
      "step": 2931
    },
    {
      "epoch": 1.9918478260869565,
      "grad_norm": 4.095905780792236,
      "learning_rate": 5.074113338395241e-06,
      "loss": 0.1137,
      "step": 2932
    },
    {
      "epoch": 1.9925271739130435,
      "grad_norm": 3.1014909744262695,
      "learning_rate": 5.06792344065609e-06,
      "loss": 0.1539,
      "step": 2933
    },
    {
      "epoch": 1.9932065217391304,
      "grad_norm": 0.11083365231752396,
      "learning_rate": 5.061736039071124e-06,
      "loss": 0.0008,
      "step": 2934
    },
    {
      "epoch": 1.9938858695652173,
      "grad_norm": 5.452953338623047,
      "learning_rate": 5.055551136771815e-06,
      "loss": 0.115,
      "step": 2935
    },
    {
      "epoch": 1.9945652173913042,
      "grad_norm": 16.405698776245117,
      "learning_rate": 5.049368736888391e-06,
      "loss": 0.5268,
      "step": 2936
    },
    {
      "epoch": 1.9952445652173914,
      "grad_norm": 0.012866927310824394,
      "learning_rate": 5.043188842549789e-06,
      "loss": 0.0001,
      "step": 2937
    },
    {
      "epoch": 1.9959239130434783,
      "grad_norm": 8.569365501403809,
      "learning_rate": 5.0370114568837055e-06,
      "loss": 0.3006,
      "step": 2938
    },
    {
      "epoch": 1.9966032608695652,
      "grad_norm": 0.6541555523872375,
      "learning_rate": 5.030836583016545e-06,
      "loss": 0.0033,
      "step": 2939
    },
    {
      "epoch": 1.9972826086956523,
      "grad_norm": 4.590346813201904,
      "learning_rate": 5.024664224073454e-06,
      "loss": 0.0887,
      "step": 2940
    },
    {
      "epoch": 1.9979619565217392,
      "grad_norm": 5.041749000549316,
      "learning_rate": 5.018494383178296e-06,
      "loss": 0.2054,
      "step": 2941
    },
    {
      "epoch": 1.9986413043478262,
      "grad_norm": 5.018064022064209,
      "learning_rate": 5.0123270634536716e-06,
      "loss": 0.1648,
      "step": 2942
    },
    {
      "epoch": 1.999320652173913,
      "grad_norm": 0.004523132462054491,
      "learning_rate": 5.006162268020891e-06,
      "loss": 0.0001,
      "step": 2943
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.7619034051895142,
      "learning_rate": 5.000000000000003e-06,
      "loss": 0.0058,
      "step": 2944
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.4451219512195122,
      "eval_loss": 0.1420830339193344,
      "eval_runtime": 134.5883,
      "eval_samples_per_second": 1.219,
      "eval_steps_per_second": 1.219,
      "step": 2944
    },
    {
      "epoch": 2.000679347826087,
      "grad_norm": 0.027734849601984024,
      "learning_rate": 4.993840262509761e-06,
      "loss": 0.0002,
      "step": 2945
    },
    {
      "epoch": 2.001358695652174,
      "grad_norm": 0.499350905418396,
      "learning_rate": 4.987683058667651e-06,
      "loss": 0.0032,
      "step": 2946
    },
    {
      "epoch": 2.0020380434782608,
      "grad_norm": 1.4055532217025757,
      "learning_rate": 4.981528391589875e-06,
      "loss": 0.0346,
      "step": 2947
    },
    {
      "epoch": 2.0027173913043477,
      "grad_norm": 0.3685511648654938,
      "learning_rate": 4.9753762643913395e-06,
      "loss": 0.0029,
      "step": 2948
    },
    {
      "epoch": 2.0033967391304346,
      "grad_norm": 0.23522990942001343,
      "learning_rate": 4.9692266801856815e-06,
      "loss": 0.0016,
      "step": 2949
    },
    {
      "epoch": 2.004076086956522,
      "grad_norm": 0.00422104075551033,
      "learning_rate": 4.963079642085236e-06,
      "loss": 0.0001,
      "step": 2950
    },
    {
      "epoch": 2.004755434782609,
      "grad_norm": 7.278140544891357,
      "learning_rate": 4.956935153201064e-06,
      "loss": 0.059,
      "step": 2951
    },
    {
      "epoch": 2.005434782608696,
      "grad_norm": 0.009695706889033318,
      "learning_rate": 4.950793216642923e-06,
      "loss": 0.0001,
      "step": 2952
    },
    {
      "epoch": 2.0061141304347827,
      "grad_norm": 0.0013998954091221094,
      "learning_rate": 4.9446538355192894e-06,
      "loss": 0.0,
      "step": 2953
    },
    {
      "epoch": 2.0067934782608696,
      "grad_norm": 0.002029943512752652,
      "learning_rate": 4.938517012937337e-06,
      "loss": 0.0,
      "step": 2954
    },
    {
      "epoch": 2.0074728260869565,
      "grad_norm": 2.3060009479522705,
      "learning_rate": 4.932382752002951e-06,
      "loss": 0.0929,
      "step": 2955
    },
    {
      "epoch": 2.0081521739130435,
      "grad_norm": 0.04830049350857735,
      "learning_rate": 4.926251055820719e-06,
      "loss": 0.0004,
      "step": 2956
    },
    {
      "epoch": 2.0088315217391304,
      "grad_norm": 17.363834381103516,
      "learning_rate": 4.920121927493934e-06,
      "loss": 0.4595,
      "step": 2957
    },
    {
      "epoch": 2.0095108695652173,
      "grad_norm": 0.0024074427783489227,
      "learning_rate": 4.913995370124578e-06,
      "loss": 0.0,
      "step": 2958
    },
    {
      "epoch": 2.010190217391304,
      "grad_norm": 2.107358694076538,
      "learning_rate": 4.907871386813347e-06,
      "loss": 0.0551,
      "step": 2959
    },
    {
      "epoch": 2.010869565217391,
      "grad_norm": 1.1393719911575317,
      "learning_rate": 4.901749980659617e-06,
      "loss": 0.0066,
      "step": 2960
    },
    {
      "epoch": 2.011548913043478,
      "grad_norm": 0.019888918846845627,
      "learning_rate": 4.8956311547614796e-06,
      "loss": 0.0001,
      "step": 2961
    },
    {
      "epoch": 2.0122282608695654,
      "grad_norm": 6.478765964508057,
      "learning_rate": 4.8895149122157014e-06,
      "loss": 0.287,
      "step": 2962
    },
    {
      "epoch": 2.0129076086956523,
      "grad_norm": 13.129448890686035,
      "learning_rate": 4.883401256117754e-06,
      "loss": 0.639,
      "step": 2963
    },
    {
      "epoch": 2.0135869565217392,
      "grad_norm": 0.09189111739397049,
      "learning_rate": 4.877290189561795e-06,
      "loss": 0.0008,
      "step": 2964
    },
    {
      "epoch": 2.014266304347826,
      "grad_norm": 0.30424708127975464,
      "learning_rate": 4.871181715640678e-06,
      "loss": 0.0015,
      "step": 2965
    },
    {
      "epoch": 2.014945652173913,
      "grad_norm": 2.8823180198669434,
      "learning_rate": 4.86507583744593e-06,
      "loss": 0.0852,
      "step": 2966
    },
    {
      "epoch": 2.015625,
      "grad_norm": 2.7006261348724365,
      "learning_rate": 4.858972558067784e-06,
      "loss": 0.0216,
      "step": 2967
    },
    {
      "epoch": 2.016304347826087,
      "grad_norm": 0.001967069925740361,
      "learning_rate": 4.852871880595137e-06,
      "loss": 0.0,
      "step": 2968
    },
    {
      "epoch": 2.016983695652174,
      "grad_norm": 0.04919997602701187,
      "learning_rate": 4.846773808115587e-06,
      "loss": 0.0004,
      "step": 2969
    },
    {
      "epoch": 2.0176630434782608,
      "grad_norm": 0.009489534422755241,
      "learning_rate": 4.840678343715399e-06,
      "loss": 0.0001,
      "step": 2970
    },
    {
      "epoch": 2.0183423913043477,
      "grad_norm": 2.764378309249878,
      "learning_rate": 4.8345854904795315e-06,
      "loss": 0.0812,
      "step": 2971
    },
    {
      "epoch": 2.0190217391304346,
      "grad_norm": 0.0036185947246849537,
      "learning_rate": 4.828495251491608e-06,
      "loss": 0.0001,
      "step": 2972
    },
    {
      "epoch": 2.019701086956522,
      "grad_norm": 0.0756191685795784,
      "learning_rate": 4.822407629833941e-06,
      "loss": 0.0005,
      "step": 2973
    },
    {
      "epoch": 2.020380434782609,
      "grad_norm": 9.731768608093262,
      "learning_rate": 4.816322628587513e-06,
      "loss": 0.2696,
      "step": 2974
    },
    {
      "epoch": 2.021059782608696,
      "grad_norm": 0.20123308897018433,
      "learning_rate": 4.810240250831977e-06,
      "loss": 0.0005,
      "step": 2975
    },
    {
      "epoch": 2.0217391304347827,
      "grad_norm": 0.05823875963687897,
      "learning_rate": 4.804160499645667e-06,
      "loss": 0.0005,
      "step": 2976
    },
    {
      "epoch": 2.0224184782608696,
      "grad_norm": 8.479321479797363,
      "learning_rate": 4.798083378105575e-06,
      "loss": 0.282,
      "step": 2977
    },
    {
      "epoch": 2.0230978260869565,
      "grad_norm": 2.631213903427124,
      "learning_rate": 4.792008889287375e-06,
      "loss": 0.0317,
      "step": 2978
    },
    {
      "epoch": 2.0237771739130435,
      "grad_norm": 4.98483419418335,
      "learning_rate": 4.7859370362654045e-06,
      "loss": 0.1072,
      "step": 2979
    },
    {
      "epoch": 2.0244565217391304,
      "grad_norm": 2.59885835647583,
      "learning_rate": 4.779867822112658e-06,
      "loss": 0.1257,
      "step": 2980
    },
    {
      "epoch": 2.0251358695652173,
      "grad_norm": 3.7878923416137695,
      "learning_rate": 4.773801249900808e-06,
      "loss": 0.1691,
      "step": 2981
    },
    {
      "epoch": 2.025815217391304,
      "grad_norm": 0.011562698520720005,
      "learning_rate": 4.767737322700185e-06,
      "loss": 0.0001,
      "step": 2982
    },
    {
      "epoch": 2.026494565217391,
      "grad_norm": 3.6725146770477295,
      "learning_rate": 4.761676043579774e-06,
      "loss": 0.0953,
      "step": 2983
    },
    {
      "epoch": 2.027173913043478,
      "grad_norm": 2.7953295707702637,
      "learning_rate": 4.755617415607232e-06,
      "loss": 0.1148,
      "step": 2984
    },
    {
      "epoch": 2.0278532608695654,
      "grad_norm": 4.336674213409424,
      "learning_rate": 4.749561441848862e-06,
      "loss": 0.1677,
      "step": 2985
    },
    {
      "epoch": 2.0285326086956523,
      "grad_norm": 2.835282802581787,
      "learning_rate": 4.743508125369634e-06,
      "loss": 0.0482,
      "step": 2986
    },
    {
      "epoch": 2.0292119565217392,
      "grad_norm": 4.40069055557251,
      "learning_rate": 4.737457469233164e-06,
      "loss": 0.0399,
      "step": 2987
    },
    {
      "epoch": 2.029891304347826,
      "grad_norm": 0.015290133655071259,
      "learning_rate": 4.7314094765017325e-06,
      "loss": 0.0002,
      "step": 2988
    },
    {
      "epoch": 2.030570652173913,
      "grad_norm": 2.7802321910858154,
      "learning_rate": 4.725364150236255e-06,
      "loss": 0.0904,
      "step": 2989
    },
    {
      "epoch": 2.03125,
      "grad_norm": 0.00531091820448637,
      "learning_rate": 4.7193214934963204e-06,
      "loss": 0.0001,
      "step": 2990
    },
    {
      "epoch": 2.031929347826087,
      "grad_norm": 1.5656814575195312,
      "learning_rate": 4.713281509340146e-06,
      "loss": 0.0076,
      "step": 2991
    },
    {
      "epoch": 2.032608695652174,
      "grad_norm": 4.815546035766602,
      "learning_rate": 4.7072442008246135e-06,
      "loss": 0.0583,
      "step": 2992
    },
    {
      "epoch": 2.0332880434782608,
      "grad_norm": 6.100472450256348,
      "learning_rate": 4.70120957100523e-06,
      "loss": 0.0163,
      "step": 2993
    },
    {
      "epoch": 2.0339673913043477,
      "grad_norm": 0.13726861774921417,
      "learning_rate": 4.695177622936169e-06,
      "loss": 0.0007,
      "step": 2994
    },
    {
      "epoch": 2.0346467391304346,
      "grad_norm": 8.610628128051758,
      "learning_rate": 4.6891483596702295e-06,
      "loss": 0.1301,
      "step": 2995
    },
    {
      "epoch": 2.035326086956522,
      "grad_norm": 0.006453342270106077,
      "learning_rate": 4.683121784258863e-06,
      "loss": 0.0001,
      "step": 2996
    },
    {
      "epoch": 2.036005434782609,
      "grad_norm": 5.680599689483643,
      "learning_rate": 4.677097899752152e-06,
      "loss": 0.0719,
      "step": 2997
    },
    {
      "epoch": 2.036684782608696,
      "grad_norm": 36.358856201171875,
      "learning_rate": 4.671076709198823e-06,
      "loss": 0.2138,
      "step": 2998
    },
    {
      "epoch": 2.0373641304347827,
      "grad_norm": 1.7314379215240479,
      "learning_rate": 4.665058215646239e-06,
      "loss": 0.0385,
      "step": 2999
    },
    {
      "epoch": 2.0380434782608696,
      "grad_norm": 0.01299190241843462,
      "learning_rate": 4.659042422140399e-06,
      "loss": 0.0001,
      "step": 3000
    },
    {
      "epoch": 2.0387228260869565,
      "grad_norm": 0.008872530423104763,
      "learning_rate": 4.653029331725926e-06,
      "loss": 0.0001,
      "step": 3001
    },
    {
      "epoch": 2.0394021739130435,
      "grad_norm": 9.648188591003418,
      "learning_rate": 4.647018947446089e-06,
      "loss": 0.168,
      "step": 3002
    },
    {
      "epoch": 2.0400815217391304,
      "grad_norm": 6.329159259796143,
      "learning_rate": 4.641011272342775e-06,
      "loss": 0.1093,
      "step": 3003
    },
    {
      "epoch": 2.0407608695652173,
      "grad_norm": 4.945162296295166,
      "learning_rate": 4.635006309456509e-06,
      "loss": 0.1047,
      "step": 3004
    },
    {
      "epoch": 2.041440217391304,
      "grad_norm": 4.884225845336914,
      "learning_rate": 4.629004061826434e-06,
      "loss": 0.2392,
      "step": 3005
    },
    {
      "epoch": 2.042119565217391,
      "grad_norm": 0.7458629012107849,
      "learning_rate": 4.623004532490328e-06,
      "loss": 0.0046,
      "step": 3006
    },
    {
      "epoch": 2.042798913043478,
      "grad_norm": 3.1257176399230957,
      "learning_rate": 4.617007724484595e-06,
      "loss": 0.102,
      "step": 3007
    },
    {
      "epoch": 2.0434782608695654,
      "grad_norm": 7.706061363220215,
      "learning_rate": 4.611013640844245e-06,
      "loss": 0.2289,
      "step": 3008
    },
    {
      "epoch": 2.0441576086956523,
      "grad_norm": 0.0026674908585846424,
      "learning_rate": 4.6050222846029315e-06,
      "loss": 0.0,
      "step": 3009
    },
    {
      "epoch": 2.0448369565217392,
      "grad_norm": 0.9858694672584534,
      "learning_rate": 4.599033658792908e-06,
      "loss": 0.0138,
      "step": 3010
    },
    {
      "epoch": 2.045516304347826,
      "grad_norm": 3.0689995288848877,
      "learning_rate": 4.5930477664450605e-06,
      "loss": 0.0658,
      "step": 3011
    },
    {
      "epoch": 2.046195652173913,
      "grad_norm": 4.470593452453613,
      "learning_rate": 4.587064610588881e-06,
      "loss": 0.1311,
      "step": 3012
    },
    {
      "epoch": 2.046875,
      "grad_norm": 4.086582660675049,
      "learning_rate": 4.581084194252486e-06,
      "loss": 0.1746,
      "step": 3013
    },
    {
      "epoch": 2.047554347826087,
      "grad_norm": 13.500624656677246,
      "learning_rate": 4.5751065204625964e-06,
      "loss": 0.1333,
      "step": 3014
    },
    {
      "epoch": 2.048233695652174,
      "grad_norm": 0.05198756977915764,
      "learning_rate": 4.569131592244552e-06,
      "loss": 0.0004,
      "step": 3015
    },
    {
      "epoch": 2.0489130434782608,
      "grad_norm": 6.446072578430176,
      "learning_rate": 4.5631594126223e-06,
      "loss": 0.1701,
      "step": 3016
    },
    {
      "epoch": 2.0495923913043477,
      "grad_norm": 5.331758499145508,
      "learning_rate": 4.557189984618401e-06,
      "loss": 0.1224,
      "step": 3017
    },
    {
      "epoch": 2.0502717391304346,
      "grad_norm": 0.005730566568672657,
      "learning_rate": 4.551223311254013e-06,
      "loss": 0.0001,
      "step": 3018
    },
    {
      "epoch": 2.050951086956522,
      "grad_norm": 0.24869172275066376,
      "learning_rate": 4.545259395548911e-06,
      "loss": 0.0014,
      "step": 3019
    },
    {
      "epoch": 2.051630434782609,
      "grad_norm": 0.012832386419177055,
      "learning_rate": 4.539298240521463e-06,
      "loss": 0.0001,
      "step": 3020
    },
    {
      "epoch": 2.052309782608696,
      "grad_norm": 8.578072547912598,
      "learning_rate": 4.533339849188656e-06,
      "loss": 0.3066,
      "step": 3021
    },
    {
      "epoch": 2.0529891304347827,
      "grad_norm": 0.05635697394609451,
      "learning_rate": 4.527384224566057e-06,
      "loss": 0.0005,
      "step": 3022
    },
    {
      "epoch": 2.0536684782608696,
      "grad_norm": 4.504042625427246,
      "learning_rate": 4.5214313696678535e-06,
      "loss": 0.0212,
      "step": 3023
    },
    {
      "epoch": 2.0543478260869565,
      "grad_norm": 0.019405940547585487,
      "learning_rate": 4.515481287506811e-06,
      "loss": 0.0002,
      "step": 3024
    },
    {
      "epoch": 2.0550271739130435,
      "grad_norm": 0.02221612073481083,
      "learning_rate": 4.509533981094317e-06,
      "loss": 0.0002,
      "step": 3025
    },
    {
      "epoch": 2.0557065217391304,
      "grad_norm": 3.751281261444092,
      "learning_rate": 4.503589453440328e-06,
      "loss": 0.2064,
      "step": 3026
    },
    {
      "epoch": 2.0563858695652173,
      "grad_norm": 1.909365177154541,
      "learning_rate": 4.497647707553414e-06,
      "loss": 0.0196,
      "step": 3027
    },
    {
      "epoch": 2.057065217391304,
      "grad_norm": 3.4191040992736816,
      "learning_rate": 4.491708746440721e-06,
      "loss": 0.213,
      "step": 3028
    },
    {
      "epoch": 2.057744565217391,
      "grad_norm": 0.34599024057388306,
      "learning_rate": 4.4857725731080025e-06,
      "loss": 0.003,
      "step": 3029
    },
    {
      "epoch": 2.058423913043478,
      "grad_norm": 1.45278000831604,
      "learning_rate": 4.479839190559583e-06,
      "loss": 0.0091,
      "step": 3030
    },
    {
      "epoch": 2.0591032608695654,
      "grad_norm": 0.002437334042042494,
      "learning_rate": 4.473908601798393e-06,
      "loss": 0.0,
      "step": 3031
    },
    {
      "epoch": 2.0597826086956523,
      "grad_norm": 3.957685947418213,
      "learning_rate": 4.4679808098259295e-06,
      "loss": 0.0876,
      "step": 3032
    },
    {
      "epoch": 2.0604619565217392,
      "grad_norm": 0.08213437348604202,
      "learning_rate": 4.462055817642291e-06,
      "loss": 0.0005,
      "step": 3033
    },
    {
      "epoch": 2.061141304347826,
      "grad_norm": 0.07710689306259155,
      "learning_rate": 4.456133628246155e-06,
      "loss": 0.0003,
      "step": 3034
    },
    {
      "epoch": 2.061820652173913,
      "grad_norm": 0.001971049001440406,
      "learning_rate": 4.4502142446347705e-06,
      "loss": 0.0,
      "step": 3035
    },
    {
      "epoch": 2.0625,
      "grad_norm": 18.650135040283203,
      "learning_rate": 4.444297669803981e-06,
      "loss": 0.2212,
      "step": 3036
    },
    {
      "epoch": 2.063179347826087,
      "grad_norm": 0.0012693350436165929,
      "learning_rate": 4.438383906748194e-06,
      "loss": 0.0,
      "step": 3037
    },
    {
      "epoch": 2.063858695652174,
      "grad_norm": 4.919429779052734,
      "learning_rate": 4.432472958460405e-06,
      "loss": 0.0378,
      "step": 3038
    },
    {
      "epoch": 2.0645380434782608,
      "grad_norm": 3.6802737712860107,
      "learning_rate": 4.426564827932185e-06,
      "loss": 0.0729,
      "step": 3039
    },
    {
      "epoch": 2.0652173913043477,
      "grad_norm": 1.676938533782959,
      "learning_rate": 4.420659518153667e-06,
      "loss": 0.043,
      "step": 3040
    },
    {
      "epoch": 2.0658967391304346,
      "grad_norm": 0.0015812200726941228,
      "learning_rate": 4.414757032113569e-06,
      "loss": 0.0,
      "step": 3041
    },
    {
      "epoch": 2.066576086956522,
      "grad_norm": 3.6144649982452393,
      "learning_rate": 4.408857372799179e-06,
      "loss": 0.187,
      "step": 3042
    },
    {
      "epoch": 2.067255434782609,
      "grad_norm": 13.244339942932129,
      "learning_rate": 4.402960543196343e-06,
      "loss": 0.1124,
      "step": 3043
    },
    {
      "epoch": 2.067934782608696,
      "grad_norm": 3.1626555919647217,
      "learning_rate": 4.39706654628949e-06,
      "loss": 0.1279,
      "step": 3044
    },
    {
      "epoch": 2.0686141304347827,
      "grad_norm": 24.694503784179688,
      "learning_rate": 4.391175385061601e-06,
      "loss": 0.1123,
      "step": 3045
    },
    {
      "epoch": 2.0692934782608696,
      "grad_norm": 0.005597379524260759,
      "learning_rate": 4.385287062494237e-06,
      "loss": 0.0001,
      "step": 3046
    },
    {
      "epoch": 2.0699728260869565,
      "grad_norm": 0.04981331527233124,
      "learning_rate": 4.379401581567504e-06,
      "loss": 0.0004,
      "step": 3047
    },
    {
      "epoch": 2.0706521739130435,
      "grad_norm": 0.5421619415283203,
      "learning_rate": 4.37351894526009e-06,
      "loss": 0.0097,
      "step": 3048
    },
    {
      "epoch": 2.0713315217391304,
      "grad_norm": 1.2587603330612183,
      "learning_rate": 4.36763915654922e-06,
      "loss": 0.0163,
      "step": 3049
    },
    {
      "epoch": 2.0720108695652173,
      "grad_norm": 2.004667282104492,
      "learning_rate": 4.361762218410709e-06,
      "loss": 0.0214,
      "step": 3050
    },
    {
      "epoch": 2.072690217391304,
      "grad_norm": 2.4360551834106445,
      "learning_rate": 4.355888133818897e-06,
      "loss": 0.0995,
      "step": 3051
    },
    {
      "epoch": 2.073369565217391,
      "grad_norm": 0.10148097574710846,
      "learning_rate": 4.350016905746703e-06,
      "loss": 0.0017,
      "step": 3052
    },
    {
      "epoch": 2.074048913043478,
      "grad_norm": 12.18896198272705,
      "learning_rate": 4.3441485371655855e-06,
      "loss": 0.3847,
      "step": 3053
    },
    {
      "epoch": 2.0747282608695654,
      "grad_norm": 2.8518729209899902,
      "learning_rate": 4.338283031045567e-06,
      "loss": 0.0531,
      "step": 3054
    },
    {
      "epoch": 2.0754076086956523,
      "grad_norm": 0.017124274745583534,
      "learning_rate": 4.33242039035521e-06,
      "loss": 0.0001,
      "step": 3055
    },
    {
      "epoch": 2.0760869565217392,
      "grad_norm": 0.1756986528635025,
      "learning_rate": 4.326560618061639e-06,
      "loss": 0.0012,
      "step": 3056
    },
    {
      "epoch": 2.076766304347826,
      "grad_norm": 0.4334653317928314,
      "learning_rate": 4.320703717130516e-06,
      "loss": 0.0033,
      "step": 3057
    },
    {
      "epoch": 2.077445652173913,
      "grad_norm": 0.0030888018663972616,
      "learning_rate": 4.314849690526055e-06,
      "loss": 0.0001,
      "step": 3058
    },
    {
      "epoch": 2.078125,
      "grad_norm": 2.604250431060791,
      "learning_rate": 4.308998541211016e-06,
      "loss": 0.0174,
      "step": 3059
    },
    {
      "epoch": 2.078804347826087,
      "grad_norm": 2.8454501628875732,
      "learning_rate": 4.303150272146706e-06,
      "loss": 0.041,
      "step": 3060
    },
    {
      "epoch": 2.079483695652174,
      "grad_norm": 0.006985641084611416,
      "learning_rate": 4.297304886292961e-06,
      "loss": 0.0001,
      "step": 3061
    },
    {
      "epoch": 2.0801630434782608,
      "grad_norm": 1.8523918390274048,
      "learning_rate": 4.2914623866081765e-06,
      "loss": 0.0299,
      "step": 3062
    },
    {
      "epoch": 2.0808423913043477,
      "grad_norm": 0.0019256055820733309,
      "learning_rate": 4.2856227760492665e-06,
      "loss": 0.0,
      "step": 3063
    },
    {
      "epoch": 2.0815217391304346,
      "grad_norm": 17.80506706237793,
      "learning_rate": 4.279786057571703e-06,
      "loss": 0.645,
      "step": 3064
    },
    {
      "epoch": 2.082201086956522,
      "grad_norm": 2.076988935470581,
      "learning_rate": 4.2739522341294785e-06,
      "loss": 0.0366,
      "step": 3065
    },
    {
      "epoch": 2.082880434782609,
      "grad_norm": 0.008153560571372509,
      "learning_rate": 4.268121308675132e-06,
      "loss": 0.0002,
      "step": 3066
    },
    {
      "epoch": 2.083559782608696,
      "grad_norm": 1.4875913858413696,
      "learning_rate": 4.2622932841597255e-06,
      "loss": 0.0303,
      "step": 3067
    },
    {
      "epoch": 2.0842391304347827,
      "grad_norm": 13.274375915527344,
      "learning_rate": 4.25646816353286e-06,
      "loss": 0.331,
      "step": 3068
    },
    {
      "epoch": 2.0849184782608696,
      "grad_norm": 4.874337673187256,
      "learning_rate": 4.2506459497426685e-06,
      "loss": 0.1394,
      "step": 3069
    },
    {
      "epoch": 2.0855978260869565,
      "grad_norm": 1.9738292694091797,
      "learning_rate": 4.2448266457358035e-06,
      "loss": 0.0121,
      "step": 3070
    },
    {
      "epoch": 2.0862771739130435,
      "grad_norm": 7.952908515930176,
      "learning_rate": 4.239010254457455e-06,
      "loss": 0.214,
      "step": 3071
    },
    {
      "epoch": 2.0869565217391304,
      "grad_norm": 7.924169063568115,
      "learning_rate": 4.2331967788513295e-06,
      "loss": 0.2278,
      "step": 3072
    },
    {
      "epoch": 2.0876358695652173,
      "grad_norm": 0.3400898873806,
      "learning_rate": 4.227386221859669e-06,
      "loss": 0.0013,
      "step": 3073
    },
    {
      "epoch": 2.088315217391304,
      "grad_norm": 0.0019318016711622477,
      "learning_rate": 4.221578586423224e-06,
      "loss": 0.0001,
      "step": 3074
    },
    {
      "epoch": 2.088994565217391,
      "grad_norm": 12.611252784729004,
      "learning_rate": 4.21577387548128e-06,
      "loss": 0.3558,
      "step": 3075
    },
    {
      "epoch": 2.089673913043478,
      "grad_norm": 1.5003166198730469,
      "learning_rate": 4.209972091971633e-06,
      "loss": 0.0283,
      "step": 3076
    },
    {
      "epoch": 2.0903532608695654,
      "grad_norm": 11.086005210876465,
      "learning_rate": 4.204173238830609e-06,
      "loss": 0.4129,
      "step": 3077
    },
    {
      "epoch": 2.0910326086956523,
      "grad_norm": 6.63864803314209,
      "learning_rate": 4.198377318993035e-06,
      "loss": 0.2793,
      "step": 3078
    },
    {
      "epoch": 2.0917119565217392,
      "grad_norm": 4.9446940422058105,
      "learning_rate": 4.192584335392266e-06,
      "loss": 0.1932,
      "step": 3079
    },
    {
      "epoch": 2.092391304347826,
      "grad_norm": 0.20247776806354523,
      "learning_rate": 4.186794290960162e-06,
      "loss": 0.002,
      "step": 3080
    },
    {
      "epoch": 2.093070652173913,
      "grad_norm": 4.598362922668457,
      "learning_rate": 4.1810071886271065e-06,
      "loss": 0.0589,
      "step": 3081
    },
    {
      "epoch": 2.09375,
      "grad_norm": 0.008710031397640705,
      "learning_rate": 4.17522303132198e-06,
      "loss": 0.0001,
      "step": 3082
    },
    {
      "epoch": 2.094429347826087,
      "grad_norm": 4.378871917724609,
      "learning_rate": 4.169441821972187e-06,
      "loss": 0.1703,
      "step": 3083
    },
    {
      "epoch": 2.095108695652174,
      "grad_norm": 0.0705883726477623,
      "learning_rate": 4.1636635635036235e-06,
      "loss": 0.0005,
      "step": 3084
    },
    {
      "epoch": 2.0957880434782608,
      "grad_norm": 11.289505004882812,
      "learning_rate": 4.157888258840714e-06,
      "loss": 0.103,
      "step": 3085
    },
    {
      "epoch": 2.0964673913043477,
      "grad_norm": 10.762846946716309,
      "learning_rate": 4.152115910906367e-06,
      "loss": 0.1746,
      "step": 3086
    },
    {
      "epoch": 2.0971467391304346,
      "grad_norm": 0.004003976937383413,
      "learning_rate": 4.146346522622008e-06,
      "loss": 0.0,
      "step": 3087
    },
    {
      "epoch": 2.097826086956522,
      "grad_norm": 5.994811058044434,
      "learning_rate": 4.140580096907554e-06,
      "loss": 0.2209,
      "step": 3088
    },
    {
      "epoch": 2.098505434782609,
      "grad_norm": 4.177919864654541,
      "learning_rate": 4.134816636681436e-06,
      "loss": 0.0841,
      "step": 3089
    },
    {
      "epoch": 2.099184782608696,
      "grad_norm": 1.4935352802276611,
      "learning_rate": 4.129056144860567e-06,
      "loss": 0.0179,
      "step": 3090
    },
    {
      "epoch": 2.0998641304347827,
      "grad_norm": 0.022483112290501595,
      "learning_rate": 4.123298624360378e-06,
      "loss": 0.0001,
      "step": 3091
    },
    {
      "epoch": 2.1005434782608696,
      "grad_norm": 2.7474453449249268,
      "learning_rate": 4.117544078094775e-06,
      "loss": 0.0366,
      "step": 3092
    },
    {
      "epoch": 2.1012228260869565,
      "grad_norm": 4.094930171966553,
      "learning_rate": 4.111792508976175e-06,
      "loss": 0.0632,
      "step": 3093
    },
    {
      "epoch": 2.1019021739130435,
      "grad_norm": 20.154573440551758,
      "learning_rate": 4.106043919915484e-06,
      "loss": 0.3414,
      "step": 3094
    },
    {
      "epoch": 2.1025815217391304,
      "grad_norm": 7.504876613616943,
      "learning_rate": 4.100298313822093e-06,
      "loss": 0.2782,
      "step": 3095
    },
    {
      "epoch": 2.1032608695652173,
      "grad_norm": 3.6513686180114746,
      "learning_rate": 4.094555693603891e-06,
      "loss": 0.0685,
      "step": 3096
    },
    {
      "epoch": 2.103940217391304,
      "grad_norm": 6.460120677947998,
      "learning_rate": 4.0888160621672566e-06,
      "loss": 0.1708,
      "step": 3097
    },
    {
      "epoch": 2.104619565217391,
      "grad_norm": 0.008657059632241726,
      "learning_rate": 4.083079422417045e-06,
      "loss": 0.0001,
      "step": 3098
    },
    {
      "epoch": 2.105298913043478,
      "grad_norm": 0.002687657019123435,
      "learning_rate": 4.077345777256614e-06,
      "loss": 0.0,
      "step": 3099
    },
    {
      "epoch": 2.1059782608695654,
      "grad_norm": 4.875553607940674,
      "learning_rate": 4.071615129587787e-06,
      "loss": 0.1551,
      "step": 3100
    },
    {
      "epoch": 2.1066576086956523,
      "grad_norm": 9.320979118347168,
      "learning_rate": 4.065887482310885e-06,
      "loss": 0.1766,
      "step": 3101
    },
    {
      "epoch": 2.1073369565217392,
      "grad_norm": 7.225959300994873,
      "learning_rate": 4.060162838324708e-06,
      "loss": 0.1795,
      "step": 3102
    },
    {
      "epoch": 2.108016304347826,
      "grad_norm": 0.001862014178186655,
      "learning_rate": 4.054441200526528e-06,
      "loss": 0.0,
      "step": 3103
    },
    {
      "epoch": 2.108695652173913,
      "grad_norm": 4.4955034255981445,
      "learning_rate": 4.048722571812105e-06,
      "loss": 0.0709,
      "step": 3104
    },
    {
      "epoch": 2.109375,
      "grad_norm": 0.22558748722076416,
      "learning_rate": 4.043006955075667e-06,
      "loss": 0.002,
      "step": 3105
    },
    {
      "epoch": 2.110054347826087,
      "grad_norm": 0.0031581460498273373,
      "learning_rate": 4.03729435320993e-06,
      "loss": 0.0001,
      "step": 3106
    },
    {
      "epoch": 2.110733695652174,
      "grad_norm": 10.258112907409668,
      "learning_rate": 4.0315847691060695e-06,
      "loss": 0.2008,
      "step": 3107
    },
    {
      "epoch": 2.1114130434782608,
      "grad_norm": 3.017719030380249,
      "learning_rate": 4.025878205653747e-06,
      "loss": 0.0928,
      "step": 3108
    },
    {
      "epoch": 2.1120923913043477,
      "grad_norm": 0.003920027520507574,
      "learning_rate": 4.0201746657410835e-06,
      "loss": 0.0001,
      "step": 3109
    },
    {
      "epoch": 2.1127717391304346,
      "grad_norm": 1.0644052028656006,
      "learning_rate": 4.014474152254678e-06,
      "loss": 0.0177,
      "step": 3110
    },
    {
      "epoch": 2.113451086956522,
      "grad_norm": 0.049696970731019974,
      "learning_rate": 4.008776668079596e-06,
      "loss": 0.0003,
      "step": 3111
    },
    {
      "epoch": 2.114130434782609,
      "grad_norm": 0.25038012862205505,
      "learning_rate": 4.003082216099374e-06,
      "loss": 0.0016,
      "step": 3112
    },
    {
      "epoch": 2.114809782608696,
      "grad_norm": 2.9032609462738037,
      "learning_rate": 3.997390799195998e-06,
      "loss": 0.1156,
      "step": 3113
    },
    {
      "epoch": 2.1154891304347827,
      "grad_norm": 8.088861465454102,
      "learning_rate": 3.991702420249941e-06,
      "loss": 0.2915,
      "step": 3114
    },
    {
      "epoch": 2.1161684782608696,
      "grad_norm": 3.57971453666687,
      "learning_rate": 3.986017082140116e-06,
      "loss": 0.0434,
      "step": 3115
    },
    {
      "epoch": 2.1168478260869565,
      "grad_norm": 7.0465497970581055,
      "learning_rate": 3.980334787743915e-06,
      "loss": 0.1867,
      "step": 3116
    },
    {
      "epoch": 2.1175271739130435,
      "grad_norm": 0.002866813912987709,
      "learning_rate": 3.974655539937176e-06,
      "loss": 0.0001,
      "step": 3117
    },
    {
      "epoch": 2.1182065217391304,
      "grad_norm": 0.04271135851740837,
      "learning_rate": 3.968979341594204e-06,
      "loss": 0.0004,
      "step": 3118
    },
    {
      "epoch": 2.1188858695652173,
      "grad_norm": 4.579995155334473,
      "learning_rate": 3.963306195587758e-06,
      "loss": 0.1493,
      "step": 3119
    },
    {
      "epoch": 2.119565217391304,
      "grad_norm": 0.029603740200400352,
      "learning_rate": 3.957636104789056e-06,
      "loss": 0.0002,
      "step": 3120
    },
    {
      "epoch": 2.120244565217391,
      "grad_norm": 5.72580623626709,
      "learning_rate": 3.951969072067758e-06,
      "loss": 0.0349,
      "step": 3121
    },
    {
      "epoch": 2.120923913043478,
      "grad_norm": 0.013596874661743641,
      "learning_rate": 3.946305100291989e-06,
      "loss": 0.0001,
      "step": 3122
    },
    {
      "epoch": 2.1216032608695654,
      "grad_norm": 19.641937255859375,
      "learning_rate": 3.940644192328317e-06,
      "loss": 0.2262,
      "step": 3123
    },
    {
      "epoch": 2.1222826086956523,
      "grad_norm": 0.11016349494457245,
      "learning_rate": 3.934986351041766e-06,
      "loss": 0.0006,
      "step": 3124
    },
    {
      "epoch": 2.1229619565217392,
      "grad_norm": 0.5219568610191345,
      "learning_rate": 3.9293315792958e-06,
      "loss": 0.0053,
      "step": 3125
    },
    {
      "epoch": 2.123641304347826,
      "grad_norm": 4.612522602081299,
      "learning_rate": 3.9236798799523375e-06,
      "loss": 0.2524,
      "step": 3126
    },
    {
      "epoch": 2.124320652173913,
      "grad_norm": 4.8578996658325195,
      "learning_rate": 3.918031255871734e-06,
      "loss": 0.0915,
      "step": 3127
    },
    {
      "epoch": 2.125,
      "grad_norm": 2.1212239265441895,
      "learning_rate": 3.912385709912794e-06,
      "loss": 0.0395,
      "step": 3128
    },
    {
      "epoch": 2.125679347826087,
      "grad_norm": 0.02044622413814068,
      "learning_rate": 3.906743244932767e-06,
      "loss": 0.0002,
      "step": 3129
    },
    {
      "epoch": 2.126358695652174,
      "grad_norm": 8.199630737304688,
      "learning_rate": 3.901103863787332e-06,
      "loss": 0.3239,
      "step": 3130
    },
    {
      "epoch": 2.1270380434782608,
      "grad_norm": 0.783574104309082,
      "learning_rate": 3.895467569330623e-06,
      "loss": 0.0058,
      "step": 3131
    },
    {
      "epoch": 2.1277173913043477,
      "grad_norm": 1.5947843790054321,
      "learning_rate": 3.8898343644151945e-06,
      "loss": 0.0149,
      "step": 3132
    },
    {
      "epoch": 2.1283967391304346,
      "grad_norm": 0.0067002554424107075,
      "learning_rate": 3.884204251892054e-06,
      "loss": 0.0001,
      "step": 3133
    },
    {
      "epoch": 2.1290760869565215,
      "grad_norm": 3.705003261566162,
      "learning_rate": 3.878577234610628e-06,
      "loss": 0.039,
      "step": 3134
    },
    {
      "epoch": 2.129755434782609,
      "grad_norm": 0.004165329970419407,
      "learning_rate": 3.872953315418793e-06,
      "loss": 0.0001,
      "step": 3135
    },
    {
      "epoch": 2.130434782608696,
      "grad_norm": 0.5757818222045898,
      "learning_rate": 3.867332497162836e-06,
      "loss": 0.0031,
      "step": 3136
    },
    {
      "epoch": 2.1311141304347827,
      "grad_norm": 0.09381017088890076,
      "learning_rate": 3.861714782687503e-06,
      "loss": 0.0007,
      "step": 3137
    },
    {
      "epoch": 2.1317934782608696,
      "grad_norm": 6.043664455413818,
      "learning_rate": 3.856100174835945e-06,
      "loss": 0.244,
      "step": 3138
    },
    {
      "epoch": 2.1324728260869565,
      "grad_norm": 3.788567543029785,
      "learning_rate": 3.850488676449753e-06,
      "loss": 0.0443,
      "step": 3139
    },
    {
      "epoch": 2.1331521739130435,
      "grad_norm": 5.028469085693359,
      "learning_rate": 3.844880290368935e-06,
      "loss": 0.1327,
      "step": 3140
    },
    {
      "epoch": 2.1338315217391304,
      "grad_norm": 4.137810230255127,
      "learning_rate": 3.8392750194319385e-06,
      "loss": 0.1115,
      "step": 3141
    },
    {
      "epoch": 2.1345108695652173,
      "grad_norm": 11.896974563598633,
      "learning_rate": 3.8336728664756165e-06,
      "loss": 0.2828,
      "step": 3142
    },
    {
      "epoch": 2.135190217391304,
      "grad_norm": 0.008577289991080761,
      "learning_rate": 3.8280738343352594e-06,
      "loss": 0.0001,
      "step": 3143
    },
    {
      "epoch": 2.135869565217391,
      "grad_norm": 6.010089874267578,
      "learning_rate": 3.822477925844564e-06,
      "loss": 0.1703,
      "step": 3144
    },
    {
      "epoch": 2.1365489130434785,
      "grad_norm": 5.298757553100586,
      "learning_rate": 3.816885143835665e-06,
      "loss": 0.2744,
      "step": 3145
    },
    {
      "epoch": 2.1372282608695654,
      "grad_norm": 3.072904348373413,
      "learning_rate": 3.8112954911390943e-06,
      "loss": 0.0769,
      "step": 3146
    },
    {
      "epoch": 2.1379076086956523,
      "grad_norm": 0.003311970504000783,
      "learning_rate": 3.805708970583817e-06,
      "loss": 0.0,
      "step": 3147
    },
    {
      "epoch": 2.1385869565217392,
      "grad_norm": 2.929009437561035,
      "learning_rate": 3.800125584997196e-06,
      "loss": 0.0315,
      "step": 3148
    },
    {
      "epoch": 2.139266304347826,
      "grad_norm": 1.8330769538879395,
      "learning_rate": 3.794545337205028e-06,
      "loss": 0.0395,
      "step": 3149
    },
    {
      "epoch": 2.139945652173913,
      "grad_norm": 0.004423850681632757,
      "learning_rate": 3.7889682300315e-06,
      "loss": 0.0001,
      "step": 3150
    },
    {
      "epoch": 2.140625,
      "grad_norm": 0.2521085739135742,
      "learning_rate": 3.7833942662992286e-06,
      "loss": 0.0014,
      "step": 3151
    },
    {
      "epoch": 2.141304347826087,
      "grad_norm": 22.952905654907227,
      "learning_rate": 3.777823448829224e-06,
      "loss": 0.1816,
      "step": 3152
    },
    {
      "epoch": 2.141983695652174,
      "grad_norm": 10.652929306030273,
      "learning_rate": 3.7722557804409145e-06,
      "loss": 0.2228,
      "step": 3153
    },
    {
      "epoch": 2.1426630434782608,
      "grad_norm": 1.3390997648239136,
      "learning_rate": 3.7666912639521316e-06,
      "loss": 0.0244,
      "step": 3154
    },
    {
      "epoch": 2.1433423913043477,
      "grad_norm": 0.3096545934677124,
      "learning_rate": 3.7611299021791137e-06,
      "loss": 0.0027,
      "step": 3155
    },
    {
      "epoch": 2.1440217391304346,
      "grad_norm": 0.005383046809583902,
      "learning_rate": 3.755571697936493e-06,
      "loss": 0.0001,
      "step": 3156
    },
    {
      "epoch": 2.1447010869565215,
      "grad_norm": 2.246490478515625,
      "learning_rate": 3.7500166540373196e-06,
      "loss": 0.0929,
      "step": 3157
    },
    {
      "epoch": 2.145380434782609,
      "grad_norm": 2.743884325027466,
      "learning_rate": 3.7444647732930263e-06,
      "loss": 0.0613,
      "step": 3158
    },
    {
      "epoch": 2.146059782608696,
      "grad_norm": 7.843092918395996,
      "learning_rate": 3.738916058513462e-06,
      "loss": 0.0961,
      "step": 3159
    },
    {
      "epoch": 2.1467391304347827,
      "grad_norm": 4.808773994445801,
      "learning_rate": 3.7333705125068576e-06,
      "loss": 0.0731,
      "step": 3160
    },
    {
      "epoch": 2.1474184782608696,
      "grad_norm": 0.0013547842390835285,
      "learning_rate": 3.7278281380798565e-06,
      "loss": 0.0,
      "step": 3161
    },
    {
      "epoch": 2.1480978260869565,
      "grad_norm": 0.003392296377569437,
      "learning_rate": 3.722288938037478e-06,
      "loss": 0.0001,
      "step": 3162
    },
    {
      "epoch": 2.1487771739130435,
      "grad_norm": 7.3841938972473145,
      "learning_rate": 3.7167529151831528e-06,
      "loss": 0.1052,
      "step": 3163
    },
    {
      "epoch": 2.1494565217391304,
      "grad_norm": 7.991420745849609,
      "learning_rate": 3.7112200723186975e-06,
      "loss": 0.4343,
      "step": 3164
    },
    {
      "epoch": 2.1501358695652173,
      "grad_norm": 0.07667511701583862,
      "learning_rate": 3.7056904122443105e-06,
      "loss": 0.0006,
      "step": 3165
    },
    {
      "epoch": 2.150815217391304,
      "grad_norm": 0.015560638159513474,
      "learning_rate": 3.700163937758594e-06,
      "loss": 0.0002,
      "step": 3166
    },
    {
      "epoch": 2.151494565217391,
      "grad_norm": 2.5694406032562256,
      "learning_rate": 3.694640651658523e-06,
      "loss": 0.179,
      "step": 3167
    },
    {
      "epoch": 2.1521739130434785,
      "grad_norm": 4.461756706237793,
      "learning_rate": 3.689120556739475e-06,
      "loss": 0.1593,
      "step": 3168
    },
    {
      "epoch": 2.1528532608695654,
      "grad_norm": 0.03534971922636032,
      "learning_rate": 3.683603655795196e-06,
      "loss": 0.0002,
      "step": 3169
    },
    {
      "epoch": 2.1535326086956523,
      "grad_norm": 0.01320419181138277,
      "learning_rate": 3.678089951617827e-06,
      "loss": 0.0002,
      "step": 3170
    },
    {
      "epoch": 2.1542119565217392,
      "grad_norm": 1.6416535377502441,
      "learning_rate": 3.672579446997887e-06,
      "loss": 0.0162,
      "step": 3171
    },
    {
      "epoch": 2.154891304347826,
      "grad_norm": 0.03482187166810036,
      "learning_rate": 3.66707214472428e-06,
      "loss": 0.0002,
      "step": 3172
    },
    {
      "epoch": 2.155570652173913,
      "grad_norm": 2.7855875492095947,
      "learning_rate": 3.6615680475842787e-06,
      "loss": 0.1392,
      "step": 3173
    },
    {
      "epoch": 2.15625,
      "grad_norm": 0.004779072478413582,
      "learning_rate": 3.6560671583635467e-06,
      "loss": 0.0001,
      "step": 3174
    },
    {
      "epoch": 2.156929347826087,
      "grad_norm": 3.5272648334503174,
      "learning_rate": 3.6505694798461124e-06,
      "loss": 0.1458,
      "step": 3175
    },
    {
      "epoch": 2.157608695652174,
      "grad_norm": 0.007979070767760277,
      "learning_rate": 3.6450750148143886e-06,
      "loss": 0.0001,
      "step": 3176
    },
    {
      "epoch": 2.1582880434782608,
      "grad_norm": 0.10747639089822769,
      "learning_rate": 3.6395837660491538e-06,
      "loss": 0.0006,
      "step": 3177
    },
    {
      "epoch": 2.1589673913043477,
      "grad_norm": 8.566231727600098,
      "learning_rate": 3.634095736329568e-06,
      "loss": 0.2239,
      "step": 3178
    },
    {
      "epoch": 2.1596467391304346,
      "grad_norm": 16.049165725708008,
      "learning_rate": 3.6286109284331474e-06,
      "loss": 0.4562,
      "step": 3179
    },
    {
      "epoch": 2.1603260869565215,
      "grad_norm": 19.908830642700195,
      "learning_rate": 3.6231293451357994e-06,
      "loss": 0.676,
      "step": 3180
    },
    {
      "epoch": 2.161005434782609,
      "grad_norm": 0.8945940732955933,
      "learning_rate": 3.6176509892117774e-06,
      "loss": 0.0103,
      "step": 3181
    },
    {
      "epoch": 2.161684782608696,
      "grad_norm": 0.04548042267560959,
      "learning_rate": 3.6121758634337166e-06,
      "loss": 0.0003,
      "step": 3182
    },
    {
      "epoch": 2.1623641304347827,
      "grad_norm": 0.0027175212744623423,
      "learning_rate": 3.606703970572607e-06,
      "loss": 0.0001,
      "step": 3183
    },
    {
      "epoch": 2.1630434782608696,
      "grad_norm": 0.6767538189888,
      "learning_rate": 3.601235313397813e-06,
      "loss": 0.0028,
      "step": 3184
    },
    {
      "epoch": 2.1637228260869565,
      "grad_norm": 0.009963398799300194,
      "learning_rate": 3.595769894677048e-06,
      "loss": 0.0001,
      "step": 3185
    },
    {
      "epoch": 2.1644021739130435,
      "grad_norm": 0.07484523206949234,
      "learning_rate": 3.590307717176401e-06,
      "loss": 0.0004,
      "step": 3186
    },
    {
      "epoch": 2.1650815217391304,
      "grad_norm": 0.009528374299407005,
      "learning_rate": 3.5848487836603062e-06,
      "loss": 0.0001,
      "step": 3187
    },
    {
      "epoch": 2.1657608695652173,
      "grad_norm": 5.183211803436279,
      "learning_rate": 3.579393096891569e-06,
      "loss": 0.113,
      "step": 3188
    },
    {
      "epoch": 2.166440217391304,
      "grad_norm": 5.2521748542785645,
      "learning_rate": 3.5739406596313474e-06,
      "loss": 0.2445,
      "step": 3189
    },
    {
      "epoch": 2.167119565217391,
      "grad_norm": 2.2017903327941895,
      "learning_rate": 3.5684914746391465e-06,
      "loss": 0.0178,
      "step": 3190
    },
    {
      "epoch": 2.1677989130434785,
      "grad_norm": 3.4724295139312744,
      "learning_rate": 3.5630455446728394e-06,
      "loss": 0.0977,
      "step": 3191
    },
    {
      "epoch": 2.1684782608695654,
      "grad_norm": 0.015150325372815132,
      "learning_rate": 3.557602872488638e-06,
      "loss": 0.0002,
      "step": 3192
    },
    {
      "epoch": 2.1691576086956523,
      "grad_norm": 3.0528016090393066,
      "learning_rate": 3.552163460841118e-06,
      "loss": 0.0403,
      "step": 3193
    },
    {
      "epoch": 2.1698369565217392,
      "grad_norm": 18.14251136779785,
      "learning_rate": 3.5467273124831936e-06,
      "loss": 0.592,
      "step": 3194
    },
    {
      "epoch": 2.170516304347826,
      "grad_norm": 0.11662381887435913,
      "learning_rate": 3.5412944301661356e-06,
      "loss": 0.0006,
      "step": 3195
    },
    {
      "epoch": 2.171195652173913,
      "grad_norm": 5.697476387023926,
      "learning_rate": 3.535864816639559e-06,
      "loss": 0.1295,
      "step": 3196
    },
    {
      "epoch": 2.171875,
      "grad_norm": 8.105521202087402,
      "learning_rate": 3.5304384746514273e-06,
      "loss": 0.2345,
      "step": 3197
    },
    {
      "epoch": 2.172554347826087,
      "grad_norm": 9.268815994262695,
      "learning_rate": 3.525015406948039e-06,
      "loss": 0.1081,
      "step": 3198
    },
    {
      "epoch": 2.173233695652174,
      "grad_norm": 0.0017165493918582797,
      "learning_rate": 3.51959561627405e-06,
      "loss": 0.0,
      "step": 3199
    },
    {
      "epoch": 2.1739130434782608,
      "grad_norm": 4.1002197265625,
      "learning_rate": 3.5141791053724405e-06,
      "loss": 0.072,
      "step": 3200
    },
    {
      "epoch": 2.1745923913043477,
      "grad_norm": 4.624571800231934,
      "learning_rate": 3.508765876984549e-06,
      "loss": 0.181,
      "step": 3201
    },
    {
      "epoch": 2.1752717391304346,
      "grad_norm": 1.5087732076644897,
      "learning_rate": 3.5033559338500343e-06,
      "loss": 0.0086,
      "step": 3202
    },
    {
      "epoch": 2.1759510869565215,
      "grad_norm": 8.601900100708008,
      "learning_rate": 3.4979492787069115e-06,
      "loss": 0.1639,
      "step": 3203
    },
    {
      "epoch": 2.176630434782609,
      "grad_norm": 0.3060217499732971,
      "learning_rate": 3.492545914291512e-06,
      "loss": 0.0013,
      "step": 3204
    },
    {
      "epoch": 2.177309782608696,
      "grad_norm": 3.4050769805908203,
      "learning_rate": 3.4871458433385176e-06,
      "loss": 0.1825,
      "step": 3205
    },
    {
      "epoch": 2.1779891304347827,
      "grad_norm": 0.007323454599827528,
      "learning_rate": 3.481749068580935e-06,
      "loss": 0.0001,
      "step": 3206
    },
    {
      "epoch": 2.1786684782608696,
      "grad_norm": 0.0017924915300682187,
      "learning_rate": 3.4763555927501113e-06,
      "loss": 0.0,
      "step": 3207
    },
    {
      "epoch": 2.1793478260869565,
      "grad_norm": 29.873424530029297,
      "learning_rate": 3.470965418575708e-06,
      "loss": 0.1226,
      "step": 3208
    },
    {
      "epoch": 2.1800271739130435,
      "grad_norm": 2.1493136882781982,
      "learning_rate": 3.465578548785734e-06,
      "loss": 0.0391,
      "step": 3209
    },
    {
      "epoch": 2.1807065217391304,
      "grad_norm": 15.936210632324219,
      "learning_rate": 3.4601949861065086e-06,
      "loss": 0.5338,
      "step": 3210
    },
    {
      "epoch": 2.1813858695652173,
      "grad_norm": 29.246278762817383,
      "learning_rate": 3.4548147332626945e-06,
      "loss": 0.4994,
      "step": 3211
    },
    {
      "epoch": 2.182065217391304,
      "grad_norm": 0.056928303092718124,
      "learning_rate": 3.4494377929772637e-06,
      "loss": 0.0003,
      "step": 3212
    },
    {
      "epoch": 2.182744565217391,
      "grad_norm": 3.6763970851898193,
      "learning_rate": 3.4440641679715204e-06,
      "loss": 0.082,
      "step": 3213
    },
    {
      "epoch": 2.1834239130434785,
      "grad_norm": 0.006219365168362856,
      "learning_rate": 3.438693860965091e-06,
      "loss": 0.0001,
      "step": 3214
    },
    {
      "epoch": 2.1841032608695654,
      "grad_norm": 0.006684422492980957,
      "learning_rate": 3.433326874675923e-06,
      "loss": 0.0001,
      "step": 3215
    },
    {
      "epoch": 2.1847826086956523,
      "grad_norm": 0.01272064819931984,
      "learning_rate": 3.4279632118202744e-06,
      "loss": 0.0002,
      "step": 3216
    },
    {
      "epoch": 2.1854619565217392,
      "grad_norm": 0.01671130768954754,
      "learning_rate": 3.422602875112735e-06,
      "loss": 0.0002,
      "step": 3217
    },
    {
      "epoch": 2.186141304347826,
      "grad_norm": 0.03546492010354996,
      "learning_rate": 3.4172458672661967e-06,
      "loss": 0.0004,
      "step": 3218
    },
    {
      "epoch": 2.186820652173913,
      "grad_norm": 7.262617588043213,
      "learning_rate": 3.411892190991882e-06,
      "loss": 0.2059,
      "step": 3219
    },
    {
      "epoch": 2.1875,
      "grad_norm": 2.3724403381347656,
      "learning_rate": 3.4065418489993118e-06,
      "loss": 0.0265,
      "step": 3220
    },
    {
      "epoch": 2.188179347826087,
      "grad_norm": 5.939566612243652,
      "learning_rate": 3.401194843996333e-06,
      "loss": 0.1837,
      "step": 3221
    },
    {
      "epoch": 2.188858695652174,
      "grad_norm": 18.80280876159668,
      "learning_rate": 3.3958511786890923e-06,
      "loss": 0.5124,
      "step": 3222
    },
    {
      "epoch": 2.1895380434782608,
      "grad_norm": 0.01121009886264801,
      "learning_rate": 3.3905108557820533e-06,
      "loss": 0.0001,
      "step": 3223
    },
    {
      "epoch": 2.1902173913043477,
      "grad_norm": 17.2290096282959,
      "learning_rate": 3.385173877977991e-06,
      "loss": 0.362,
      "step": 3224
    },
    {
      "epoch": 2.1908967391304346,
      "grad_norm": 0.2073490172624588,
      "learning_rate": 3.3798402479779747e-06,
      "loss": 0.0013,
      "step": 3225
    },
    {
      "epoch": 2.1915760869565215,
      "grad_norm": 0.0026551522314548492,
      "learning_rate": 3.3745099684813953e-06,
      "loss": 0.0,
      "step": 3226
    },
    {
      "epoch": 2.192255434782609,
      "grad_norm": 0.25223925709724426,
      "learning_rate": 3.3691830421859317e-06,
      "loss": 0.0022,
      "step": 3227
    },
    {
      "epoch": 2.192934782608696,
      "grad_norm": 0.14869382977485657,
      "learning_rate": 3.3638594717875807e-06,
      "loss": 0.0007,
      "step": 3228
    },
    {
      "epoch": 2.1936141304347827,
      "grad_norm": 0.004125875886529684,
      "learning_rate": 3.3585392599806286e-06,
      "loss": 0.0001,
      "step": 3229
    },
    {
      "epoch": 2.1942934782608696,
      "grad_norm": 0.19167932868003845,
      "learning_rate": 3.3532224094576725e-06,
      "loss": 0.0011,
      "step": 3230
    },
    {
      "epoch": 2.1949728260869565,
      "grad_norm": 1.6481596231460571,
      "learning_rate": 3.347908922909594e-06,
      "loss": 0.0308,
      "step": 3231
    },
    {
      "epoch": 2.1956521739130435,
      "grad_norm": 3.7446846961975098,
      "learning_rate": 3.342598803025595e-06,
      "loss": 0.0637,
      "step": 3232
    },
    {
      "epoch": 2.1963315217391304,
      "grad_norm": 1.0125699043273926,
      "learning_rate": 3.3372920524931474e-06,
      "loss": 0.0162,
      "step": 3233
    },
    {
      "epoch": 2.1970108695652173,
      "grad_norm": 4.435356616973877,
      "learning_rate": 3.33198867399804e-06,
      "loss": 0.089,
      "step": 3234
    },
    {
      "epoch": 2.197690217391304,
      "grad_norm": 5.829504489898682,
      "learning_rate": 3.3266886702243363e-06,
      "loss": 0.168,
      "step": 3235
    },
    {
      "epoch": 2.198369565217391,
      "grad_norm": 4.179469585418701,
      "learning_rate": 3.321392043854407e-06,
      "loss": 0.0561,
      "step": 3236
    },
    {
      "epoch": 2.1990489130434785,
      "grad_norm": 0.9045516848564148,
      "learning_rate": 3.3160987975689017e-06,
      "loss": 0.0041,
      "step": 3237
    },
    {
      "epoch": 2.1997282608695654,
      "grad_norm": 3.8047351837158203,
      "learning_rate": 3.310808934046772e-06,
      "loss": 0.0829,
      "step": 3238
    },
    {
      "epoch": 2.2004076086956523,
      "grad_norm": 0.03966245800256729,
      "learning_rate": 3.3055224559652387e-06,
      "loss": 0.0003,
      "step": 3239
    },
    {
      "epoch": 2.2010869565217392,
      "grad_norm": 2.7426154613494873,
      "learning_rate": 3.3002393659998357e-06,
      "loss": 0.0387,
      "step": 3240
    },
    {
      "epoch": 2.201766304347826,
      "grad_norm": 0.005315417889505625,
      "learning_rate": 3.2949596668243556e-06,
      "loss": 0.0001,
      "step": 3241
    },
    {
      "epoch": 2.202445652173913,
      "grad_norm": 0.002400456229224801,
      "learning_rate": 3.2896833611108945e-06,
      "loss": 0.0,
      "step": 3242
    },
    {
      "epoch": 2.203125,
      "grad_norm": 0.03176841139793396,
      "learning_rate": 3.284410451529816e-06,
      "loss": 0.0003,
      "step": 3243
    },
    {
      "epoch": 2.203804347826087,
      "grad_norm": 1.4673817157745361,
      "learning_rate": 3.279140940749778e-06,
      "loss": 0.0131,
      "step": 3244
    },
    {
      "epoch": 2.204483695652174,
      "grad_norm": 8.710539817810059,
      "learning_rate": 3.2738748314377055e-06,
      "loss": 0.1709,
      "step": 3245
    },
    {
      "epoch": 2.2051630434782608,
      "grad_norm": 5.453139305114746,
      "learning_rate": 3.2686121262588165e-06,
      "loss": 0.0402,
      "step": 3246
    },
    {
      "epoch": 2.2058423913043477,
      "grad_norm": 5.815247058868408,
      "learning_rate": 3.2633528278765915e-06,
      "loss": 0.1755,
      "step": 3247
    },
    {
      "epoch": 2.2065217391304346,
      "grad_norm": 9.076013565063477,
      "learning_rate": 3.258096938952796e-06,
      "loss": 0.1529,
      "step": 3248
    },
    {
      "epoch": 2.2072010869565215,
      "grad_norm": 7.097052574157715,
      "learning_rate": 3.252844462147472e-06,
      "loss": 0.3417,
      "step": 3249
    },
    {
      "epoch": 2.207880434782609,
      "grad_norm": 8.17911434173584,
      "learning_rate": 3.2475954001189225e-06,
      "loss": 0.2461,
      "step": 3250
    },
    {
      "epoch": 2.208559782608696,
      "grad_norm": 2.357887029647827,
      "learning_rate": 3.242349755523737e-06,
      "loss": 0.0582,
      "step": 3251
    },
    {
      "epoch": 2.2092391304347827,
      "grad_norm": 4.2470316886901855,
      "learning_rate": 3.2371075310167634e-06,
      "loss": 0.1663,
      "step": 3252
    },
    {
      "epoch": 2.2099184782608696,
      "grad_norm": 7.999729633331299,
      "learning_rate": 3.2318687292511274e-06,
      "loss": 0.2936,
      "step": 3253
    },
    {
      "epoch": 2.2105978260869565,
      "grad_norm": 6.380068302154541,
      "learning_rate": 3.2266333528782135e-06,
      "loss": 0.0929,
      "step": 3254
    },
    {
      "epoch": 2.2112771739130435,
      "grad_norm": 0.1842394471168518,
      "learning_rate": 3.2214014045476815e-06,
      "loss": 0.0016,
      "step": 3255
    },
    {
      "epoch": 2.2119565217391304,
      "grad_norm": 5.845843315124512,
      "learning_rate": 3.2161728869074517e-06,
      "loss": 0.1479,
      "step": 3256
    },
    {
      "epoch": 2.2126358695652173,
      "grad_norm": 0.0969633087515831,
      "learning_rate": 3.2109478026037134e-06,
      "loss": 0.0004,
      "step": 3257
    },
    {
      "epoch": 2.213315217391304,
      "grad_norm": 1.0437787771224976,
      "learning_rate": 3.205726154280905e-06,
      "loss": 0.0037,
      "step": 3258
    },
    {
      "epoch": 2.213994565217391,
      "grad_norm": 4.496150970458984,
      "learning_rate": 3.2005079445817445e-06,
      "loss": 0.0778,
      "step": 3259
    },
    {
      "epoch": 2.2146739130434785,
      "grad_norm": 14.942741394042969,
      "learning_rate": 3.1952931761471893e-06,
      "loss": 0.5142,
      "step": 3260
    },
    {
      "epoch": 2.2153532608695654,
      "grad_norm": 2.513653039932251,
      "learning_rate": 3.1900818516164766e-06,
      "loss": 0.0346,
      "step": 3261
    },
    {
      "epoch": 2.2160326086956523,
      "grad_norm": 1.8412507772445679,
      "learning_rate": 3.1848739736270794e-06,
      "loss": 0.0331,
      "step": 3262
    },
    {
      "epoch": 2.2167119565217392,
      "grad_norm": 0.005606329999864101,
      "learning_rate": 3.179669544814745e-06,
      "loss": 0.0001,
      "step": 3263
    },
    {
      "epoch": 2.217391304347826,
      "grad_norm": 5.3127827644348145,
      "learning_rate": 3.174468567813461e-06,
      "loss": 0.0464,
      "step": 3264
    },
    {
      "epoch": 2.218070652173913,
      "grad_norm": 0.030637668445706367,
      "learning_rate": 3.1692710452554755e-06,
      "loss": 0.0002,
      "step": 3265
    },
    {
      "epoch": 2.21875,
      "grad_norm": 0.004667073953896761,
      "learning_rate": 3.1640769797712865e-06,
      "loss": 0.0001,
      "step": 3266
    },
    {
      "epoch": 2.219429347826087,
      "grad_norm": 0.001999324420467019,
      "learning_rate": 3.1588863739896457e-06,
      "loss": 0.0,
      "step": 3267
    },
    {
      "epoch": 2.220108695652174,
      "grad_norm": 3.4197888374328613,
      "learning_rate": 3.1536992305375457e-06,
      "loss": 0.0415,
      "step": 3268
    },
    {
      "epoch": 2.2207880434782608,
      "grad_norm": 2.6394660472869873,
      "learning_rate": 3.1485155520402354e-06,
      "loss": 0.0312,
      "step": 3269
    },
    {
      "epoch": 2.2214673913043477,
      "grad_norm": 0.07207261025905609,
      "learning_rate": 3.143335341121202e-06,
      "loss": 0.0005,
      "step": 3270
    },
    {
      "epoch": 2.2221467391304346,
      "grad_norm": 11.433541297912598,
      "learning_rate": 3.138158600402188e-06,
      "loss": 0.3108,
      "step": 3271
    },
    {
      "epoch": 2.2228260869565215,
      "grad_norm": 0.2766325771808624,
      "learning_rate": 3.132985332503167e-06,
      "loss": 0.0018,
      "step": 3272
    },
    {
      "epoch": 2.223505434782609,
      "grad_norm": 5.6488189697265625,
      "learning_rate": 3.1278155400423673e-06,
      "loss": 0.232,
      "step": 3273
    },
    {
      "epoch": 2.224184782608696,
      "grad_norm": 4.502895832061768,
      "learning_rate": 3.122649225636243e-06,
      "loss": 0.0418,
      "step": 3274
    },
    {
      "epoch": 2.2248641304347827,
      "grad_norm": 5.164059162139893,
      "learning_rate": 3.1174863918995114e-06,
      "loss": 0.1755,
      "step": 3275
    },
    {
      "epoch": 2.2255434782608696,
      "grad_norm": 0.0014664841582998633,
      "learning_rate": 3.1123270414451035e-06,
      "loss": 0.0,
      "step": 3276
    },
    {
      "epoch": 2.2262228260869565,
      "grad_norm": 0.7184913158416748,
      "learning_rate": 3.107171176884206e-06,
      "loss": 0.0063,
      "step": 3277
    },
    {
      "epoch": 2.2269021739130435,
      "grad_norm": 0.002342762192711234,
      "learning_rate": 3.1020188008262253e-06,
      "loss": 0.0,
      "step": 3278
    },
    {
      "epoch": 2.2275815217391304,
      "grad_norm": 5.528779983520508,
      "learning_rate": 3.0968699158788185e-06,
      "loss": 0.1033,
      "step": 3279
    },
    {
      "epoch": 2.2282608695652173,
      "grad_norm": 12.091682434082031,
      "learning_rate": 3.091724524647861e-06,
      "loss": 0.1414,
      "step": 3280
    },
    {
      "epoch": 2.228940217391304,
      "grad_norm": 6.282473564147949,
      "learning_rate": 3.0865826297374733e-06,
      "loss": 0.1031,
      "step": 3281
    },
    {
      "epoch": 2.229619565217391,
      "grad_norm": 8.145586013793945,
      "learning_rate": 3.081444233749994e-06,
      "loss": 0.1699,
      "step": 3282
    },
    {
      "epoch": 2.2302989130434785,
      "grad_norm": 0.04731268435716629,
      "learning_rate": 3.076309339285998e-06,
      "loss": 0.0004,
      "step": 3283
    },
    {
      "epoch": 2.2309782608695654,
      "grad_norm": 3.74210524559021,
      "learning_rate": 3.0711779489442918e-06,
      "loss": 0.0789,
      "step": 3284
    },
    {
      "epoch": 2.2316576086956523,
      "grad_norm": 3.636293411254883,
      "learning_rate": 3.0660500653218973e-06,
      "loss": 0.0444,
      "step": 3285
    },
    {
      "epoch": 2.2323369565217392,
      "grad_norm": 5.770855903625488,
      "learning_rate": 3.060925691014073e-06,
      "loss": 0.0964,
      "step": 3286
    },
    {
      "epoch": 2.233016304347826,
      "grad_norm": 0.015825696289539337,
      "learning_rate": 3.0558048286142905e-06,
      "loss": 0.0001,
      "step": 3287
    },
    {
      "epoch": 2.233695652173913,
      "grad_norm": 0.0014666833449155092,
      "learning_rate": 3.050687480714256e-06,
      "loss": 0.0,
      "step": 3288
    },
    {
      "epoch": 2.234375,
      "grad_norm": 6.5551533699035645,
      "learning_rate": 3.0455736499038847e-06,
      "loss": 0.2614,
      "step": 3289
    },
    {
      "epoch": 2.235054347826087,
      "grad_norm": 0.2466752678155899,
      "learning_rate": 3.040463338771323e-06,
      "loss": 0.0014,
      "step": 3290
    },
    {
      "epoch": 2.235733695652174,
      "grad_norm": 0.06433503329753876,
      "learning_rate": 3.0353565499029223e-06,
      "loss": 0.0004,
      "step": 3291
    },
    {
      "epoch": 2.2364130434782608,
      "grad_norm": 4.424401760101318,
      "learning_rate": 3.0302532858832723e-06,
      "loss": 0.156,
      "step": 3292
    },
    {
      "epoch": 2.2370923913043477,
      "grad_norm": 14.16065502166748,
      "learning_rate": 3.0251535492951556e-06,
      "loss": 0.7765,
      "step": 3293
    },
    {
      "epoch": 2.2377717391304346,
      "grad_norm": 0.012563546188175678,
      "learning_rate": 3.0200573427195877e-06,
      "loss": 0.0001,
      "step": 3294
    },
    {
      "epoch": 2.2384510869565215,
      "grad_norm": 0.02820832096040249,
      "learning_rate": 3.0149646687357825e-06,
      "loss": 0.0002,
      "step": 3295
    },
    {
      "epoch": 2.239130434782609,
      "grad_norm": 0.38231438398361206,
      "learning_rate": 3.009875529921181e-06,
      "loss": 0.0022,
      "step": 3296
    },
    {
      "epoch": 2.239809782608696,
      "grad_norm": 9.904553413391113,
      "learning_rate": 3.0047899288514213e-06,
      "loss": 0.979,
      "step": 3297
    },
    {
      "epoch": 2.2404891304347827,
      "grad_norm": 0.02784769982099533,
      "learning_rate": 2.999707868100362e-06,
      "loss": 0.0002,
      "step": 3298
    },
    {
      "epoch": 2.2411684782608696,
      "grad_norm": 1.8704458475112915,
      "learning_rate": 2.99462935024006e-06,
      "loss": 0.0238,
      "step": 3299
    },
    {
      "epoch": 2.2418478260869565,
      "grad_norm": 6.344371318817139,
      "learning_rate": 2.9895543778407875e-06,
      "loss": 0.2141,
      "step": 3300
    },
    {
      "epoch": 2.2425271739130435,
      "grad_norm": 16.072925567626953,
      "learning_rate": 2.9844829534710196e-06,
      "loss": 0.1715,
      "step": 3301
    },
    {
      "epoch": 2.2432065217391304,
      "grad_norm": 2.6024959087371826,
      "learning_rate": 2.9794150796974376e-06,
      "loss": 0.1313,
      "step": 3302
    },
    {
      "epoch": 2.2438858695652173,
      "grad_norm": 5.98674201965332,
      "learning_rate": 2.9743507590849176e-06,
      "loss": 0.0642,
      "step": 3303
    },
    {
      "epoch": 2.244565217391304,
      "grad_norm": 0.0401628240942955,
      "learning_rate": 2.9692899941965493e-06,
      "loss": 0.0003,
      "step": 3304
    },
    {
      "epoch": 2.245244565217391,
      "grad_norm": 0.03438784182071686,
      "learning_rate": 2.9642327875936104e-06,
      "loss": 0.0002,
      "step": 3305
    },
    {
      "epoch": 2.2459239130434785,
      "grad_norm": 0.7984787225723267,
      "learning_rate": 2.959179141835591e-06,
      "loss": 0.0095,
      "step": 3306
    },
    {
      "epoch": 2.2466032608695654,
      "grad_norm": 1.9503097534179688,
      "learning_rate": 2.954129059480165e-06,
      "loss": 0.0287,
      "step": 3307
    },
    {
      "epoch": 2.2472826086956523,
      "grad_norm": 5.759758472442627,
      "learning_rate": 2.949082543083215e-06,
      "loss": 0.0497,
      "step": 3308
    },
    {
      "epoch": 2.2479619565217392,
      "grad_norm": 9.447754859924316,
      "learning_rate": 2.944039595198814e-06,
      "loss": 0.175,
      "step": 3309
    },
    {
      "epoch": 2.248641304347826,
      "grad_norm": 5.501798152923584,
      "learning_rate": 2.9390002183792267e-06,
      "loss": 0.1075,
      "step": 3310
    },
    {
      "epoch": 2.249320652173913,
      "grad_norm": 4.260791778564453,
      "learning_rate": 2.933964415174915e-06,
      "loss": 0.0468,
      "step": 3311
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.10520844161510468,
      "learning_rate": 2.9289321881345257e-06,
      "loss": 0.0006,
      "step": 3312
    },
    {
      "epoch": 2.250679347826087,
      "grad_norm": 0.015451407991349697,
      "learning_rate": 2.923903539804902e-06,
      "loss": 0.0002,
      "step": 3313
    },
    {
      "epoch": 2.251358695652174,
      "grad_norm": 0.04704892262816429,
      "learning_rate": 2.918878472731077e-06,
      "loss": 0.0003,
      "step": 3314
    },
    {
      "epoch": 2.2520380434782608,
      "grad_norm": 5.966765403747559,
      "learning_rate": 2.913856989456262e-06,
      "loss": 0.2468,
      "step": 3315
    },
    {
      "epoch": 2.2527173913043477,
      "grad_norm": 0.022527683526277542,
      "learning_rate": 2.9088390925218667e-06,
      "loss": 0.0002,
      "step": 3316
    },
    {
      "epoch": 2.2533967391304346,
      "grad_norm": 0.006131172180175781,
      "learning_rate": 2.9038247844674726e-06,
      "loss": 0.0001,
      "step": 3317
    },
    {
      "epoch": 2.2540760869565215,
      "grad_norm": 6.103166580200195,
      "learning_rate": 2.898814067830855e-06,
      "loss": 0.2677,
      "step": 3318
    },
    {
      "epoch": 2.254755434782609,
      "grad_norm": 0.22485531866550446,
      "learning_rate": 2.8938069451479722e-06,
      "loss": 0.0013,
      "step": 3319
    },
    {
      "epoch": 2.255434782608696,
      "grad_norm": 5.804366111755371,
      "learning_rate": 2.8888034189529524e-06,
      "loss": 0.1126,
      "step": 3320
    },
    {
      "epoch": 2.2561141304347827,
      "grad_norm": 0.004231482278555632,
      "learning_rate": 2.8838034917781187e-06,
      "loss": 0.0001,
      "step": 3321
    },
    {
      "epoch": 2.2567934782608696,
      "grad_norm": 2.1637985706329346,
      "learning_rate": 2.878807166153956e-06,
      "loss": 0.0387,
      "step": 3322
    },
    {
      "epoch": 2.2574728260869565,
      "grad_norm": 0.13668474555015564,
      "learning_rate": 2.8738144446091452e-06,
      "loss": 0.0005,
      "step": 3323
    },
    {
      "epoch": 2.2581521739130435,
      "grad_norm": 0.016104288399219513,
      "learning_rate": 2.868825329670524e-06,
      "loss": 0.0001,
      "step": 3324
    },
    {
      "epoch": 2.2588315217391304,
      "grad_norm": 2.965115785598755,
      "learning_rate": 2.8638398238631183e-06,
      "loss": 0.0912,
      "step": 3325
    },
    {
      "epoch": 2.2595108695652173,
      "grad_norm": 0.003624384291470051,
      "learning_rate": 2.858857929710123e-06,
      "loss": 0.0001,
      "step": 3326
    },
    {
      "epoch": 2.260190217391304,
      "grad_norm": 9.241392135620117,
      "learning_rate": 2.853879649732908e-06,
      "loss": 0.1215,
      "step": 3327
    },
    {
      "epoch": 2.260869565217391,
      "grad_norm": 1.431038498878479,
      "learning_rate": 2.8489049864510053e-06,
      "loss": 0.0307,
      "step": 3328
    },
    {
      "epoch": 2.2615489130434785,
      "grad_norm": 6.953608989715576,
      "learning_rate": 2.84393394238213e-06,
      "loss": 0.2452,
      "step": 3329
    },
    {
      "epoch": 2.2622282608695654,
      "grad_norm": 38.90434265136719,
      "learning_rate": 2.83896652004215e-06,
      "loss": 0.424,
      "step": 3330
    },
    {
      "epoch": 2.2629076086956523,
      "grad_norm": 2.8605096340179443,
      "learning_rate": 2.834002721945115e-06,
      "loss": 0.1645,
      "step": 3331
    },
    {
      "epoch": 2.2635869565217392,
      "grad_norm": 4.869969844818115,
      "learning_rate": 2.829042550603228e-06,
      "loss": 0.0682,
      "step": 3332
    },
    {
      "epoch": 2.264266304347826,
      "grad_norm": 0.004247279837727547,
      "learning_rate": 2.8240860085268683e-06,
      "loss": 0.0001,
      "step": 3333
    },
    {
      "epoch": 2.264945652173913,
      "grad_norm": 0.0036950779613107443,
      "learning_rate": 2.8191330982245614e-06,
      "loss": 0.0001,
      "step": 3334
    },
    {
      "epoch": 2.265625,
      "grad_norm": 0.006729313172399998,
      "learning_rate": 2.8141838222030195e-06,
      "loss": 0.0001,
      "step": 3335
    },
    {
      "epoch": 2.266304347826087,
      "grad_norm": 12.451820373535156,
      "learning_rate": 2.809238182967092e-06,
      "loss": 0.08,
      "step": 3336
    },
    {
      "epoch": 2.266983695652174,
      "grad_norm": 0.8667246103286743,
      "learning_rate": 2.8042961830198034e-06,
      "loss": 0.0048,
      "step": 3337
    },
    {
      "epoch": 2.2676630434782608,
      "grad_norm": 1.7435696125030518,
      "learning_rate": 2.7993578248623233e-06,
      "loss": 0.0109,
      "step": 3338
    },
    {
      "epoch": 2.2683423913043477,
      "grad_norm": 0.014583589509129524,
      "learning_rate": 2.794423110993991e-06,
      "loss": 0.0001,
      "step": 3339
    },
    {
      "epoch": 2.2690217391304346,
      "grad_norm": 2.664954423904419,
      "learning_rate": 2.7894920439122907e-06,
      "loss": 0.0524,
      "step": 3340
    },
    {
      "epoch": 2.2697010869565215,
      "grad_norm": 2.205449104309082,
      "learning_rate": 2.7845646261128724e-06,
      "loss": 0.0297,
      "step": 3341
    },
    {
      "epoch": 2.270380434782609,
      "grad_norm": 15.654495239257812,
      "learning_rate": 2.779640860089523e-06,
      "loss": 0.3521,
      "step": 3342
    },
    {
      "epoch": 2.271059782608696,
      "grad_norm": 5.2575812339782715,
      "learning_rate": 2.7747207483341966e-06,
      "loss": 0.0762,
      "step": 3343
    },
    {
      "epoch": 2.2717391304347827,
      "grad_norm": 14.761536598205566,
      "learning_rate": 2.769804293336994e-06,
      "loss": 0.1029,
      "step": 3344
    },
    {
      "epoch": 2.2724184782608696,
      "grad_norm": 0.0017156872199848294,
      "learning_rate": 2.7648914975861573e-06,
      "loss": 0.0,
      "step": 3345
    },
    {
      "epoch": 2.2730978260869565,
      "grad_norm": 1.9831478595733643,
      "learning_rate": 2.759982363568089e-06,
      "loss": 0.0266,
      "step": 3346
    },
    {
      "epoch": 2.2737771739130435,
      "grad_norm": 7.917717933654785,
      "learning_rate": 2.7550768937673255e-06,
      "loss": 0.1676,
      "step": 3347
    },
    {
      "epoch": 2.2744565217391304,
      "grad_norm": 27.185083389282227,
      "learning_rate": 2.7501750906665603e-06,
      "loss": 0.1097,
      "step": 3348
    },
    {
      "epoch": 2.2751358695652173,
      "grad_norm": 3.395101547241211,
      "learning_rate": 2.745276956746621e-06,
      "loss": 0.0374,
      "step": 3349
    },
    {
      "epoch": 2.275815217391304,
      "grad_norm": 2.5257673263549805,
      "learning_rate": 2.74038249448649e-06,
      "loss": 0.0551,
      "step": 3350
    },
    {
      "epoch": 2.276494565217391,
      "grad_norm": 0.023588718846440315,
      "learning_rate": 2.7354917063632735e-06,
      "loss": 0.0002,
      "step": 3351
    },
    {
      "epoch": 2.2771739130434785,
      "grad_norm": 0.5109377503395081,
      "learning_rate": 2.730604594852243e-06,
      "loss": 0.0026,
      "step": 3352
    },
    {
      "epoch": 2.2778532608695654,
      "grad_norm": 14.734243392944336,
      "learning_rate": 2.7257211624267855e-06,
      "loss": 0.7486,
      "step": 3353
    },
    {
      "epoch": 2.2785326086956523,
      "grad_norm": 0.0034307080786675215,
      "learning_rate": 2.7208414115584436e-06,
      "loss": 0.0001,
      "step": 3354
    },
    {
      "epoch": 2.2792119565217392,
      "grad_norm": 3.4132747650146484,
      "learning_rate": 2.715965344716881e-06,
      "loss": 0.0463,
      "step": 3355
    },
    {
      "epoch": 2.279891304347826,
      "grad_norm": 0.015488947741687298,
      "learning_rate": 2.7110929643699133e-06,
      "loss": 0.0001,
      "step": 3356
    },
    {
      "epoch": 2.280570652173913,
      "grad_norm": 0.14526744186878204,
      "learning_rate": 2.7062242729834743e-06,
      "loss": 0.0007,
      "step": 3357
    },
    {
      "epoch": 2.28125,
      "grad_norm": 13.025382041931152,
      "learning_rate": 2.7013592730216464e-06,
      "loss": 0.5972,
      "step": 3358
    },
    {
      "epoch": 2.281929347826087,
      "grad_norm": 11.07834529876709,
      "learning_rate": 2.6964979669466275e-06,
      "loss": 0.3405,
      "step": 3359
    },
    {
      "epoch": 2.282608695652174,
      "grad_norm": 2.039618492126465,
      "learning_rate": 2.691640357218759e-06,
      "loss": 0.0524,
      "step": 3360
    },
    {
      "epoch": 2.2832880434782608,
      "grad_norm": 3.5142457485198975,
      "learning_rate": 2.6867864462965064e-06,
      "loss": 0.0815,
      "step": 3361
    },
    {
      "epoch": 2.2839673913043477,
      "grad_norm": 2.4689793586730957,
      "learning_rate": 2.6819362366364676e-06,
      "loss": 0.0416,
      "step": 3362
    },
    {
      "epoch": 2.2846467391304346,
      "grad_norm": 4.551786422729492,
      "learning_rate": 2.677089730693356e-06,
      "loss": 0.0232,
      "step": 3363
    },
    {
      "epoch": 2.2853260869565215,
      "grad_norm": 0.40804362297058105,
      "learning_rate": 2.6722469309200262e-06,
      "loss": 0.002,
      "step": 3364
    },
    {
      "epoch": 2.286005434782609,
      "grad_norm": 0.5142170786857605,
      "learning_rate": 2.667407839767441e-06,
      "loss": 0.0042,
      "step": 3365
    },
    {
      "epoch": 2.286684782608696,
      "grad_norm": 3.515662431716919,
      "learning_rate": 2.662572459684699e-06,
      "loss": 0.1185,
      "step": 3366
    },
    {
      "epoch": 2.2873641304347827,
      "grad_norm": 8.765226364135742,
      "learning_rate": 2.6577407931190124e-06,
      "loss": 0.1958,
      "step": 3367
    },
    {
      "epoch": 2.2880434782608696,
      "grad_norm": 0.19326698780059814,
      "learning_rate": 2.6529128425157226e-06,
      "loss": 0.0015,
      "step": 3368
    },
    {
      "epoch": 2.2887228260869565,
      "grad_norm": 0.229450061917305,
      "learning_rate": 2.648088610318278e-06,
      "loss": 0.0024,
      "step": 3369
    },
    {
      "epoch": 2.2894021739130435,
      "grad_norm": 4.9145731925964355,
      "learning_rate": 2.643268098968256e-06,
      "loss": 0.1362,
      "step": 3370
    },
    {
      "epoch": 2.2900815217391304,
      "grad_norm": 0.17656636238098145,
      "learning_rate": 2.6384513109053457e-06,
      "loss": 0.0016,
      "step": 3371
    },
    {
      "epoch": 2.2907608695652173,
      "grad_norm": 1.5661022663116455,
      "learning_rate": 2.6336382485673574e-06,
      "loss": 0.0211,
      "step": 3372
    },
    {
      "epoch": 2.291440217391304,
      "grad_norm": 8.072854995727539,
      "learning_rate": 2.6288289143902046e-06,
      "loss": 0.3437,
      "step": 3373
    },
    {
      "epoch": 2.292119565217391,
      "grad_norm": 0.001941403141245246,
      "learning_rate": 2.6240233108079282e-06,
      "loss": 0.0001,
      "step": 3374
    },
    {
      "epoch": 2.2927989130434785,
      "grad_norm": 0.0024950336664915085,
      "learning_rate": 2.6192214402526662e-06,
      "loss": 0.0,
      "step": 3375
    },
    {
      "epoch": 2.2934782608695654,
      "grad_norm": 0.07808399945497513,
      "learning_rate": 2.6144233051546797e-06,
      "loss": 0.0004,
      "step": 3376
    },
    {
      "epoch": 2.2941576086956523,
      "grad_norm": 13.611896514892578,
      "learning_rate": 2.609628907942331e-06,
      "loss": 0.6018,
      "step": 3377
    },
    {
      "epoch": 2.2948369565217392,
      "grad_norm": 0.001349208177998662,
      "learning_rate": 2.6048382510420954e-06,
      "loss": 0.0,
      "step": 3378
    },
    {
      "epoch": 2.295516304347826,
      "grad_norm": 3.2071752548217773,
      "learning_rate": 2.6000513368785574e-06,
      "loss": 0.0472,
      "step": 3379
    },
    {
      "epoch": 2.296195652173913,
      "grad_norm": 6.409430027008057,
      "learning_rate": 2.595268167874396e-06,
      "loss": 0.1728,
      "step": 3380
    },
    {
      "epoch": 2.296875,
      "grad_norm": 0.01045544259250164,
      "learning_rate": 2.5904887464504115e-06,
      "loss": 0.0002,
      "step": 3381
    },
    {
      "epoch": 2.297554347826087,
      "grad_norm": 7.092723369598389,
      "learning_rate": 2.5857130750254887e-06,
      "loss": 0.3221,
      "step": 3382
    },
    {
      "epoch": 2.298233695652174,
      "grad_norm": 3.41395902633667,
      "learning_rate": 2.580941156016632e-06,
      "loss": 0.0959,
      "step": 3383
    },
    {
      "epoch": 2.2989130434782608,
      "grad_norm": 1.5532904863357544,
      "learning_rate": 2.576172991838933e-06,
      "loss": 0.069,
      "step": 3384
    },
    {
      "epoch": 2.2995923913043477,
      "grad_norm": 0.004724240396171808,
      "learning_rate": 2.5714085849055945e-06,
      "loss": 0.0,
      "step": 3385
    },
    {
      "epoch": 2.3002717391304346,
      "grad_norm": 6.956016540527344,
      "learning_rate": 2.566647937627904e-06,
      "loss": 0.2948,
      "step": 3386
    },
    {
      "epoch": 2.3009510869565215,
      "grad_norm": 0.09075430035591125,
      "learning_rate": 2.5618910524152652e-06,
      "loss": 0.0006,
      "step": 3387
    },
    {
      "epoch": 2.301630434782609,
      "grad_norm": 0.0040030390955507755,
      "learning_rate": 2.5571379316751565e-06,
      "loss": 0.0001,
      "step": 3388
    },
    {
      "epoch": 2.302309782608696,
      "grad_norm": 0.027220385149121284,
      "learning_rate": 2.5523885778131706e-06,
      "loss": 0.0002,
      "step": 3389
    },
    {
      "epoch": 2.3029891304347827,
      "grad_norm": 0.13856419920921326,
      "learning_rate": 2.547642993232976e-06,
      "loss": 0.001,
      "step": 3390
    },
    {
      "epoch": 2.3036684782608696,
      "grad_norm": 9.773639678955078,
      "learning_rate": 2.5429011803363503e-06,
      "loss": 0.0529,
      "step": 3391
    },
    {
      "epoch": 2.3043478260869565,
      "grad_norm": 4.719015598297119,
      "learning_rate": 2.5381631415231455e-06,
      "loss": 0.1025,
      "step": 3392
    },
    {
      "epoch": 2.3050271739130435,
      "grad_norm": 0.6495563387870789,
      "learning_rate": 2.533428879191321e-06,
      "loss": 0.0037,
      "step": 3393
    },
    {
      "epoch": 2.3057065217391304,
      "grad_norm": 15.700133323669434,
      "learning_rate": 2.5286983957369037e-06,
      "loss": 0.2894,
      "step": 3394
    },
    {
      "epoch": 2.3063858695652173,
      "grad_norm": 0.005314390175044537,
      "learning_rate": 2.523971693554036e-06,
      "loss": 0.0001,
      "step": 3395
    },
    {
      "epoch": 2.307065217391304,
      "grad_norm": 3.370091199874878,
      "learning_rate": 2.519248775034918e-06,
      "loss": 0.0238,
      "step": 3396
    },
    {
      "epoch": 2.307744565217391,
      "grad_norm": 20.068614959716797,
      "learning_rate": 2.5145296425698575e-06,
      "loss": 0.3023,
      "step": 3397
    },
    {
      "epoch": 2.3084239130434785,
      "grad_norm": 15.481624603271484,
      "learning_rate": 2.5098142985472274e-06,
      "loss": 0.6489,
      "step": 3398
    },
    {
      "epoch": 2.3091032608695654,
      "grad_norm": 0.036222897469997406,
      "learning_rate": 2.505102745353499e-06,
      "loss": 0.0002,
      "step": 3399
    },
    {
      "epoch": 2.3097826086956523,
      "grad_norm": 0.7641611099243164,
      "learning_rate": 2.5003949853732135e-06,
      "loss": 0.0059,
      "step": 3400
    },
    {
      "epoch": 2.3104619565217392,
      "grad_norm": 3.377209186553955,
      "learning_rate": 2.4956910209890017e-06,
      "loss": 0.0659,
      "step": 3401
    },
    {
      "epoch": 2.311141304347826,
      "grad_norm": 6.840648651123047,
      "learning_rate": 2.490990854581563e-06,
      "loss": 0.2195,
      "step": 3402
    },
    {
      "epoch": 2.311820652173913,
      "grad_norm": 9.731575012207031,
      "learning_rate": 2.4862944885296846e-06,
      "loss": 0.0728,
      "step": 3403
    },
    {
      "epoch": 2.3125,
      "grad_norm": 4.822611331939697,
      "learning_rate": 2.4816019252102274e-06,
      "loss": 0.1302,
      "step": 3404
    },
    {
      "epoch": 2.313179347826087,
      "grad_norm": 0.006409110501408577,
      "learning_rate": 2.4769131669981217e-06,
      "loss": 0.0001,
      "step": 3405
    },
    {
      "epoch": 2.313858695652174,
      "grad_norm": 0.7591956853866577,
      "learning_rate": 2.4722282162663826e-06,
      "loss": 0.0038,
      "step": 3406
    },
    {
      "epoch": 2.3145380434782608,
      "grad_norm": 6.426026344299316,
      "learning_rate": 2.467547075386085e-06,
      "loss": 0.1913,
      "step": 3407
    },
    {
      "epoch": 2.3152173913043477,
      "grad_norm": 0.05837174877524376,
      "learning_rate": 2.4628697467263916e-06,
      "loss": 0.0004,
      "step": 3408
    },
    {
      "epoch": 2.3158967391304346,
      "grad_norm": 7.618968486785889,
      "learning_rate": 2.4581962326545184e-06,
      "loss": 0.2188,
      "step": 3409
    },
    {
      "epoch": 2.3165760869565215,
      "grad_norm": 1.2271441221237183,
      "learning_rate": 2.4535265355357675e-06,
      "loss": 0.0181,
      "step": 3410
    },
    {
      "epoch": 2.317255434782609,
      "grad_norm": 0.15427610278129578,
      "learning_rate": 2.448860657733495e-06,
      "loss": 0.0014,
      "step": 3411
    },
    {
      "epoch": 2.317934782608696,
      "grad_norm": 4.602290153503418,
      "learning_rate": 2.4441986016091325e-06,
      "loss": 0.1921,
      "step": 3412
    },
    {
      "epoch": 2.3186141304347827,
      "grad_norm": 0.9934400320053101,
      "learning_rate": 2.4395403695221754e-06,
      "loss": 0.0066,
      "step": 3413
    },
    {
      "epoch": 2.3192934782608696,
      "grad_norm": 0.001955461222678423,
      "learning_rate": 2.4348859638301857e-06,
      "loss": 0.0,
      "step": 3414
    },
    {
      "epoch": 2.3199728260869565,
      "grad_norm": 0.434481680393219,
      "learning_rate": 2.430235386888783e-06,
      "loss": 0.0012,
      "step": 3415
    },
    {
      "epoch": 2.3206521739130435,
      "grad_norm": 14.298727035522461,
      "learning_rate": 2.425588641051656e-06,
      "loss": 0.0572,
      "step": 3416
    },
    {
      "epoch": 2.3213315217391304,
      "grad_norm": 3.962371349334717,
      "learning_rate": 2.4209457286705475e-06,
      "loss": 0.0932,
      "step": 3417
    },
    {
      "epoch": 2.3220108695652173,
      "grad_norm": 5.601373672485352,
      "learning_rate": 2.4163066520952684e-06,
      "loss": 0.1768,
      "step": 3418
    },
    {
      "epoch": 2.322690217391304,
      "grad_norm": 3.7993180751800537,
      "learning_rate": 2.4116714136736784e-06,
      "loss": 0.0318,
      "step": 3419
    },
    {
      "epoch": 2.323369565217391,
      "grad_norm": 0.1047997698187828,
      "learning_rate": 2.4070400157517036e-06,
      "loss": 0.0007,
      "step": 3420
    },
    {
      "epoch": 2.3240489130434785,
      "grad_norm": 13.122052192687988,
      "learning_rate": 2.4024124606733225e-06,
      "loss": 0.1335,
      "step": 3421
    },
    {
      "epoch": 2.3247282608695654,
      "grad_norm": 0.07505274564027786,
      "learning_rate": 2.397788750780572e-06,
      "loss": 0.0007,
      "step": 3422
    },
    {
      "epoch": 2.3254076086956523,
      "grad_norm": 0.07848980277776718,
      "learning_rate": 2.393168888413533e-06,
      "loss": 0.0004,
      "step": 3423
    },
    {
      "epoch": 2.3260869565217392,
      "grad_norm": 0.00932376179844141,
      "learning_rate": 2.388552875910354e-06,
      "loss": 0.0001,
      "step": 3424
    },
    {
      "epoch": 2.326766304347826,
      "grad_norm": 1.388533592224121,
      "learning_rate": 2.3839407156072203e-06,
      "loss": 0.0288,
      "step": 3425
    },
    {
      "epoch": 2.327445652173913,
      "grad_norm": 0.008487861603498459,
      "learning_rate": 2.3793324098383796e-06,
      "loss": 0.0001,
      "step": 3426
    },
    {
      "epoch": 2.328125,
      "grad_norm": 1.7708373069763184,
      "learning_rate": 2.3747279609361197e-06,
      "loss": 0.0288,
      "step": 3427
    },
    {
      "epoch": 2.328804347826087,
      "grad_norm": 5.180197715759277,
      "learning_rate": 2.370127371230785e-06,
      "loss": 0.1585,
      "step": 3428
    },
    {
      "epoch": 2.329483695652174,
      "grad_norm": 4.464332103729248,
      "learning_rate": 2.3655306430507563e-06,
      "loss": 0.1958,
      "step": 3429
    },
    {
      "epoch": 2.3301630434782608,
      "grad_norm": 0.0027455780655145645,
      "learning_rate": 2.3609377787224697e-06,
      "loss": 0.0001,
      "step": 3430
    },
    {
      "epoch": 2.3308423913043477,
      "grad_norm": 0.23273023962974548,
      "learning_rate": 2.356348780570401e-06,
      "loss": 0.0009,
      "step": 3431
    },
    {
      "epoch": 2.3315217391304346,
      "grad_norm": 1.7371662855148315,
      "learning_rate": 2.351763650917074e-06,
      "loss": 0.0638,
      "step": 3432
    },
    {
      "epoch": 2.3322010869565215,
      "grad_norm": 0.3490947484970093,
      "learning_rate": 2.347182392083045e-06,
      "loss": 0.0024,
      "step": 3433
    },
    {
      "epoch": 2.332880434782609,
      "grad_norm": 6.592639923095703,
      "learning_rate": 2.342605006386922e-06,
      "loss": 0.0473,
      "step": 3434
    },
    {
      "epoch": 2.333559782608696,
      "grad_norm": 7.101757526397705,
      "learning_rate": 2.338031496145343e-06,
      "loss": 0.1804,
      "step": 3435
    },
    {
      "epoch": 2.3342391304347827,
      "grad_norm": 7.237837314605713,
      "learning_rate": 2.3334618636729956e-06,
      "loss": 0.1164,
      "step": 3436
    },
    {
      "epoch": 2.3349184782608696,
      "grad_norm": 10.289713859558105,
      "learning_rate": 2.3288961112825925e-06,
      "loss": 0.09,
      "step": 3437
    },
    {
      "epoch": 2.3355978260869565,
      "grad_norm": 4.483493804931641,
      "learning_rate": 2.3243342412848923e-06,
      "loss": 0.181,
      "step": 3438
    },
    {
      "epoch": 2.3362771739130435,
      "grad_norm": 3.1546456813812256,
      "learning_rate": 2.319776255988687e-06,
      "loss": 0.1078,
      "step": 3439
    },
    {
      "epoch": 2.3369565217391304,
      "grad_norm": 1.067020058631897,
      "learning_rate": 2.315222157700797e-06,
      "loss": 0.0097,
      "step": 3440
    },
    {
      "epoch": 2.3376358695652173,
      "grad_norm": 0.11960714310407639,
      "learning_rate": 2.3106719487260843e-06,
      "loss": 0.0005,
      "step": 3441
    },
    {
      "epoch": 2.338315217391304,
      "grad_norm": 1.5731041431427002,
      "learning_rate": 2.306125631367432e-06,
      "loss": 0.0192,
      "step": 3442
    },
    {
      "epoch": 2.338994565217391,
      "grad_norm": 1.6151018142700195,
      "learning_rate": 2.3015832079257637e-06,
      "loss": 0.0105,
      "step": 3443
    },
    {
      "epoch": 2.3396739130434785,
      "grad_norm": 1.6145522594451904,
      "learning_rate": 2.2970446807000237e-06,
      "loss": 0.0121,
      "step": 3444
    },
    {
      "epoch": 2.3403532608695654,
      "grad_norm": 0.14565184712409973,
      "learning_rate": 2.2925100519871934e-06,
      "loss": 0.0018,
      "step": 3445
    },
    {
      "epoch": 2.3410326086956523,
      "grad_norm": 5.7833452224731445,
      "learning_rate": 2.287979324082268e-06,
      "loss": 0.1703,
      "step": 3446
    },
    {
      "epoch": 2.3417119565217392,
      "grad_norm": 7.078647136688232,
      "learning_rate": 2.2834524992782867e-06,
      "loss": 0.0768,
      "step": 3447
    },
    {
      "epoch": 2.342391304347826,
      "grad_norm": 8.819345474243164,
      "learning_rate": 2.2789295798662967e-06,
      "loss": 0.26,
      "step": 3448
    },
    {
      "epoch": 2.343070652173913,
      "grad_norm": 3.7308006286621094,
      "learning_rate": 2.27441056813538e-06,
      "loss": 0.2128,
      "step": 3449
    },
    {
      "epoch": 2.34375,
      "grad_norm": 0.964884877204895,
      "learning_rate": 2.26989546637263e-06,
      "loss": 0.0141,
      "step": 3450
    },
    {
      "epoch": 2.344429347826087,
      "grad_norm": 5.512770652770996,
      "learning_rate": 2.265384276863174e-06,
      "loss": 0.188,
      "step": 3451
    },
    {
      "epoch": 2.345108695652174,
      "grad_norm": 5.22365140914917,
      "learning_rate": 2.260877001890147e-06,
      "loss": 0.1679,
      "step": 3452
    },
    {
      "epoch": 2.3457880434782608,
      "grad_norm": 0.8635427355766296,
      "learning_rate": 2.256373643734713e-06,
      "loss": 0.0054,
      "step": 3453
    },
    {
      "epoch": 2.3464673913043477,
      "grad_norm": 7.692317485809326,
      "learning_rate": 2.2518742046760445e-06,
      "loss": 0.0844,
      "step": 3454
    },
    {
      "epoch": 2.3471467391304346,
      "grad_norm": 30.040515899658203,
      "learning_rate": 2.247378686991337e-06,
      "loss": 0.4609,
      "step": 3455
    },
    {
      "epoch": 2.3478260869565215,
      "grad_norm": 8.527338981628418,
      "learning_rate": 2.2428870929558012e-06,
      "loss": 0.3858,
      "step": 3456
    },
    {
      "epoch": 2.348505434782609,
      "grad_norm": 0.010843309573829174,
      "learning_rate": 2.238399424842661e-06,
      "loss": 0.0001,
      "step": 3457
    },
    {
      "epoch": 2.349184782608696,
      "grad_norm": 2.565436840057373,
      "learning_rate": 2.2339156849231503e-06,
      "loss": 0.0595,
      "step": 3458
    },
    {
      "epoch": 2.3498641304347827,
      "grad_norm": 2.452253818511963,
      "learning_rate": 2.229435875466519e-06,
      "loss": 0.0546,
      "step": 3459
    },
    {
      "epoch": 2.3505434782608696,
      "grad_norm": 4.248946189880371,
      "learning_rate": 2.2249599987400237e-06,
      "loss": 0.0664,
      "step": 3460
    },
    {
      "epoch": 2.3512228260869565,
      "grad_norm": 0.009135524742305279,
      "learning_rate": 2.2204880570089383e-06,
      "loss": 0.0001,
      "step": 3461
    },
    {
      "epoch": 2.3519021739130435,
      "grad_norm": 6.666645526885986,
      "learning_rate": 2.2160200525365326e-06,
      "loss": 0.1254,
      "step": 3462
    },
    {
      "epoch": 2.3525815217391304,
      "grad_norm": 4.2236433029174805,
      "learning_rate": 2.2115559875840943e-06,
      "loss": 0.1062,
      "step": 3463
    },
    {
      "epoch": 2.3532608695652173,
      "grad_norm": 0.004545318428426981,
      "learning_rate": 2.207095864410919e-06,
      "loss": 0.0001,
      "step": 3464
    },
    {
      "epoch": 2.353940217391304,
      "grad_norm": 0.008088670670986176,
      "learning_rate": 2.2026396852742936e-06,
      "loss": 0.0001,
      "step": 3465
    },
    {
      "epoch": 2.354619565217391,
      "grad_norm": 0.022976288571953773,
      "learning_rate": 2.1981874524295255e-06,
      "loss": 0.0003,
      "step": 3466
    },
    {
      "epoch": 2.3552989130434785,
      "grad_norm": 4.504271507263184,
      "learning_rate": 2.1937391681299103e-06,
      "loss": 0.0431,
      "step": 3467
    },
    {
      "epoch": 2.3559782608695654,
      "grad_norm": 8.177877426147461,
      "learning_rate": 2.1892948346267583e-06,
      "loss": 0.3045,
      "step": 3468
    },
    {
      "epoch": 2.3566576086956523,
      "grad_norm": 0.014498356729745865,
      "learning_rate": 2.1848544541693674e-06,
      "loss": 0.0003,
      "step": 3469
    },
    {
      "epoch": 2.3573369565217392,
      "grad_norm": 0.9141684770584106,
      "learning_rate": 2.180418029005048e-06,
      "loss": 0.0048,
      "step": 3470
    },
    {
      "epoch": 2.358016304347826,
      "grad_norm": 9.337663650512695,
      "learning_rate": 2.175985561379097e-06,
      "loss": 0.0913,
      "step": 3471
    },
    {
      "epoch": 2.358695652173913,
      "grad_norm": 6.665194034576416,
      "learning_rate": 2.171557053534814e-06,
      "loss": 0.1068,
      "step": 3472
    },
    {
      "epoch": 2.359375,
      "grad_norm": 8.150068283081055,
      "learning_rate": 2.1671325077134963e-06,
      "loss": 0.3938,
      "step": 3473
    },
    {
      "epoch": 2.360054347826087,
      "grad_norm": 0.032465044409036636,
      "learning_rate": 2.1627119261544348e-06,
      "loss": 0.0002,
      "step": 3474
    },
    {
      "epoch": 2.360733695652174,
      "grad_norm": 8.565719604492188,
      "learning_rate": 2.1582953110949077e-06,
      "loss": 0.2281,
      "step": 3475
    },
    {
      "epoch": 2.3614130434782608,
      "grad_norm": 11.211366653442383,
      "learning_rate": 2.153882664770197e-06,
      "loss": 0.6274,
      "step": 3476
    },
    {
      "epoch": 2.3620923913043477,
      "grad_norm": 4.592090129852295,
      "learning_rate": 2.149473989413564e-06,
      "loss": 0.0406,
      "step": 3477
    },
    {
      "epoch": 2.3627717391304346,
      "grad_norm": 6.834652900695801,
      "learning_rate": 2.145069287256273e-06,
      "loss": 0.1069,
      "step": 3478
    },
    {
      "epoch": 2.3634510869565215,
      "grad_norm": 2.3435168266296387,
      "learning_rate": 2.1406685605275647e-06,
      "loss": 0.0155,
      "step": 3479
    },
    {
      "epoch": 2.364130434782609,
      "grad_norm": 2.0517427921295166,
      "learning_rate": 2.1362718114546777e-06,
      "loss": 0.0274,
      "step": 3480
    },
    {
      "epoch": 2.364809782608696,
      "grad_norm": 0.3583054542541504,
      "learning_rate": 2.131879042262828e-06,
      "loss": 0.0033,
      "step": 3481
    },
    {
      "epoch": 2.3654891304347827,
      "grad_norm": 4.285407066345215,
      "learning_rate": 2.127490255175232e-06,
      "loss": 0.161,
      "step": 3482
    },
    {
      "epoch": 2.3661684782608696,
      "grad_norm": 21.955726623535156,
      "learning_rate": 2.1231054524130746e-06,
      "loss": 1.2556,
      "step": 3483
    },
    {
      "epoch": 2.3668478260869565,
      "grad_norm": 3.0237679481506348,
      "learning_rate": 2.118724636195536e-06,
      "loss": 0.0417,
      "step": 3484
    },
    {
      "epoch": 2.3675271739130435,
      "grad_norm": 5.288114070892334,
      "learning_rate": 2.1143478087397706e-06,
      "loss": 0.0906,
      "step": 3485
    },
    {
      "epoch": 2.3682065217391304,
      "grad_norm": 15.873176574707031,
      "learning_rate": 2.109974972260921e-06,
      "loss": 0.6859,
      "step": 3486
    },
    {
      "epoch": 2.3688858695652173,
      "grad_norm": 12.698506355285645,
      "learning_rate": 2.1056061289721008e-06,
      "loss": 0.3124,
      "step": 3487
    },
    {
      "epoch": 2.369565217391304,
      "grad_norm": 0.008516231551766396,
      "learning_rate": 2.101241281084416e-06,
      "loss": 0.0001,
      "step": 3488
    },
    {
      "epoch": 2.370244565217391,
      "grad_norm": 0.1450466811656952,
      "learning_rate": 2.0968804308069324e-06,
      "loss": 0.0008,
      "step": 3489
    },
    {
      "epoch": 2.3709239130434785,
      "grad_norm": 2.4746503829956055,
      "learning_rate": 2.092523580346716e-06,
      "loss": 0.0106,
      "step": 3490
    },
    {
      "epoch": 2.3716032608695654,
      "grad_norm": 0.21067745983600616,
      "learning_rate": 2.0881707319087863e-06,
      "loss": 0.0011,
      "step": 3491
    },
    {
      "epoch": 2.3722826086956523,
      "grad_norm": 4.989714622497559,
      "learning_rate": 2.0838218876961524e-06,
      "loss": 0.1374,
      "step": 3492
    },
    {
      "epoch": 2.3729619565217392,
      "grad_norm": 0.019285719841718674,
      "learning_rate": 2.0794770499097848e-06,
      "loss": 0.0002,
      "step": 3493
    },
    {
      "epoch": 2.373641304347826,
      "grad_norm": 5.813663005828857,
      "learning_rate": 2.075136220748638e-06,
      "loss": 0.1329,
      "step": 3494
    },
    {
      "epoch": 2.374320652173913,
      "grad_norm": 1.06073796749115,
      "learning_rate": 2.070799402409628e-06,
      "loss": 0.0049,
      "step": 3495
    },
    {
      "epoch": 2.375,
      "grad_norm": 0.0036395229399204254,
      "learning_rate": 2.0664665970876496e-06,
      "loss": 0.0001,
      "step": 3496
    },
    {
      "epoch": 2.375679347826087,
      "grad_norm": 0.10543865710496902,
      "learning_rate": 2.062137806975557e-06,
      "loss": 0.0006,
      "step": 3497
    },
    {
      "epoch": 2.376358695652174,
      "grad_norm": 0.0035481962841004133,
      "learning_rate": 2.057813034264181e-06,
      "loss": 0.0001,
      "step": 3498
    },
    {
      "epoch": 2.3770380434782608,
      "grad_norm": 5.521352767944336,
      "learning_rate": 2.0534922811423165e-06,
      "loss": 0.1083,
      "step": 3499
    },
    {
      "epoch": 2.3777173913043477,
      "grad_norm": 5.5487380027771,
      "learning_rate": 2.0491755497967183e-06,
      "loss": 0.1417,
      "step": 3500
    },
    {
      "epoch": 2.3783967391304346,
      "grad_norm": 5.943140029907227,
      "learning_rate": 2.0448628424121173e-06,
      "loss": 0.0816,
      "step": 3501
    },
    {
      "epoch": 2.3790760869565215,
      "grad_norm": 0.05966227874159813,
      "learning_rate": 2.0405541611711943e-06,
      "loss": 0.0005,
      "step": 3502
    },
    {
      "epoch": 2.379755434782609,
      "grad_norm": 9.1693754196167,
      "learning_rate": 2.036249508254605e-06,
      "loss": 0.486,
      "step": 3503
    },
    {
      "epoch": 2.380434782608696,
      "grad_norm": 12.355142593383789,
      "learning_rate": 2.0319488858409552e-06,
      "loss": 0.3221,
      "step": 3504
    },
    {
      "epoch": 2.3811141304347827,
      "grad_norm": 0.8499402403831482,
      "learning_rate": 2.0276522961068225e-06,
      "loss": 0.0077,
      "step": 3505
    },
    {
      "epoch": 2.3817934782608696,
      "grad_norm": 8.11854362487793,
      "learning_rate": 2.0233597412267303e-06,
      "loss": 0.2046,
      "step": 3506
    },
    {
      "epoch": 2.3824728260869565,
      "grad_norm": 3.5690152645111084,
      "learning_rate": 2.019071223373171e-06,
      "loss": 0.055,
      "step": 3507
    },
    {
      "epoch": 2.3831521739130435,
      "grad_norm": 3.6207618713378906,
      "learning_rate": 2.0147867447165894e-06,
      "loss": 0.1261,
      "step": 3508
    },
    {
      "epoch": 2.3838315217391304,
      "grad_norm": 1.9686737060546875,
      "learning_rate": 2.0105063074253894e-06,
      "loss": 0.042,
      "step": 3509
    },
    {
      "epoch": 2.3845108695652173,
      "grad_norm": 0.2651108205318451,
      "learning_rate": 2.0062299136659203e-06,
      "loss": 0.0014,
      "step": 3510
    },
    {
      "epoch": 2.385190217391304,
      "grad_norm": 0.0035538384690880775,
      "learning_rate": 2.001957565602498e-06,
      "loss": 0.0001,
      "step": 3511
    },
    {
      "epoch": 2.385869565217391,
      "grad_norm": 17.644935607910156,
      "learning_rate": 1.997689265397377e-06,
      "loss": 0.4513,
      "step": 3512
    },
    {
      "epoch": 2.3865489130434785,
      "grad_norm": 4.156787872314453,
      "learning_rate": 1.993425015210777e-06,
      "loss": 0.0663,
      "step": 3513
    },
    {
      "epoch": 2.3872282608695654,
      "grad_norm": 0.029963916167616844,
      "learning_rate": 1.989164817200855e-06,
      "loss": 0.0002,
      "step": 3514
    },
    {
      "epoch": 2.3879076086956523,
      "grad_norm": 5.29587984085083,
      "learning_rate": 1.9849086735237254e-06,
      "loss": 0.1667,
      "step": 3515
    },
    {
      "epoch": 2.3885869565217392,
      "grad_norm": 4.149905681610107,
      "learning_rate": 1.980656586333449e-06,
      "loss": 0.0619,
      "step": 3516
    },
    {
      "epoch": 2.389266304347826,
      "grad_norm": 0.02546706795692444,
      "learning_rate": 1.976408557782038e-06,
      "loss": 0.0002,
      "step": 3517
    },
    {
      "epoch": 2.389945652173913,
      "grad_norm": 0.006518357899039984,
      "learning_rate": 1.9721645900194373e-06,
      "loss": 0.0001,
      "step": 3518
    },
    {
      "epoch": 2.390625,
      "grad_norm": 6.485321521759033,
      "learning_rate": 1.967924685193552e-06,
      "loss": 0.1257,
      "step": 3519
    },
    {
      "epoch": 2.391304347826087,
      "grad_norm": 3.4345061779022217,
      "learning_rate": 1.963688845450218e-06,
      "loss": 0.0467,
      "step": 3520
    },
    {
      "epoch": 2.391983695652174,
      "grad_norm": 9.952530860900879,
      "learning_rate": 1.959457072933225e-06,
      "loss": 0.3153,
      "step": 3521
    },
    {
      "epoch": 2.3926630434782608,
      "grad_norm": 3.868854284286499,
      "learning_rate": 1.955229369784295e-06,
      "loss": 0.136,
      "step": 3522
    },
    {
      "epoch": 2.3933423913043477,
      "grad_norm": 0.24308598041534424,
      "learning_rate": 1.951005738143098e-06,
      "loss": 0.0041,
      "step": 3523
    },
    {
      "epoch": 2.3940217391304346,
      "grad_norm": 2.0558605194091797,
      "learning_rate": 1.9467861801472355e-06,
      "loss": 0.0305,
      "step": 3524
    },
    {
      "epoch": 2.3947010869565215,
      "grad_norm": 8.44122314453125,
      "learning_rate": 1.9425706979322544e-06,
      "loss": 0.1544,
      "step": 3525
    },
    {
      "epoch": 2.395380434782609,
      "grad_norm": 6.566772937774658,
      "learning_rate": 1.938359293631639e-06,
      "loss": 0.0804,
      "step": 3526
    },
    {
      "epoch": 2.396059782608696,
      "grad_norm": 0.02898462861776352,
      "learning_rate": 1.9341519693767994e-06,
      "loss": 0.0002,
      "step": 3527
    },
    {
      "epoch": 2.3967391304347827,
      "grad_norm": 1.3161237239837646,
      "learning_rate": 1.929948727297096e-06,
      "loss": 0.0245,
      "step": 3528
    },
    {
      "epoch": 2.3974184782608696,
      "grad_norm": 20.545942306518555,
      "learning_rate": 1.925749569519809e-06,
      "loss": 0.2619,
      "step": 3529
    },
    {
      "epoch": 2.3980978260869565,
      "grad_norm": 4.244870185852051,
      "learning_rate": 1.9215544981701616e-06,
      "loss": 0.0605,
      "step": 3530
    },
    {
      "epoch": 2.3987771739130435,
      "grad_norm": 1.9801418781280518,
      "learning_rate": 1.9173635153713066e-06,
      "loss": 0.02,
      "step": 3531
    },
    {
      "epoch": 2.3994565217391304,
      "grad_norm": 7.4721760749816895,
      "learning_rate": 1.9131766232443205e-06,
      "loss": 0.3248,
      "step": 3532
    },
    {
      "epoch": 2.4001358695652173,
      "grad_norm": 0.3542722761631012,
      "learning_rate": 1.9089938239082184e-06,
      "loss": 0.0014,
      "step": 3533
    },
    {
      "epoch": 2.400815217391304,
      "grad_norm": 0.005073010455816984,
      "learning_rate": 1.9048151194799435e-06,
      "loss": 0.0001,
      "step": 3534
    },
    {
      "epoch": 2.401494565217391,
      "grad_norm": 4.239828586578369,
      "learning_rate": 1.9006405120743588e-06,
      "loss": 0.1513,
      "step": 3535
    },
    {
      "epoch": 2.4021739130434785,
      "grad_norm": 0.10506366193294525,
      "learning_rate": 1.8964700038042628e-06,
      "loss": 0.0007,
      "step": 3536
    },
    {
      "epoch": 2.4028532608695654,
      "grad_norm": 8.038130760192871,
      "learning_rate": 1.8923035967803704e-06,
      "loss": 0.2759,
      "step": 3537
    },
    {
      "epoch": 2.4035326086956523,
      "grad_norm": 6.373029708862305,
      "learning_rate": 1.8881412931113318e-06,
      "loss": 0.1272,
      "step": 3538
    },
    {
      "epoch": 2.4042119565217392,
      "grad_norm": 7.427576541900635,
      "learning_rate": 1.8839830949037075e-06,
      "loss": 0.1588,
      "step": 3539
    },
    {
      "epoch": 2.404891304347826,
      "grad_norm": 1.8136745691299438,
      "learning_rate": 1.8798290042619949e-06,
      "loss": 0.0229,
      "step": 3540
    },
    {
      "epoch": 2.405570652173913,
      "grad_norm": 0.004802524112164974,
      "learning_rate": 1.8756790232885946e-06,
      "loss": 0.0001,
      "step": 3541
    },
    {
      "epoch": 2.40625,
      "grad_norm": 0.03369686007499695,
      "learning_rate": 1.8715331540838488e-06,
      "loss": 0.0002,
      "step": 3542
    },
    {
      "epoch": 2.406929347826087,
      "grad_norm": 0.7805411219596863,
      "learning_rate": 1.867391398745999e-06,
      "loss": 0.0033,
      "step": 3543
    },
    {
      "epoch": 2.407608695652174,
      "grad_norm": 0.47068607807159424,
      "learning_rate": 1.8632537593712186e-06,
      "loss": 0.0033,
      "step": 3544
    },
    {
      "epoch": 2.4082880434782608,
      "grad_norm": 1.720184326171875,
      "learning_rate": 1.8591202380535867e-06,
      "loss": 0.0462,
      "step": 3545
    },
    {
      "epoch": 2.4089673913043477,
      "grad_norm": 23.883928298950195,
      "learning_rate": 1.8549908368851099e-06,
      "loss": 0.3319,
      "step": 3546
    },
    {
      "epoch": 2.4096467391304346,
      "grad_norm": 7.082210540771484,
      "learning_rate": 1.8508655579556978e-06,
      "loss": 0.2451,
      "step": 3547
    },
    {
      "epoch": 2.4103260869565215,
      "grad_norm": 0.016316529363393784,
      "learning_rate": 1.8467444033531834e-06,
      "loss": 0.0001,
      "step": 3548
    },
    {
      "epoch": 2.411005434782609,
      "grad_norm": 10.68127155303955,
      "learning_rate": 1.842627375163305e-06,
      "loss": 0.2655,
      "step": 3549
    },
    {
      "epoch": 2.411684782608696,
      "grad_norm": 0.018506718799471855,
      "learning_rate": 1.838514475469717e-06,
      "loss": 0.0001,
      "step": 3550
    },
    {
      "epoch": 2.4123641304347827,
      "grad_norm": 0.004722780082374811,
      "learning_rate": 1.8344057063539832e-06,
      "loss": 0.0001,
      "step": 3551
    },
    {
      "epoch": 2.4130434782608696,
      "grad_norm": 5.396523952484131,
      "learning_rate": 1.8303010698955803e-06,
      "loss": 0.1053,
      "step": 3552
    },
    {
      "epoch": 2.4137228260869565,
      "grad_norm": 4.721130847930908,
      "learning_rate": 1.826200568171884e-06,
      "loss": 0.2169,
      "step": 3553
    },
    {
      "epoch": 2.4144021739130435,
      "grad_norm": 6.1616621017456055,
      "learning_rate": 1.8221042032581892e-06,
      "loss": 0.0275,
      "step": 3554
    },
    {
      "epoch": 2.4150815217391304,
      "grad_norm": 0.001631696941331029,
      "learning_rate": 1.818011977227686e-06,
      "loss": 0.0,
      "step": 3555
    },
    {
      "epoch": 2.4157608695652173,
      "grad_norm": 0.006096009165048599,
      "learning_rate": 1.8139238921514802e-06,
      "loss": 0.0,
      "step": 3556
    },
    {
      "epoch": 2.416440217391304,
      "grad_norm": 0.21868038177490234,
      "learning_rate": 1.8098399500985708e-06,
      "loss": 0.0016,
      "step": 3557
    },
    {
      "epoch": 2.417119565217391,
      "grad_norm": 13.017807960510254,
      "learning_rate": 1.8057601531358693e-06,
      "loss": 0.2295,
      "step": 3558
    },
    {
      "epoch": 2.4177989130434785,
      "grad_norm": 0.0025043925270438194,
      "learning_rate": 1.8016845033281883e-06,
      "loss": 0.0,
      "step": 3559
    },
    {
      "epoch": 2.4184782608695654,
      "grad_norm": 0.9677441120147705,
      "learning_rate": 1.7976130027382332e-06,
      "loss": 0.0273,
      "step": 3560
    },
    {
      "epoch": 2.4191576086956523,
      "grad_norm": 11.302496910095215,
      "learning_rate": 1.7935456534266227e-06,
      "loss": 0.2422,
      "step": 3561
    },
    {
      "epoch": 2.4198369565217392,
      "grad_norm": 0.0069413683377206326,
      "learning_rate": 1.7894824574518599e-06,
      "loss": 0.0001,
      "step": 3562
    },
    {
      "epoch": 2.420516304347826,
      "grad_norm": 5.828571319580078,
      "learning_rate": 1.7854234168703589e-06,
      "loss": 0.0852,
      "step": 3563
    },
    {
      "epoch": 2.421195652173913,
      "grad_norm": 0.00420683529227972,
      "learning_rate": 1.7813685337364205e-06,
      "loss": 0.0001,
      "step": 3564
    },
    {
      "epoch": 2.421875,
      "grad_norm": 0.002909599570557475,
      "learning_rate": 1.7773178101022514e-06,
      "loss": 0.0,
      "step": 3565
    },
    {
      "epoch": 2.422554347826087,
      "grad_norm": 6.414432525634766,
      "learning_rate": 1.7732712480179416e-06,
      "loss": 0.1271,
      "step": 3566
    },
    {
      "epoch": 2.423233695652174,
      "grad_norm": 3.1418702602386475,
      "learning_rate": 1.7692288495314836e-06,
      "loss": 0.079,
      "step": 3567
    },
    {
      "epoch": 2.4239130434782608,
      "grad_norm": 13.044829368591309,
      "learning_rate": 1.76519061668876e-06,
      "loss": 0.3966,
      "step": 3568
    },
    {
      "epoch": 2.4245923913043477,
      "grad_norm": 9.349715232849121,
      "learning_rate": 1.7611565515335471e-06,
      "loss": 0.2173,
      "step": 3569
    },
    {
      "epoch": 2.4252717391304346,
      "grad_norm": 4.671012878417969,
      "learning_rate": 1.7571266561075073e-06,
      "loss": 0.1041,
      "step": 3570
    },
    {
      "epoch": 2.4259510869565215,
      "grad_norm": 6.702610969543457,
      "learning_rate": 1.753100932450198e-06,
      "loss": 0.1033,
      "step": 3571
    },
    {
      "epoch": 2.426630434782609,
      "grad_norm": 8.167983055114746,
      "learning_rate": 1.7490793825990593e-06,
      "loss": 0.0848,
      "step": 3572
    },
    {
      "epoch": 2.427309782608696,
      "grad_norm": 12.349641799926758,
      "learning_rate": 1.7450620085894255e-06,
      "loss": 0.4206,
      "step": 3573
    },
    {
      "epoch": 2.4279891304347827,
      "grad_norm": 4.433418273925781,
      "learning_rate": 1.741048812454511e-06,
      "loss": 0.029,
      "step": 3574
    },
    {
      "epoch": 2.4286684782608696,
      "grad_norm": 9.503297805786133,
      "learning_rate": 1.7370397962254226e-06,
      "loss": 0.1595,
      "step": 3575
    },
    {
      "epoch": 2.4293478260869565,
      "grad_norm": 6.872061729431152,
      "learning_rate": 1.7330349619311415e-06,
      "loss": 0.1901,
      "step": 3576
    },
    {
      "epoch": 2.4300271739130435,
      "grad_norm": 24.284866333007812,
      "learning_rate": 1.7290343115985486e-06,
      "loss": 0.1149,
      "step": 3577
    },
    {
      "epoch": 2.4307065217391304,
      "grad_norm": 10.618477821350098,
      "learning_rate": 1.7250378472523887e-06,
      "loss": 0.3032,
      "step": 3578
    },
    {
      "epoch": 2.4313858695652173,
      "grad_norm": 0.0019259225809946656,
      "learning_rate": 1.721045570915304e-06,
      "loss": 0.0,
      "step": 3579
    },
    {
      "epoch": 2.432065217391304,
      "grad_norm": 28.246702194213867,
      "learning_rate": 1.7170574846078037e-06,
      "loss": 0.5925,
      "step": 3580
    },
    {
      "epoch": 2.432744565217391,
      "grad_norm": 6.662070274353027,
      "learning_rate": 1.7130735903482886e-06,
      "loss": 0.213,
      "step": 3581
    },
    {
      "epoch": 2.4334239130434785,
      "grad_norm": 0.5229048132896423,
      "learning_rate": 1.7090938901530264e-06,
      "loss": 0.0028,
      "step": 3582
    },
    {
      "epoch": 2.4341032608695654,
      "grad_norm": 8.41073226928711,
      "learning_rate": 1.7051183860361719e-06,
      "loss": 0.1887,
      "step": 3583
    },
    {
      "epoch": 2.4347826086956523,
      "grad_norm": 11.869099617004395,
      "learning_rate": 1.7011470800097496e-06,
      "loss": 0.3008,
      "step": 3584
    },
    {
      "epoch": 2.4354619565217392,
      "grad_norm": 0.8270977735519409,
      "learning_rate": 1.6971799740836625e-06,
      "loss": 0.0131,
      "step": 3585
    },
    {
      "epoch": 2.436141304347826,
      "grad_norm": 16.074052810668945,
      "learning_rate": 1.693217070265689e-06,
      "loss": 0.5774,
      "step": 3586
    },
    {
      "epoch": 2.436820652173913,
      "grad_norm": 0.04925144836306572,
      "learning_rate": 1.6892583705614762e-06,
      "loss": 0.0006,
      "step": 3587
    },
    {
      "epoch": 2.4375,
      "grad_norm": 3.3837227821350098,
      "learning_rate": 1.6853038769745466e-06,
      "loss": 0.0341,
      "step": 3588
    },
    {
      "epoch": 2.438179347826087,
      "grad_norm": 5.875230312347412,
      "learning_rate": 1.6813535915062985e-06,
      "loss": 0.1474,
      "step": 3589
    },
    {
      "epoch": 2.438858695652174,
      "grad_norm": 6.147729396820068,
      "learning_rate": 1.677407516155989e-06,
      "loss": 0.0823,
      "step": 3590
    },
    {
      "epoch": 2.4395380434782608,
      "grad_norm": 0.8140918612480164,
      "learning_rate": 1.673465652920755e-06,
      "loss": 0.0074,
      "step": 3591
    },
    {
      "epoch": 2.4402173913043477,
      "grad_norm": 7.004301071166992,
      "learning_rate": 1.6695280037955953e-06,
      "loss": 0.2639,
      "step": 3592
    },
    {
      "epoch": 2.4408967391304346,
      "grad_norm": 0.05688421055674553,
      "learning_rate": 1.665594570773379e-06,
      "loss": 0.0004,
      "step": 3593
    },
    {
      "epoch": 2.4415760869565215,
      "grad_norm": 19.544477462768555,
      "learning_rate": 1.6616653558448437e-06,
      "loss": 0.301,
      "step": 3594
    },
    {
      "epoch": 2.442255434782609,
      "grad_norm": 0.002199155278503895,
      "learning_rate": 1.6577403609985842e-06,
      "loss": 0.0,
      "step": 3595
    },
    {
      "epoch": 2.442934782608696,
      "grad_norm": 3.232205629348755,
      "learning_rate": 1.6538195882210685e-06,
      "loss": 0.0224,
      "step": 3596
    },
    {
      "epoch": 2.4436141304347827,
      "grad_norm": 7.272396564483643,
      "learning_rate": 1.649903039496621e-06,
      "loss": 0.1815,
      "step": 3597
    },
    {
      "epoch": 2.4442934782608696,
      "grad_norm": 0.44873836636543274,
      "learning_rate": 1.6459907168074329e-06,
      "loss": 0.0038,
      "step": 3598
    },
    {
      "epoch": 2.4449728260869565,
      "grad_norm": 10.013269424438477,
      "learning_rate": 1.6420826221335517e-06,
      "loss": 0.1019,
      "step": 3599
    },
    {
      "epoch": 2.4456521739130435,
      "grad_norm": 12.15616512298584,
      "learning_rate": 1.638178757452894e-06,
      "loss": 0.616,
      "step": 3600
    },
    {
      "epoch": 2.4463315217391304,
      "grad_norm": 2.6532835960388184,
      "learning_rate": 1.6342791247412193e-06,
      "loss": 0.045,
      "step": 3601
    },
    {
      "epoch": 2.4470108695652173,
      "grad_norm": 0.9885587692260742,
      "learning_rate": 1.630383725972169e-06,
      "loss": 0.0068,
      "step": 3602
    },
    {
      "epoch": 2.447690217391304,
      "grad_norm": 0.0018510471563786268,
      "learning_rate": 1.626492563117217e-06,
      "loss": 0.0,
      "step": 3603
    },
    {
      "epoch": 2.448369565217391,
      "grad_norm": 13.470455169677734,
      "learning_rate": 1.6226056381457134e-06,
      "loss": 0.3516,
      "step": 3604
    },
    {
      "epoch": 2.4490489130434785,
      "grad_norm": 0.002357998164370656,
      "learning_rate": 1.618722953024847e-06,
      "loss": 0.0,
      "step": 3605
    },
    {
      "epoch": 2.4497282608695654,
      "grad_norm": 12.428204536437988,
      "learning_rate": 1.614844509719674e-06,
      "loss": 0.5045,
      "step": 3606
    },
    {
      "epoch": 2.4504076086956523,
      "grad_norm": 0.011881337501108646,
      "learning_rate": 1.6109703101930951e-06,
      "loss": 0.0001,
      "step": 3607
    },
    {
      "epoch": 2.4510869565217392,
      "grad_norm": 0.0012149709509685636,
      "learning_rate": 1.6071003564058697e-06,
      "loss": 0.0,
      "step": 3608
    },
    {
      "epoch": 2.451766304347826,
      "grad_norm": 0.0021001824643462896,
      "learning_rate": 1.6032346503166007e-06,
      "loss": 0.0,
      "step": 3609
    },
    {
      "epoch": 2.452445652173913,
      "grad_norm": 22.500015258789062,
      "learning_rate": 1.5993731938817481e-06,
      "loss": 0.4386,
      "step": 3610
    },
    {
      "epoch": 2.453125,
      "grad_norm": 10.179825782775879,
      "learning_rate": 1.5955159890556182e-06,
      "loss": 0.1349,
      "step": 3611
    },
    {
      "epoch": 2.453804347826087,
      "grad_norm": 0.09978611767292023,
      "learning_rate": 1.5916630377903696e-06,
      "loss": 0.0006,
      "step": 3612
    },
    {
      "epoch": 2.454483695652174,
      "grad_norm": 0.20117264986038208,
      "learning_rate": 1.5878143420359993e-06,
      "loss": 0.0014,
      "step": 3613
    },
    {
      "epoch": 2.4551630434782608,
      "grad_norm": 0.009773500263690948,
      "learning_rate": 1.58396990374036e-06,
      "loss": 0.0001,
      "step": 3614
    },
    {
      "epoch": 2.4558423913043477,
      "grad_norm": 0.11494339257478714,
      "learning_rate": 1.580129724849141e-06,
      "loss": 0.0011,
      "step": 3615
    },
    {
      "epoch": 2.4565217391304346,
      "grad_norm": 8.389273643493652,
      "learning_rate": 1.5762938073058853e-06,
      "loss": 0.0864,
      "step": 3616
    },
    {
      "epoch": 2.4572010869565215,
      "grad_norm": 19.65793228149414,
      "learning_rate": 1.572462153051969e-06,
      "loss": 0.7181,
      "step": 3617
    },
    {
      "epoch": 2.457880434782609,
      "grad_norm": 2.368281841278076,
      "learning_rate": 1.5686347640266208e-06,
      "loss": 0.0106,
      "step": 3618
    },
    {
      "epoch": 2.458559782608696,
      "grad_norm": 0.10798543691635132,
      "learning_rate": 1.5648116421669025e-06,
      "loss": 0.0008,
      "step": 3619
    },
    {
      "epoch": 2.4592391304347827,
      "grad_norm": 4.793790340423584,
      "learning_rate": 1.5609927894077193e-06,
      "loss": 0.1612,
      "step": 3620
    },
    {
      "epoch": 2.4599184782608696,
      "grad_norm": 3.6067748069763184,
      "learning_rate": 1.5571782076818197e-06,
      "loss": 0.1563,
      "step": 3621
    },
    {
      "epoch": 2.4605978260869565,
      "grad_norm": 1.9874539375305176,
      "learning_rate": 1.5533678989197832e-06,
      "loss": 0.0171,
      "step": 3622
    },
    {
      "epoch": 2.4612771739130435,
      "grad_norm": 7.187639236450195,
      "learning_rate": 1.5495618650500332e-06,
      "loss": 0.2222,
      "step": 3623
    },
    {
      "epoch": 2.4619565217391304,
      "grad_norm": 0.1049869954586029,
      "learning_rate": 1.5457601079988226e-06,
      "loss": 0.0018,
      "step": 3624
    },
    {
      "epoch": 2.4626358695652173,
      "grad_norm": 0.3514481484889984,
      "learning_rate": 1.541962629690249e-06,
      "loss": 0.0017,
      "step": 3625
    },
    {
      "epoch": 2.463315217391304,
      "grad_norm": 8.979299545288086,
      "learning_rate": 1.5381694320462349e-06,
      "loss": 0.1679,
      "step": 3626
    },
    {
      "epoch": 2.463994565217391,
      "grad_norm": 12.882416725158691,
      "learning_rate": 1.5343805169865434e-06,
      "loss": 0.2494,
      "step": 3627
    },
    {
      "epoch": 2.4646739130434785,
      "grad_norm": 0.005782924592494965,
      "learning_rate": 1.5305958864287673e-06,
      "loss": 0.0001,
      "step": 3628
    },
    {
      "epoch": 2.4653532608695654,
      "grad_norm": 5.6842193603515625,
      "learning_rate": 1.5268155422883336e-06,
      "loss": 0.2311,
      "step": 3629
    },
    {
      "epoch": 2.4660326086956523,
      "grad_norm": 0.002273776102811098,
      "learning_rate": 1.5230394864784925e-06,
      "loss": 0.0,
      "step": 3630
    },
    {
      "epoch": 2.4667119565217392,
      "grad_norm": 14.646930694580078,
      "learning_rate": 1.5192677209103345e-06,
      "loss": 0.3824,
      "step": 3631
    },
    {
      "epoch": 2.467391304347826,
      "grad_norm": 7.3247785568237305,
      "learning_rate": 1.5155002474927683e-06,
      "loss": 0.1391,
      "step": 3632
    },
    {
      "epoch": 2.468070652173913,
      "grad_norm": 0.0020179643761366606,
      "learning_rate": 1.5117370681325393e-06,
      "loss": 0.0,
      "step": 3633
    },
    {
      "epoch": 2.46875,
      "grad_norm": 2.8536620140075684,
      "learning_rate": 1.5079781847342122e-06,
      "loss": 0.0193,
      "step": 3634
    },
    {
      "epoch": 2.469429347826087,
      "grad_norm": 0.044843148440122604,
      "learning_rate": 1.504223599200184e-06,
      "loss": 0.0005,
      "step": 3635
    },
    {
      "epoch": 2.470108695652174,
      "grad_norm": 3.3866238594055176,
      "learning_rate": 1.5004733134306692e-06,
      "loss": 0.0491,
      "step": 3636
    },
    {
      "epoch": 2.4707880434782608,
      "grad_norm": 0.003515862859785557,
      "learning_rate": 1.4967273293237173e-06,
      "loss": 0.0001,
      "step": 3637
    },
    {
      "epoch": 2.4714673913043477,
      "grad_norm": 0.0022269701585173607,
      "learning_rate": 1.492985648775187e-06,
      "loss": 0.0,
      "step": 3638
    },
    {
      "epoch": 2.4721467391304346,
      "grad_norm": 0.0020413671154528856,
      "learning_rate": 1.4892482736787717e-06,
      "loss": 0.0,
      "step": 3639
    },
    {
      "epoch": 2.4728260869565215,
      "grad_norm": 0.7686254382133484,
      "learning_rate": 1.4855152059259737e-06,
      "loss": 0.0087,
      "step": 3640
    },
    {
      "epoch": 2.473505434782609,
      "grad_norm": 5.958136558532715,
      "learning_rate": 1.4817864474061271e-06,
      "loss": 0.0279,
      "step": 3641
    },
    {
      "epoch": 2.474184782608696,
      "grad_norm": 3.8742737770080566,
      "learning_rate": 1.478062000006375e-06,
      "loss": 0.0462,
      "step": 3642
    },
    {
      "epoch": 2.4748641304347827,
      "grad_norm": 9.820707321166992,
      "learning_rate": 1.4743418656116871e-06,
      "loss": 0.048,
      "step": 3643
    },
    {
      "epoch": 2.4755434782608696,
      "grad_norm": 1.174506664276123,
      "learning_rate": 1.4706260461048417e-06,
      "loss": 0.0175,
      "step": 3644
    },
    {
      "epoch": 2.4762228260869565,
      "grad_norm": 5.476019382476807,
      "learning_rate": 1.46691454336644e-06,
      "loss": 0.1855,
      "step": 3645
    },
    {
      "epoch": 2.4769021739130435,
      "grad_norm": 0.015651877969503403,
      "learning_rate": 1.4632073592748985e-06,
      "loss": 0.0001,
      "step": 3646
    },
    {
      "epoch": 2.4775815217391304,
      "grad_norm": 10.485705375671387,
      "learning_rate": 1.4595044957064418e-06,
      "loss": 0.1699,
      "step": 3647
    },
    {
      "epoch": 2.4782608695652173,
      "grad_norm": 10.284422874450684,
      "learning_rate": 1.4558059545351144e-06,
      "loss": 0.332,
      "step": 3648
    },
    {
      "epoch": 2.478940217391304,
      "grad_norm": 0.009776471182703972,
      "learning_rate": 1.4521117376327708e-06,
      "loss": 0.0001,
      "step": 3649
    },
    {
      "epoch": 2.479619565217391,
      "grad_norm": 0.0018853857181966305,
      "learning_rate": 1.4484218468690757e-06,
      "loss": 0.0,
      "step": 3650
    },
    {
      "epoch": 2.4802989130434785,
      "grad_norm": 0.006282113492488861,
      "learning_rate": 1.4447362841115075e-06,
      "loss": 0.0001,
      "step": 3651
    },
    {
      "epoch": 2.4809782608695654,
      "grad_norm": 0.0033914591185748577,
      "learning_rate": 1.4410550512253474e-06,
      "loss": 0.0001,
      "step": 3652
    },
    {
      "epoch": 2.4816576086956523,
      "grad_norm": 12.053030967712402,
      "learning_rate": 1.437378150073694e-06,
      "loss": 0.5262,
      "step": 3653
    },
    {
      "epoch": 2.4823369565217392,
      "grad_norm": 6.340660095214844,
      "learning_rate": 1.4337055825174506e-06,
      "loss": 0.304,
      "step": 3654
    },
    {
      "epoch": 2.483016304347826,
      "grad_norm": 0.609063446521759,
      "learning_rate": 1.4300373504153208e-06,
      "loss": 0.0027,
      "step": 3655
    },
    {
      "epoch": 2.483695652173913,
      "grad_norm": 0.0035493350587785244,
      "learning_rate": 1.4263734556238262e-06,
      "loss": 0.0001,
      "step": 3656
    },
    {
      "epoch": 2.484375,
      "grad_norm": 7.583008766174316,
      "learning_rate": 1.4227138999972801e-06,
      "loss": 0.2802,
      "step": 3657
    },
    {
      "epoch": 2.485054347826087,
      "grad_norm": 0.5466716885566711,
      "learning_rate": 1.4190586853878107e-06,
      "loss": 0.0058,
      "step": 3658
    },
    {
      "epoch": 2.485733695652174,
      "grad_norm": 15.38832950592041,
      "learning_rate": 1.4154078136453397e-06,
      "loss": 0.1215,
      "step": 3659
    },
    {
      "epoch": 2.4864130434782608,
      "grad_norm": 19.127164840698242,
      "learning_rate": 1.4117612866176022e-06,
      "loss": 0.2818,
      "step": 3660
    },
    {
      "epoch": 2.4870923913043477,
      "grad_norm": 4.282548904418945,
      "learning_rate": 1.4081191061501209e-06,
      "loss": 0.1251,
      "step": 3661
    },
    {
      "epoch": 2.4877717391304346,
      "grad_norm": 4.180630683898926,
      "learning_rate": 1.4044812740862302e-06,
      "loss": 0.0945,
      "step": 3662
    },
    {
      "epoch": 2.4884510869565215,
      "grad_norm": 3.0001485347747803,
      "learning_rate": 1.4008477922670571e-06,
      "loss": 0.1574,
      "step": 3663
    },
    {
      "epoch": 2.489130434782609,
      "grad_norm": 3.718549966812134,
      "learning_rate": 1.397218662531532e-06,
      "loss": 0.0879,
      "step": 3664
    },
    {
      "epoch": 2.489809782608696,
      "grad_norm": 1.56443190574646,
      "learning_rate": 1.3935938867163757e-06,
      "loss": 0.0169,
      "step": 3665
    },
    {
      "epoch": 2.4904891304347827,
      "grad_norm": 1.6468127965927124,
      "learning_rate": 1.3899734666561138e-06,
      "loss": 0.0307,
      "step": 3666
    },
    {
      "epoch": 2.4911684782608696,
      "grad_norm": 9.708263397216797,
      "learning_rate": 1.3863574041830574e-06,
      "loss": 0.2059,
      "step": 3667
    },
    {
      "epoch": 2.4918478260869565,
      "grad_norm": 0.0023547005839645863,
      "learning_rate": 1.382745701127325e-06,
      "loss": 0.0,
      "step": 3668
    },
    {
      "epoch": 2.4925271739130435,
      "grad_norm": 0.01925748959183693,
      "learning_rate": 1.379138359316814e-06,
      "loss": 0.0002,
      "step": 3669
    },
    {
      "epoch": 2.4932065217391304,
      "grad_norm": 0.01183271873742342,
      "learning_rate": 1.3755353805772265e-06,
      "loss": 0.0001,
      "step": 3670
    },
    {
      "epoch": 2.4938858695652173,
      "grad_norm": 11.498869895935059,
      "learning_rate": 1.3719367667320526e-06,
      "loss": 0.4392,
      "step": 3671
    },
    {
      "epoch": 2.494565217391304,
      "grad_norm": 0.4865572154521942,
      "learning_rate": 1.3683425196025734e-06,
      "loss": 0.0026,
      "step": 3672
    },
    {
      "epoch": 2.495244565217391,
      "grad_norm": 0.004729319829493761,
      "learning_rate": 1.3647526410078548e-06,
      "loss": 0.0001,
      "step": 3673
    },
    {
      "epoch": 2.4959239130434785,
      "grad_norm": 8.970049858093262,
      "learning_rate": 1.3611671327647636e-06,
      "loss": 0.0936,
      "step": 3674
    },
    {
      "epoch": 2.4966032608695654,
      "grad_norm": 3.0541799068450928,
      "learning_rate": 1.357585996687939e-06,
      "loss": 0.0247,
      "step": 3675
    },
    {
      "epoch": 2.4972826086956523,
      "grad_norm": 1.6263444423675537,
      "learning_rate": 1.3540092345898237e-06,
      "loss": 0.0157,
      "step": 3676
    },
    {
      "epoch": 2.4979619565217392,
      "grad_norm": 0.726109504699707,
      "learning_rate": 1.3504368482806329e-06,
      "loss": 0.014,
      "step": 3677
    },
    {
      "epoch": 2.498641304347826,
      "grad_norm": 10.657633781433105,
      "learning_rate": 1.3468688395683783e-06,
      "loss": 0.1102,
      "step": 3678
    },
    {
      "epoch": 2.499320652173913,
      "grad_norm": 16.701068878173828,
      "learning_rate": 1.3433052102588462e-06,
      "loss": 0.3029,
      "step": 3679
    },
    {
      "epoch": 2.5,
      "grad_norm": 20.72580337524414,
      "learning_rate": 1.339745962155613e-06,
      "loss": 0.9736,
      "step": 3680
    },
    {
      "epoch": 2.500679347826087,
      "grad_norm": 6.136915683746338,
      "learning_rate": 1.33619109706004e-06,
      "loss": 0.0907,
      "step": 3681
    },
    {
      "epoch": 2.501358695652174,
      "grad_norm": 0.0029153977520763874,
      "learning_rate": 1.3326406167712592e-06,
      "loss": 0.0001,
      "step": 3682
    },
    {
      "epoch": 2.5020380434782608,
      "grad_norm": 3.4449310302734375,
      "learning_rate": 1.3290945230861962e-06,
      "loss": 0.0235,
      "step": 3683
    },
    {
      "epoch": 2.5027173913043477,
      "grad_norm": 1.0293926000595093,
      "learning_rate": 1.325552817799547e-06,
      "loss": 0.011,
      "step": 3684
    },
    {
      "epoch": 2.5033967391304346,
      "grad_norm": 0.0023379975464195013,
      "learning_rate": 1.3220155027037939e-06,
      "loss": 0.0,
      "step": 3685
    },
    {
      "epoch": 2.5040760869565215,
      "grad_norm": 0.003204082138836384,
      "learning_rate": 1.3184825795891887e-06,
      "loss": 0.0001,
      "step": 3686
    },
    {
      "epoch": 2.5047554347826084,
      "grad_norm": 11.229448318481445,
      "learning_rate": 1.314954050243772e-06,
      "loss": 0.3677,
      "step": 3687
    },
    {
      "epoch": 2.505434782608696,
      "grad_norm": 1.2557424306869507,
      "learning_rate": 1.3114299164533451e-06,
      "loss": 0.0221,
      "step": 3688
    },
    {
      "epoch": 2.5061141304347827,
      "grad_norm": 4.4497504234313965,
      "learning_rate": 1.3079101800015038e-06,
      "loss": 0.134,
      "step": 3689
    },
    {
      "epoch": 2.5067934782608696,
      "grad_norm": 0.03446129709482193,
      "learning_rate": 1.3043948426696019e-06,
      "loss": 0.0003,
      "step": 3690
    },
    {
      "epoch": 2.5074728260869565,
      "grad_norm": 0.011768810451030731,
      "learning_rate": 1.3008839062367772e-06,
      "loss": 0.0001,
      "step": 3691
    },
    {
      "epoch": 2.5081521739130435,
      "grad_norm": 4.908017158508301,
      "learning_rate": 1.297377372479931e-06,
      "loss": 0.1476,
      "step": 3692
    },
    {
      "epoch": 2.5088315217391304,
      "grad_norm": 0.008587892167270184,
      "learning_rate": 1.2938752431737467e-06,
      "loss": 0.0001,
      "step": 3693
    },
    {
      "epoch": 2.5095108695652173,
      "grad_norm": 1.8989365100860596,
      "learning_rate": 1.29037752009067e-06,
      "loss": 0.0196,
      "step": 3694
    },
    {
      "epoch": 2.510190217391304,
      "grad_norm": 5.32953405380249,
      "learning_rate": 1.2868842050009223e-06,
      "loss": 0.1603,
      "step": 3695
    },
    {
      "epoch": 2.5108695652173916,
      "grad_norm": 0.005754378624260426,
      "learning_rate": 1.2833952996724864e-06,
      "loss": 0.0001,
      "step": 3696
    },
    {
      "epoch": 2.5115489130434785,
      "grad_norm": 0.0028331903740763664,
      "learning_rate": 1.2799108058711274e-06,
      "loss": 0.0,
      "step": 3697
    },
    {
      "epoch": 2.5122282608695654,
      "grad_norm": 0.14696277678012848,
      "learning_rate": 1.2764307253603625e-06,
      "loss": 0.0009,
      "step": 3698
    },
    {
      "epoch": 2.5129076086956523,
      "grad_norm": 0.16789434850215912,
      "learning_rate": 1.2729550599014862e-06,
      "loss": 0.0008,
      "step": 3699
    },
    {
      "epoch": 2.5135869565217392,
      "grad_norm": 7.705533027648926,
      "learning_rate": 1.269483811253549e-06,
      "loss": 0.111,
      "step": 3700
    },
    {
      "epoch": 2.514266304347826,
      "grad_norm": 0.3289998769760132,
      "learning_rate": 1.266016981173377e-06,
      "loss": 0.0017,
      "step": 3701
    },
    {
      "epoch": 2.514945652173913,
      "grad_norm": 19.169418334960938,
      "learning_rate": 1.2625545714155474e-06,
      "loss": 0.4471,
      "step": 3702
    },
    {
      "epoch": 2.515625,
      "grad_norm": 0.02012527361512184,
      "learning_rate": 1.2590965837324132e-06,
      "loss": 0.0001,
      "step": 3703
    },
    {
      "epoch": 2.516304347826087,
      "grad_norm": 21.286090850830078,
      "learning_rate": 1.2556430198740776e-06,
      "loss": 0.6409,
      "step": 3704
    },
    {
      "epoch": 2.516983695652174,
      "grad_norm": 8.123693466186523,
      "learning_rate": 1.252193881588415e-06,
      "loss": 0.1995,
      "step": 3705
    },
    {
      "epoch": 2.5176630434782608,
      "grad_norm": 0.002273260150104761,
      "learning_rate": 1.248749170621052e-06,
      "loss": 0.0,
      "step": 3706
    },
    {
      "epoch": 2.5183423913043477,
      "grad_norm": 4.360897064208984,
      "learning_rate": 1.245308888715383e-06,
      "loss": 0.0564,
      "step": 3707
    },
    {
      "epoch": 2.5190217391304346,
      "grad_norm": 0.6124895811080933,
      "learning_rate": 1.24187303761255e-06,
      "loss": 0.0093,
      "step": 3708
    },
    {
      "epoch": 2.5197010869565215,
      "grad_norm": 4.653532028198242,
      "learning_rate": 1.2384416190514625e-06,
      "loss": 0.1183,
      "step": 3709
    },
    {
      "epoch": 2.5203804347826084,
      "grad_norm": 9.045937538146973,
      "learning_rate": 1.2350146347687798e-06,
      "loss": 0.0719,
      "step": 3710
    },
    {
      "epoch": 2.521059782608696,
      "grad_norm": 10.509419441223145,
      "learning_rate": 1.2315920864989218e-06,
      "loss": 0.2649,
      "step": 3711
    },
    {
      "epoch": 2.5217391304347827,
      "grad_norm": 0.003105931682512164,
      "learning_rate": 1.2281739759740575e-06,
      "loss": 0.0001,
      "step": 3712
    },
    {
      "epoch": 2.5224184782608696,
      "grad_norm": 0.0031967544928193092,
      "learning_rate": 1.2247603049241186e-06,
      "loss": 0.0001,
      "step": 3713
    },
    {
      "epoch": 2.5230978260869565,
      "grad_norm": 0.05943584442138672,
      "learning_rate": 1.221351075076781e-06,
      "loss": 0.0004,
      "step": 3714
    },
    {
      "epoch": 2.5237771739130435,
      "grad_norm": 0.0028794293757528067,
      "learning_rate": 1.2179462881574778e-06,
      "loss": 0.0001,
      "step": 3715
    },
    {
      "epoch": 2.5244565217391304,
      "grad_norm": 6.799959659576416,
      "learning_rate": 1.2145459458893938e-06,
      "loss": 0.2376,
      "step": 3716
    },
    {
      "epoch": 2.5251358695652173,
      "grad_norm": 3.9944889545440674,
      "learning_rate": 1.2111500499934613e-06,
      "loss": 0.1983,
      "step": 3717
    },
    {
      "epoch": 2.525815217391304,
      "grad_norm": 9.986104965209961,
      "learning_rate": 1.2077586021883669e-06,
      "loss": 0.1196,
      "step": 3718
    },
    {
      "epoch": 2.5264945652173916,
      "grad_norm": 0.03935762122273445,
      "learning_rate": 1.2043716041905396e-06,
      "loss": 0.0003,
      "step": 3719
    },
    {
      "epoch": 2.5271739130434785,
      "grad_norm": 5.9515275955200195,
      "learning_rate": 1.2009890577141625e-06,
      "loss": 0.0382,
      "step": 3720
    },
    {
      "epoch": 2.5278532608695654,
      "grad_norm": 0.6989331841468811,
      "learning_rate": 1.197610964471161e-06,
      "loss": 0.0068,
      "step": 3721
    },
    {
      "epoch": 2.5285326086956523,
      "grad_norm": 0.24832847714424133,
      "learning_rate": 1.194237326171208e-06,
      "loss": 0.0014,
      "step": 3722
    },
    {
      "epoch": 2.5292119565217392,
      "grad_norm": 5.0325927734375,
      "learning_rate": 1.1908681445217263e-06,
      "loss": 0.1188,
      "step": 3723
    },
    {
      "epoch": 2.529891304347826,
      "grad_norm": 0.0017376618925482035,
      "learning_rate": 1.187503421227878e-06,
      "loss": 0.0,
      "step": 3724
    },
    {
      "epoch": 2.530570652173913,
      "grad_norm": 1.2699568271636963,
      "learning_rate": 1.1841431579925689e-06,
      "loss": 0.0216,
      "step": 3725
    },
    {
      "epoch": 2.53125,
      "grad_norm": 3.870729446411133,
      "learning_rate": 1.1807873565164507e-06,
      "loss": 0.0654,
      "step": 3726
    },
    {
      "epoch": 2.531929347826087,
      "grad_norm": 5.453258514404297,
      "learning_rate": 1.1774360184979128e-06,
      "loss": 0.111,
      "step": 3727
    },
    {
      "epoch": 2.532608695652174,
      "grad_norm": 18.875036239624023,
      "learning_rate": 1.1740891456330894e-06,
      "loss": 0.49,
      "step": 3728
    },
    {
      "epoch": 2.5332880434782608,
      "grad_norm": 21.971282958984375,
      "learning_rate": 1.1707467396158524e-06,
      "loss": 0.4517,
      "step": 3729
    },
    {
      "epoch": 2.5339673913043477,
      "grad_norm": 0.002608843147754669,
      "learning_rate": 1.167408802137816e-06,
      "loss": 0.0001,
      "step": 3730
    },
    {
      "epoch": 2.5346467391304346,
      "grad_norm": 2.617720365524292,
      "learning_rate": 1.1640753348883261e-06,
      "loss": 0.0426,
      "step": 3731
    },
    {
      "epoch": 2.5353260869565215,
      "grad_norm": 0.0018656050087884068,
      "learning_rate": 1.1607463395544782e-06,
      "loss": 0.0,
      "step": 3732
    },
    {
      "epoch": 2.5360054347826084,
      "grad_norm": 0.0046134633012115955,
      "learning_rate": 1.1574218178210906e-06,
      "loss": 0.0001,
      "step": 3733
    },
    {
      "epoch": 2.536684782608696,
      "grad_norm": 10.328786849975586,
      "learning_rate": 1.1541017713707292e-06,
      "loss": 0.2763,
      "step": 3734
    },
    {
      "epoch": 2.5373641304347827,
      "grad_norm": 8.607648849487305,
      "learning_rate": 1.1507862018836846e-06,
      "loss": 0.3063,
      "step": 3735
    },
    {
      "epoch": 2.5380434782608696,
      "grad_norm": 0.025012115016579628,
      "learning_rate": 1.1474751110379933e-06,
      "loss": 0.0002,
      "step": 3736
    },
    {
      "epoch": 2.5387228260869565,
      "grad_norm": 1.7845547199249268,
      "learning_rate": 1.1441685005094116e-06,
      "loss": 0.0079,
      "step": 3737
    },
    {
      "epoch": 2.5394021739130435,
      "grad_norm": 0.029797229915857315,
      "learning_rate": 1.1408663719714418e-06,
      "loss": 0.0003,
      "step": 3738
    },
    {
      "epoch": 2.5400815217391304,
      "grad_norm": 0.0036288180854171515,
      "learning_rate": 1.1375687270953061e-06,
      "loss": 0.0,
      "step": 3739
    },
    {
      "epoch": 2.5407608695652173,
      "grad_norm": 0.03301079198718071,
      "learning_rate": 1.134275567549965e-06,
      "loss": 0.0002,
      "step": 3740
    },
    {
      "epoch": 2.541440217391304,
      "grad_norm": 0.0017235064879059792,
      "learning_rate": 1.1309868950021085e-06,
      "loss": 0.0,
      "step": 3741
    },
    {
      "epoch": 2.5421195652173916,
      "grad_norm": 7.178980827331543,
      "learning_rate": 1.1277027111161509e-06,
      "loss": 0.1118,
      "step": 3742
    },
    {
      "epoch": 2.5427989130434785,
      "grad_norm": 0.004489567130804062,
      "learning_rate": 1.1244230175542413e-06,
      "loss": 0.0001,
      "step": 3743
    },
    {
      "epoch": 2.5434782608695654,
      "grad_norm": 15.007002830505371,
      "learning_rate": 1.121147815976248e-06,
      "loss": 0.1824,
      "step": 3744
    },
    {
      "epoch": 2.5441576086956523,
      "grad_norm": 0.009622214362025261,
      "learning_rate": 1.1178771080397755e-06,
      "loss": 0.0001,
      "step": 3745
    },
    {
      "epoch": 2.5448369565217392,
      "grad_norm": 0.0024474700912833214,
      "learning_rate": 1.1146108954001455e-06,
      "loss": 0.0,
      "step": 3746
    },
    {
      "epoch": 2.545516304347826,
      "grad_norm": 1.069092869758606,
      "learning_rate": 1.1113491797104093e-06,
      "loss": 0.0181,
      "step": 3747
    },
    {
      "epoch": 2.546195652173913,
      "grad_norm": 3.877345323562622,
      "learning_rate": 1.1080919626213405e-06,
      "loss": 0.1265,
      "step": 3748
    },
    {
      "epoch": 2.546875,
      "grad_norm": 8.648390769958496,
      "learning_rate": 1.1048392457814406e-06,
      "loss": 0.3338,
      "step": 3749
    },
    {
      "epoch": 2.547554347826087,
      "grad_norm": 0.05134209245443344,
      "learning_rate": 1.1015910308369239e-06,
      "loss": 0.0007,
      "step": 3750
    },
    {
      "epoch": 2.548233695652174,
      "grad_norm": 25.11045265197754,
      "learning_rate": 1.0983473194317373e-06,
      "loss": 0.334,
      "step": 3751
    },
    {
      "epoch": 2.5489130434782608,
      "grad_norm": 0.005765840876847506,
      "learning_rate": 1.095108113207537e-06,
      "loss": 0.0001,
      "step": 3752
    },
    {
      "epoch": 2.5495923913043477,
      "grad_norm": 8.568964004516602,
      "learning_rate": 1.0918734138037113e-06,
      "loss": 0.2396,
      "step": 3753
    },
    {
      "epoch": 2.5502717391304346,
      "grad_norm": 9.631778717041016,
      "learning_rate": 1.0886432228573563e-06,
      "loss": 0.414,
      "step": 3754
    },
    {
      "epoch": 2.5509510869565215,
      "grad_norm": 0.0042685335502028465,
      "learning_rate": 1.0854175420032964e-06,
      "loss": 0.0001,
      "step": 3755
    },
    {
      "epoch": 2.5516304347826084,
      "grad_norm": 0.0315643735229969,
      "learning_rate": 1.0821963728740626e-06,
      "loss": 0.0002,
      "step": 3756
    },
    {
      "epoch": 2.552309782608696,
      "grad_norm": 6.185661792755127,
      "learning_rate": 1.0789797170999117e-06,
      "loss": 0.1186,
      "step": 3757
    },
    {
      "epoch": 2.5529891304347827,
      "grad_norm": 2.5096678733825684,
      "learning_rate": 1.0757675763088126e-06,
      "loss": 0.0212,
      "step": 3758
    },
    {
      "epoch": 2.5536684782608696,
      "grad_norm": 0.0036202645860612392,
      "learning_rate": 1.0725599521264518e-06,
      "loss": 0.0001,
      "step": 3759
    },
    {
      "epoch": 2.5543478260869565,
      "grad_norm": 0.010553602129220963,
      "learning_rate": 1.0693568461762238e-06,
      "loss": 0.0001,
      "step": 3760
    },
    {
      "epoch": 2.5550271739130435,
      "grad_norm": 6.122210502624512,
      "learning_rate": 1.0661582600792432e-06,
      "loss": 0.1077,
      "step": 3761
    },
    {
      "epoch": 2.5557065217391304,
      "grad_norm": 8.498170852661133,
      "learning_rate": 1.062964195454329e-06,
      "loss": 0.1252,
      "step": 3762
    },
    {
      "epoch": 2.5563858695652173,
      "grad_norm": 0.006217610090970993,
      "learning_rate": 1.0597746539180243e-06,
      "loss": 0.0001,
      "step": 3763
    },
    {
      "epoch": 2.557065217391304,
      "grad_norm": 7.206101417541504,
      "learning_rate": 1.0565896370845686e-06,
      "loss": 0.2358,
      "step": 3764
    },
    {
      "epoch": 2.5577445652173916,
      "grad_norm": 3.750685214996338,
      "learning_rate": 1.0534091465659212e-06,
      "loss": 0.0877,
      "step": 3765
    },
    {
      "epoch": 2.5584239130434785,
      "grad_norm": 3.7973949909210205,
      "learning_rate": 1.0502331839717493e-06,
      "loss": 0.2486,
      "step": 3766
    },
    {
      "epoch": 2.5591032608695654,
      "grad_norm": 0.014483482576906681,
      "learning_rate": 1.0470617509094271e-06,
      "loss": 0.0001,
      "step": 3767
    },
    {
      "epoch": 2.5597826086956523,
      "grad_norm": 11.677969932556152,
      "learning_rate": 1.0438948489840327e-06,
      "loss": 0.5822,
      "step": 3768
    },
    {
      "epoch": 2.5604619565217392,
      "grad_norm": 1.3313908576965332,
      "learning_rate": 1.0407324797983597e-06,
      "loss": 0.01,
      "step": 3769
    },
    {
      "epoch": 2.561141304347826,
      "grad_norm": 7.982093334197998,
      "learning_rate": 1.0375746449528978e-06,
      "loss": 0.0826,
      "step": 3770
    },
    {
      "epoch": 2.561820652173913,
      "grad_norm": 4.879724025726318,
      "learning_rate": 1.0344213460458496e-06,
      "loss": 0.0216,
      "step": 3771
    },
    {
      "epoch": 2.5625,
      "grad_norm": 0.0526069775223732,
      "learning_rate": 1.0312725846731174e-06,
      "loss": 0.0003,
      "step": 3772
    },
    {
      "epoch": 2.563179347826087,
      "grad_norm": 5.091769695281982,
      "learning_rate": 1.02812836242831e-06,
      "loss": 0.1277,
      "step": 3773
    },
    {
      "epoch": 2.563858695652174,
      "grad_norm": 0.15005649626255035,
      "learning_rate": 1.0249886809027355e-06,
      "loss": 0.0008,
      "step": 3774
    },
    {
      "epoch": 2.5645380434782608,
      "grad_norm": 5.116811752319336,
      "learning_rate": 1.021853541685407e-06,
      "loss": 0.1724,
      "step": 3775
    },
    {
      "epoch": 2.5652173913043477,
      "grad_norm": 1.0804426670074463,
      "learning_rate": 1.01872294636304e-06,
      "loss": 0.0041,
      "step": 3776
    },
    {
      "epoch": 2.5658967391304346,
      "grad_norm": 4.649576187133789,
      "learning_rate": 1.0155968965200435e-06,
      "loss": 0.1989,
      "step": 3777
    },
    {
      "epoch": 2.5665760869565215,
      "grad_norm": 3.7411184310913086,
      "learning_rate": 1.0124753937385357e-06,
      "loss": 0.0219,
      "step": 3778
    },
    {
      "epoch": 2.5672554347826084,
      "grad_norm": 4.406476020812988,
      "learning_rate": 1.0093584395983224e-06,
      "loss": 0.2042,
      "step": 3779
    },
    {
      "epoch": 2.567934782608696,
      "grad_norm": 3.092097043991089,
      "learning_rate": 1.0062460356769189e-06,
      "loss": 0.0685,
      "step": 3780
    },
    {
      "epoch": 2.5686141304347827,
      "grad_norm": 0.003938042558729649,
      "learning_rate": 1.003138183549527e-06,
      "loss": 0.0001,
      "step": 3781
    },
    {
      "epoch": 2.5692934782608696,
      "grad_norm": 0.011859165504574776,
      "learning_rate": 1.000034884789054e-06,
      "loss": 0.0001,
      "step": 3782
    },
    {
      "epoch": 2.5699728260869565,
      "grad_norm": 0.028293408453464508,
      "learning_rate": 9.969361409660927e-07,
      "loss": 0.0003,
      "step": 3783
    },
    {
      "epoch": 2.5706521739130435,
      "grad_norm": 0.2895532250404358,
      "learning_rate": 9.93841953648944e-07,
      "loss": 0.0014,
      "step": 3784
    },
    {
      "epoch": 2.5713315217391304,
      "grad_norm": 1.5136674642562866,
      "learning_rate": 9.907523244035887e-07,
      "loss": 0.0114,
      "step": 3785
    },
    {
      "epoch": 2.5720108695652173,
      "grad_norm": 5.161391735076904,
      "learning_rate": 9.876672547937117e-07,
      "loss": 0.1311,
      "step": 3786
    },
    {
      "epoch": 2.572690217391304,
      "grad_norm": 5.650180816650391,
      "learning_rate": 9.845867463806812e-07,
      "loss": 0.034,
      "step": 3787
    },
    {
      "epoch": 2.5733695652173916,
      "grad_norm": 3.7067458629608154,
      "learning_rate": 9.815108007235663e-07,
      "loss": 0.1123,
      "step": 3788
    },
    {
      "epoch": 2.5740489130434785,
      "grad_norm": 0.4669032692909241,
      "learning_rate": 9.784394193791169e-07,
      "loss": 0.0027,
      "step": 3789
    },
    {
      "epoch": 2.5747282608695654,
      "grad_norm": 4.840965747833252,
      "learning_rate": 9.75372603901783e-07,
      "loss": 0.118,
      "step": 3790
    },
    {
      "epoch": 2.5754076086956523,
      "grad_norm": 0.0034154534805566072,
      "learning_rate": 9.723103558436907e-07,
      "loss": 0.0,
      "step": 3791
    },
    {
      "epoch": 2.5760869565217392,
      "grad_norm": 0.002074696123600006,
      "learning_rate": 9.692526767546727e-07,
      "loss": 0.0,
      "step": 3792
    },
    {
      "epoch": 2.576766304347826,
      "grad_norm": 0.05279656499624252,
      "learning_rate": 9.661995681822322e-07,
      "loss": 0.0003,
      "step": 3793
    },
    {
      "epoch": 2.577445652173913,
      "grad_norm": 16.987159729003906,
      "learning_rate": 9.631510316715708e-07,
      "loss": 0.3052,
      "step": 3794
    },
    {
      "epoch": 2.578125,
      "grad_norm": 5.589359283447266,
      "learning_rate": 9.601070687655667e-07,
      "loss": 0.1852,
      "step": 3795
    },
    {
      "epoch": 2.578804347826087,
      "grad_norm": 5.9846062660217285,
      "learning_rate": 9.570676810047918e-07,
      "loss": 0.1953,
      "step": 3796
    },
    {
      "epoch": 2.579483695652174,
      "grad_norm": 0.08352120220661163,
      "learning_rate": 9.540328699274958e-07,
      "loss": 0.0006,
      "step": 3797
    },
    {
      "epoch": 2.5801630434782608,
      "grad_norm": 8.265019416809082,
      "learning_rate": 9.51002637069619e-07,
      "loss": 0.2106,
      "step": 3798
    },
    {
      "epoch": 2.5808423913043477,
      "grad_norm": 7.921262741088867,
      "learning_rate": 9.479769839647768e-07,
      "loss": 0.1728,
      "step": 3799
    },
    {
      "epoch": 2.5815217391304346,
      "grad_norm": 0.031118465587496758,
      "learning_rate": 9.449559121442731e-07,
      "loss": 0.0003,
      "step": 3800
    },
    {
      "epoch": 2.5822010869565215,
      "grad_norm": 0.18133923411369324,
      "learning_rate": 9.419394231370926e-07,
      "loss": 0.0011,
      "step": 3801
    },
    {
      "epoch": 2.5828804347826084,
      "grad_norm": 4.915460109710693,
      "learning_rate": 9.389275184698943e-07,
      "loss": 0.261,
      "step": 3802
    },
    {
      "epoch": 2.583559782608696,
      "grad_norm": 0.1074904203414917,
      "learning_rate": 9.359201996670264e-07,
      "loss": 0.0008,
      "step": 3803
    },
    {
      "epoch": 2.5842391304347827,
      "grad_norm": 0.0015545033384114504,
      "learning_rate": 9.32917468250506e-07,
      "loss": 0.0,
      "step": 3804
    },
    {
      "epoch": 2.5849184782608696,
      "grad_norm": 12.658638000488281,
      "learning_rate": 9.299193257400397e-07,
      "loss": 0.2085,
      "step": 3805
    },
    {
      "epoch": 2.5855978260869565,
      "grad_norm": 0.0010635696817189455,
      "learning_rate": 9.269257736530013e-07,
      "loss": 0.0,
      "step": 3806
    },
    {
      "epoch": 2.5862771739130435,
      "grad_norm": 0.012513970956206322,
      "learning_rate": 9.23936813504448e-07,
      "loss": 0.0001,
      "step": 3807
    },
    {
      "epoch": 2.5869565217391304,
      "grad_norm": 3.9940717220306396,
      "learning_rate": 9.209524468071096e-07,
      "loss": 0.1157,
      "step": 3808
    },
    {
      "epoch": 2.5876358695652173,
      "grad_norm": 5.574696063995361,
      "learning_rate": 9.179726750713958e-07,
      "loss": 0.0793,
      "step": 3809
    },
    {
      "epoch": 2.588315217391304,
      "grad_norm": 0.6971484422683716,
      "learning_rate": 9.149974998053823e-07,
      "loss": 0.0084,
      "step": 3810
    },
    {
      "epoch": 2.5889945652173916,
      "grad_norm": 0.001802462968043983,
      "learning_rate": 9.120269225148282e-07,
      "loss": 0.0,
      "step": 3811
    },
    {
      "epoch": 2.5896739130434785,
      "grad_norm": 0.19161354005336761,
      "learning_rate": 9.090609447031573e-07,
      "loss": 0.0008,
      "step": 3812
    },
    {
      "epoch": 2.5903532608695654,
      "grad_norm": 0.01635289564728737,
      "learning_rate": 9.060995678714712e-07,
      "loss": 0.0002,
      "step": 3813
    },
    {
      "epoch": 2.5910326086956523,
      "grad_norm": 0.0054807816632092,
      "learning_rate": 9.031427935185399e-07,
      "loss": 0.0001,
      "step": 3814
    },
    {
      "epoch": 2.5917119565217392,
      "grad_norm": 4.475234031677246,
      "learning_rate": 9.001906231408064e-07,
      "loss": 0.0767,
      "step": 3815
    },
    {
      "epoch": 2.592391304347826,
      "grad_norm": 0.4168024957180023,
      "learning_rate": 8.972430582323788e-07,
      "loss": 0.0025,
      "step": 3816
    },
    {
      "epoch": 2.593070652173913,
      "grad_norm": 5.815498352050781,
      "learning_rate": 8.943001002850415e-07,
      "loss": 0.2162,
      "step": 3817
    },
    {
      "epoch": 2.59375,
      "grad_norm": 9.603501319885254,
      "learning_rate": 8.91361750788241e-07,
      "loss": 0.3825,
      "step": 3818
    },
    {
      "epoch": 2.594429347826087,
      "grad_norm": 0.2382575124502182,
      "learning_rate": 8.884280112290977e-07,
      "loss": 0.0011,
      "step": 3819
    },
    {
      "epoch": 2.595108695652174,
      "grad_norm": 6.680704116821289,
      "learning_rate": 8.854988830923905e-07,
      "loss": 0.0732,
      "step": 3820
    },
    {
      "epoch": 2.5957880434782608,
      "grad_norm": 8.294928550720215,
      "learning_rate": 8.825743678605736e-07,
      "loss": 0.2702,
      "step": 3821
    },
    {
      "epoch": 2.5964673913043477,
      "grad_norm": 7.878635883331299,
      "learning_rate": 8.796544670137574e-07,
      "loss": 0.2119,
      "step": 3822
    },
    {
      "epoch": 2.5971467391304346,
      "grad_norm": 0.00402507558465004,
      "learning_rate": 8.767391820297267e-07,
      "loss": 0.0001,
      "step": 3823
    },
    {
      "epoch": 2.5978260869565215,
      "grad_norm": 2.701876640319824,
      "learning_rate": 8.738285143839198e-07,
      "loss": 0.0192,
      "step": 3824
    },
    {
      "epoch": 2.5985054347826084,
      "grad_norm": 7.345675468444824,
      "learning_rate": 8.709224655494475e-07,
      "loss": 0.3085,
      "step": 3825
    },
    {
      "epoch": 2.599184782608696,
      "grad_norm": 0.2192474752664566,
      "learning_rate": 8.680210369970743e-07,
      "loss": 0.001,
      "step": 3826
    },
    {
      "epoch": 2.5998641304347827,
      "grad_norm": 0.818199872970581,
      "learning_rate": 8.651242301952378e-07,
      "loss": 0.0124,
      "step": 3827
    },
    {
      "epoch": 2.6005434782608696,
      "grad_norm": 4.272220134735107,
      "learning_rate": 8.622320466100242e-07,
      "loss": 0.0626,
      "step": 3828
    },
    {
      "epoch": 2.6012228260869565,
      "grad_norm": 4.892832279205322,
      "learning_rate": 8.593444877051882e-07,
      "loss": 0.051,
      "step": 3829
    },
    {
      "epoch": 2.6019021739130435,
      "grad_norm": 0.0155011722818017,
      "learning_rate": 8.564615549421396e-07,
      "loss": 0.0001,
      "step": 3830
    },
    {
      "epoch": 2.6025815217391304,
      "grad_norm": 0.05373933166265488,
      "learning_rate": 8.53583249779949e-07,
      "loss": 0.0004,
      "step": 3831
    },
    {
      "epoch": 2.6032608695652173,
      "grad_norm": 5.882824897766113,
      "learning_rate": 8.507095736753435e-07,
      "loss": 0.2214,
      "step": 3832
    },
    {
      "epoch": 2.603940217391304,
      "grad_norm": 5.1505537033081055,
      "learning_rate": 8.478405280827107e-07,
      "loss": 0.1558,
      "step": 3833
    },
    {
      "epoch": 2.6046195652173916,
      "grad_norm": 13.419687271118164,
      "learning_rate": 8.449761144540869e-07,
      "loss": 0.0794,
      "step": 3834
    },
    {
      "epoch": 2.6052989130434785,
      "grad_norm": 1.8632005453109741,
      "learning_rate": 8.421163342391736e-07,
      "loss": 0.0248,
      "step": 3835
    },
    {
      "epoch": 2.6059782608695654,
      "grad_norm": 0.0018551793182268739,
      "learning_rate": 8.392611888853241e-07,
      "loss": 0.0,
      "step": 3836
    },
    {
      "epoch": 2.6066576086956523,
      "grad_norm": 4.227345943450928,
      "learning_rate": 8.364106798375416e-07,
      "loss": 0.1186,
      "step": 3837
    },
    {
      "epoch": 2.6073369565217392,
      "grad_norm": 6.3830742835998535,
      "learning_rate": 8.335648085384885e-07,
      "loss": 0.2412,
      "step": 3838
    },
    {
      "epoch": 2.608016304347826,
      "grad_norm": 0.14348426461219788,
      "learning_rate": 8.30723576428476e-07,
      "loss": 0.0014,
      "step": 3839
    },
    {
      "epoch": 2.608695652173913,
      "grad_norm": 0.004570060409605503,
      "learning_rate": 8.278869849454718e-07,
      "loss": 0.0001,
      "step": 3840
    },
    {
      "epoch": 2.609375,
      "grad_norm": 0.5304221510887146,
      "learning_rate": 8.250550355250875e-07,
      "loss": 0.0096,
      "step": 3841
    },
    {
      "epoch": 2.610054347826087,
      "grad_norm": 2.3644027709960938,
      "learning_rate": 8.222277296005954e-07,
      "loss": 0.0557,
      "step": 3842
    },
    {
      "epoch": 2.610733695652174,
      "grad_norm": 0.00310318055562675,
      "learning_rate": 8.194050686029065e-07,
      "loss": 0.0,
      "step": 3843
    },
    {
      "epoch": 2.6114130434782608,
      "grad_norm": 0.002073752461001277,
      "learning_rate": 8.165870539605936e-07,
      "loss": 0.0,
      "step": 3844
    },
    {
      "epoch": 2.6120923913043477,
      "grad_norm": 0.005504139699041843,
      "learning_rate": 8.13773687099867e-07,
      "loss": 0.0001,
      "step": 3845
    },
    {
      "epoch": 2.6127717391304346,
      "grad_norm": 0.2171248495578766,
      "learning_rate": 8.109649694445898e-07,
      "loss": 0.0013,
      "step": 3846
    },
    {
      "epoch": 2.6134510869565215,
      "grad_norm": 1.6170231103897095,
      "learning_rate": 8.081609024162706e-07,
      "loss": 0.0429,
      "step": 3847
    },
    {
      "epoch": 2.6141304347826084,
      "grad_norm": 0.00825865101069212,
      "learning_rate": 8.053614874340665e-07,
      "loss": 0.0001,
      "step": 3848
    },
    {
      "epoch": 2.614809782608696,
      "grad_norm": 0.004548440687358379,
      "learning_rate": 8.025667259147773e-07,
      "loss": 0.0001,
      "step": 3849
    },
    {
      "epoch": 2.6154891304347827,
      "grad_norm": 0.0041778478771448135,
      "learning_rate": 7.997766192728496e-07,
      "loss": 0.0001,
      "step": 3850
    },
    {
      "epoch": 2.6161684782608696,
      "grad_norm": 7.826907157897949,
      "learning_rate": 7.969911689203713e-07,
      "loss": 0.1077,
      "step": 3851
    },
    {
      "epoch": 2.6168478260869565,
      "grad_norm": 2.5771167278289795,
      "learning_rate": 7.942103762670783e-07,
      "loss": 0.0543,
      "step": 3852
    },
    {
      "epoch": 2.6175271739130435,
      "grad_norm": 0.01771288551390171,
      "learning_rate": 7.914342427203459e-07,
      "loss": 0.0001,
      "step": 3853
    },
    {
      "epoch": 2.6182065217391304,
      "grad_norm": 0.7959855794906616,
      "learning_rate": 7.886627696851945e-07,
      "loss": 0.013,
      "step": 3854
    },
    {
      "epoch": 2.6188858695652173,
      "grad_norm": 0.20527741312980652,
      "learning_rate": 7.8589595856428e-07,
      "loss": 0.0015,
      "step": 3855
    },
    {
      "epoch": 2.619565217391304,
      "grad_norm": 0.3731398582458496,
      "learning_rate": 7.831338107579056e-07,
      "loss": 0.0041,
      "step": 3856
    },
    {
      "epoch": 2.6202445652173916,
      "grad_norm": 1.8531440496444702,
      "learning_rate": 7.803763276640086e-07,
      "loss": 0.0186,
      "step": 3857
    },
    {
      "epoch": 2.6209239130434785,
      "grad_norm": 14.764335632324219,
      "learning_rate": 7.776235106781704e-07,
      "loss": 0.2782,
      "step": 3858
    },
    {
      "epoch": 2.6216032608695654,
      "grad_norm": 4.38131046295166,
      "learning_rate": 7.748753611936055e-07,
      "loss": 0.1499,
      "step": 3859
    },
    {
      "epoch": 2.6222826086956523,
      "grad_norm": 0.011497776955366135,
      "learning_rate": 7.721318806011713e-07,
      "loss": 0.0001,
      "step": 3860
    },
    {
      "epoch": 2.6229619565217392,
      "grad_norm": 10.447029113769531,
      "learning_rate": 7.693930702893626e-07,
      "loss": 0.0741,
      "step": 3861
    },
    {
      "epoch": 2.623641304347826,
      "grad_norm": 11.387177467346191,
      "learning_rate": 7.666589316443029e-07,
      "loss": 0.3535,
      "step": 3862
    },
    {
      "epoch": 2.624320652173913,
      "grad_norm": 5.018098831176758,
      "learning_rate": 7.639294660497609e-07,
      "loss": 0.1579,
      "step": 3863
    },
    {
      "epoch": 2.625,
      "grad_norm": 0.008932647295296192,
      "learning_rate": 7.612046748871327e-07,
      "loss": 0.0001,
      "step": 3864
    },
    {
      "epoch": 2.625679347826087,
      "grad_norm": 0.008167361840605736,
      "learning_rate": 7.584845595354529e-07,
      "loss": 0.0001,
      "step": 3865
    },
    {
      "epoch": 2.626358695652174,
      "grad_norm": 5.772029399871826,
      "learning_rate": 7.557691213713914e-07,
      "loss": 0.1237,
      "step": 3866
    },
    {
      "epoch": 2.6270380434782608,
      "grad_norm": 8.757843971252441,
      "learning_rate": 7.530583617692433e-07,
      "loss": 0.3127,
      "step": 3867
    },
    {
      "epoch": 2.6277173913043477,
      "grad_norm": 0.050000809133052826,
      "learning_rate": 7.503522821009434e-07,
      "loss": 0.0006,
      "step": 3868
    },
    {
      "epoch": 2.6283967391304346,
      "grad_norm": 6.691068172454834,
      "learning_rate": 7.476508837360541e-07,
      "loss": 0.0443,
      "step": 3869
    },
    {
      "epoch": 2.6290760869565215,
      "grad_norm": 0.2996862232685089,
      "learning_rate": 7.449541680417704e-07,
      "loss": 0.0017,
      "step": 3870
    },
    {
      "epoch": 2.6297554347826084,
      "grad_norm": 0.006445449311286211,
      "learning_rate": 7.422621363829186e-07,
      "loss": 0.0001,
      "step": 3871
    },
    {
      "epoch": 2.630434782608696,
      "grad_norm": 0.0077000767923891544,
      "learning_rate": 7.395747901219474e-07,
      "loss": 0.0001,
      "step": 3872
    },
    {
      "epoch": 2.6311141304347827,
      "grad_norm": 10.20249080657959,
      "learning_rate": 7.368921306189447e-07,
      "loss": 0.1597,
      "step": 3873
    },
    {
      "epoch": 2.6317934782608696,
      "grad_norm": 0.03239309415221214,
      "learning_rate": 7.342141592316165e-07,
      "loss": 0.0003,
      "step": 3874
    },
    {
      "epoch": 2.6324728260869565,
      "grad_norm": 1.890641450881958,
      "learning_rate": 7.315408773153044e-07,
      "loss": 0.0365,
      "step": 3875
    },
    {
      "epoch": 2.6331521739130435,
      "grad_norm": 0.0170816108584404,
      "learning_rate": 7.288722862229691e-07,
      "loss": 0.0001,
      "step": 3876
    },
    {
      "epoch": 2.6338315217391304,
      "grad_norm": 0.0020460677333176136,
      "learning_rate": 7.262083873052017e-07,
      "loss": 0.0,
      "step": 3877
    },
    {
      "epoch": 2.6345108695652173,
      "grad_norm": 13.152481079101562,
      "learning_rate": 7.235491819102192e-07,
      "loss": 0.0752,
      "step": 3878
    },
    {
      "epoch": 2.635190217391304,
      "grad_norm": 0.4636653959751129,
      "learning_rate": 7.208946713838638e-07,
      "loss": 0.0037,
      "step": 3879
    },
    {
      "epoch": 2.6358695652173916,
      "grad_norm": 0.004544025287032127,
      "learning_rate": 7.182448570695944e-07,
      "loss": 0.0001,
      "step": 3880
    },
    {
      "epoch": 2.6365489130434785,
      "grad_norm": 4.082566261291504,
      "learning_rate": 7.155997403085024e-07,
      "loss": 0.0972,
      "step": 3881
    },
    {
      "epoch": 2.6372282608695654,
      "grad_norm": 0.016099361702799797,
      "learning_rate": 7.12959322439295e-07,
      "loss": 0.0001,
      "step": 3882
    },
    {
      "epoch": 2.6379076086956523,
      "grad_norm": 10.763904571533203,
      "learning_rate": 7.103236047983053e-07,
      "loss": 0.5685,
      "step": 3883
    },
    {
      "epoch": 2.6385869565217392,
      "grad_norm": 0.36390066146850586,
      "learning_rate": 7.076925887194852e-07,
      "loss": 0.0015,
      "step": 3884
    },
    {
      "epoch": 2.639266304347826,
      "grad_norm": 0.20337584614753723,
      "learning_rate": 7.050662755344096e-07,
      "loss": 0.0013,
      "step": 3885
    },
    {
      "epoch": 2.639945652173913,
      "grad_norm": 0.01693401299417019,
      "learning_rate": 7.024446665722683e-07,
      "loss": 0.0002,
      "step": 3886
    },
    {
      "epoch": 2.640625,
      "grad_norm": 2.7075068950653076,
      "learning_rate": 6.998277631598793e-07,
      "loss": 0.0545,
      "step": 3887
    },
    {
      "epoch": 2.641304347826087,
      "grad_norm": 5.682165145874023,
      "learning_rate": 6.972155666216684e-07,
      "loss": 0.1001,
      "step": 3888
    },
    {
      "epoch": 2.641983695652174,
      "grad_norm": 6.198507308959961,
      "learning_rate": 6.946080782796872e-07,
      "loss": 0.1199,
      "step": 3889
    },
    {
      "epoch": 2.6426630434782608,
      "grad_norm": 1.2796140909194946,
      "learning_rate": 6.920052994535998e-07,
      "loss": 0.0068,
      "step": 3890
    },
    {
      "epoch": 2.6433423913043477,
      "grad_norm": 13.845203399658203,
      "learning_rate": 6.894072314606892e-07,
      "loss": 0.7252,
      "step": 3891
    },
    {
      "epoch": 2.6440217391304346,
      "grad_norm": 11.842031478881836,
      "learning_rate": 6.868138756158538e-07,
      "loss": 0.5076,
      "step": 3892
    },
    {
      "epoch": 2.6447010869565215,
      "grad_norm": 2.2395191192626953,
      "learning_rate": 6.842252332316069e-07,
      "loss": 0.0581,
      "step": 3893
    },
    {
      "epoch": 2.6453804347826084,
      "grad_norm": 0.002766608726233244,
      "learning_rate": 6.816413056180748e-07,
      "loss": 0.0001,
      "step": 3894
    },
    {
      "epoch": 2.646059782608696,
      "grad_norm": 0.7120469808578491,
      "learning_rate": 6.790620940830006e-07,
      "loss": 0.0073,
      "step": 3895
    },
    {
      "epoch": 2.6467391304347827,
      "grad_norm": 0.926520586013794,
      "learning_rate": 6.76487599931741e-07,
      "loss": 0.0051,
      "step": 3896
    },
    {
      "epoch": 2.6474184782608696,
      "grad_norm": 3.7439985275268555,
      "learning_rate": 6.739178244672584e-07,
      "loss": 0.1777,
      "step": 3897
    },
    {
      "epoch": 2.6480978260869565,
      "grad_norm": 0.006148742977529764,
      "learning_rate": 6.713527689901366e-07,
      "loss": 0.0001,
      "step": 3898
    },
    {
      "epoch": 2.6487771739130435,
      "grad_norm": 8.498764991760254,
      "learning_rate": 6.687924347985619e-07,
      "loss": 0.2743,
      "step": 3899
    },
    {
      "epoch": 2.6494565217391304,
      "grad_norm": 0.002514891093596816,
      "learning_rate": 6.662368231883388e-07,
      "loss": 0.0,
      "step": 3900
    },
    {
      "epoch": 2.6501358695652173,
      "grad_norm": 6.046058654785156,
      "learning_rate": 6.636859354528746e-07,
      "loss": 0.0961,
      "step": 3901
    },
    {
      "epoch": 2.650815217391304,
      "grad_norm": 10.666419982910156,
      "learning_rate": 6.611397728831925e-07,
      "loss": 0.1976,
      "step": 3902
    },
    {
      "epoch": 2.6514945652173916,
      "grad_norm": 0.2088613659143448,
      "learning_rate": 6.585983367679171e-07,
      "loss": 0.0019,
      "step": 3903
    },
    {
      "epoch": 2.6521739130434785,
      "grad_norm": 5.9547648429870605,
      "learning_rate": 6.560616283932897e-07,
      "loss": 0.2355,
      "step": 3904
    },
    {
      "epoch": 2.6528532608695654,
      "grad_norm": 0.002672487637028098,
      "learning_rate": 6.535296490431497e-07,
      "loss": 0.0,
      "step": 3905
    },
    {
      "epoch": 2.6535326086956523,
      "grad_norm": 0.005451408214867115,
      "learning_rate": 6.510023999989501e-07,
      "loss": 0.0001,
      "step": 3906
    },
    {
      "epoch": 2.6542119565217392,
      "grad_norm": 0.01738096959888935,
      "learning_rate": 6.484798825397454e-07,
      "loss": 0.0002,
      "step": 3907
    },
    {
      "epoch": 2.654891304347826,
      "grad_norm": 6.12021541595459,
      "learning_rate": 6.459620979421988e-07,
      "loss": 0.1968,
      "step": 3908
    },
    {
      "epoch": 2.655570652173913,
      "grad_norm": 1.4216535091400146,
      "learning_rate": 6.434490474805743e-07,
      "loss": 0.0063,
      "step": 3909
    },
    {
      "epoch": 2.65625,
      "grad_norm": 8.547737121582031,
      "learning_rate": 6.409407324267448e-07,
      "loss": 0.1434,
      "step": 3910
    },
    {
      "epoch": 2.656929347826087,
      "grad_norm": 7.102546215057373,
      "learning_rate": 6.384371540501799e-07,
      "loss": 0.0708,
      "step": 3911
    },
    {
      "epoch": 2.657608695652174,
      "grad_norm": 3.3518295288085938,
      "learning_rate": 6.359383136179598e-07,
      "loss": 0.0952,
      "step": 3912
    },
    {
      "epoch": 2.6582880434782608,
      "grad_norm": 6.947208881378174,
      "learning_rate": 6.334442123947615e-07,
      "loss": 0.0972,
      "step": 3913
    },
    {
      "epoch": 2.6589673913043477,
      "grad_norm": 10.278397560119629,
      "learning_rate": 6.309548516428666e-07,
      "loss": 0.7673,
      "step": 3914
    },
    {
      "epoch": 2.6596467391304346,
      "grad_norm": 0.008896439336240292,
      "learning_rate": 6.284702326221537e-07,
      "loss": 0.0001,
      "step": 3915
    },
    {
      "epoch": 2.6603260869565215,
      "grad_norm": 12.313488960266113,
      "learning_rate": 6.259903565901049e-07,
      "loss": 0.3642,
      "step": 3916
    },
    {
      "epoch": 2.6610054347826084,
      "grad_norm": 0.011828926391899586,
      "learning_rate": 6.235152248017984e-07,
      "loss": 0.0002,
      "step": 3917
    },
    {
      "epoch": 2.661684782608696,
      "grad_norm": 0.0036219796165823936,
      "learning_rate": 6.210448385099177e-07,
      "loss": 0.0001,
      "step": 3918
    },
    {
      "epoch": 2.6623641304347827,
      "grad_norm": 1.3770521879196167,
      "learning_rate": 6.18579198964736e-07,
      "loss": 0.007,
      "step": 3919
    },
    {
      "epoch": 2.6630434782608696,
      "grad_norm": 6.581512928009033,
      "learning_rate": 6.161183074141319e-07,
      "loss": 0.0456,
      "step": 3920
    },
    {
      "epoch": 2.6637228260869565,
      "grad_norm": 9.204089164733887,
      "learning_rate": 6.136621651035756e-07,
      "loss": 0.2173,
      "step": 3921
    },
    {
      "epoch": 2.6644021739130435,
      "grad_norm": 0.043814267963171005,
      "learning_rate": 6.112107732761363e-07,
      "loss": 0.0003,
      "step": 3922
    },
    {
      "epoch": 2.6650815217391304,
      "grad_norm": 4.268980503082275,
      "learning_rate": 6.087641331724792e-07,
      "loss": 0.1314,
      "step": 3923
    },
    {
      "epoch": 2.6657608695652173,
      "grad_norm": 4.517233371734619,
      "learning_rate": 6.063222460308649e-07,
      "loss": 0.0986,
      "step": 3924
    },
    {
      "epoch": 2.666440217391304,
      "grad_norm": 0.025036808103322983,
      "learning_rate": 6.038851130871438e-07,
      "loss": 0.0002,
      "step": 3925
    },
    {
      "epoch": 2.6671195652173916,
      "grad_norm": 0.12298571318387985,
      "learning_rate": 6.014527355747679e-07,
      "loss": 0.0009,
      "step": 3926
    },
    {
      "epoch": 2.6677989130434785,
      "grad_norm": 2.554849147796631,
      "learning_rate": 5.99025114724775e-07,
      "loss": 0.0315,
      "step": 3927
    },
    {
      "epoch": 2.6684782608695654,
      "grad_norm": 0.024288346990942955,
      "learning_rate": 5.96602251765801e-07,
      "loss": 0.0002,
      "step": 3928
    },
    {
      "epoch": 2.6691576086956523,
      "grad_norm": 13.277841567993164,
      "learning_rate": 5.941841479240706e-07,
      "loss": 0.3088,
      "step": 3929
    },
    {
      "epoch": 2.6698369565217392,
      "grad_norm": 0.027421439066529274,
      "learning_rate": 5.917708044234017e-07,
      "loss": 0.0002,
      "step": 3930
    },
    {
      "epoch": 2.670516304347826,
      "grad_norm": 4.823789596557617,
      "learning_rate": 5.893622224852025e-07,
      "loss": 0.1344,
      "step": 3931
    },
    {
      "epoch": 2.671195652173913,
      "grad_norm": 0.016711793839931488,
      "learning_rate": 5.869584033284703e-07,
      "loss": 0.0002,
      "step": 3932
    },
    {
      "epoch": 2.671875,
      "grad_norm": 0.004112767055630684,
      "learning_rate": 5.845593481697931e-07,
      "loss": 0.0001,
      "step": 3933
    },
    {
      "epoch": 2.672554347826087,
      "grad_norm": 0.10043858736753464,
      "learning_rate": 5.821650582233463e-07,
      "loss": 0.0008,
      "step": 3934
    },
    {
      "epoch": 2.673233695652174,
      "grad_norm": 0.004717372823506594,
      "learning_rate": 5.797755347008971e-07,
      "loss": 0.0001,
      "step": 3935
    },
    {
      "epoch": 2.6739130434782608,
      "grad_norm": 3.170048475265503,
      "learning_rate": 5.77390778811796e-07,
      "loss": 0.0791,
      "step": 3936
    },
    {
      "epoch": 2.6745923913043477,
      "grad_norm": 0.0015049157664179802,
      "learning_rate": 5.750107917629832e-07,
      "loss": 0.0,
      "step": 3937
    },
    {
      "epoch": 2.6752717391304346,
      "grad_norm": 0.0441875085234642,
      "learning_rate": 5.726355747589829e-07,
      "loss": 0.0005,
      "step": 3938
    },
    {
      "epoch": 2.6759510869565215,
      "grad_norm": 5.214298725128174,
      "learning_rate": 5.702651290019112e-07,
      "loss": 0.2034,
      "step": 3939
    },
    {
      "epoch": 2.6766304347826084,
      "grad_norm": 0.0017181227449327707,
      "learning_rate": 5.678994556914618e-07,
      "loss": 0.0,
      "step": 3940
    },
    {
      "epoch": 2.677309782608696,
      "grad_norm": 0.8648819327354431,
      "learning_rate": 5.655385560249193e-07,
      "loss": 0.0178,
      "step": 3941
    },
    {
      "epoch": 2.6779891304347827,
      "grad_norm": 2.8329484462738037,
      "learning_rate": 5.631824311971456e-07,
      "loss": 0.0943,
      "step": 3942
    },
    {
      "epoch": 2.6786684782608696,
      "grad_norm": 0.1321098655462265,
      "learning_rate": 5.608310824005936e-07,
      "loss": 0.0018,
      "step": 3943
    },
    {
      "epoch": 2.6793478260869565,
      "grad_norm": 4.189053058624268,
      "learning_rate": 5.584845108252923e-07,
      "loss": 0.0931,
      "step": 3944
    },
    {
      "epoch": 2.6800271739130435,
      "grad_norm": 0.0022435022983700037,
      "learning_rate": 5.561427176588586e-07,
      "loss": 0.0,
      "step": 3945
    },
    {
      "epoch": 2.6807065217391304,
      "grad_norm": 3.9835548400878906,
      "learning_rate": 5.538057040864841e-07,
      "loss": 0.1818,
      "step": 3946
    },
    {
      "epoch": 2.6813858695652173,
      "grad_norm": 4.543872356414795,
      "learning_rate": 5.514734712909519e-07,
      "loss": 0.1431,
      "step": 3947
    },
    {
      "epoch": 2.682065217391304,
      "grad_norm": 0.0032090763561427593,
      "learning_rate": 5.491460204526156e-07,
      "loss": 0.0,
      "step": 3948
    },
    {
      "epoch": 2.6827445652173916,
      "grad_norm": 3.204773187637329,
      "learning_rate": 5.468233527494138e-07,
      "loss": 0.0439,
      "step": 3949
    },
    {
      "epoch": 2.6834239130434785,
      "grad_norm": 9.883163452148438,
      "learning_rate": 5.445054693568608e-07,
      "loss": 0.1321,
      "step": 3950
    },
    {
      "epoch": 2.6841032608695654,
      "grad_norm": 0.003031299915164709,
      "learning_rate": 5.421923714480537e-07,
      "loss": 0.0001,
      "step": 3951
    },
    {
      "epoch": 2.6847826086956523,
      "grad_norm": 0.23606762290000916,
      "learning_rate": 5.398840601936628e-07,
      "loss": 0.0012,
      "step": 3952
    },
    {
      "epoch": 2.6854619565217392,
      "grad_norm": 0.04020196199417114,
      "learning_rate": 5.375805367619424e-07,
      "loss": 0.0003,
      "step": 3953
    },
    {
      "epoch": 2.686141304347826,
      "grad_norm": 3.990490198135376,
      "learning_rate": 5.352818023187167e-07,
      "loss": 0.0586,
      "step": 3954
    },
    {
      "epoch": 2.686820652173913,
      "grad_norm": 15.285901069641113,
      "learning_rate": 5.329878580273906e-07,
      "loss": 0.4935,
      "step": 3955
    },
    {
      "epoch": 2.6875,
      "grad_norm": 0.6837837100028992,
      "learning_rate": 5.306987050489442e-07,
      "loss": 0.0082,
      "step": 3956
    },
    {
      "epoch": 2.688179347826087,
      "grad_norm": 0.024851273745298386,
      "learning_rate": 5.284143445419288e-07,
      "loss": 0.0002,
      "step": 3957
    },
    {
      "epoch": 2.688858695652174,
      "grad_norm": 0.007970074191689491,
      "learning_rate": 5.261347776624781e-07,
      "loss": 0.0001,
      "step": 3958
    },
    {
      "epoch": 2.6895380434782608,
      "grad_norm": 0.006568680051714182,
      "learning_rate": 5.238600055642895e-07,
      "loss": 0.0001,
      "step": 3959
    },
    {
      "epoch": 2.6902173913043477,
      "grad_norm": 20.829084396362305,
      "learning_rate": 5.215900293986431e-07,
      "loss": 0.5253,
      "step": 3960
    },
    {
      "epoch": 2.6908967391304346,
      "grad_norm": 0.011663137003779411,
      "learning_rate": 5.193248503143855e-07,
      "loss": 0.0001,
      "step": 3961
    },
    {
      "epoch": 2.6915760869565215,
      "grad_norm": 0.21871548891067505,
      "learning_rate": 5.170644694579396e-07,
      "loss": 0.0016,
      "step": 3962
    },
    {
      "epoch": 2.6922554347826084,
      "grad_norm": 0.1668008267879486,
      "learning_rate": 5.14808887973296e-07,
      "loss": 0.0009,
      "step": 3963
    },
    {
      "epoch": 2.692934782608696,
      "grad_norm": 4.99207878112793,
      "learning_rate": 5.125581070020192e-07,
      "loss": 0.1375,
      "step": 3964
    },
    {
      "epoch": 2.6936141304347827,
      "grad_norm": 1.610454797744751,
      "learning_rate": 5.103121276832434e-07,
      "loss": 0.0282,
      "step": 3965
    },
    {
      "epoch": 2.6942934782608696,
      "grad_norm": 0.007429586257785559,
      "learning_rate": 5.08070951153673e-07,
      "loss": 0.0001,
      "step": 3966
    },
    {
      "epoch": 2.6949728260869565,
      "grad_norm": 0.016567323356866837,
      "learning_rate": 5.058345785475805e-07,
      "loss": 0.0002,
      "step": 3967
    },
    {
      "epoch": 2.6956521739130435,
      "grad_norm": 11.687535285949707,
      "learning_rate": 5.036030109968082e-07,
      "loss": 0.2868,
      "step": 3968
    },
    {
      "epoch": 2.6963315217391304,
      "grad_norm": 3.2112252712249756,
      "learning_rate": 5.01376249630764e-07,
      "loss": 0.0815,
      "step": 3969
    },
    {
      "epoch": 2.6970108695652173,
      "grad_norm": 2.1803994178771973,
      "learning_rate": 4.991542955764295e-07,
      "loss": 0.0369,
      "step": 3970
    },
    {
      "epoch": 2.697690217391304,
      "grad_norm": 4.214768886566162,
      "learning_rate": 4.969371499583465e-07,
      "loss": 0.1292,
      "step": 3971
    },
    {
      "epoch": 2.6983695652173916,
      "grad_norm": 5.310330390930176,
      "learning_rate": 4.947248138986249e-07,
      "loss": 0.0801,
      "step": 3972
    },
    {
      "epoch": 2.6990489130434785,
      "grad_norm": 0.004032152239233255,
      "learning_rate": 4.925172885169438e-07,
      "loss": 0.0001,
      "step": 3973
    },
    {
      "epoch": 2.6997282608695654,
      "grad_norm": 0.0526931956410408,
      "learning_rate": 4.90314574930546e-07,
      "loss": 0.0004,
      "step": 3974
    },
    {
      "epoch": 2.7004076086956523,
      "grad_norm": 0.023117443546652794,
      "learning_rate": 4.881166742542365e-07,
      "loss": 0.0001,
      "step": 3975
    },
    {
      "epoch": 2.7010869565217392,
      "grad_norm": 5.183065891265869,
      "learning_rate": 4.859235876003876e-07,
      "loss": 0.1079,
      "step": 3976
    },
    {
      "epoch": 2.701766304347826,
      "grad_norm": 0.09091398864984512,
      "learning_rate": 4.837353160789315e-07,
      "loss": 0.0006,
      "step": 3977
    },
    {
      "epoch": 2.702445652173913,
      "grad_norm": 5.345612049102783,
      "learning_rate": 4.81551860797369e-07,
      "loss": 0.1775,
      "step": 3978
    },
    {
      "epoch": 2.703125,
      "grad_norm": 0.0077220662496984005,
      "learning_rate": 4.793732228607573e-07,
      "loss": 0.0001,
      "step": 3979
    },
    {
      "epoch": 2.703804347826087,
      "grad_norm": 0.39830225706100464,
      "learning_rate": 4.77199403371722e-07,
      "loss": 0.0026,
      "step": 3980
    },
    {
      "epoch": 2.704483695652174,
      "grad_norm": 0.8582947850227356,
      "learning_rate": 4.7503040343044205e-07,
      "loss": 0.005,
      "step": 3981
    },
    {
      "epoch": 2.7051630434782608,
      "grad_norm": 10.103323936462402,
      "learning_rate": 4.7286622413466377e-07,
      "loss": 1.0001,
      "step": 3982
    },
    {
      "epoch": 2.7058423913043477,
      "grad_norm": 0.002885903464630246,
      "learning_rate": 4.707068665796921e-07,
      "loss": 0.0,
      "step": 3983
    },
    {
      "epoch": 2.7065217391304346,
      "grad_norm": 1.5793362855911255,
      "learning_rate": 4.6855233185839175e-07,
      "loss": 0.039,
      "step": 3984
    },
    {
      "epoch": 2.7072010869565215,
      "grad_norm": 0.25876495242118835,
      "learning_rate": 4.664026210611838e-07,
      "loss": 0.0011,
      "step": 3985
    },
    {
      "epoch": 2.7078804347826084,
      "grad_norm": 19.250774383544922,
      "learning_rate": 4.642577352760524e-07,
      "loss": 0.4826,
      "step": 3986
    },
    {
      "epoch": 2.708559782608696,
      "grad_norm": 3.5575575828552246,
      "learning_rate": 4.6211767558853484e-07,
      "loss": 0.1007,
      "step": 3987
    },
    {
      "epoch": 2.7092391304347827,
      "grad_norm": 0.1238764151930809,
      "learning_rate": 4.5998244308173126e-07,
      "loss": 0.0008,
      "step": 3988
    },
    {
      "epoch": 2.7099184782608696,
      "grad_norm": 6.265100955963135,
      "learning_rate": 4.578520388362928e-07,
      "loss": 0.2207,
      "step": 3989
    },
    {
      "epoch": 2.7105978260869565,
      "grad_norm": 2.752284049987793,
      "learning_rate": 4.557264639304315e-07,
      "loss": 0.0632,
      "step": 3990
    },
    {
      "epoch": 2.7112771739130435,
      "grad_norm": 10.819167137145996,
      "learning_rate": 4.536057194399157e-07,
      "loss": 0.1042,
      "step": 3991
    },
    {
      "epoch": 2.7119565217391304,
      "grad_norm": 3.818591594696045,
      "learning_rate": 4.514898064380646e-07,
      "loss": 0.1107,
      "step": 3992
    },
    {
      "epoch": 2.7126358695652173,
      "grad_norm": 6.197628021240234,
      "learning_rate": 4.4937872599575605e-07,
      "loss": 0.2542,
      "step": 3993
    },
    {
      "epoch": 2.713315217391304,
      "grad_norm": 3.358940362930298,
      "learning_rate": 4.472724791814198e-07,
      "loss": 0.1022,
      "step": 3994
    },
    {
      "epoch": 2.7139945652173916,
      "grad_norm": 5.144237518310547,
      "learning_rate": 4.451710670610421e-07,
      "loss": 0.1968,
      "step": 3995
    },
    {
      "epoch": 2.7146739130434785,
      "grad_norm": 6.778408527374268,
      "learning_rate": 4.430744906981577e-07,
      "loss": 0.134,
      "step": 3996
    },
    {
      "epoch": 2.7153532608695654,
      "grad_norm": 3.5626637935638428,
      "learning_rate": 4.4098275115386004e-07,
      "loss": 0.0396,
      "step": 3997
    },
    {
      "epoch": 2.7160326086956523,
      "grad_norm": 2.6363489627838135,
      "learning_rate": 4.388958494867868e-07,
      "loss": 0.0221,
      "step": 3998
    },
    {
      "epoch": 2.7167119565217392,
      "grad_norm": 0.0014371181605383754,
      "learning_rate": 4.3681378675313747e-07,
      "loss": 0.0,
      "step": 3999
    },
    {
      "epoch": 2.717391304347826,
      "grad_norm": 5.14848518371582,
      "learning_rate": 4.3473656400665256e-07,
      "loss": 0.118,
      "step": 4000
    },
    {
      "epoch": 2.718070652173913,
      "grad_norm": 5.166167259216309,
      "learning_rate": 4.326641822986299e-07,
      "loss": 0.1662,
      "step": 4001
    },
    {
      "epoch": 2.71875,
      "grad_norm": 7.748570919036865,
      "learning_rate": 4.305966426779118e-07,
      "loss": 0.286,
      "step": 4002
    },
    {
      "epoch": 2.719429347826087,
      "grad_norm": 0.09082771092653275,
      "learning_rate": 4.285339461908944e-07,
      "loss": 0.0006,
      "step": 4003
    },
    {
      "epoch": 2.720108695652174,
      "grad_norm": 0.005543080158531666,
      "learning_rate": 4.2647609388152043e-07,
      "loss": 0.0001,
      "step": 4004
    },
    {
      "epoch": 2.7207880434782608,
      "grad_norm": 1.4245485067367554,
      "learning_rate": 4.244230867912835e-07,
      "loss": 0.0058,
      "step": 4005
    },
    {
      "epoch": 2.7214673913043477,
      "grad_norm": 2.9030401706695557,
      "learning_rate": 4.2237492595922025e-07,
      "loss": 0.036,
      "step": 4006
    },
    {
      "epoch": 2.7221467391304346,
      "grad_norm": 9.756990432739258,
      "learning_rate": 4.203316124219181e-07,
      "loss": 0.3098,
      "step": 4007
    },
    {
      "epoch": 2.7228260869565215,
      "grad_norm": 4.931600570678711,
      "learning_rate": 4.1829314721351213e-07,
      "loss": 0.0883,
      "step": 4008
    },
    {
      "epoch": 2.7235054347826084,
      "grad_norm": 1.5621623992919922,
      "learning_rate": 4.162595313656814e-07,
      "loss": 0.0046,
      "step": 4009
    },
    {
      "epoch": 2.724184782608696,
      "grad_norm": 7.517866134643555,
      "learning_rate": 4.142307659076494e-07,
      "loss": 0.0421,
      "step": 4010
    },
    {
      "epoch": 2.7248641304347827,
      "grad_norm": 9.025696754455566,
      "learning_rate": 4.1220685186619037e-07,
      "loss": 0.2598,
      "step": 4011
    },
    {
      "epoch": 2.7255434782608696,
      "grad_norm": 0.028920331969857216,
      "learning_rate": 4.1018779026561595e-07,
      "loss": 0.0002,
      "step": 4012
    },
    {
      "epoch": 2.7262228260869565,
      "grad_norm": 0.01436662022024393,
      "learning_rate": 4.081735821277899e-07,
      "loss": 0.0002,
      "step": 4013
    },
    {
      "epoch": 2.7269021739130435,
      "grad_norm": 0.00669438298791647,
      "learning_rate": 4.0616422847211013e-07,
      "loss": 0.0001,
      "step": 4014
    },
    {
      "epoch": 2.7275815217391304,
      "grad_norm": 0.004939178004860878,
      "learning_rate": 4.0415973031552535e-07,
      "loss": 0.0001,
      "step": 4015
    },
    {
      "epoch": 2.7282608695652173,
      "grad_norm": 8.37053394317627,
      "learning_rate": 4.021600886725263e-07,
      "loss": 0.2036,
      "step": 4016
    },
    {
      "epoch": 2.728940217391304,
      "grad_norm": 1.6933056116104126,
      "learning_rate": 4.0016530455514013e-07,
      "loss": 0.0308,
      "step": 4017
    },
    {
      "epoch": 2.7296195652173916,
      "grad_norm": 1.4423431158065796,
      "learning_rate": 3.9817537897294254e-07,
      "loss": 0.0092,
      "step": 4018
    },
    {
      "epoch": 2.7302989130434785,
      "grad_norm": 0.0021368295419961214,
      "learning_rate": 3.9619031293304467e-07,
      "loss": 0.0,
      "step": 4019
    },
    {
      "epoch": 2.7309782608695654,
      "grad_norm": 3.7785348892211914,
      "learning_rate": 3.942101074401028e-07,
      "loss": 0.1066,
      "step": 4020
    },
    {
      "epoch": 2.7316576086956523,
      "grad_norm": 0.03868458420038223,
      "learning_rate": 3.922347634963097e-07,
      "loss": 0.0003,
      "step": 4021
    },
    {
      "epoch": 2.7323369565217392,
      "grad_norm": 18.554458618164062,
      "learning_rate": 3.9026428210139913e-07,
      "loss": 0.4308,
      "step": 4022
    },
    {
      "epoch": 2.733016304347826,
      "grad_norm": 0.004422962199896574,
      "learning_rate": 3.8829866425264317e-07,
      "loss": 0.0001,
      "step": 4023
    },
    {
      "epoch": 2.733695652173913,
      "grad_norm": 0.003683364950120449,
      "learning_rate": 3.8633791094485397e-07,
      "loss": 0.0001,
      "step": 4024
    },
    {
      "epoch": 2.734375,
      "grad_norm": 0.1359224170446396,
      "learning_rate": 3.8438202317037987e-07,
      "loss": 0.0005,
      "step": 4025
    },
    {
      "epoch": 2.735054347826087,
      "grad_norm": 3.3269989490509033,
      "learning_rate": 3.824310019191102e-07,
      "loss": 0.0986,
      "step": 4026
    },
    {
      "epoch": 2.735733695652174,
      "grad_norm": 22.992265701293945,
      "learning_rate": 3.8048484817846623e-07,
      "loss": 0.2217,
      "step": 4027
    },
    {
      "epoch": 2.7364130434782608,
      "grad_norm": 5.358827590942383,
      "learning_rate": 3.7854356293341e-07,
      "loss": 0.095,
      "step": 4028
    },
    {
      "epoch": 2.7370923913043477,
      "grad_norm": 12.638309478759766,
      "learning_rate": 3.7660714716643563e-07,
      "loss": 0.057,
      "step": 4029
    },
    {
      "epoch": 2.7377717391304346,
      "grad_norm": 0.005630781874060631,
      "learning_rate": 3.7467560185757813e-07,
      "loss": 0.0001,
      "step": 4030
    },
    {
      "epoch": 2.7384510869565215,
      "grad_norm": 0.5933682322502136,
      "learning_rate": 3.7274892798440096e-07,
      "loss": 0.0034,
      "step": 4031
    },
    {
      "epoch": 2.7391304347826084,
      "grad_norm": 17.274763107299805,
      "learning_rate": 3.708271265220087e-07,
      "loss": 0.3261,
      "step": 4032
    },
    {
      "epoch": 2.739809782608696,
      "grad_norm": 3.631336212158203,
      "learning_rate": 3.6891019844303213e-07,
      "loss": 0.1962,
      "step": 4033
    },
    {
      "epoch": 2.7404891304347827,
      "grad_norm": 9.680237770080566,
      "learning_rate": 3.6699814471764626e-07,
      "loss": 0.0644,
      "step": 4034
    },
    {
      "epoch": 2.7411684782608696,
      "grad_norm": 5.3544769287109375,
      "learning_rate": 3.650909663135505e-07,
      "loss": 0.0647,
      "step": 4035
    },
    {
      "epoch": 2.7418478260869565,
      "grad_norm": 3.2741646766662598,
      "learning_rate": 3.631886641959792e-07,
      "loss": 0.0697,
      "step": 4036
    },
    {
      "epoch": 2.7425271739130435,
      "grad_norm": 0.047133058309555054,
      "learning_rate": 3.6129123932769907e-07,
      "loss": 0.0003,
      "step": 4037
    },
    {
      "epoch": 2.7432065217391304,
      "grad_norm": 0.0048357234336435795,
      "learning_rate": 3.5939869266901073e-07,
      "loss": 0.0001,
      "step": 4038
    },
    {
      "epoch": 2.7438858695652173,
      "grad_norm": 3.3176772594451904,
      "learning_rate": 3.5751102517773916e-07,
      "loss": 0.1265,
      "step": 4039
    },
    {
      "epoch": 2.744565217391304,
      "grad_norm": 7.629772663116455,
      "learning_rate": 3.5562823780924906e-07,
      "loss": 0.1273,
      "step": 4040
    },
    {
      "epoch": 2.7452445652173916,
      "grad_norm": 0.0256736408919096,
      "learning_rate": 3.537503315164259e-07,
      "loss": 0.0003,
      "step": 4041
    },
    {
      "epoch": 2.7459239130434785,
      "grad_norm": 0.00204340647906065,
      "learning_rate": 3.5187730724969507e-07,
      "loss": 0.0,
      "step": 4042
    },
    {
      "epoch": 2.7466032608695654,
      "grad_norm": 4.956358432769775,
      "learning_rate": 3.5000916595700264e-07,
      "loss": 0.1348,
      "step": 4043
    },
    {
      "epoch": 2.7472826086956523,
      "grad_norm": 10.273360252380371,
      "learning_rate": 3.481459085838268e-07,
      "loss": 0.2423,
      "step": 4044
    },
    {
      "epoch": 2.7479619565217392,
      "grad_norm": 0.11032360047101974,
      "learning_rate": 3.4628753607317213e-07,
      "loss": 0.0007,
      "step": 4045
    },
    {
      "epoch": 2.748641304347826,
      "grad_norm": 0.005269190762192011,
      "learning_rate": 3.44434049365574e-07,
      "loss": 0.0001,
      "step": 4046
    },
    {
      "epoch": 2.749320652173913,
      "grad_norm": 0.05170975625514984,
      "learning_rate": 3.4258544939909324e-07,
      "loss": 0.0004,
      "step": 4047
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.008982029743492603,
      "learning_rate": 3.4074173710931804e-07,
      "loss": 0.0001,
      "step": 4048
    },
    {
      "epoch": 2.750679347826087,
      "grad_norm": 5.262153148651123,
      "learning_rate": 3.3890291342936087e-07,
      "loss": 0.1017,
      "step": 4049
    },
    {
      "epoch": 2.751358695652174,
      "grad_norm": 0.003083902643993497,
      "learning_rate": 3.370689792898618e-07,
      "loss": 0.0,
      "step": 4050
    },
    {
      "epoch": 2.7520380434782608,
      "grad_norm": 3.1846680641174316,
      "learning_rate": 3.352399356189884e-07,
      "loss": 0.0959,
      "step": 4051
    },
    {
      "epoch": 2.7527173913043477,
      "grad_norm": 0.07846346497535706,
      "learning_rate": 3.33415783342429e-07,
      "loss": 0.0005,
      "step": 4052
    },
    {
      "epoch": 2.7533967391304346,
      "grad_norm": 2.484224319458008,
      "learning_rate": 3.3159652338339953e-07,
      "loss": 0.0497,
      "step": 4053
    },
    {
      "epoch": 2.7540760869565215,
      "grad_norm": 5.490437984466553,
      "learning_rate": 3.297821566626358e-07,
      "loss": 0.169,
      "step": 4054
    },
    {
      "epoch": 2.7547554347826084,
      "grad_norm": 4.113143444061279,
      "learning_rate": 3.279726840984032e-07,
      "loss": 0.0968,
      "step": 4055
    },
    {
      "epoch": 2.755434782608696,
      "grad_norm": 3.445847272872925,
      "learning_rate": 3.261681066064859e-07,
      "loss": 0.1985,
      "step": 4056
    },
    {
      "epoch": 2.7561141304347827,
      "grad_norm": 4.146409511566162,
      "learning_rate": 3.2436842510019107e-07,
      "loss": 0.1275,
      "step": 4057
    },
    {
      "epoch": 2.7567934782608696,
      "grad_norm": 1.5452489852905273,
      "learning_rate": 3.225736404903479e-07,
      "loss": 0.0246,
      "step": 4058
    },
    {
      "epoch": 2.7574728260869565,
      "grad_norm": 0.6900842189788818,
      "learning_rate": 3.207837536853087e-07,
      "loss": 0.0086,
      "step": 4059
    },
    {
      "epoch": 2.7581521739130435,
      "grad_norm": 5.05826997756958,
      "learning_rate": 3.1899876559094657e-07,
      "loss": 0.275,
      "step": 4060
    },
    {
      "epoch": 2.7588315217391304,
      "grad_norm": 12.392158508300781,
      "learning_rate": 3.172186771106556e-07,
      "loss": 0.6078,
      "step": 4061
    },
    {
      "epoch": 2.7595108695652173,
      "grad_norm": 0.00151423632632941,
      "learning_rate": 3.154434891453473e-07,
      "loss": 0.0,
      "step": 4062
    },
    {
      "epoch": 2.760190217391304,
      "grad_norm": 4.959366321563721,
      "learning_rate": 3.136732025934575e-07,
      "loss": 0.1535,
      "step": 4063
    },
    {
      "epoch": 2.7608695652173916,
      "grad_norm": 0.0029921664390712976,
      "learning_rate": 3.119078183509372e-07,
      "loss": 0.0,
      "step": 4064
    },
    {
      "epoch": 2.7615489130434785,
      "grad_norm": 0.014721943996846676,
      "learning_rate": 3.1014733731125955e-07,
      "loss": 0.0002,
      "step": 4065
    },
    {
      "epoch": 2.7622282608695654,
      "grad_norm": 0.010566875338554382,
      "learning_rate": 3.08391760365413e-07,
      "loss": 0.0001,
      "step": 4066
    },
    {
      "epoch": 2.7629076086956523,
      "grad_norm": 10.675289154052734,
      "learning_rate": 3.066410884019066e-07,
      "loss": 0.3288,
      "step": 4067
    },
    {
      "epoch": 2.7635869565217392,
      "grad_norm": 0.004089395981281996,
      "learning_rate": 3.0489532230676744e-07,
      "loss": 0.0001,
      "step": 4068
    },
    {
      "epoch": 2.764266304347826,
      "grad_norm": 18.918737411499023,
      "learning_rate": 3.0315446296353746e-07,
      "loss": 0.6284,
      "step": 4069
    },
    {
      "epoch": 2.764945652173913,
      "grad_norm": 15.138153076171875,
      "learning_rate": 3.0141851125327636e-07,
      "loss": 0.484,
      "step": 4070
    },
    {
      "epoch": 2.765625,
      "grad_norm": 0.5566046237945557,
      "learning_rate": 2.996874680545603e-07,
      "loss": 0.0085,
      "step": 4071
    },
    {
      "epoch": 2.766304347826087,
      "grad_norm": 2.8791797161102295,
      "learning_rate": 2.979613342434795e-07,
      "loss": 0.0445,
      "step": 4072
    },
    {
      "epoch": 2.766983695652174,
      "grad_norm": 4.280122756958008,
      "learning_rate": 2.96240110693643e-07,
      "loss": 0.1467,
      "step": 4073
    },
    {
      "epoch": 2.7676630434782608,
      "grad_norm": 0.006030001677572727,
      "learning_rate": 2.945237982761706e-07,
      "loss": 0.0001,
      "step": 4074
    },
    {
      "epoch": 2.7683423913043477,
      "grad_norm": 0.013810351490974426,
      "learning_rate": 2.9281239785969974e-07,
      "loss": 0.0001,
      "step": 4075
    },
    {
      "epoch": 2.7690217391304346,
      "grad_norm": 4.168213367462158,
      "learning_rate": 2.911059103103797e-07,
      "loss": 0.0852,
      "step": 4076
    },
    {
      "epoch": 2.7697010869565215,
      "grad_norm": 0.0017496699001640081,
      "learning_rate": 2.8940433649187525e-07,
      "loss": 0.0,
      "step": 4077
    },
    {
      "epoch": 2.7703804347826084,
      "grad_norm": 2.6295998096466064,
      "learning_rate": 2.877076772653631e-07,
      "loss": 0.0313,
      "step": 4078
    },
    {
      "epoch": 2.771059782608696,
      "grad_norm": 4.952249050140381,
      "learning_rate": 2.860159334895318e-07,
      "loss": 0.0231,
      "step": 4079
    },
    {
      "epoch": 2.7717391304347827,
      "grad_norm": 13.446399688720703,
      "learning_rate": 2.843291060205855e-07,
      "loss": 0.077,
      "step": 4080
    },
    {
      "epoch": 2.7724184782608696,
      "grad_norm": 9.803481101989746,
      "learning_rate": 2.8264719571223564e-07,
      "loss": 0.2381,
      "step": 4081
    },
    {
      "epoch": 2.7730978260869565,
      "grad_norm": 0.023444071412086487,
      "learning_rate": 2.80970203415708e-07,
      "loss": 0.0002,
      "step": 4082
    },
    {
      "epoch": 2.7737771739130435,
      "grad_norm": 0.9117060303688049,
      "learning_rate": 2.7929812997974036e-07,
      "loss": 0.005,
      "step": 4083
    },
    {
      "epoch": 2.7744565217391304,
      "grad_norm": 0.08279174566268921,
      "learning_rate": 2.776309762505769e-07,
      "loss": 0.0005,
      "step": 4084
    },
    {
      "epoch": 2.7751358695652173,
      "grad_norm": 0.03789449855685234,
      "learning_rate": 2.7596874307197487e-07,
      "loss": 0.0006,
      "step": 4085
    },
    {
      "epoch": 2.775815217391304,
      "grad_norm": 7.728710651397705,
      "learning_rate": 2.7431143128520243e-07,
      "loss": 0.1381,
      "step": 4086
    },
    {
      "epoch": 2.7764945652173916,
      "grad_norm": 0.015973353758454323,
      "learning_rate": 2.7265904172903313e-07,
      "loss": 0.0001,
      "step": 4087
    },
    {
      "epoch": 2.7771739130434785,
      "grad_norm": 7.507625579833984,
      "learning_rate": 2.710115752397535e-07,
      "loss": 0.324,
      "step": 4088
    },
    {
      "epoch": 2.7778532608695654,
      "grad_norm": 7.284273624420166,
      "learning_rate": 2.693690326511533e-07,
      "loss": 0.069,
      "step": 4089
    },
    {
      "epoch": 2.7785326086956523,
      "grad_norm": 3.334177255630493,
      "learning_rate": 2.6773141479453646e-07,
      "loss": 0.0479,
      "step": 4090
    },
    {
      "epoch": 2.7792119565217392,
      "grad_norm": 18.436628341674805,
      "learning_rate": 2.660987224987099e-07,
      "loss": 0.127,
      "step": 4091
    },
    {
      "epoch": 2.779891304347826,
      "grad_norm": 3.9560678005218506,
      "learning_rate": 2.6447095658999054e-07,
      "loss": 0.0722,
      "step": 4092
    },
    {
      "epoch": 2.780570652173913,
      "grad_norm": 0.00724533898755908,
      "learning_rate": 2.628481178921971e-07,
      "loss": 0.0001,
      "step": 4093
    },
    {
      "epoch": 2.78125,
      "grad_norm": 0.026998214423656464,
      "learning_rate": 2.612302072266637e-07,
      "loss": 0.0002,
      "step": 4094
    },
    {
      "epoch": 2.781929347826087,
      "grad_norm": 0.018215475603938103,
      "learning_rate": 2.596172254122209e-07,
      "loss": 0.0002,
      "step": 4095
    },
    {
      "epoch": 2.782608695652174,
      "grad_norm": 0.06764154136180878,
      "learning_rate": 2.5800917326521013e-07,
      "loss": 0.0004,
      "step": 4096
    },
    {
      "epoch": 2.7832880434782608,
      "grad_norm": 7.685258865356445,
      "learning_rate": 2.5640605159947484e-07,
      "loss": 0.1024,
      "step": 4097
    },
    {
      "epoch": 2.7839673913043477,
      "grad_norm": 0.31995466351509094,
      "learning_rate": 2.5480786122636713e-07,
      "loss": 0.005,
      "step": 4098
    },
    {
      "epoch": 2.7846467391304346,
      "grad_norm": 9.36571216583252,
      "learning_rate": 2.5321460295474e-07,
      "loss": 0.3296,
      "step": 4099
    },
    {
      "epoch": 2.7853260869565215,
      "grad_norm": 3.856513500213623,
      "learning_rate": 2.516262775909506e-07,
      "loss": 0.0463,
      "step": 4100
    },
    {
      "epoch": 2.7860054347826084,
      "grad_norm": 0.006307005882263184,
      "learning_rate": 2.500428859388593e-07,
      "loss": 0.0001,
      "step": 4101
    },
    {
      "epoch": 2.786684782608696,
      "grad_norm": 0.10016041994094849,
      "learning_rate": 2.484644287998328e-07,
      "loss": 0.0009,
      "step": 4102
    },
    {
      "epoch": 2.7873641304347827,
      "grad_norm": 4.653907775878906,
      "learning_rate": 2.4689090697273546e-07,
      "loss": 0.0712,
      "step": 4103
    },
    {
      "epoch": 2.7880434782608696,
      "grad_norm": 3.061779022216797,
      "learning_rate": 2.453223212539391e-07,
      "loss": 0.074,
      "step": 4104
    },
    {
      "epoch": 2.7887228260869565,
      "grad_norm": 9.024165153503418,
      "learning_rate": 2.43758672437312e-07,
      "loss": 0.1303,
      "step": 4105
    },
    {
      "epoch": 2.7894021739130435,
      "grad_norm": 4.684097766876221,
      "learning_rate": 2.4219996131422895e-07,
      "loss": 0.0847,
      "step": 4106
    },
    {
      "epoch": 2.7900815217391304,
      "grad_norm": 0.00556338531896472,
      "learning_rate": 2.4064618867356003e-07,
      "loss": 0.0001,
      "step": 4107
    },
    {
      "epoch": 2.7907608695652173,
      "grad_norm": 5.8081746101379395,
      "learning_rate": 2.3909735530168175e-07,
      "loss": 0.1822,
      "step": 4108
    },
    {
      "epoch": 2.791440217391304,
      "grad_norm": 13.62263298034668,
      "learning_rate": 2.3755346198246599e-07,
      "loss": 0.5628,
      "step": 4109
    },
    {
      "epoch": 2.7921195652173916,
      "grad_norm": 0.001772131770849228,
      "learning_rate": 2.3601450949728876e-07,
      "loss": 0.0,
      "step": 4110
    },
    {
      "epoch": 2.7927989130434785,
      "grad_norm": 8.276498794555664,
      "learning_rate": 2.3448049862502265e-07,
      "loss": 0.0249,
      "step": 4111
    },
    {
      "epoch": 2.7934782608695654,
      "grad_norm": 12.521810531616211,
      "learning_rate": 2.329514301420388e-07,
      "loss": 0.3445,
      "step": 4112
    },
    {
      "epoch": 2.7941576086956523,
      "grad_norm": 15.002884864807129,
      "learning_rate": 2.314273048222093e-07,
      "loss": 0.1793,
      "step": 4113
    },
    {
      "epoch": 2.7948369565217392,
      "grad_norm": 4.915746212005615,
      "learning_rate": 2.2990812343690382e-07,
      "loss": 0.1401,
      "step": 4114
    },
    {
      "epoch": 2.795516304347826,
      "grad_norm": 8.237235069274902,
      "learning_rate": 2.283938867549884e-07,
      "loss": 0.1358,
      "step": 4115
    },
    {
      "epoch": 2.796195652173913,
      "grad_norm": 0.11390608549118042,
      "learning_rate": 2.2688459554282673e-07,
      "loss": 0.0008,
      "step": 4116
    },
    {
      "epoch": 2.796875,
      "grad_norm": 15.977274894714355,
      "learning_rate": 2.2538025056428216e-07,
      "loss": 0.2431,
      "step": 4117
    },
    {
      "epoch": 2.797554347826087,
      "grad_norm": 0.005456062033772469,
      "learning_rate": 2.2388085258071124e-07,
      "loss": 0.0001,
      "step": 4118
    },
    {
      "epoch": 2.798233695652174,
      "grad_norm": 0.03731711208820343,
      "learning_rate": 2.2238640235097032e-07,
      "loss": 0.0003,
      "step": 4119
    },
    {
      "epoch": 2.7989130434782608,
      "grad_norm": 16.939668655395508,
      "learning_rate": 2.2089690063140766e-07,
      "loss": 0.579,
      "step": 4120
    },
    {
      "epoch": 2.7995923913043477,
      "grad_norm": 0.020302768796682358,
      "learning_rate": 2.1941234817587143e-07,
      "loss": 0.0003,
      "step": 4121
    },
    {
      "epoch": 2.8002717391304346,
      "grad_norm": 5.534564018249512,
      "learning_rate": 2.1793274573570166e-07,
      "loss": 0.1092,
      "step": 4122
    },
    {
      "epoch": 2.8009510869565215,
      "grad_norm": 8.352275848388672,
      "learning_rate": 2.1645809405973384e-07,
      "loss": 0.1788,
      "step": 4123
    },
    {
      "epoch": 2.8016304347826084,
      "grad_norm": 5.609335422515869,
      "learning_rate": 2.149883938942987e-07,
      "loss": 0.0783,
      "step": 4124
    },
    {
      "epoch": 2.802309782608696,
      "grad_norm": 0.0016775111434981227,
      "learning_rate": 2.135236459832213e-07,
      "loss": 0.0,
      "step": 4125
    },
    {
      "epoch": 2.8029891304347827,
      "grad_norm": 4.223796844482422,
      "learning_rate": 2.1206385106781634e-07,
      "loss": 0.2312,
      "step": 4126
    },
    {
      "epoch": 2.8036684782608696,
      "grad_norm": 19.472715377807617,
      "learning_rate": 2.106090098868996e-07,
      "loss": 0.1989,
      "step": 4127
    },
    {
      "epoch": 2.8043478260869565,
      "grad_norm": 2.468744993209839,
      "learning_rate": 2.091591231767709e-07,
      "loss": 0.0767,
      "step": 4128
    },
    {
      "epoch": 2.8050271739130435,
      "grad_norm": 12.966964721679688,
      "learning_rate": 2.0771419167122997e-07,
      "loss": 0.1671,
      "step": 4129
    },
    {
      "epoch": 2.8057065217391304,
      "grad_norm": 0.6153160929679871,
      "learning_rate": 2.0627421610156407e-07,
      "loss": 0.0063,
      "step": 4130
    },
    {
      "epoch": 2.8063858695652173,
      "grad_norm": 0.015102640725672245,
      "learning_rate": 2.0483919719655466e-07,
      "loss": 0.0002,
      "step": 4131
    },
    {
      "epoch": 2.807065217391304,
      "grad_norm": 0.009439042769372463,
      "learning_rate": 2.0340913568247078e-07,
      "loss": 0.0002,
      "step": 4132
    },
    {
      "epoch": 2.8077445652173916,
      "grad_norm": 0.0017654398689046502,
      "learning_rate": 2.0198403228307905e-07,
      "loss": 0.0,
      "step": 4133
    },
    {
      "epoch": 2.8084239130434785,
      "grad_norm": 0.007569719571620226,
      "learning_rate": 2.005638877196303e-07,
      "loss": 0.0001,
      "step": 4134
    },
    {
      "epoch": 2.8091032608695654,
      "grad_norm": 0.11772137135267258,
      "learning_rate": 1.9914870271087072e-07,
      "loss": 0.0012,
      "step": 4135
    },
    {
      "epoch": 2.8097826086956523,
      "grad_norm": 14.520963668823242,
      "learning_rate": 1.977384779730307e-07,
      "loss": 0.1263,
      "step": 4136
    },
    {
      "epoch": 2.8104619565217392,
      "grad_norm": 21.373035430908203,
      "learning_rate": 1.9633321421983708e-07,
      "loss": 0.4827,
      "step": 4137
    },
    {
      "epoch": 2.811141304347826,
      "grad_norm": 4.304066181182861,
      "learning_rate": 1.9493291216250098e-07,
      "loss": 0.0731,
      "step": 4138
    },
    {
      "epoch": 2.811820652173913,
      "grad_norm": 13.315221786499023,
      "learning_rate": 1.9353757250972328e-07,
      "loss": 0.1476,
      "step": 4139
    },
    {
      "epoch": 2.8125,
      "grad_norm": 7.243809700012207,
      "learning_rate": 1.921471959676957e-07,
      "loss": 0.0399,
      "step": 4140
    },
    {
      "epoch": 2.813179347826087,
      "grad_norm": 5.868599891662598,
      "learning_rate": 1.907617832400954e-07,
      "loss": 0.1235,
      "step": 4141
    },
    {
      "epoch": 2.813858695652174,
      "grad_norm": 19.378517150878906,
      "learning_rate": 1.893813350280871e-07,
      "loss": 0.049,
      "step": 4142
    },
    {
      "epoch": 2.8145380434782608,
      "grad_norm": 0.21442578732967377,
      "learning_rate": 1.8800585203032517e-07,
      "loss": 0.0019,
      "step": 4143
    },
    {
      "epoch": 2.8152173913043477,
      "grad_norm": 14.995680809020996,
      "learning_rate": 1.866353349429506e-07,
      "loss": 0.178,
      "step": 4144
    },
    {
      "epoch": 2.8158967391304346,
      "grad_norm": 0.10570324212312698,
      "learning_rate": 1.8526978445958854e-07,
      "loss": 0.0008,
      "step": 4145
    },
    {
      "epoch": 2.8165760869565215,
      "grad_norm": 0.0038954413030296564,
      "learning_rate": 1.8390920127135613e-07,
      "loss": 0.0001,
      "step": 4146
    },
    {
      "epoch": 2.8172554347826084,
      "grad_norm": 0.017262276262044907,
      "learning_rate": 1.8255358606684815e-07,
      "loss": 0.0002,
      "step": 4147
    },
    {
      "epoch": 2.817934782608696,
      "grad_norm": 0.38570636510849,
      "learning_rate": 1.812029395321535e-07,
      "loss": 0.0023,
      "step": 4148
    },
    {
      "epoch": 2.8186141304347827,
      "grad_norm": 19.247133255004883,
      "learning_rate": 1.79857262350841e-07,
      "loss": 0.4791,
      "step": 4149
    },
    {
      "epoch": 2.8192934782608696,
      "grad_norm": 6.098787784576416,
      "learning_rate": 1.7851655520396583e-07,
      "loss": 0.097,
      "step": 4150
    },
    {
      "epoch": 2.8199728260869565,
      "grad_norm": 9.586454391479492,
      "learning_rate": 1.7718081877006966e-07,
      "loss": 0.1568,
      "step": 4151
    },
    {
      "epoch": 2.8206521739130435,
      "grad_norm": 5.580276012420654,
      "learning_rate": 1.7585005372517504e-07,
      "loss": 0.162,
      "step": 4152
    },
    {
      "epoch": 2.8213315217391304,
      "grad_norm": 1.41097092628479,
      "learning_rate": 1.7452426074278995e-07,
      "loss": 0.0094,
      "step": 4153
    },
    {
      "epoch": 2.8220108695652173,
      "grad_norm": 0.12054790556430817,
      "learning_rate": 1.732034404939098e-07,
      "loss": 0.0007,
      "step": 4154
    },
    {
      "epoch": 2.822690217391304,
      "grad_norm": 9.154775619506836,
      "learning_rate": 1.7188759364700658e-07,
      "loss": 0.2874,
      "step": 4155
    },
    {
      "epoch": 2.8233695652173916,
      "grad_norm": 3.001373052597046,
      "learning_rate": 1.7057672086803978e-07,
      "loss": 0.1131,
      "step": 4156
    },
    {
      "epoch": 2.8240489130434785,
      "grad_norm": 22.20004653930664,
      "learning_rate": 1.6927082282044982e-07,
      "loss": 0.5054,
      "step": 4157
    },
    {
      "epoch": 2.8247282608695654,
      "grad_norm": 8.742151260375977,
      "learning_rate": 1.6796990016515914e-07,
      "loss": 0.0976,
      "step": 4158
    },
    {
      "epoch": 2.8254076086956523,
      "grad_norm": 10.737271308898926,
      "learning_rate": 1.6667395356057325e-07,
      "loss": 0.0617,
      "step": 4159
    },
    {
      "epoch": 2.8260869565217392,
      "grad_norm": 1.1238058805465698,
      "learning_rate": 1.6538298366257975e-07,
      "loss": 0.0193,
      "step": 4160
    },
    {
      "epoch": 2.826766304347826,
      "grad_norm": 0.006883468013256788,
      "learning_rate": 1.640969911245438e-07,
      "loss": 0.0001,
      "step": 4161
    },
    {
      "epoch": 2.827445652173913,
      "grad_norm": 1.3581020832061768,
      "learning_rate": 1.6281597659731584e-07,
      "loss": 0.0086,
      "step": 4162
    },
    {
      "epoch": 2.828125,
      "grad_norm": 0.028357943519949913,
      "learning_rate": 1.615399407292251e-07,
      "loss": 0.0004,
      "step": 4163
    },
    {
      "epoch": 2.828804347826087,
      "grad_norm": 4.725820541381836,
      "learning_rate": 1.6026888416608267e-07,
      "loss": 0.1602,
      "step": 4164
    },
    {
      "epoch": 2.829483695652174,
      "grad_norm": 0.015594483353197575,
      "learning_rate": 1.5900280755117403e-07,
      "loss": 0.0001,
      "step": 4165
    },
    {
      "epoch": 2.8301630434782608,
      "grad_norm": 0.058932267129421234,
      "learning_rate": 1.5774171152527218e-07,
      "loss": 0.0007,
      "step": 4166
    },
    {
      "epoch": 2.8308423913043477,
      "grad_norm": 0.004004320595413446,
      "learning_rate": 1.5648559672662322e-07,
      "loss": 0.0001,
      "step": 4167
    },
    {
      "epoch": 2.8315217391304346,
      "grad_norm": 3.4004669189453125,
      "learning_rate": 1.552344637909564e-07,
      "loss": 0.0349,
      "step": 4168
    },
    {
      "epoch": 2.8322010869565215,
      "grad_norm": 12.276222229003906,
      "learning_rate": 1.5398831335147636e-07,
      "loss": 0.1419,
      "step": 4169
    },
    {
      "epoch": 2.8328804347826084,
      "grad_norm": 0.4026872515678406,
      "learning_rate": 1.5274714603886742e-07,
      "loss": 0.0026,
      "step": 4170
    },
    {
      "epoch": 2.833559782608696,
      "grad_norm": 0.005506731104105711,
      "learning_rate": 1.515109624812927e-07,
      "loss": 0.0001,
      "step": 4171
    },
    {
      "epoch": 2.8342391304347827,
      "grad_norm": 0.022070568054914474,
      "learning_rate": 1.5027976330439175e-07,
      "loss": 0.0002,
      "step": 4172
    },
    {
      "epoch": 2.8349184782608696,
      "grad_norm": 12.01931381225586,
      "learning_rate": 1.4905354913128279e-07,
      "loss": 0.3877,
      "step": 4173
    },
    {
      "epoch": 2.8355978260869565,
      "grad_norm": 0.014744739048182964,
      "learning_rate": 1.4783232058255826e-07,
      "loss": 0.0002,
      "step": 4174
    },
    {
      "epoch": 2.8362771739130435,
      "grad_norm": 4.529953956604004,
      "learning_rate": 1.4661607827629266e-07,
      "loss": 0.0258,
      "step": 4175
    },
    {
      "epoch": 2.8369565217391304,
      "grad_norm": 5.298038005828857,
      "learning_rate": 1.4540482282803136e-07,
      "loss": 0.1353,
      "step": 4176
    },
    {
      "epoch": 2.8376358695652173,
      "grad_norm": 5.676628589630127,
      "learning_rate": 1.441985548507996e-07,
      "loss": 0.1743,
      "step": 4177
    },
    {
      "epoch": 2.838315217391304,
      "grad_norm": 6.63571310043335,
      "learning_rate": 1.4299727495509565e-07,
      "loss": 0.1776,
      "step": 4178
    },
    {
      "epoch": 2.8389945652173916,
      "grad_norm": 13.969572067260742,
      "learning_rate": 1.4180098374889429e-07,
      "loss": 0.2553,
      "step": 4179
    },
    {
      "epoch": 2.8396739130434785,
      "grad_norm": 5.4234724044799805,
      "learning_rate": 1.4060968183764678e-07,
      "loss": 0.1284,
      "step": 4180
    },
    {
      "epoch": 2.8403532608695654,
      "grad_norm": 6.785265922546387,
      "learning_rate": 1.3942336982427974e-07,
      "loss": 0.0795,
      "step": 4181
    },
    {
      "epoch": 2.8410326086956523,
      "grad_norm": 2.785101890563965,
      "learning_rate": 1.3824204830918952e-07,
      "loss": 0.0074,
      "step": 4182
    },
    {
      "epoch": 2.8417119565217392,
      "grad_norm": 0.00248875399120152,
      "learning_rate": 1.3706571789025457e-07,
      "loss": 0.0,
      "step": 4183
    },
    {
      "epoch": 2.842391304347826,
      "grad_norm": 11.751965522766113,
      "learning_rate": 1.3589437916281867e-07,
      "loss": 0.8759,
      "step": 4184
    },
    {
      "epoch": 2.843070652173913,
      "grad_norm": 2.38700532913208,
      "learning_rate": 1.3472803271970536e-07,
      "loss": 0.0261,
      "step": 4185
    },
    {
      "epoch": 2.84375,
      "grad_norm": 5.740895748138428,
      "learning_rate": 1.3356667915121025e-07,
      "loss": 0.1778,
      "step": 4186
    },
    {
      "epoch": 2.844429347826087,
      "grad_norm": 3.671522855758667,
      "learning_rate": 1.3241031904510093e-07,
      "loss": 0.0971,
      "step": 4187
    },
    {
      "epoch": 2.845108695652174,
      "grad_norm": 16.766199111938477,
      "learning_rate": 1.3125895298661705e-07,
      "loss": 0.5132,
      "step": 4188
    },
    {
      "epoch": 2.8457880434782608,
      "grad_norm": 0.004258354660123587,
      "learning_rate": 1.3011258155847583e-07,
      "loss": 0.0001,
      "step": 4189
    },
    {
      "epoch": 2.8464673913043477,
      "grad_norm": 6.11667537689209,
      "learning_rate": 1.289712053408587e-07,
      "loss": 0.058,
      "step": 4190
    },
    {
      "epoch": 2.8471467391304346,
      "grad_norm": 4.724775314331055,
      "learning_rate": 1.2783482491142474e-07,
      "loss": 0.0914,
      "step": 4191
    },
    {
      "epoch": 2.8478260869565215,
      "grad_norm": 0.04764304682612419,
      "learning_rate": 1.2670344084530384e-07,
      "loss": 0.0005,
      "step": 4192
    },
    {
      "epoch": 2.8485054347826084,
      "grad_norm": 13.790027618408203,
      "learning_rate": 1.2557705371509575e-07,
      "loss": 0.6146,
      "step": 4193
    },
    {
      "epoch": 2.849184782608696,
      "grad_norm": 10.736832618713379,
      "learning_rate": 1.244556640908712e-07,
      "loss": 0.2243,
      "step": 4194
    },
    {
      "epoch": 2.8498641304347827,
      "grad_norm": 0.018052222207188606,
      "learning_rate": 1.2333927254017387e-07,
      "loss": 0.0002,
      "step": 4195
    },
    {
      "epoch": 2.8505434782608696,
      "grad_norm": 0.0037021564785391092,
      "learning_rate": 1.222278796280152e-07,
      "loss": 0.0001,
      "step": 4196
    },
    {
      "epoch": 2.8512228260869565,
      "grad_norm": 7.358076572418213,
      "learning_rate": 1.2112148591687743e-07,
      "loss": 0.1764,
      "step": 4197
    },
    {
      "epoch": 2.8519021739130435,
      "grad_norm": 6.734840393066406,
      "learning_rate": 1.2002009196671494e-07,
      "loss": 0.0863,
      "step": 4198
    },
    {
      "epoch": 2.8525815217391304,
      "grad_norm": 0.04205317795276642,
      "learning_rate": 1.1892369833494955e-07,
      "loss": 0.0003,
      "step": 4199
    },
    {
      "epoch": 2.8532608695652173,
      "grad_norm": 0.22604475915431976,
      "learning_rate": 1.1783230557647075e-07,
      "loss": 0.0008,
      "step": 4200
    },
    {
      "epoch": 2.853940217391304,
      "grad_norm": 4.61293888092041,
      "learning_rate": 1.1674591424364224e-07,
      "loss": 0.063,
      "step": 4201
    },
    {
      "epoch": 2.8546195652173916,
      "grad_norm": 0.0017816374311223626,
      "learning_rate": 1.1566452488629088e-07,
      "loss": 0.0,
      "step": 4202
    },
    {
      "epoch": 2.8552989130434785,
      "grad_norm": 5.285614967346191,
      "learning_rate": 1.1458813805171665e-07,
      "loss": 0.2095,
      "step": 4203
    },
    {
      "epoch": 2.8559782608695654,
      "grad_norm": 6.334031581878662,
      "learning_rate": 1.1351675428468267e-07,
      "loss": 0.1355,
      "step": 4204
    },
    {
      "epoch": 2.8566576086956523,
      "grad_norm": 0.016591394320130348,
      "learning_rate": 1.124503741274241e-07,
      "loss": 0.0002,
      "step": 4205
    },
    {
      "epoch": 2.8573369565217392,
      "grad_norm": 4.169040203094482,
      "learning_rate": 1.1138899811964477e-07,
      "loss": 0.0871,
      "step": 4206
    },
    {
      "epoch": 2.858016304347826,
      "grad_norm": 0.14598031342029572,
      "learning_rate": 1.1033262679850943e-07,
      "loss": 0.0012,
      "step": 4207
    },
    {
      "epoch": 2.858695652173913,
      "grad_norm": 9.91357421875,
      "learning_rate": 1.0928126069865819e-07,
      "loss": 0.0858,
      "step": 4208
    },
    {
      "epoch": 2.859375,
      "grad_norm": 0.0019819391891360283,
      "learning_rate": 1.0823490035218986e-07,
      "loss": 0.0,
      "step": 4209
    },
    {
      "epoch": 2.860054347826087,
      "grad_norm": 6.3528618812561035,
      "learning_rate": 1.071935462886775e-07,
      "loss": 0.1885,
      "step": 4210
    },
    {
      "epoch": 2.860733695652174,
      "grad_norm": 3.414355754852295,
      "learning_rate": 1.0615719903515509e-07,
      "loss": 0.1526,
      "step": 4211
    },
    {
      "epoch": 2.8614130434782608,
      "grad_norm": 18.601539611816406,
      "learning_rate": 1.0512585911612416e-07,
      "loss": 0.4912,
      "step": 4212
    },
    {
      "epoch": 2.8620923913043477,
      "grad_norm": 3.7333383560180664,
      "learning_rate": 1.0409952705355164e-07,
      "loss": 0.0618,
      "step": 4213
    },
    {
      "epoch": 2.8627717391304346,
      "grad_norm": 2.1078407764434814,
      "learning_rate": 1.0307820336687091e-07,
      "loss": 0.0151,
      "step": 4214
    },
    {
      "epoch": 2.8634510869565215,
      "grad_norm": 8.71791934967041,
      "learning_rate": 1.0206188857298182e-07,
      "loss": 0.2029,
      "step": 4215
    },
    {
      "epoch": 2.8641304347826084,
      "grad_norm": 0.7727157473564148,
      "learning_rate": 1.0105058318624516e-07,
      "loss": 0.0129,
      "step": 4216
    },
    {
      "epoch": 2.864809782608696,
      "grad_norm": 0.011068195104598999,
      "learning_rate": 1.0004428771849039e-07,
      "loss": 0.0001,
      "step": 4217
    },
    {
      "epoch": 2.8654891304347827,
      "grad_norm": 3.8963840007781982,
      "learning_rate": 9.904300267901012e-08,
      "loss": 0.1104,
      "step": 4218
    },
    {
      "epoch": 2.8661684782608696,
      "grad_norm": 6.201594829559326,
      "learning_rate": 9.804672857455788e-08,
      "loss": 0.2652,
      "step": 4219
    },
    {
      "epoch": 2.8668478260869565,
      "grad_norm": 11.544429779052734,
      "learning_rate": 9.70554659093581e-08,
      "loss": 0.3522,
      "step": 4220
    },
    {
      "epoch": 2.8675271739130435,
      "grad_norm": 5.389957904815674,
      "learning_rate": 9.606921518509172e-08,
      "loss": 0.0607,
      "step": 4221
    },
    {
      "epoch": 2.8682065217391304,
      "grad_norm": 0.0031909183599054813,
      "learning_rate": 9.508797690090721e-08,
      "loss": 0.0001,
      "step": 4222
    },
    {
      "epoch": 2.8688858695652173,
      "grad_norm": 3.493325710296631,
      "learning_rate": 9.411175155341623e-08,
      "loss": 0.113,
      "step": 4223
    },
    {
      "epoch": 2.869565217391304,
      "grad_norm": 2.145371913909912,
      "learning_rate": 9.314053963669245e-08,
      "loss": 0.0623,
      "step": 4224
    },
    {
      "epoch": 2.8702445652173916,
      "grad_norm": 0.003911213483661413,
      "learning_rate": 9.217434164227046e-08,
      "loss": 0.0001,
      "step": 4225
    },
    {
      "epoch": 2.8709239130434785,
      "grad_norm": 5.28827428817749,
      "learning_rate": 9.121315805915132e-08,
      "loss": 0.0463,
      "step": 4226
    },
    {
      "epoch": 2.8716032608695654,
      "grad_norm": 0.0036991348024457693,
      "learning_rate": 9.025698937379368e-08,
      "loss": 0.0,
      "step": 4227
    },
    {
      "epoch": 2.8722826086956523,
      "grad_norm": 1.7846139669418335,
      "learning_rate": 8.930583607012155e-08,
      "loss": 0.0273,
      "step": 4228
    },
    {
      "epoch": 2.8729619565217392,
      "grad_norm": 5.493021488189697,
      "learning_rate": 8.835969862951876e-08,
      "loss": 0.1688,
      "step": 4229
    },
    {
      "epoch": 2.873641304347826,
      "grad_norm": 0.1305476725101471,
      "learning_rate": 8.741857753083228e-08,
      "loss": 0.0006,
      "step": 4230
    },
    {
      "epoch": 2.874320652173913,
      "grad_norm": 7.908353805541992,
      "learning_rate": 8.648247325036885e-08,
      "loss": 0.1885,
      "step": 4231
    },
    {
      "epoch": 2.875,
      "grad_norm": 3.171057939529419,
      "learning_rate": 8.555138626189619e-08,
      "loss": 0.0707,
      "step": 4232
    },
    {
      "epoch": 2.875679347826087,
      "grad_norm": 5.378636837005615,
      "learning_rate": 8.46253170366429e-08,
      "loss": 0.1323,
      "step": 4233
    },
    {
      "epoch": 2.876358695652174,
      "grad_norm": 5.572697162628174,
      "learning_rate": 8.370426604329961e-08,
      "loss": 0.0997,
      "step": 4234
    },
    {
      "epoch": 2.8770380434782608,
      "grad_norm": 3.589245319366455,
      "learning_rate": 8.27882337480146e-08,
      "loss": 0.062,
      "step": 4235
    },
    {
      "epoch": 2.8777173913043477,
      "grad_norm": 4.26552677154541,
      "learning_rate": 8.187722061439806e-08,
      "loss": 0.0982,
      "step": 4236
    },
    {
      "epoch": 2.8783967391304346,
      "grad_norm": 6.69954252243042,
      "learning_rate": 8.097122710352013e-08,
      "loss": 0.1141,
      "step": 4237
    },
    {
      "epoch": 2.8790760869565215,
      "grad_norm": 5.897829055786133,
      "learning_rate": 8.007025367390731e-08,
      "loss": 0.0933,
      "step": 4238
    },
    {
      "epoch": 2.8797554347826084,
      "grad_norm": 3.451951503753662,
      "learning_rate": 7.91743007815493e-08,
      "loss": 0.1284,
      "step": 4239
    },
    {
      "epoch": 2.880434782608696,
      "grad_norm": 4.5687737464904785,
      "learning_rate": 7.82833688798934e-08,
      "loss": 0.1174,
      "step": 4240
    },
    {
      "epoch": 2.8811141304347827,
      "grad_norm": 4.469584941864014,
      "learning_rate": 7.739745841984559e-08,
      "loss": 0.0498,
      "step": 4241
    },
    {
      "epoch": 2.8817934782608696,
      "grad_norm": 0.0035014150198549032,
      "learning_rate": 7.651656984977051e-08,
      "loss": 0.0001,
      "step": 4242
    },
    {
      "epoch": 2.8824728260869565,
      "grad_norm": 6.285389423370361,
      "learning_rate": 7.564070361549158e-08,
      "loss": 0.1595,
      "step": 4243
    },
    {
      "epoch": 2.8831521739130435,
      "grad_norm": 9.788439750671387,
      "learning_rate": 7.476986016028976e-08,
      "loss": 0.1447,
      "step": 4244
    },
    {
      "epoch": 2.8838315217391304,
      "grad_norm": 35.39814758300781,
      "learning_rate": 7.390403992490358e-08,
      "loss": 0.1262,
      "step": 4245
    },
    {
      "epoch": 2.8845108695652173,
      "grad_norm": 0.02742340788245201,
      "learning_rate": 7.304324334753143e-08,
      "loss": 0.0002,
      "step": 4246
    },
    {
      "epoch": 2.885190217391304,
      "grad_norm": 0.1303165853023529,
      "learning_rate": 7.218747086382705e-08,
      "loss": 0.0007,
      "step": 4247
    },
    {
      "epoch": 2.8858695652173916,
      "grad_norm": 9.084955215454102,
      "learning_rate": 7.133672290690064e-08,
      "loss": 0.1996,
      "step": 4248
    },
    {
      "epoch": 2.8865489130434785,
      "grad_norm": 8.151556015014648,
      "learning_rate": 7.049099990732444e-08,
      "loss": 0.1392,
      "step": 4249
    },
    {
      "epoch": 2.8872282608695654,
      "grad_norm": 3.6417734622955322,
      "learning_rate": 6.965030229312053e-08,
      "loss": 0.1189,
      "step": 4250
    },
    {
      "epoch": 2.8879076086956523,
      "grad_norm": 0.011608417145907879,
      "learning_rate": 6.8814630489773e-08,
      "loss": 0.0001,
      "step": 4251
    },
    {
      "epoch": 2.8885869565217392,
      "grad_norm": 14.229642868041992,
      "learning_rate": 6.798398492022018e-08,
      "loss": 0.8458,
      "step": 4252
    },
    {
      "epoch": 2.889266304347826,
      "grad_norm": 0.01524973101913929,
      "learning_rate": 6.715836600485693e-08,
      "loss": 0.0002,
      "step": 4253
    },
    {
      "epoch": 2.889945652173913,
      "grad_norm": 0.0019883671775460243,
      "learning_rate": 6.633777416153232e-08,
      "loss": 0.0,
      "step": 4254
    },
    {
      "epoch": 2.890625,
      "grad_norm": 0.010101190768182278,
      "learning_rate": 6.552220980555635e-08,
      "loss": 0.0001,
      "step": 4255
    },
    {
      "epoch": 2.891304347826087,
      "grad_norm": 5.966160774230957,
      "learning_rate": 6.471167334968887e-08,
      "loss": 0.0983,
      "step": 4256
    },
    {
      "epoch": 2.891983695652174,
      "grad_norm": 4.006173133850098,
      "learning_rate": 6.390616520414617e-08,
      "loss": 0.1613,
      "step": 4257
    },
    {
      "epoch": 2.8926630434782608,
      "grad_norm": 1.0642801523208618,
      "learning_rate": 6.310568577660436e-08,
      "loss": 0.013,
      "step": 4258
    },
    {
      "epoch": 2.8933423913043477,
      "grad_norm": 0.004095870070159435,
      "learning_rate": 6.231023547218828e-08,
      "loss": 0.0001,
      "step": 4259
    },
    {
      "epoch": 2.8940217391304346,
      "grad_norm": 0.011015676893293858,
      "learning_rate": 6.151981469348034e-08,
      "loss": 0.0001,
      "step": 4260
    },
    {
      "epoch": 2.8947010869565215,
      "grad_norm": 6.974361896514893,
      "learning_rate": 6.073442384051942e-08,
      "loss": 0.1399,
      "step": 4261
    },
    {
      "epoch": 2.8953804347826084,
      "grad_norm": 3.0906217098236084,
      "learning_rate": 5.995406331079423e-08,
      "loss": 0.1011,
      "step": 4262
    },
    {
      "epoch": 2.896059782608696,
      "grad_norm": 17.296981811523438,
      "learning_rate": 5.9178733499251073e-08,
      "loss": 0.5692,
      "step": 4263
    },
    {
      "epoch": 2.8967391304347827,
      "grad_norm": 4.5257697105407715,
      "learning_rate": 5.840843479828939e-08,
      "loss": 0.1199,
      "step": 4264
    },
    {
      "epoch": 2.8974184782608696,
      "grad_norm": 0.004126636777073145,
      "learning_rate": 5.7643167597761784e-08,
      "loss": 0.0001,
      "step": 4265
    },
    {
      "epoch": 2.8980978260869565,
      "grad_norm": 0.0023388145491480827,
      "learning_rate": 5.688293228497399e-08,
      "loss": 0.0,
      "step": 4266
    },
    {
      "epoch": 2.8987771739130435,
      "grad_norm": 0.061806511133909225,
      "learning_rate": 5.6127729244686015e-08,
      "loss": 0.0004,
      "step": 4267
    },
    {
      "epoch": 2.8994565217391304,
      "grad_norm": 0.39397120475769043,
      "learning_rate": 5.537755885911211e-08,
      "loss": 0.0019,
      "step": 4268
    },
    {
      "epoch": 2.9001358695652173,
      "grad_norm": 6.67024564743042,
      "learning_rate": 5.4632421507916366e-08,
      "loss": 0.0806,
      "step": 4269
    },
    {
      "epoch": 2.900815217391304,
      "grad_norm": 0.0037080971524119377,
      "learning_rate": 5.3892317568218224e-08,
      "loss": 0.0001,
      "step": 4270
    },
    {
      "epoch": 2.9014945652173916,
      "grad_norm": 0.004243549425154924,
      "learning_rate": 5.3157247414589163e-08,
      "loss": 0.0001,
      "step": 4271
    },
    {
      "epoch": 2.9021739130434785,
      "grad_norm": 3.8982110023498535,
      "learning_rate": 5.2427211419051605e-08,
      "loss": 0.0514,
      "step": 4272
    },
    {
      "epoch": 2.9028532608695654,
      "grad_norm": 5.835785388946533,
      "learning_rate": 5.1702209951082216e-08,
      "loss": 0.2514,
      "step": 4273
    },
    {
      "epoch": 2.9035326086956523,
      "grad_norm": 8.669743537902832,
      "learning_rate": 5.09822433776086e-08,
      "loss": 0.2305,
      "step": 4274
    },
    {
      "epoch": 2.9042119565217392,
      "grad_norm": 4.883800983428955,
      "learning_rate": 5.0267312063009275e-08,
      "loss": 0.1415,
      "step": 4275
    },
    {
      "epoch": 2.904891304347826,
      "grad_norm": 5.781136512756348,
      "learning_rate": 4.955741636911704e-08,
      "loss": 0.1769,
      "step": 4276
    },
    {
      "epoch": 2.905570652173913,
      "grad_norm": 0.1137828677892685,
      "learning_rate": 4.885255665521227e-08,
      "loss": 0.0007,
      "step": 4277
    },
    {
      "epoch": 2.90625,
      "grad_norm": 8.554205894470215,
      "learning_rate": 4.815273327803183e-08,
      "loss": 0.4762,
      "step": 4278
    },
    {
      "epoch": 2.906929347826087,
      "grad_norm": 0.0015709634171798825,
      "learning_rate": 4.745794659175684e-08,
      "loss": 0.0,
      "step": 4279
    },
    {
      "epoch": 2.907608695652174,
      "grad_norm": 2.5185413360595703,
      "learning_rate": 4.676819694802604e-08,
      "loss": 0.0284,
      "step": 4280
    },
    {
      "epoch": 2.9082880434782608,
      "grad_norm": 0.1923297494649887,
      "learning_rate": 4.608348469592461e-08,
      "loss": 0.0013,
      "step": 4281
    },
    {
      "epoch": 2.9089673913043477,
      "grad_norm": 0.6554039716720581,
      "learning_rate": 4.540381018199092e-08,
      "loss": 0.0103,
      "step": 4282
    },
    {
      "epoch": 2.9096467391304346,
      "grad_norm": 0.24165725708007812,
      "learning_rate": 4.47291737502098e-08,
      "loss": 0.0018,
      "step": 4283
    },
    {
      "epoch": 2.9103260869565215,
      "grad_norm": 4.526845455169678,
      "learning_rate": 4.405957574202147e-08,
      "loss": 0.116,
      "step": 4284
    },
    {
      "epoch": 2.9110054347826084,
      "grad_norm": 2.2097883224487305,
      "learning_rate": 4.3395016496312614e-08,
      "loss": 0.0623,
      "step": 4285
    },
    {
      "epoch": 2.911684782608696,
      "grad_norm": 0.044588036835193634,
      "learning_rate": 4.273549634942198e-08,
      "loss": 0.0004,
      "step": 4286
    },
    {
      "epoch": 2.9123641304347827,
      "grad_norm": 5.409454822540283,
      "learning_rate": 4.208101563513367e-08,
      "loss": 0.2338,
      "step": 4287
    },
    {
      "epoch": 2.9130434782608696,
      "grad_norm": 0.12463498115539551,
      "learning_rate": 4.143157468468717e-08,
      "loss": 0.0011,
      "step": 4288
    },
    {
      "epoch": 2.9137228260869565,
      "grad_norm": 13.455326080322266,
      "learning_rate": 4.078717382676733e-08,
      "loss": 0.2816,
      "step": 4289
    },
    {
      "epoch": 2.9144021739130435,
      "grad_norm": 4.910722255706787,
      "learning_rate": 4.014781338751106e-08,
      "loss": 0.0985,
      "step": 4290
    },
    {
      "epoch": 2.9150815217391304,
      "grad_norm": 0.002598458668217063,
      "learning_rate": 3.9513493690499504e-08,
      "loss": 0.0,
      "step": 4291
    },
    {
      "epoch": 2.9157608695652173,
      "grad_norm": 1.8188077211380005,
      "learning_rate": 3.8884215056768094e-08,
      "loss": 0.0595,
      "step": 4292
    },
    {
      "epoch": 2.916440217391304,
      "grad_norm": 9.403770446777344,
      "learning_rate": 3.8259977804797624e-08,
      "loss": 0.2068,
      "step": 4293
    },
    {
      "epoch": 2.9171195652173916,
      "grad_norm": 2.2557144165039062,
      "learning_rate": 3.764078225051982e-08,
      "loss": 0.0282,
      "step": 4294
    },
    {
      "epoch": 2.9177989130434785,
      "grad_norm": 1.0129376649856567,
      "learning_rate": 3.702662870731177e-08,
      "loss": 0.0075,
      "step": 4295
    },
    {
      "epoch": 2.9184782608695654,
      "grad_norm": 1.341009497642517,
      "learning_rate": 3.641751748600042e-08,
      "loss": 0.0186,
      "step": 4296
    },
    {
      "epoch": 2.9191576086956523,
      "grad_norm": 9.12753677368164,
      "learning_rate": 3.581344889486138e-08,
      "loss": 0.1637,
      "step": 4297
    },
    {
      "epoch": 2.9198369565217392,
      "grad_norm": 0.002348273526877165,
      "learning_rate": 3.5214423239616766e-08,
      "loss": 0.0,
      "step": 4298
    },
    {
      "epoch": 2.920516304347826,
      "grad_norm": 1.1985633373260498,
      "learning_rate": 3.4620440823438517e-08,
      "loss": 0.0052,
      "step": 4299
    },
    {
      "epoch": 2.921195652173913,
      "grad_norm": 9.644657135009766,
      "learning_rate": 3.4031501946942826e-08,
      "loss": 0.3058,
      "step": 4300
    },
    {
      "epoch": 2.921875,
      "grad_norm": 0.051281318068504333,
      "learning_rate": 3.3447606908196815e-08,
      "loss": 0.0003,
      "step": 4301
    },
    {
      "epoch": 2.922554347826087,
      "grad_norm": 28.94818687438965,
      "learning_rate": 3.2868756002712997e-08,
      "loss": 0.2076,
      "step": 4302
    },
    {
      "epoch": 2.923233695652174,
      "grad_norm": 7.126872539520264,
      "learning_rate": 3.229494952345036e-08,
      "loss": 0.0849,
      "step": 4303
    },
    {
      "epoch": 2.9239130434782608,
      "grad_norm": 0.0016990223666653037,
      "learning_rate": 3.1726187760817704e-08,
      "loss": 0.0,
      "step": 4304
    },
    {
      "epoch": 2.9245923913043477,
      "grad_norm": 10.31013011932373,
      "learning_rate": 3.1162471002668113e-08,
      "loss": 0.1328,
      "step": 4305
    },
    {
      "epoch": 2.9252717391304346,
      "grad_norm": 5.548074245452881,
      "learning_rate": 3.060379953430004e-08,
      "loss": 0.0943,
      "step": 4306
    },
    {
      "epoch": 2.9259510869565215,
      "grad_norm": 12.516368865966797,
      "learning_rate": 3.005017363846396e-08,
      "loss": 0.3234,
      "step": 4307
    },
    {
      "epoch": 2.9266304347826084,
      "grad_norm": 1.8966110944747925,
      "learning_rate": 2.950159359535132e-08,
      "loss": 0.0086,
      "step": 4308
    },
    {
      "epoch": 2.927309782608696,
      "grad_norm": 7.454137325286865,
      "learning_rate": 2.8958059682602236e-08,
      "loss": 0.133,
      "step": 4309
    },
    {
      "epoch": 2.9279891304347827,
      "grad_norm": 0.4387320280075073,
      "learning_rate": 2.8419572175302225e-08,
      "loss": 0.0025,
      "step": 4310
    },
    {
      "epoch": 2.9286684782608696,
      "grad_norm": 12.479447364807129,
      "learning_rate": 2.788613134598328e-08,
      "loss": 0.2431,
      "step": 4311
    },
    {
      "epoch": 2.9293478260869565,
      "grad_norm": 0.33297058939933777,
      "learning_rate": 2.735773746462389e-08,
      "loss": 0.0032,
      "step": 4312
    },
    {
      "epoch": 2.9300271739130435,
      "grad_norm": 5.438710689544678,
      "learning_rate": 2.6834390798645693e-08,
      "loss": 0.1597,
      "step": 4313
    },
    {
      "epoch": 2.9307065217391304,
      "grad_norm": 0.003370726015418768,
      "learning_rate": 2.6316091612920146e-08,
      "loss": 0.0001,
      "step": 4314
    },
    {
      "epoch": 2.9313858695652173,
      "grad_norm": 5.682933330535889,
      "learning_rate": 2.5802840169759645e-08,
      "loss": 0.1149,
      "step": 4315
    },
    {
      "epoch": 2.932065217391304,
      "grad_norm": 1.998095154762268,
      "learning_rate": 2.529463672892418e-08,
      "loss": 0.0471,
      "step": 4316
    },
    {
      "epoch": 2.9327445652173916,
      "grad_norm": 0.2699042856693268,
      "learning_rate": 2.4791481547619123e-08,
      "loss": 0.0023,
      "step": 4317
    },
    {
      "epoch": 2.9334239130434785,
      "grad_norm": 11.158784866333008,
      "learning_rate": 2.4293374880492993e-08,
      "loss": 0.2824,
      "step": 4318
    },
    {
      "epoch": 2.9341032608695654,
      "grad_norm": 0.5508503317832947,
      "learning_rate": 2.3800316979643022e-08,
      "loss": 0.0037,
      "step": 4319
    },
    {
      "epoch": 2.9347826086956523,
      "grad_norm": 0.010844689793884754,
      "learning_rate": 2.3312308094607382e-08,
      "loss": 0.0001,
      "step": 4320
    },
    {
      "epoch": 2.9354619565217392,
      "grad_norm": 0.016474565491080284,
      "learning_rate": 2.2829348472371836e-08,
      "loss": 0.0003,
      "step": 4321
    },
    {
      "epoch": 2.936141304347826,
      "grad_norm": 7.341201305389404,
      "learning_rate": 2.2351438357361976e-08,
      "loss": 0.1185,
      "step": 4322
    },
    {
      "epoch": 2.936820652173913,
      "grad_norm": 20.924768447875977,
      "learning_rate": 2.187857799145432e-08,
      "loss": 0.4758,
      "step": 4323
    },
    {
      "epoch": 2.9375,
      "grad_norm": 42.23672866821289,
      "learning_rate": 2.1410767613965212e-08,
      "loss": 0.3819,
      "step": 4324
    },
    {
      "epoch": 2.938179347826087,
      "grad_norm": 19.742042541503906,
      "learning_rate": 2.0948007461655263e-08,
      "loss": 0.6925,
      "step": 4325
    },
    {
      "epoch": 2.938858695652174,
      "grad_norm": 6.475447654724121,
      "learning_rate": 2.049029776873268e-08,
      "loss": 0.0253,
      "step": 4326
    },
    {
      "epoch": 2.9395380434782608,
      "grad_norm": 2.0063765048980713,
      "learning_rate": 2.0037638766844392e-08,
      "loss": 0.0762,
      "step": 4327
    },
    {
      "epoch": 2.9402173913043477,
      "grad_norm": 0.014746646396815777,
      "learning_rate": 1.9590030685086026e-08,
      "loss": 0.0001,
      "step": 4328
    },
    {
      "epoch": 2.9408967391304346,
      "grad_norm": 1.776798129081726,
      "learning_rate": 1.914747374999304e-08,
      "loss": 0.0093,
      "step": 4329
    },
    {
      "epoch": 2.9415760869565215,
      "grad_norm": 0.006787540856748819,
      "learning_rate": 1.8709968185547378e-08,
      "loss": 0.0001,
      "step": 4330
    },
    {
      "epoch": 2.9422554347826084,
      "grad_norm": 0.0023310270626097918,
      "learning_rate": 1.827751421317303e-08,
      "loss": 0.0001,
      "step": 4331
    },
    {
      "epoch": 2.942934782608696,
      "grad_norm": 5.174911975860596,
      "learning_rate": 1.7850112051738255e-08,
      "loss": 0.2943,
      "step": 4332
    },
    {
      "epoch": 2.9436141304347827,
      "grad_norm": 0.05250182002782822,
      "learning_rate": 1.7427761917553356e-08,
      "loss": 0.0003,
      "step": 4333
    },
    {
      "epoch": 2.9442934782608696,
      "grad_norm": 17.795087814331055,
      "learning_rate": 1.7010464024371785e-08,
      "loss": 0.3192,
      "step": 4334
    },
    {
      "epoch": 2.9449728260869565,
      "grad_norm": 3.7614383697509766,
      "learning_rate": 1.6598218583390168e-08,
      "loss": 0.147,
      "step": 4335
    },
    {
      "epoch": 2.9456521739130435,
      "grad_norm": 0.09150127321481705,
      "learning_rate": 1.6191025803250493e-08,
      "loss": 0.0006,
      "step": 4336
    },
    {
      "epoch": 2.9463315217391304,
      "grad_norm": 9.2700777053833,
      "learning_rate": 1.5788885890033468e-08,
      "loss": 0.0663,
      "step": 4337
    },
    {
      "epoch": 2.9470108695652173,
      "grad_norm": 0.001978812273591757,
      "learning_rate": 1.5391799047266287e-08,
      "loss": 0.0,
      "step": 4338
    },
    {
      "epoch": 2.947690217391304,
      "grad_norm": 9.524341583251953,
      "learning_rate": 1.499976547591486e-08,
      "loss": 0.1092,
      "step": 4339
    },
    {
      "epoch": 2.9483695652173916,
      "grad_norm": 0.007087888661772013,
      "learning_rate": 1.4612785374392701e-08,
      "loss": 0.0001,
      "step": 4340
    },
    {
      "epoch": 2.9490489130434785,
      "grad_norm": 3.7522430419921875,
      "learning_rate": 1.4230858938549808e-08,
      "loss": 0.1247,
      "step": 4341
    },
    {
      "epoch": 2.9497282608695654,
      "grad_norm": 0.0025984260719269514,
      "learning_rate": 1.385398636168378e-08,
      "loss": 0.0,
      "step": 4342
    },
    {
      "epoch": 2.9504076086956523,
      "grad_norm": 0.0027971474919468164,
      "learning_rate": 1.3482167834529824e-08,
      "loss": 0.0,
      "step": 4343
    },
    {
      "epoch": 2.9510869565217392,
      "grad_norm": 5.85515022277832,
      "learning_rate": 1.3115403545270744e-08,
      "loss": 0.1543,
      "step": 4344
    },
    {
      "epoch": 2.951766304347826,
      "grad_norm": 0.024588072672486305,
      "learning_rate": 1.2753693679525835e-08,
      "loss": 0.0002,
      "step": 4345
    },
    {
      "epoch": 2.952445652173913,
      "grad_norm": 0.17301414906978607,
      "learning_rate": 1.2397038420358664e-08,
      "loss": 0.0018,
      "step": 4346
    },
    {
      "epoch": 2.953125,
      "grad_norm": 0.0014878218062222004,
      "learning_rate": 1.2045437948275952e-08,
      "loss": 0.0,
      "step": 4347
    },
    {
      "epoch": 2.953804347826087,
      "grad_norm": 17.492490768432617,
      "learning_rate": 1.1698892441224241e-08,
      "loss": 0.2449,
      "step": 4348
    },
    {
      "epoch": 2.954483695652174,
      "grad_norm": 0.01893697865307331,
      "learning_rate": 1.1357402074592128e-08,
      "loss": 0.0002,
      "step": 4349
    },
    {
      "epoch": 2.9551630434782608,
      "grad_norm": 2.6442770957946777,
      "learning_rate": 1.1020967021210249e-08,
      "loss": 0.0419,
      "step": 4350
    },
    {
      "epoch": 2.9558423913043477,
      "grad_norm": 0.0018177774036303163,
      "learning_rate": 1.068958745134907e-08,
      "loss": 0.0,
      "step": 4351
    },
    {
      "epoch": 2.9565217391304346,
      "grad_norm": 7.630525588989258,
      "learning_rate": 1.0363263532724433e-08,
      "loss": 0.2041,
      "step": 4352
    },
    {
      "epoch": 2.9572010869565215,
      "grad_norm": 0.002573911566287279,
      "learning_rate": 1.0041995430488671e-08,
      "loss": 0.0,
      "step": 4353
    },
    {
      "epoch": 2.9578804347826084,
      "grad_norm": 11.70982837677002,
      "learning_rate": 9.7257833072395e-09,
      "loss": 0.1096,
      "step": 4354
    },
    {
      "epoch": 2.958559782608696,
      "grad_norm": 0.0013220662949606776,
      "learning_rate": 9.414627323011128e-09,
      "loss": 0.0,
      "step": 4355
    },
    {
      "epoch": 2.9592391304347827,
      "grad_norm": 11.915719985961914,
      "learning_rate": 9.108527635284248e-09,
      "loss": 0.1271,
      "step": 4356
    },
    {
      "epoch": 2.9599184782608696,
      "grad_norm": 0.0016176074277609587,
      "learning_rate": 8.807484398976051e-09,
      "loss": 0.0,
      "step": 4357
    },
    {
      "epoch": 2.9605978260869565,
      "grad_norm": 0.0017215847037732601,
      "learning_rate": 8.511497766446885e-09,
      "loss": 0.0,
      "step": 4358
    },
    {
      "epoch": 2.9612771739130435,
      "grad_norm": 1.7268980741500854,
      "learning_rate": 8.220567887498033e-09,
      "loss": 0.0313,
      "step": 4359
    },
    {
      "epoch": 2.9619565217391304,
      "grad_norm": 0.0034894822165369987,
      "learning_rate": 7.93469490936949e-09,
      "loss": 0.0001,
      "step": 4360
    },
    {
      "epoch": 2.9626358695652173,
      "grad_norm": 0.002770814346149564,
      "learning_rate": 7.65387897674441e-09,
      "loss": 0.0001,
      "step": 4361
    },
    {
      "epoch": 2.963315217391304,
      "grad_norm": 0.18845675885677338,
      "learning_rate": 7.378120231745778e-09,
      "loss": 0.0014,
      "step": 4362
    },
    {
      "epoch": 2.9639945652173916,
      "grad_norm": 0.13688760995864868,
      "learning_rate": 7.107418813935285e-09,
      "loss": 0.0008,
      "step": 4363
    },
    {
      "epoch": 2.9646739130434785,
      "grad_norm": 0.0028883691411465406,
      "learning_rate": 6.841774860317785e-09,
      "loss": 0.0001,
      "step": 4364
    },
    {
      "epoch": 2.9653532608695654,
      "grad_norm": 5.4399495124816895,
      "learning_rate": 6.5811885053368444e-09,
      "loss": 0.1641,
      "step": 4365
    },
    {
      "epoch": 2.9660326086956523,
      "grad_norm": 10.163169860839844,
      "learning_rate": 6.325659880876966e-09,
      "loss": 0.1651,
      "step": 4366
    },
    {
      "epoch": 2.9667119565217392,
      "grad_norm": 1.5652108192443848,
      "learning_rate": 6.0751891162635915e-09,
      "loss": 0.0255,
      "step": 4367
    },
    {
      "epoch": 2.967391304347826,
      "grad_norm": 0.013942231424152851,
      "learning_rate": 5.8297763382597625e-09,
      "loss": 0.0002,
      "step": 4368
    },
    {
      "epoch": 2.968070652173913,
      "grad_norm": 3.455815315246582,
      "learning_rate": 5.589421671071682e-09,
      "loss": 0.074,
      "step": 4369
    },
    {
      "epoch": 2.96875,
      "grad_norm": 1.2590746879577637,
      "learning_rate": 5.354125236343155e-09,
      "loss": 0.0242,
      "step": 4370
    },
    {
      "epoch": 2.969429347826087,
      "grad_norm": 10.148330688476562,
      "learning_rate": 5.123887153161145e-09,
      "loss": 0.2853,
      "step": 4371
    },
    {
      "epoch": 2.970108695652174,
      "grad_norm": 6.637248516082764,
      "learning_rate": 4.898707538047998e-09,
      "loss": 0.151,
      "step": 4372
    },
    {
      "epoch": 2.9707880434782608,
      "grad_norm": 0.017700599506497383,
      "learning_rate": 4.678586504971439e-09,
      "loss": 0.0001,
      "step": 4373
    },
    {
      "epoch": 2.9714673913043477,
      "grad_norm": 7.307412624359131,
      "learning_rate": 4.463524165333466e-09,
      "loss": 0.3709,
      "step": 4374
    },
    {
      "epoch": 2.9721467391304346,
      "grad_norm": 5.2548441886901855,
      "learning_rate": 4.253520627979235e-09,
      "loss": 0.0535,
      "step": 4375
    },
    {
      "epoch": 2.9728260869565215,
      "grad_norm": 2.8051185607910156,
      "learning_rate": 4.0485759991937264e-09,
      "loss": 0.0318,
      "step": 4376
    },
    {
      "epoch": 2.9735054347826084,
      "grad_norm": 0.013445461168885231,
      "learning_rate": 3.8486903826995266e-09,
      "loss": 0.0001,
      "step": 4377
    },
    {
      "epoch": 2.974184782608696,
      "grad_norm": 0.010744833387434483,
      "learning_rate": 3.6538638796601578e-09,
      "loss": 0.0001,
      "step": 4378
    },
    {
      "epoch": 2.9748641304347827,
      "grad_norm": 3.3944718837738037,
      "learning_rate": 3.464096588680077e-09,
      "loss": 0.0188,
      "step": 4379
    },
    {
      "epoch": 2.9755434782608696,
      "grad_norm": 0.002163194352760911,
      "learning_rate": 3.2793886057991277e-09,
      "loss": 0.0,
      "step": 4380
    },
    {
      "epoch": 2.9762228260869565,
      "grad_norm": 0.7317907810211182,
      "learning_rate": 3.0997400245003084e-09,
      "loss": 0.0064,
      "step": 4381
    },
    {
      "epoch": 2.9769021739130435,
      "grad_norm": 20.319908142089844,
      "learning_rate": 2.925150935705334e-09,
      "loss": 0.5365,
      "step": 4382
    },
    {
      "epoch": 2.9775815217391304,
      "grad_norm": 12.518245697021484,
      "learning_rate": 2.755621427774635e-09,
      "loss": 0.2323,
      "step": 4383
    },
    {
      "epoch": 2.9782608695652173,
      "grad_norm": 7.947078704833984,
      "learning_rate": 2.591151586508467e-09,
      "loss": 0.3513,
      "step": 4384
    },
    {
      "epoch": 2.978940217391304,
      "grad_norm": 0.5100730061531067,
      "learning_rate": 2.4317414951446903e-09,
      "loss": 0.0033,
      "step": 4385
    },
    {
      "epoch": 2.9796195652173916,
      "grad_norm": 7.20029354095459,
      "learning_rate": 2.277391234363213e-09,
      "loss": 0.117,
      "step": 4386
    },
    {
      "epoch": 2.9802989130434785,
      "grad_norm": 0.05048840865492821,
      "learning_rate": 2.128100882280437e-09,
      "loss": 0.0003,
      "step": 4387
    },
    {
      "epoch": 2.9809782608695654,
      "grad_norm": 0.05050215870141983,
      "learning_rate": 1.9838705144537006e-09,
      "loss": 0.0006,
      "step": 4388
    },
    {
      "epoch": 2.9816576086956523,
      "grad_norm": 14.66140079498291,
      "learning_rate": 1.8447002038779471e-09,
      "loss": 0.1413,
      "step": 4389
    },
    {
      "epoch": 2.9823369565217392,
      "grad_norm": 3.612893581390381,
      "learning_rate": 1.710590020990166e-09,
      "loss": 0.1136,
      "step": 4390
    },
    {
      "epoch": 2.983016304347826,
      "grad_norm": 0.7167248725891113,
      "learning_rate": 1.5815400336627318e-09,
      "loss": 0.0049,
      "step": 4391
    },
    {
      "epoch": 2.983695652173913,
      "grad_norm": 8.244987487792969,
      "learning_rate": 1.4575503072100649e-09,
      "loss": 0.1198,
      "step": 4392
    },
    {
      "epoch": 2.984375,
      "grad_norm": 0.024220891296863556,
      "learning_rate": 1.3386209043819708e-09,
      "loss": 0.0004,
      "step": 4393
    },
    {
      "epoch": 2.985054347826087,
      "grad_norm": 1.997528314590454,
      "learning_rate": 1.2247518853714113e-09,
      "loss": 0.0379,
      "step": 4394
    },
    {
      "epoch": 2.985733695652174,
      "grad_norm": 7.74222993850708,
      "learning_rate": 1.1159433078067327e-09,
      "loss": 0.136,
      "step": 4395
    },
    {
      "epoch": 2.9864130434782608,
      "grad_norm": 6.139791965484619,
      "learning_rate": 1.0121952267572176e-09,
      "loss": 0.2087,
      "step": 4396
    },
    {
      "epoch": 2.9870923913043477,
      "grad_norm": 0.1912377029657364,
      "learning_rate": 9.135076947308641e-10,
      "loss": 0.002,
      "step": 4397
    },
    {
      "epoch": 2.9877717391304346,
      "grad_norm": 6.1534833908081055,
      "learning_rate": 8.198807616732752e-10,
      "loss": 0.2996,
      "step": 4398
    },
    {
      "epoch": 2.9884510869565215,
      "grad_norm": 6.9261884689331055,
      "learning_rate": 7.313144749698798e-10,
      "loss": 0.2284,
      "step": 4399
    },
    {
      "epoch": 2.9891304347826084,
      "grad_norm": 4.814520359039307,
      "learning_rate": 6.478088794448223e-10,
      "loss": 0.1697,
      "step": 4400
    },
    {
      "epoch": 2.989809782608696,
      "grad_norm": 0.00990053080022335,
      "learning_rate": 5.693640173598525e-10,
      "loss": 0.0001,
      "step": 4401
    },
    {
      "epoch": 2.9904891304347827,
      "grad_norm": 1.96162748336792,
      "learning_rate": 4.959799284176559e-10,
      "loss": 0.0435,
      "step": 4402
    },
    {
      "epoch": 2.9911684782608696,
      "grad_norm": 0.16455376148223877,
      "learning_rate": 4.276566497585233e-10,
      "loss": 0.0024,
      "step": 4403
    },
    {
      "epoch": 2.9918478260869565,
      "grad_norm": 2.7803196907043457,
      "learning_rate": 3.6439421595924065e-10,
      "loss": 0.0726,
      "step": 4404
    },
    {
      "epoch": 2.9925271739130435,
      "grad_norm": 0.0041475142352283,
      "learning_rate": 3.0619265903975013e-10,
      "loss": 0.0001,
      "step": 4405
    },
    {
      "epoch": 2.9932065217391304,
      "grad_norm": 0.10920688509941101,
      "learning_rate": 2.530520084553789e-10,
      "loss": 0.0007,
      "step": 4406
    },
    {
      "epoch": 2.9938858695652173,
      "grad_norm": 23.907041549682617,
      "learning_rate": 2.0497229110016948e-10,
      "loss": 0.4468,
      "step": 4407
    },
    {
      "epoch": 2.994565217391304,
      "grad_norm": 0.9913516640663147,
      "learning_rate": 1.6195353130799007e-10,
      "loss": 0.0108,
      "step": 4408
    },
    {
      "epoch": 2.9952445652173916,
      "grad_norm": 0.2410772740840912,
      "learning_rate": 1.2399575085142445e-10,
      "loss": 0.0022,
      "step": 4409
    },
    {
      "epoch": 2.9959239130434785,
      "grad_norm": 6.2755446434021,
      "learning_rate": 9.109896894066161e-11,
      "loss": 0.192,
      "step": 4410
    },
    {
      "epoch": 2.9966032608695654,
      "grad_norm": 0.0895162895321846,
      "learning_rate": 6.326320222571625e-11,
      "loss": 0.0005,
      "step": 4411
    },
    {
      "epoch": 2.9972826086956523,
      "grad_norm": 0.003935888409614563,
      "learning_rate": 4.0488464793098095e-11,
      "loss": 0.0001,
      "step": 4412
    },
    {
      "epoch": 2.9979619565217392,
      "grad_norm": 5.090413570404053,
      "learning_rate": 2.2774768170252813e-11,
      "loss": 0.0235,
      "step": 4413
    },
    {
      "epoch": 2.998641304347826,
      "grad_norm": 3.521937370300293,
      "learning_rate": 1.0122121321121115e-11,
      "loss": 0.2352,
      "step": 4414
    },
    {
      "epoch": 2.999320652173913,
      "grad_norm": 0.0560709610581398,
      "learning_rate": 2.530530650579621e-12,
      "loss": 0.0004,
      "step": 4415
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.06011884659528732,
      "learning_rate": 0.0,
      "loss": 0.0005,
      "step": 4416
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.4634146341463415,
      "eval_loss": 0.15549667179584503,
      "eval_runtime": 133.3461,
      "eval_samples_per_second": 1.23,
      "eval_steps_per_second": 1.23,
      "step": 4416
    }
  ],
  "logging_steps": 1,
  "max_steps": 4416,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.1259360935950336e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
