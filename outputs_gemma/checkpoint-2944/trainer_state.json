{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 2944,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0006793478260869565,
      "grad_norm": 0.7870401740074158,
      "learning_rate": 1.999999746946935e-05,
      "loss": 1.4558,
      "step": 1
    },
    {
      "epoch": 0.001358695652173913,
      "grad_norm": 0.7333515882492065,
      "learning_rate": 1.999998987787868e-05,
      "loss": 1.5721,
      "step": 2
    },
    {
      "epoch": 0.0020380434782608695,
      "grad_norm": 0.7393332719802856,
      "learning_rate": 1.9999977225231833e-05,
      "loss": 1.4822,
      "step": 3
    },
    {
      "epoch": 0.002717391304347826,
      "grad_norm": 0.7678321599960327,
      "learning_rate": 1.9999959511535207e-05,
      "loss": 1.6223,
      "step": 4
    },
    {
      "epoch": 0.0033967391304347825,
      "grad_norm": 0.7536096572875977,
      "learning_rate": 1.9999936736797775e-05,
      "loss": 1.4867,
      "step": 5
    },
    {
      "epoch": 0.004076086956521739,
      "grad_norm": 0.840135931968689,
      "learning_rate": 1.999990890103106e-05,
      "loss": 1.6121,
      "step": 6
    },
    {
      "epoch": 0.004755434782608696,
      "grad_norm": 0.8250735402107239,
      "learning_rate": 1.999987600424915e-05,
      "loss": 1.4305,
      "step": 7
    },
    {
      "epoch": 0.005434782608695652,
      "grad_norm": 0.7522395253181458,
      "learning_rate": 1.9999838046468693e-05,
      "loss": 1.45,
      "step": 8
    },
    {
      "epoch": 0.006114130434782609,
      "grad_norm": 1.2500064373016357,
      "learning_rate": 1.99997950277089e-05,
      "loss": 1.4941,
      "step": 9
    },
    {
      "epoch": 0.006793478260869565,
      "grad_norm": 0.7079985737800598,
      "learning_rate": 1.9999746947991546e-05,
      "loss": 1.3534,
      "step": 10
    },
    {
      "epoch": 0.007472826086956522,
      "grad_norm": 0.7096807956695557,
      "learning_rate": 1.999969380734096e-05,
      "loss": 1.4339,
      "step": 11
    },
    {
      "epoch": 0.008152173913043478,
      "grad_norm": 0.761134922504425,
      "learning_rate": 1.9999635605784042e-05,
      "loss": 1.5001,
      "step": 12
    },
    {
      "epoch": 0.008831521739130434,
      "grad_norm": 1.4025198221206665,
      "learning_rate": 1.999957234335024e-05,
      "loss": 1.411,
      "step": 13
    },
    {
      "epoch": 0.009510869565217392,
      "grad_norm": 0.704071581363678,
      "learning_rate": 1.9999504020071586e-05,
      "loss": 1.335,
      "step": 14
    },
    {
      "epoch": 0.010190217391304348,
      "grad_norm": 0.7547473311424255,
      "learning_rate": 1.9999430635982643e-05,
      "loss": 1.4145,
      "step": 15
    },
    {
      "epoch": 0.010869565217391304,
      "grad_norm": 0.8837788105010986,
      "learning_rate": 1.9999352191120556e-05,
      "loss": 1.456,
      "step": 16
    },
    {
      "epoch": 0.01154891304347826,
      "grad_norm": 1.052673578262329,
      "learning_rate": 1.9999268685525034e-05,
      "loss": 1.303,
      "step": 17
    },
    {
      "epoch": 0.012228260869565218,
      "grad_norm": 0.9304532408714294,
      "learning_rate": 1.9999180119238327e-05,
      "loss": 1.489,
      "step": 18
    },
    {
      "epoch": 0.012907608695652174,
      "grad_norm": 0.9732642769813538,
      "learning_rate": 1.999908649230527e-05,
      "loss": 1.4223,
      "step": 19
    },
    {
      "epoch": 0.01358695652173913,
      "grad_norm": 1.029969573020935,
      "learning_rate": 1.9998987804773244e-05,
      "loss": 1.4905,
      "step": 20
    },
    {
      "epoch": 0.014266304347826086,
      "grad_norm": 0.7710385918617249,
      "learning_rate": 1.9998884056692195e-05,
      "loss": 1.3981,
      "step": 21
    },
    {
      "epoch": 0.014945652173913044,
      "grad_norm": 0.8643012642860413,
      "learning_rate": 1.999877524811463e-05,
      "loss": 1.3625,
      "step": 22
    },
    {
      "epoch": 0.015625,
      "grad_norm": 0.7808313965797424,
      "learning_rate": 1.9998661379095622e-05,
      "loss": 1.3922,
      "step": 23
    },
    {
      "epoch": 0.016304347826086956,
      "grad_norm": 1.015305995941162,
      "learning_rate": 1.9998542449692794e-05,
      "loss": 1.3554,
      "step": 24
    },
    {
      "epoch": 0.016983695652173912,
      "grad_norm": 1.0153642892837524,
      "learning_rate": 1.999841845996634e-05,
      "loss": 1.4158,
      "step": 25
    },
    {
      "epoch": 0.017663043478260868,
      "grad_norm": 0.9631015658378601,
      "learning_rate": 1.999828940997901e-05,
      "loss": 1.4603,
      "step": 26
    },
    {
      "epoch": 0.018342391304347828,
      "grad_norm": 1.4065693616867065,
      "learning_rate": 1.9998155299796122e-05,
      "loss": 1.5908,
      "step": 27
    },
    {
      "epoch": 0.019021739130434784,
      "grad_norm": 1.2740405797958374,
      "learning_rate": 1.9998016129485548e-05,
      "loss": 1.5716,
      "step": 28
    },
    {
      "epoch": 0.01970108695652174,
      "grad_norm": 1.529653549194336,
      "learning_rate": 1.9997871899117723e-05,
      "loss": 1.4551,
      "step": 29
    },
    {
      "epoch": 0.020380434782608696,
      "grad_norm": 1.0504618883132935,
      "learning_rate": 1.999772260876564e-05,
      "loss": 1.4177,
      "step": 30
    },
    {
      "epoch": 0.021059782608695652,
      "grad_norm": 1.3083947896957397,
      "learning_rate": 1.9997568258504856e-05,
      "loss": 1.4913,
      "step": 31
    },
    {
      "epoch": 0.021739130434782608,
      "grad_norm": 1.2233011722564697,
      "learning_rate": 1.9997408848413494e-05,
      "loss": 1.4415,
      "step": 32
    },
    {
      "epoch": 0.022418478260869564,
      "grad_norm": 0.9135554432868958,
      "learning_rate": 1.9997244378572227e-05,
      "loss": 1.3226,
      "step": 33
    },
    {
      "epoch": 0.02309782608695652,
      "grad_norm": 1.0823973417282104,
      "learning_rate": 1.9997074849064296e-05,
      "loss": 1.304,
      "step": 34
    },
    {
      "epoch": 0.02377717391304348,
      "grad_norm": 1.6877737045288086,
      "learning_rate": 1.99969002599755e-05,
      "loss": 1.3976,
      "step": 35
    },
    {
      "epoch": 0.024456521739130436,
      "grad_norm": 1.1709731817245483,
      "learning_rate": 1.99967206113942e-05,
      "loss": 1.3465,
      "step": 36
    },
    {
      "epoch": 0.025135869565217392,
      "grad_norm": 1.8257285356521606,
      "learning_rate": 1.999653590341132e-05,
      "loss": 1.279,
      "step": 37
    },
    {
      "epoch": 0.025815217391304348,
      "grad_norm": 1.0402066707611084,
      "learning_rate": 1.9996346136120342e-05,
      "loss": 1.2762,
      "step": 38
    },
    {
      "epoch": 0.026494565217391304,
      "grad_norm": 1.2029296159744263,
      "learning_rate": 1.99961513096173e-05,
      "loss": 1.321,
      "step": 39
    },
    {
      "epoch": 0.02717391304347826,
      "grad_norm": 1.0141279697418213,
      "learning_rate": 1.999595142400081e-05,
      "loss": 1.371,
      "step": 40
    },
    {
      "epoch": 0.027853260869565216,
      "grad_norm": 1.2048466205596924,
      "learning_rate": 1.9995746479372023e-05,
      "loss": 1.3837,
      "step": 41
    },
    {
      "epoch": 0.028532608695652172,
      "grad_norm": 1.1231133937835693,
      "learning_rate": 1.9995536475834667e-05,
      "loss": 1.3901,
      "step": 42
    },
    {
      "epoch": 0.029211956521739132,
      "grad_norm": 1.3421157598495483,
      "learning_rate": 1.999532141349503e-05,
      "loss": 1.1679,
      "step": 43
    },
    {
      "epoch": 0.029891304347826088,
      "grad_norm": 1.823555588722229,
      "learning_rate": 1.9995101292461954e-05,
      "loss": 1.2882,
      "step": 44
    },
    {
      "epoch": 0.030570652173913044,
      "grad_norm": 1.2464213371276855,
      "learning_rate": 1.999487611284684e-05,
      "loss": 1.4231,
      "step": 45
    },
    {
      "epoch": 0.03125,
      "grad_norm": 1.3050110340118408,
      "learning_rate": 1.9994645874763657e-05,
      "loss": 1.3446,
      "step": 46
    },
    {
      "epoch": 0.03192934782608696,
      "grad_norm": 1.1807715892791748,
      "learning_rate": 1.999441057832893e-05,
      "loss": 1.195,
      "step": 47
    },
    {
      "epoch": 0.03260869565217391,
      "grad_norm": 2.377896547317505,
      "learning_rate": 1.999417022366174e-05,
      "loss": 1.4155,
      "step": 48
    },
    {
      "epoch": 0.03328804347826087,
      "grad_norm": 1.5238443613052368,
      "learning_rate": 1.9993924810883737e-05,
      "loss": 1.2854,
      "step": 49
    },
    {
      "epoch": 0.033967391304347824,
      "grad_norm": 1.2550139427185059,
      "learning_rate": 1.9993674340119124e-05,
      "loss": 1.2359,
      "step": 50
    },
    {
      "epoch": 0.034646739130434784,
      "grad_norm": 1.6950091123580933,
      "learning_rate": 1.9993418811494663e-05,
      "loss": 1.2302,
      "step": 51
    },
    {
      "epoch": 0.035326086956521736,
      "grad_norm": 1.1024881601333618,
      "learning_rate": 1.9993158225139682e-05,
      "loss": 1.3896,
      "step": 52
    },
    {
      "epoch": 0.036005434782608696,
      "grad_norm": 1.5394368171691895,
      "learning_rate": 1.9992892581186067e-05,
      "loss": 1.2197,
      "step": 53
    },
    {
      "epoch": 0.036684782608695655,
      "grad_norm": 1.4138100147247314,
      "learning_rate": 1.9992621879768256e-05,
      "loss": 1.2522,
      "step": 54
    },
    {
      "epoch": 0.03736413043478261,
      "grad_norm": 1.2546651363372803,
      "learning_rate": 1.999234612102326e-05,
      "loss": 1.1995,
      "step": 55
    },
    {
      "epoch": 0.03804347826086957,
      "grad_norm": 1.3502243757247925,
      "learning_rate": 1.999206530509063e-05,
      "loss": 1.1957,
      "step": 56
    },
    {
      "epoch": 0.03872282608695652,
      "grad_norm": 1.3898134231567383,
      "learning_rate": 1.9991779432112503e-05,
      "loss": 1.3182,
      "step": 57
    },
    {
      "epoch": 0.03940217391304348,
      "grad_norm": 1.4581021070480347,
      "learning_rate": 1.9991488502233553e-05,
      "loss": 1.1337,
      "step": 58
    },
    {
      "epoch": 0.04008152173913043,
      "grad_norm": 1.2061243057250977,
      "learning_rate": 1.9991192515601024e-05,
      "loss": 1.2748,
      "step": 59
    },
    {
      "epoch": 0.04076086956521739,
      "grad_norm": 1.1776667833328247,
      "learning_rate": 1.999089147236472e-05,
      "loss": 1.1777,
      "step": 60
    },
    {
      "epoch": 0.041440217391304345,
      "grad_norm": 1.2546942234039307,
      "learning_rate": 1.999058537267699e-05,
      "loss": 1.2717,
      "step": 61
    },
    {
      "epoch": 0.042119565217391304,
      "grad_norm": 1.3662368059158325,
      "learning_rate": 1.9990274216692762e-05,
      "loss": 1.1585,
      "step": 62
    },
    {
      "epoch": 0.042798913043478264,
      "grad_norm": 1.223254919052124,
      "learning_rate": 1.9989958004569514e-05,
      "loss": 1.2298,
      "step": 63
    },
    {
      "epoch": 0.043478260869565216,
      "grad_norm": 1.1864265203475952,
      "learning_rate": 1.9989636736467278e-05,
      "loss": 1.1478,
      "step": 64
    },
    {
      "epoch": 0.044157608695652176,
      "grad_norm": 1.2616453170776367,
      "learning_rate": 1.9989310412548653e-05,
      "loss": 1.3243,
      "step": 65
    },
    {
      "epoch": 0.04483695652173913,
      "grad_norm": 1.4292845726013184,
      "learning_rate": 1.998897903297879e-05,
      "loss": 1.1879,
      "step": 66
    },
    {
      "epoch": 0.04551630434782609,
      "grad_norm": 1.303294062614441,
      "learning_rate": 1.9988642597925408e-05,
      "loss": 1.3421,
      "step": 67
    },
    {
      "epoch": 0.04619565217391304,
      "grad_norm": 1.6082708835601807,
      "learning_rate": 1.9988301107558777e-05,
      "loss": 1.2232,
      "step": 68
    },
    {
      "epoch": 0.046875,
      "grad_norm": 1.3437477350234985,
      "learning_rate": 1.9987954562051724e-05,
      "loss": 1.1187,
      "step": 69
    },
    {
      "epoch": 0.04755434782608696,
      "grad_norm": 1.402751088142395,
      "learning_rate": 1.9987602961579646e-05,
      "loss": 1.0784,
      "step": 70
    },
    {
      "epoch": 0.04823369565217391,
      "grad_norm": 1.5496832132339478,
      "learning_rate": 1.9987246306320476e-05,
      "loss": 1.0963,
      "step": 71
    },
    {
      "epoch": 0.04891304347826087,
      "grad_norm": 1.6905206441879272,
      "learning_rate": 1.998688459645473e-05,
      "loss": 1.2328,
      "step": 72
    },
    {
      "epoch": 0.049592391304347824,
      "grad_norm": 1.391547679901123,
      "learning_rate": 1.998651783216547e-05,
      "loss": 1.0825,
      "step": 73
    },
    {
      "epoch": 0.050271739130434784,
      "grad_norm": 1.207642912864685,
      "learning_rate": 1.9986146013638315e-05,
      "loss": 1.2997,
      "step": 74
    },
    {
      "epoch": 0.050951086956521736,
      "grad_norm": 1.3229007720947266,
      "learning_rate": 1.998576914106145e-05,
      "loss": 1.2629,
      "step": 75
    },
    {
      "epoch": 0.051630434782608696,
      "grad_norm": 1.3827407360076904,
      "learning_rate": 1.998538721462561e-05,
      "loss": 1.1941,
      "step": 76
    },
    {
      "epoch": 0.052309782608695655,
      "grad_norm": 1.4126698970794678,
      "learning_rate": 1.9985000234524086e-05,
      "loss": 1.1022,
      "step": 77
    },
    {
      "epoch": 0.05298913043478261,
      "grad_norm": 2.2047383785247803,
      "learning_rate": 1.9984608200952736e-05,
      "loss": 1.2098,
      "step": 78
    },
    {
      "epoch": 0.05366847826086957,
      "grad_norm": 1.5136791467666626,
      "learning_rate": 1.998421111410997e-05,
      "loss": 1.0157,
      "step": 79
    },
    {
      "epoch": 0.05434782608695652,
      "grad_norm": 1.333340048789978,
      "learning_rate": 1.9983808974196752e-05,
      "loss": 1.0877,
      "step": 80
    },
    {
      "epoch": 0.05502717391304348,
      "grad_norm": 1.4389259815216064,
      "learning_rate": 1.998340178141661e-05,
      "loss": 1.2072,
      "step": 81
    },
    {
      "epoch": 0.05570652173913043,
      "grad_norm": 1.5836304426193237,
      "learning_rate": 1.998298953597563e-05,
      "loss": 1.1877,
      "step": 82
    },
    {
      "epoch": 0.05638586956521739,
      "grad_norm": 1.276432991027832,
      "learning_rate": 1.9982572238082446e-05,
      "loss": 1.1894,
      "step": 83
    },
    {
      "epoch": 0.057065217391304345,
      "grad_norm": 1.4255393743515015,
      "learning_rate": 1.9982149887948264e-05,
      "loss": 1.1903,
      "step": 84
    },
    {
      "epoch": 0.057744565217391304,
      "grad_norm": 1.4669640064239502,
      "learning_rate": 1.9981722485786828e-05,
      "loss": 1.1034,
      "step": 85
    },
    {
      "epoch": 0.058423913043478264,
      "grad_norm": 1.3648256063461304,
      "learning_rate": 1.9981290031814456e-05,
      "loss": 1.1863,
      "step": 86
    },
    {
      "epoch": 0.059103260869565216,
      "grad_norm": 1.4905917644500732,
      "learning_rate": 1.998085252625001e-05,
      "loss": 1.0922,
      "step": 87
    },
    {
      "epoch": 0.059782608695652176,
      "grad_norm": 1.2823330163955688,
      "learning_rate": 1.9980409969314917e-05,
      "loss": 0.9296,
      "step": 88
    },
    {
      "epoch": 0.06046195652173913,
      "grad_norm": 1.8728147745132446,
      "learning_rate": 1.997996236123316e-05,
      "loss": 1.1178,
      "step": 89
    },
    {
      "epoch": 0.06114130434782609,
      "grad_norm": 1.6180318593978882,
      "learning_rate": 1.997950970223127e-05,
      "loss": 1.0671,
      "step": 90
    },
    {
      "epoch": 0.06182065217391304,
      "grad_norm": 1.4075521230697632,
      "learning_rate": 1.9979051992538346e-05,
      "loss": 0.9868,
      "step": 91
    },
    {
      "epoch": 0.0625,
      "grad_norm": 1.079682469367981,
      "learning_rate": 1.9978589232386036e-05,
      "loss": 1.0455,
      "step": 92
    },
    {
      "epoch": 0.06317934782608696,
      "grad_norm": 1.6233781576156616,
      "learning_rate": 1.9978121422008547e-05,
      "loss": 1.2126,
      "step": 93
    },
    {
      "epoch": 0.06385869565217392,
      "grad_norm": 1.360658049583435,
      "learning_rate": 1.997764856164264e-05,
      "loss": 1.0517,
      "step": 94
    },
    {
      "epoch": 0.06453804347826086,
      "grad_norm": 1.7491767406463623,
      "learning_rate": 1.997717065152763e-05,
      "loss": 1.0654,
      "step": 95
    },
    {
      "epoch": 0.06521739130434782,
      "grad_norm": 1.497955322265625,
      "learning_rate": 1.9976687691905394e-05,
      "loss": 1.1287,
      "step": 96
    },
    {
      "epoch": 0.06589673913043478,
      "grad_norm": 1.599922776222229,
      "learning_rate": 1.997619968302036e-05,
      "loss": 1.0467,
      "step": 97
    },
    {
      "epoch": 0.06657608695652174,
      "grad_norm": 1.420379638671875,
      "learning_rate": 1.997570662511951e-05,
      "loss": 1.0971,
      "step": 98
    },
    {
      "epoch": 0.06725543478260869,
      "grad_norm": 1.4834535121917725,
      "learning_rate": 1.9975208518452384e-05,
      "loss": 1.014,
      "step": 99
    },
    {
      "epoch": 0.06793478260869565,
      "grad_norm": 1.4577267169952393,
      "learning_rate": 1.9974705363271076e-05,
      "loss": 0.915,
      "step": 100
    },
    {
      "epoch": 0.06861413043478261,
      "grad_norm": 1.6652635335922241,
      "learning_rate": 1.9974197159830243e-05,
      "loss": 1.0263,
      "step": 101
    },
    {
      "epoch": 0.06929347826086957,
      "grad_norm": 1.522212028503418,
      "learning_rate": 1.997368390838708e-05,
      "loss": 0.9,
      "step": 102
    },
    {
      "epoch": 0.06997282608695653,
      "grad_norm": 1.464546799659729,
      "learning_rate": 1.9973165609201354e-05,
      "loss": 1.059,
      "step": 103
    },
    {
      "epoch": 0.07065217391304347,
      "grad_norm": 1.5678322315216064,
      "learning_rate": 1.997264226253538e-05,
      "loss": 1.1052,
      "step": 104
    },
    {
      "epoch": 0.07133152173913043,
      "grad_norm": 1.5123610496520996,
      "learning_rate": 1.9972113868654016e-05,
      "loss": 0.9268,
      "step": 105
    },
    {
      "epoch": 0.07201086956521739,
      "grad_norm": 1.282019019126892,
      "learning_rate": 1.99715804278247e-05,
      "loss": 0.8438,
      "step": 106
    },
    {
      "epoch": 0.07269021739130435,
      "grad_norm": 1.4266608953475952,
      "learning_rate": 1.99710419403174e-05,
      "loss": 0.8892,
      "step": 107
    },
    {
      "epoch": 0.07336956521739131,
      "grad_norm": 1.322978138923645,
      "learning_rate": 1.997049840640465e-05,
      "loss": 0.9748,
      "step": 108
    },
    {
      "epoch": 0.07404891304347826,
      "grad_norm": 1.3259443044662476,
      "learning_rate": 1.996994982636154e-05,
      "loss": 1.0339,
      "step": 109
    },
    {
      "epoch": 0.07472826086956522,
      "grad_norm": 1.3638184070587158,
      "learning_rate": 1.99693962004657e-05,
      "loss": 0.7887,
      "step": 110
    },
    {
      "epoch": 0.07540760869565218,
      "grad_norm": 1.4813146591186523,
      "learning_rate": 1.9968837528997333e-05,
      "loss": 0.8685,
      "step": 111
    },
    {
      "epoch": 0.07608695652173914,
      "grad_norm": 1.5414507389068604,
      "learning_rate": 1.9968273812239185e-05,
      "loss": 0.8606,
      "step": 112
    },
    {
      "epoch": 0.07676630434782608,
      "grad_norm": 1.4036318063735962,
      "learning_rate": 1.9967705050476552e-05,
      "loss": 0.8297,
      "step": 113
    },
    {
      "epoch": 0.07744565217391304,
      "grad_norm": 1.519258737564087,
      "learning_rate": 1.996713124399729e-05,
      "loss": 0.8613,
      "step": 114
    },
    {
      "epoch": 0.078125,
      "grad_norm": 1.5442595481872559,
      "learning_rate": 1.9966552393091804e-05,
      "loss": 0.9792,
      "step": 115
    },
    {
      "epoch": 0.07880434782608696,
      "grad_norm": 1.6487165689468384,
      "learning_rate": 1.996596849805306e-05,
      "loss": 0.8571,
      "step": 116
    },
    {
      "epoch": 0.07948369565217392,
      "grad_norm": 1.4373884201049805,
      "learning_rate": 1.9965379559176562e-05,
      "loss": 0.894,
      "step": 117
    },
    {
      "epoch": 0.08016304347826086,
      "grad_norm": 1.8203485012054443,
      "learning_rate": 1.9964785576760385e-05,
      "loss": 0.9131,
      "step": 118
    },
    {
      "epoch": 0.08084239130434782,
      "grad_norm": 1.6589685678482056,
      "learning_rate": 1.996418655110514e-05,
      "loss": 1.0298,
      "step": 119
    },
    {
      "epoch": 0.08152173913043478,
      "grad_norm": 1.9003061056137085,
      "learning_rate": 1.9963582482514003e-05,
      "loss": 0.993,
      "step": 120
    },
    {
      "epoch": 0.08220108695652174,
      "grad_norm": 1.6307710409164429,
      "learning_rate": 1.9962973371292692e-05,
      "loss": 0.9962,
      "step": 121
    },
    {
      "epoch": 0.08288043478260869,
      "grad_norm": 1.8260070085525513,
      "learning_rate": 1.9962359217749482e-05,
      "loss": 0.7991,
      "step": 122
    },
    {
      "epoch": 0.08355978260869565,
      "grad_norm": 1.8492709398269653,
      "learning_rate": 1.9961740022195202e-05,
      "loss": 0.8876,
      "step": 123
    },
    {
      "epoch": 0.08423913043478261,
      "grad_norm": 1.661940336227417,
      "learning_rate": 1.9961115784943232e-05,
      "loss": 0.9706,
      "step": 124
    },
    {
      "epoch": 0.08491847826086957,
      "grad_norm": 1.8207132816314697,
      "learning_rate": 1.99604865063095e-05,
      "loss": 0.9592,
      "step": 125
    },
    {
      "epoch": 0.08559782608695653,
      "grad_norm": 1.7035369873046875,
      "learning_rate": 1.9959852186612492e-05,
      "loss": 0.8192,
      "step": 126
    },
    {
      "epoch": 0.08627717391304347,
      "grad_norm": 1.4774878025054932,
      "learning_rate": 1.9959212826173236e-05,
      "loss": 0.9846,
      "step": 127
    },
    {
      "epoch": 0.08695652173913043,
      "grad_norm": 1.6288330554962158,
      "learning_rate": 1.9958568425315316e-05,
      "loss": 0.7394,
      "step": 128
    },
    {
      "epoch": 0.08763586956521739,
      "grad_norm": 1.7255723476409912,
      "learning_rate": 1.995791898436487e-05,
      "loss": 0.7414,
      "step": 129
    },
    {
      "epoch": 0.08831521739130435,
      "grad_norm": 2.0060112476348877,
      "learning_rate": 1.995726450365058e-05,
      "loss": 0.9248,
      "step": 130
    },
    {
      "epoch": 0.08899456521739131,
      "grad_norm": 1.866074800491333,
      "learning_rate": 1.9956604983503686e-05,
      "loss": 0.9111,
      "step": 131
    },
    {
      "epoch": 0.08967391304347826,
      "grad_norm": 1.407524824142456,
      "learning_rate": 1.995594042425798e-05,
      "loss": 0.7388,
      "step": 132
    },
    {
      "epoch": 0.09035326086956522,
      "grad_norm": 2.03910231590271,
      "learning_rate": 1.995527082624979e-05,
      "loss": 0.9521,
      "step": 133
    },
    {
      "epoch": 0.09103260869565218,
      "grad_norm": 1.779966950416565,
      "learning_rate": 1.995459618981801e-05,
      "loss": 0.8523,
      "step": 134
    },
    {
      "epoch": 0.09171195652173914,
      "grad_norm": 1.8392956256866455,
      "learning_rate": 1.9953916515304077e-05,
      "loss": 0.716,
      "step": 135
    },
    {
      "epoch": 0.09239130434782608,
      "grad_norm": 1.728538155555725,
      "learning_rate": 1.9953231803051977e-05,
      "loss": 0.6965,
      "step": 136
    },
    {
      "epoch": 0.09307065217391304,
      "grad_norm": 1.6829414367675781,
      "learning_rate": 1.9952542053408247e-05,
      "loss": 0.6939,
      "step": 137
    },
    {
      "epoch": 0.09375,
      "grad_norm": 1.8614095449447632,
      "learning_rate": 1.995184726672197e-05,
      "loss": 0.8782,
      "step": 138
    },
    {
      "epoch": 0.09442934782608696,
      "grad_norm": 1.9146242141723633,
      "learning_rate": 1.9951147443344788e-05,
      "loss": 0.7532,
      "step": 139
    },
    {
      "epoch": 0.09510869565217392,
      "grad_norm": 1.4748085737228394,
      "learning_rate": 1.9950442583630884e-05,
      "loss": 0.6732,
      "step": 140
    },
    {
      "epoch": 0.09578804347826086,
      "grad_norm": 1.810081958770752,
      "learning_rate": 1.9949732687936992e-05,
      "loss": 0.81,
      "step": 141
    },
    {
      "epoch": 0.09646739130434782,
      "grad_norm": 1.9671112298965454,
      "learning_rate": 1.9949017756622393e-05,
      "loss": 0.83,
      "step": 142
    },
    {
      "epoch": 0.09714673913043478,
      "grad_norm": 1.8696287870407104,
      "learning_rate": 1.994829779004892e-05,
      "loss": 0.9373,
      "step": 143
    },
    {
      "epoch": 0.09782608695652174,
      "grad_norm": 1.8956648111343384,
      "learning_rate": 1.994757278858095e-05,
      "loss": 0.9071,
      "step": 144
    },
    {
      "epoch": 0.09850543478260869,
      "grad_norm": 1.816324234008789,
      "learning_rate": 1.9946842752585414e-05,
      "loss": 0.6909,
      "step": 145
    },
    {
      "epoch": 0.09918478260869565,
      "grad_norm": 1.8271182775497437,
      "learning_rate": 1.9946107682431784e-05,
      "loss": 0.6343,
      "step": 146
    },
    {
      "epoch": 0.09986413043478261,
      "grad_norm": 1.8231451511383057,
      "learning_rate": 1.9945367578492085e-05,
      "loss": 0.6141,
      "step": 147
    },
    {
      "epoch": 0.10054347826086957,
      "grad_norm": 2.1899282932281494,
      "learning_rate": 1.994462244114089e-05,
      "loss": 0.7301,
      "step": 148
    },
    {
      "epoch": 0.10122282608695653,
      "grad_norm": 2.0205116271972656,
      "learning_rate": 1.9943872270755316e-05,
      "loss": 0.7352,
      "step": 149
    },
    {
      "epoch": 0.10190217391304347,
      "grad_norm": 1.8234200477600098,
      "learning_rate": 1.994311706771503e-05,
      "loss": 0.6935,
      "step": 150
    },
    {
      "epoch": 0.10258152173913043,
      "grad_norm": 2.175447463989258,
      "learning_rate": 1.9942356832402242e-05,
      "loss": 0.6516,
      "step": 151
    },
    {
      "epoch": 0.10326086956521739,
      "grad_norm": 1.4855459928512573,
      "learning_rate": 1.9941591565201712e-05,
      "loss": 0.7183,
      "step": 152
    },
    {
      "epoch": 0.10394021739130435,
      "grad_norm": 1.9310334920883179,
      "learning_rate": 1.994082126650075e-05,
      "loss": 0.7811,
      "step": 153
    },
    {
      "epoch": 0.10461956521739131,
      "grad_norm": 2.1952879428863525,
      "learning_rate": 1.9940045936689208e-05,
      "loss": 0.7121,
      "step": 154
    },
    {
      "epoch": 0.10529891304347826,
      "grad_norm": 2.339949131011963,
      "learning_rate": 1.9939265576159483e-05,
      "loss": 0.7953,
      "step": 155
    },
    {
      "epoch": 0.10597826086956522,
      "grad_norm": 1.9426319599151611,
      "learning_rate": 1.993848018530652e-05,
      "loss": 0.7737,
      "step": 156
    },
    {
      "epoch": 0.10665760869565218,
      "grad_norm": 1.9457658529281616,
      "learning_rate": 1.9937689764527812e-05,
      "loss": 0.6449,
      "step": 157
    },
    {
      "epoch": 0.10733695652173914,
      "grad_norm": 2.125056028366089,
      "learning_rate": 1.9936894314223395e-05,
      "loss": 0.7498,
      "step": 158
    },
    {
      "epoch": 0.10801630434782608,
      "grad_norm": 1.6908775568008423,
      "learning_rate": 1.9936093834795853e-05,
      "loss": 0.6933,
      "step": 159
    },
    {
      "epoch": 0.10869565217391304,
      "grad_norm": 2.082380533218384,
      "learning_rate": 1.9935288326650314e-05,
      "loss": 0.534,
      "step": 160
    },
    {
      "epoch": 0.109375,
      "grad_norm": 1.9696738719940186,
      "learning_rate": 1.9934477790194445e-05,
      "loss": 0.6392,
      "step": 161
    },
    {
      "epoch": 0.11005434782608696,
      "grad_norm": 2.0341570377349854,
      "learning_rate": 1.993366222583847e-05,
      "loss": 0.5308,
      "step": 162
    },
    {
      "epoch": 0.11073369565217392,
      "grad_norm": 2.163055419921875,
      "learning_rate": 1.9932841633995147e-05,
      "loss": 0.5455,
      "step": 163
    },
    {
      "epoch": 0.11141304347826086,
      "grad_norm": 1.8174934387207031,
      "learning_rate": 1.9932016015079784e-05,
      "loss": 0.6817,
      "step": 164
    },
    {
      "epoch": 0.11209239130434782,
      "grad_norm": 1.7072395086288452,
      "learning_rate": 1.9931185369510228e-05,
      "loss": 0.6814,
      "step": 165
    },
    {
      "epoch": 0.11277173913043478,
      "grad_norm": 1.5355011224746704,
      "learning_rate": 1.9930349697706882e-05,
      "loss": 0.691,
      "step": 166
    },
    {
      "epoch": 0.11345108695652174,
      "grad_norm": 1.9725369215011597,
      "learning_rate": 1.9929509000092676e-05,
      "loss": 0.5125,
      "step": 167
    },
    {
      "epoch": 0.11413043478260869,
      "grad_norm": 1.8478907346725464,
      "learning_rate": 1.99286632770931e-05,
      "loss": 0.4872,
      "step": 168
    },
    {
      "epoch": 0.11480978260869565,
      "grad_norm": 1.9601807594299316,
      "learning_rate": 1.9927812529136175e-05,
      "loss": 0.4579,
      "step": 169
    },
    {
      "epoch": 0.11548913043478261,
      "grad_norm": 1.8024543523788452,
      "learning_rate": 1.992695675665247e-05,
      "loss": 0.7067,
      "step": 170
    },
    {
      "epoch": 0.11616847826086957,
      "grad_norm": 2.303701877593994,
      "learning_rate": 1.9926095960075097e-05,
      "loss": 0.5488,
      "step": 171
    },
    {
      "epoch": 0.11684782608695653,
      "grad_norm": 2.1783995628356934,
      "learning_rate": 1.9925230139839714e-05,
      "loss": 0.6536,
      "step": 172
    },
    {
      "epoch": 0.11752717391304347,
      "grad_norm": 1.7418969869613647,
      "learning_rate": 1.992435929638451e-05,
      "loss": 0.4513,
      "step": 173
    },
    {
      "epoch": 0.11820652173913043,
      "grad_norm": 2.1845405101776123,
      "learning_rate": 1.992348343015023e-05,
      "loss": 0.4943,
      "step": 174
    },
    {
      "epoch": 0.11888586956521739,
      "grad_norm": 1.897070288658142,
      "learning_rate": 1.9922602541580158e-05,
      "loss": 0.5259,
      "step": 175
    },
    {
      "epoch": 0.11956521739130435,
      "grad_norm": 1.4120700359344482,
      "learning_rate": 1.992171663112011e-05,
      "loss": 0.5518,
      "step": 176
    },
    {
      "epoch": 0.12024456521739131,
      "grad_norm": 1.9826481342315674,
      "learning_rate": 1.9920825699218453e-05,
      "loss": 0.4753,
      "step": 177
    },
    {
      "epoch": 0.12092391304347826,
      "grad_norm": 1.6848524808883667,
      "learning_rate": 1.9919929746326095e-05,
      "loss": 0.4396,
      "step": 178
    },
    {
      "epoch": 0.12160326086956522,
      "grad_norm": 1.4221380949020386,
      "learning_rate": 1.9919028772896484e-05,
      "loss": 0.6377,
      "step": 179
    },
    {
      "epoch": 0.12228260869565218,
      "grad_norm": 1.5105446577072144,
      "learning_rate": 1.99181227793856e-05,
      "loss": 0.5704,
      "step": 180
    },
    {
      "epoch": 0.12296195652173914,
      "grad_norm": 1.7343623638153076,
      "learning_rate": 1.9917211766251987e-05,
      "loss": 0.4435,
      "step": 181
    },
    {
      "epoch": 0.12364130434782608,
      "grad_norm": 1.7809264659881592,
      "learning_rate": 1.9916295733956702e-05,
      "loss": 0.4502,
      "step": 182
    },
    {
      "epoch": 0.12432065217391304,
      "grad_norm": 1.5768356323242188,
      "learning_rate": 1.9915374682963358e-05,
      "loss": 0.4268,
      "step": 183
    },
    {
      "epoch": 0.125,
      "grad_norm": 1.473698377609253,
      "learning_rate": 1.9914448613738107e-05,
      "loss": 0.5793,
      "step": 184
    },
    {
      "epoch": 0.12567934782608695,
      "grad_norm": 1.2734112739562988,
      "learning_rate": 1.9913517526749632e-05,
      "loss": 0.4564,
      "step": 185
    },
    {
      "epoch": 0.12635869565217392,
      "grad_norm": 1.596161127090454,
      "learning_rate": 1.991258142246917e-05,
      "loss": 0.3941,
      "step": 186
    },
    {
      "epoch": 0.12703804347826086,
      "grad_norm": 2.6241655349731445,
      "learning_rate": 1.9911640301370484e-05,
      "loss": 0.4912,
      "step": 187
    },
    {
      "epoch": 0.12771739130434784,
      "grad_norm": 1.503063678741455,
      "learning_rate": 1.991069416392988e-05,
      "loss": 0.5664,
      "step": 188
    },
    {
      "epoch": 0.12839673913043478,
      "grad_norm": 1.8410273790359497,
      "learning_rate": 1.990974301062621e-05,
      "loss": 0.5805,
      "step": 189
    },
    {
      "epoch": 0.12907608695652173,
      "grad_norm": 1.3508473634719849,
      "learning_rate": 1.990878684194085e-05,
      "loss": 0.3212,
      "step": 190
    },
    {
      "epoch": 0.1297554347826087,
      "grad_norm": 1.4879213571548462,
      "learning_rate": 1.990782565835773e-05,
      "loss": 0.3486,
      "step": 191
    },
    {
      "epoch": 0.13043478260869565,
      "grad_norm": 1.5134450197219849,
      "learning_rate": 1.9906859460363307e-05,
      "loss": 0.6056,
      "step": 192
    },
    {
      "epoch": 0.13111413043478262,
      "grad_norm": 1.5481712818145752,
      "learning_rate": 1.9905888248446584e-05,
      "loss": 0.2784,
      "step": 193
    },
    {
      "epoch": 0.13179347826086957,
      "grad_norm": 1.3017969131469727,
      "learning_rate": 1.9904912023099096e-05,
      "loss": 0.3231,
      "step": 194
    },
    {
      "epoch": 0.1324728260869565,
      "grad_norm": 2.3729236125946045,
      "learning_rate": 1.9903930784814908e-05,
      "loss": 0.4987,
      "step": 195
    },
    {
      "epoch": 0.1331521739130435,
      "grad_norm": 1.3513175249099731,
      "learning_rate": 1.9902944534090644e-05,
      "loss": 0.3837,
      "step": 196
    },
    {
      "epoch": 0.13383152173913043,
      "grad_norm": 1.415433406829834,
      "learning_rate": 1.990195327142544e-05,
      "loss": 0.29,
      "step": 197
    },
    {
      "epoch": 0.13451086956521738,
      "grad_norm": 1.8773984909057617,
      "learning_rate": 1.990095699732099e-05,
      "loss": 0.3669,
      "step": 198
    },
    {
      "epoch": 0.13519021739130435,
      "grad_norm": 2.0895755290985107,
      "learning_rate": 1.989995571228151e-05,
      "loss": 0.4757,
      "step": 199
    },
    {
      "epoch": 0.1358695652173913,
      "grad_norm": 1.568145751953125,
      "learning_rate": 1.9898949416813757e-05,
      "loss": 0.3255,
      "step": 200
    },
    {
      "epoch": 0.13654891304347827,
      "grad_norm": 1.725048542022705,
      "learning_rate": 1.989793811142702e-05,
      "loss": 0.2855,
      "step": 201
    },
    {
      "epoch": 0.13722826086956522,
      "grad_norm": 1.6922767162322998,
      "learning_rate": 1.989692179663313e-05,
      "loss": 0.3991,
      "step": 202
    },
    {
      "epoch": 0.13790760869565216,
      "grad_norm": 1.1641958951950073,
      "learning_rate": 1.989590047294645e-05,
      "loss": 0.509,
      "step": 203
    },
    {
      "epoch": 0.13858695652173914,
      "grad_norm": 1.3430712223052979,
      "learning_rate": 1.9894874140883877e-05,
      "loss": 0.2643,
      "step": 204
    },
    {
      "epoch": 0.13926630434782608,
      "grad_norm": 1.944981575012207,
      "learning_rate": 1.9893842800964845e-05,
      "loss": 0.5222,
      "step": 205
    },
    {
      "epoch": 0.13994565217391305,
      "grad_norm": 1.66845703125,
      "learning_rate": 1.9892806453711325e-05,
      "loss": 0.4464,
      "step": 206
    },
    {
      "epoch": 0.140625,
      "grad_norm": 1.4363259077072144,
      "learning_rate": 1.989176509964781e-05,
      "loss": 0.2862,
      "step": 207
    },
    {
      "epoch": 0.14130434782608695,
      "grad_norm": 1.5863772630691528,
      "learning_rate": 1.9890718739301346e-05,
      "loss": 0.3998,
      "step": 208
    },
    {
      "epoch": 0.14198369565217392,
      "grad_norm": 1.7233750820159912,
      "learning_rate": 1.988966737320149e-05,
      "loss": 0.2833,
      "step": 209
    },
    {
      "epoch": 0.14266304347826086,
      "grad_norm": 1.3285231590270996,
      "learning_rate": 1.9888611001880357e-05,
      "loss": 0.2499,
      "step": 210
    },
    {
      "epoch": 0.14334239130434784,
      "grad_norm": 1.7455546855926514,
      "learning_rate": 1.9887549625872577e-05,
      "loss": 0.3013,
      "step": 211
    },
    {
      "epoch": 0.14402173913043478,
      "grad_norm": 1.9255971908569336,
      "learning_rate": 1.988648324571532e-05,
      "loss": 0.3679,
      "step": 212
    },
    {
      "epoch": 0.14470108695652173,
      "grad_norm": 1.170053482055664,
      "learning_rate": 1.9885411861948287e-05,
      "loss": 0.1764,
      "step": 213
    },
    {
      "epoch": 0.1453804347826087,
      "grad_norm": 1.4925602674484253,
      "learning_rate": 1.988433547511371e-05,
      "loss": 0.3642,
      "step": 214
    },
    {
      "epoch": 0.14605978260869565,
      "grad_norm": 2.113670587539673,
      "learning_rate": 1.9883254085756357e-05,
      "loss": 0.3745,
      "step": 215
    },
    {
      "epoch": 0.14673913043478262,
      "grad_norm": 1.540824055671692,
      "learning_rate": 1.988216769442353e-05,
      "loss": 0.3437,
      "step": 216
    },
    {
      "epoch": 0.14741847826086957,
      "grad_norm": 1.611240029335022,
      "learning_rate": 1.988107630166505e-05,
      "loss": 0.4928,
      "step": 217
    },
    {
      "epoch": 0.1480978260869565,
      "grad_norm": 1.1978182792663574,
      "learning_rate": 1.9879979908033287e-05,
      "loss": 0.2031,
      "step": 218
    },
    {
      "epoch": 0.1487771739130435,
      "grad_norm": 1.685251235961914,
      "learning_rate": 1.9878878514083124e-05,
      "loss": 0.3018,
      "step": 219
    },
    {
      "epoch": 0.14945652173913043,
      "grad_norm": 0.9499410390853882,
      "learning_rate": 1.9877772120371986e-05,
      "loss": 0.1819,
      "step": 220
    },
    {
      "epoch": 0.15013586956521738,
      "grad_norm": 2.0058162212371826,
      "learning_rate": 1.9876660727459826e-05,
      "loss": 0.3333,
      "step": 221
    },
    {
      "epoch": 0.15081521739130435,
      "grad_norm": 1.6356556415557861,
      "learning_rate": 1.987554433590913e-05,
      "loss": 0.273,
      "step": 222
    },
    {
      "epoch": 0.1514945652173913,
      "grad_norm": 1.7010304927825928,
      "learning_rate": 1.9874422946284904e-05,
      "loss": 0.3796,
      "step": 223
    },
    {
      "epoch": 0.15217391304347827,
      "grad_norm": 1.1169167757034302,
      "learning_rate": 1.98732965591547e-05,
      "loss": 0.4056,
      "step": 224
    },
    {
      "epoch": 0.15285326086956522,
      "grad_norm": 1.2210373878479004,
      "learning_rate": 1.9872165175088578e-05,
      "loss": 0.2007,
      "step": 225
    },
    {
      "epoch": 0.15353260869565216,
      "grad_norm": 1.5919158458709717,
      "learning_rate": 1.987102879465914e-05,
      "loss": 0.2378,
      "step": 226
    },
    {
      "epoch": 0.15421195652173914,
      "grad_norm": 1.4941837787628174,
      "learning_rate": 1.9869887418441525e-05,
      "loss": 0.3045,
      "step": 227
    },
    {
      "epoch": 0.15489130434782608,
      "grad_norm": 1.0509368181228638,
      "learning_rate": 1.9868741047013382e-05,
      "loss": 0.2134,
      "step": 228
    },
    {
      "epoch": 0.15557065217391305,
      "grad_norm": 1.219947099685669,
      "learning_rate": 1.9867589680954902e-05,
      "loss": 0.159,
      "step": 229
    },
    {
      "epoch": 0.15625,
      "grad_norm": 1.5221573114395142,
      "learning_rate": 1.9866433320848793e-05,
      "loss": 0.1787,
      "step": 230
    },
    {
      "epoch": 0.15692934782608695,
      "grad_norm": 1.3308565616607666,
      "learning_rate": 1.9865271967280297e-05,
      "loss": 0.4182,
      "step": 231
    },
    {
      "epoch": 0.15760869565217392,
      "grad_norm": 1.4578099250793457,
      "learning_rate": 1.9864105620837182e-05,
      "loss": 0.2154,
      "step": 232
    },
    {
      "epoch": 0.15828804347826086,
      "grad_norm": 1.3683538436889648,
      "learning_rate": 1.9862934282109746e-05,
      "loss": 0.2192,
      "step": 233
    },
    {
      "epoch": 0.15896739130434784,
      "grad_norm": 1.24293851852417,
      "learning_rate": 1.9861757951690813e-05,
      "loss": 0.1444,
      "step": 234
    },
    {
      "epoch": 0.15964673913043478,
      "grad_norm": 0.8515646457672119,
      "learning_rate": 1.9860576630175723e-05,
      "loss": 0.1593,
      "step": 235
    },
    {
      "epoch": 0.16032608695652173,
      "grad_norm": 1.2150874137878418,
      "learning_rate": 1.9859390318162354e-05,
      "loss": 0.2689,
      "step": 236
    },
    {
      "epoch": 0.1610054347826087,
      "grad_norm": 1.1507092714309692,
      "learning_rate": 1.9858199016251106e-05,
      "loss": 0.146,
      "step": 237
    },
    {
      "epoch": 0.16168478260869565,
      "grad_norm": 1.6402037143707275,
      "learning_rate": 1.9857002725044907e-05,
      "loss": 0.2357,
      "step": 238
    },
    {
      "epoch": 0.16236413043478262,
      "grad_norm": 0.8464673161506653,
      "learning_rate": 1.9855801445149204e-05,
      "loss": 0.1219,
      "step": 239
    },
    {
      "epoch": 0.16304347826086957,
      "grad_norm": 0.8827566504478455,
      "learning_rate": 1.9854595177171968e-05,
      "loss": 0.1382,
      "step": 240
    },
    {
      "epoch": 0.1637228260869565,
      "grad_norm": 1.0496174097061157,
      "learning_rate": 1.9853383921723708e-05,
      "loss": 0.1278,
      "step": 241
    },
    {
      "epoch": 0.1644021739130435,
      "grad_norm": 1.545210838317871,
      "learning_rate": 1.9852167679417445e-05,
      "loss": 0.2237,
      "step": 242
    },
    {
      "epoch": 0.16508152173913043,
      "grad_norm": 1.5975944995880127,
      "learning_rate": 1.985094645086872e-05,
      "loss": 0.2593,
      "step": 243
    },
    {
      "epoch": 0.16576086956521738,
      "grad_norm": 1.0715895891189575,
      "learning_rate": 1.984972023669561e-05,
      "loss": 0.161,
      "step": 244
    },
    {
      "epoch": 0.16644021739130435,
      "grad_norm": 1.3790514469146729,
      "learning_rate": 1.984848903751871e-05,
      "loss": 0.3228,
      "step": 245
    },
    {
      "epoch": 0.1671195652173913,
      "grad_norm": 1.12848699092865,
      "learning_rate": 1.9847252853961136e-05,
      "loss": 0.1214,
      "step": 246
    },
    {
      "epoch": 0.16779891304347827,
      "grad_norm": 1.3233307600021362,
      "learning_rate": 1.9846011686648525e-05,
      "loss": 0.2005,
      "step": 247
    },
    {
      "epoch": 0.16847826086956522,
      "grad_norm": 1.554508090019226,
      "learning_rate": 1.9844765536209045e-05,
      "loss": 0.3794,
      "step": 248
    },
    {
      "epoch": 0.16915760869565216,
      "grad_norm": 1.1465654373168945,
      "learning_rate": 1.9843514403273378e-05,
      "loss": 0.1291,
      "step": 249
    },
    {
      "epoch": 0.16983695652173914,
      "grad_norm": 1.327318787574768,
      "learning_rate": 1.984225828847473e-05,
      "loss": 0.1653,
      "step": 250
    },
    {
      "epoch": 0.17051630434782608,
      "grad_norm": 1.2177168130874634,
      "learning_rate": 1.9840997192448827e-05,
      "loss": 0.1703,
      "step": 251
    },
    {
      "epoch": 0.17119565217391305,
      "grad_norm": 1.3024417161941528,
      "learning_rate": 1.983973111583392e-05,
      "loss": 0.132,
      "step": 252
    },
    {
      "epoch": 0.171875,
      "grad_norm": 1.3674675226211548,
      "learning_rate": 1.9838460059270775e-05,
      "loss": 0.305,
      "step": 253
    },
    {
      "epoch": 0.17255434782608695,
      "grad_norm": 1.6800847053527832,
      "learning_rate": 1.9837184023402683e-05,
      "loss": 0.3749,
      "step": 254
    },
    {
      "epoch": 0.17323369565217392,
      "grad_norm": 1.6873819828033447,
      "learning_rate": 1.9835903008875458e-05,
      "loss": 0.3213,
      "step": 255
    },
    {
      "epoch": 0.17391304347826086,
      "grad_norm": 0.8665537238121033,
      "learning_rate": 1.9834617016337424e-05,
      "loss": 0.0943,
      "step": 256
    },
    {
      "epoch": 0.17459239130434784,
      "grad_norm": 2.07338285446167,
      "learning_rate": 1.9833326046439428e-05,
      "loss": 0.4218,
      "step": 257
    },
    {
      "epoch": 0.17527173913043478,
      "grad_norm": 2.2790772914886475,
      "learning_rate": 1.983203009983484e-05,
      "loss": 0.2442,
      "step": 258
    },
    {
      "epoch": 0.17595108695652173,
      "grad_norm": 1.0389987230300903,
      "learning_rate": 1.9830729177179552e-05,
      "loss": 0.1041,
      "step": 259
    },
    {
      "epoch": 0.1766304347826087,
      "grad_norm": 1.322441577911377,
      "learning_rate": 1.9829423279131962e-05,
      "loss": 0.1935,
      "step": 260
    },
    {
      "epoch": 0.17730978260869565,
      "grad_norm": 1.9899176359176636,
      "learning_rate": 1.9828112406352994e-05,
      "loss": 0.3112,
      "step": 261
    },
    {
      "epoch": 0.17798913043478262,
      "grad_norm": 1.2533161640167236,
      "learning_rate": 1.9826796559506092e-05,
      "loss": 0.1894,
      "step": 262
    },
    {
      "epoch": 0.17866847826086957,
      "grad_norm": 1.8846650123596191,
      "learning_rate": 1.982547573925721e-05,
      "loss": 0.2968,
      "step": 263
    },
    {
      "epoch": 0.1793478260869565,
      "grad_norm": 1.1229360103607178,
      "learning_rate": 1.9824149946274827e-05,
      "loss": 0.1118,
      "step": 264
    },
    {
      "epoch": 0.1800271739130435,
      "grad_norm": 0.9609580636024475,
      "learning_rate": 1.9822819181229934e-05,
      "loss": 0.1364,
      "step": 265
    },
    {
      "epoch": 0.18070652173913043,
      "grad_norm": 0.986274242401123,
      "learning_rate": 1.982148344479604e-05,
      "loss": 0.0989,
      "step": 266
    },
    {
      "epoch": 0.18138586956521738,
      "grad_norm": 1.4888715744018555,
      "learning_rate": 1.982014273764916e-05,
      "loss": 0.2304,
      "step": 267
    },
    {
      "epoch": 0.18206521739130435,
      "grad_norm": 1.297545313835144,
      "learning_rate": 1.9818797060467848e-05,
      "loss": 0.1171,
      "step": 268
    },
    {
      "epoch": 0.1827445652173913,
      "grad_norm": 0.9409723877906799,
      "learning_rate": 1.9817446413933153e-05,
      "loss": 0.1274,
      "step": 269
    },
    {
      "epoch": 0.18342391304347827,
      "grad_norm": 2.3254470825195312,
      "learning_rate": 1.9816090798728648e-05,
      "loss": 0.3396,
      "step": 270
    },
    {
      "epoch": 0.18410326086956522,
      "grad_norm": 1.2730677127838135,
      "learning_rate": 1.9814730215540412e-05,
      "loss": 0.2713,
      "step": 271
    },
    {
      "epoch": 0.18478260869565216,
      "grad_norm": 1.3140339851379395,
      "learning_rate": 1.981336466505705e-05,
      "loss": 0.2073,
      "step": 272
    },
    {
      "epoch": 0.18546195652173914,
      "grad_norm": 1.1898138523101807,
      "learning_rate": 1.9811994147969676e-05,
      "loss": 0.2365,
      "step": 273
    },
    {
      "epoch": 0.18614130434782608,
      "grad_norm": 0.9270482659339905,
      "learning_rate": 1.9810618664971915e-05,
      "loss": 0.0978,
      "step": 274
    },
    {
      "epoch": 0.18682065217391305,
      "grad_norm": 0.8266478776931763,
      "learning_rate": 1.9809238216759906e-05,
      "loss": 0.1354,
      "step": 275
    },
    {
      "epoch": 0.1875,
      "grad_norm": 1.0792070627212524,
      "learning_rate": 1.9807852804032306e-05,
      "loss": 0.1765,
      "step": 276
    },
    {
      "epoch": 0.18817934782608695,
      "grad_norm": 2.0860092639923096,
      "learning_rate": 1.9806462427490278e-05,
      "loss": 0.3099,
      "step": 277
    },
    {
      "epoch": 0.18885869565217392,
      "grad_norm": 0.955254852771759,
      "learning_rate": 1.98050670878375e-05,
      "loss": 0.1069,
      "step": 278
    },
    {
      "epoch": 0.18953804347826086,
      "grad_norm": 1.815977692604065,
      "learning_rate": 1.9803666785780165e-05,
      "loss": 0.2329,
      "step": 279
    },
    {
      "epoch": 0.19021739130434784,
      "grad_norm": 1.6806070804595947,
      "learning_rate": 1.980226152202697e-05,
      "loss": 0.3237,
      "step": 280
    },
    {
      "epoch": 0.19089673913043478,
      "grad_norm": 2.643200159072876,
      "learning_rate": 1.980085129728913e-05,
      "loss": 0.3353,
      "step": 281
    },
    {
      "epoch": 0.19157608695652173,
      "grad_norm": 1.2682639360427856,
      "learning_rate": 1.9799436112280374e-05,
      "loss": 0.2492,
      "step": 282
    },
    {
      "epoch": 0.1922554347826087,
      "grad_norm": 0.8415590524673462,
      "learning_rate": 1.9798015967716924e-05,
      "loss": 0.0805,
      "step": 283
    },
    {
      "epoch": 0.19293478260869565,
      "grad_norm": 0.8031695485115051,
      "learning_rate": 1.979659086431753e-05,
      "loss": 0.0698,
      "step": 284
    },
    {
      "epoch": 0.19361413043478262,
      "grad_norm": 1.2157799005508423,
      "learning_rate": 1.979516080280345e-05,
      "loss": 0.0982,
      "step": 285
    },
    {
      "epoch": 0.19429347826086957,
      "grad_norm": 0.9393426179885864,
      "learning_rate": 1.979372578389844e-05,
      "loss": 0.0942,
      "step": 286
    },
    {
      "epoch": 0.1949728260869565,
      "grad_norm": 0.9019344449043274,
      "learning_rate": 1.9792285808328772e-05,
      "loss": 0.0741,
      "step": 287
    },
    {
      "epoch": 0.1956521739130435,
      "grad_norm": 0.9358389377593994,
      "learning_rate": 1.979084087682323e-05,
      "loss": 0.1502,
      "step": 288
    },
    {
      "epoch": 0.19633152173913043,
      "grad_norm": 1.6083592176437378,
      "learning_rate": 1.9789390990113106e-05,
      "loss": 0.2334,
      "step": 289
    },
    {
      "epoch": 0.19701086956521738,
      "grad_norm": 0.7552184462547302,
      "learning_rate": 1.9787936148932186e-05,
      "loss": 0.0876,
      "step": 290
    },
    {
      "epoch": 0.19769021739130435,
      "grad_norm": 0.7765791416168213,
      "learning_rate": 1.9786476354016782e-05,
      "loss": 0.0567,
      "step": 291
    },
    {
      "epoch": 0.1983695652173913,
      "grad_norm": 1.1239756345748901,
      "learning_rate": 1.9785011606105702e-05,
      "loss": 0.116,
      "step": 292
    },
    {
      "epoch": 0.19904891304347827,
      "grad_norm": 0.8777628540992737,
      "learning_rate": 1.978354190594027e-05,
      "loss": 0.0936,
      "step": 293
    },
    {
      "epoch": 0.19972826086956522,
      "grad_norm": 1.5092411041259766,
      "learning_rate": 1.97820672542643e-05,
      "loss": 0.2089,
      "step": 294
    },
    {
      "epoch": 0.20040760869565216,
      "grad_norm": 1.1982319355010986,
      "learning_rate": 1.978058765182413e-05,
      "loss": 0.2403,
      "step": 295
    },
    {
      "epoch": 0.20108695652173914,
      "grad_norm": 0.7134907841682434,
      "learning_rate": 1.9779103099368596e-05,
      "loss": 0.0714,
      "step": 296
    },
    {
      "epoch": 0.20176630434782608,
      "grad_norm": 1.479239821434021,
      "learning_rate": 1.9777613597649033e-05,
      "loss": 0.2082,
      "step": 297
    },
    {
      "epoch": 0.20244565217391305,
      "grad_norm": 1.405830979347229,
      "learning_rate": 1.9776119147419292e-05,
      "loss": 0.0998,
      "step": 298
    },
    {
      "epoch": 0.203125,
      "grad_norm": 0.5630810856819153,
      "learning_rate": 1.977461974943572e-05,
      "loss": 0.0457,
      "step": 299
    },
    {
      "epoch": 0.20380434782608695,
      "grad_norm": 1.0475691556930542,
      "learning_rate": 1.9773115404457175e-05,
      "loss": 0.0704,
      "step": 300
    },
    {
      "epoch": 0.20448369565217392,
      "grad_norm": 2.053662061691284,
      "learning_rate": 1.9771606113245014e-05,
      "loss": 0.2312,
      "step": 301
    },
    {
      "epoch": 0.20516304347826086,
      "grad_norm": 2.998011350631714,
      "learning_rate": 1.97700918765631e-05,
      "loss": 0.3442,
      "step": 302
    },
    {
      "epoch": 0.20584239130434784,
      "grad_norm": 0.709164023399353,
      "learning_rate": 1.976857269517779e-05,
      "loss": 0.0482,
      "step": 303
    },
    {
      "epoch": 0.20652173913043478,
      "grad_norm": 2.340777635574341,
      "learning_rate": 1.9767048569857963e-05,
      "loss": 0.2479,
      "step": 304
    },
    {
      "epoch": 0.20720108695652173,
      "grad_norm": 0.8955355882644653,
      "learning_rate": 1.9765519501374977e-05,
      "loss": 0.0707,
      "step": 305
    },
    {
      "epoch": 0.2078804347826087,
      "grad_norm": 2.1661665439605713,
      "learning_rate": 1.9763985490502714e-05,
      "loss": 0.3674,
      "step": 306
    },
    {
      "epoch": 0.20855978260869565,
      "grad_norm": 1.438428521156311,
      "learning_rate": 1.9762446538017535e-05,
      "loss": 0.2939,
      "step": 307
    },
    {
      "epoch": 0.20923913043478262,
      "grad_norm": 0.4806319773197174,
      "learning_rate": 1.9760902644698323e-05,
      "loss": 0.0377,
      "step": 308
    },
    {
      "epoch": 0.20991847826086957,
      "grad_norm": 1.8882215023040771,
      "learning_rate": 1.975935381132644e-05,
      "loss": 0.234,
      "step": 309
    },
    {
      "epoch": 0.2105978260869565,
      "grad_norm": 1.7526088953018188,
      "learning_rate": 1.9757800038685773e-05,
      "loss": 0.2052,
      "step": 310
    },
    {
      "epoch": 0.2112771739130435,
      "grad_norm": 0.7126509547233582,
      "learning_rate": 1.975624132756269e-05,
      "loss": 0.0538,
      "step": 311
    },
    {
      "epoch": 0.21195652173913043,
      "grad_norm": 0.61531662940979,
      "learning_rate": 1.9754677678746064e-05,
      "loss": 0.046,
      "step": 312
    },
    {
      "epoch": 0.21263586956521738,
      "grad_norm": 2.0885231494903564,
      "learning_rate": 1.9753109093027264e-05,
      "loss": 0.2767,
      "step": 313
    },
    {
      "epoch": 0.21331521739130435,
      "grad_norm": 1.8826446533203125,
      "learning_rate": 1.975153557120017e-05,
      "loss": 0.247,
      "step": 314
    },
    {
      "epoch": 0.2139945652173913,
      "grad_norm": 0.7194649577140808,
      "learning_rate": 1.9749957114061143e-05,
      "loss": 0.0509,
      "step": 315
    },
    {
      "epoch": 0.21467391304347827,
      "grad_norm": 2.933917760848999,
      "learning_rate": 1.9748373722409052e-05,
      "loss": 0.3056,
      "step": 316
    },
    {
      "epoch": 0.21535326086956522,
      "grad_norm": 0.4886815547943115,
      "learning_rate": 1.9746785397045262e-05,
      "loss": 0.0378,
      "step": 317
    },
    {
      "epoch": 0.21603260869565216,
      "grad_norm": 0.5095583200454712,
      "learning_rate": 1.9745192138773633e-05,
      "loss": 0.0382,
      "step": 318
    },
    {
      "epoch": 0.21671195652173914,
      "grad_norm": 2.043480157852173,
      "learning_rate": 1.9743593948400527e-05,
      "loss": 0.2593,
      "step": 319
    },
    {
      "epoch": 0.21739130434782608,
      "grad_norm": 1.5165892839431763,
      "learning_rate": 1.9741990826734793e-05,
      "loss": 0.24,
      "step": 320
    },
    {
      "epoch": 0.21807065217391305,
      "grad_norm": 0.7677818536758423,
      "learning_rate": 1.974038277458778e-05,
      "loss": 0.0449,
      "step": 321
    },
    {
      "epoch": 0.21875,
      "grad_norm": 1.330828309059143,
      "learning_rate": 1.9738769792773338e-05,
      "loss": 0.0657,
      "step": 322
    },
    {
      "epoch": 0.21942934782608695,
      "grad_norm": 0.6799430251121521,
      "learning_rate": 1.9737151882107803e-05,
      "loss": 0.0359,
      "step": 323
    },
    {
      "epoch": 0.22010869565217392,
      "grad_norm": 1.6223567724227905,
      "learning_rate": 1.9735529043410012e-05,
      "loss": 0.2789,
      "step": 324
    },
    {
      "epoch": 0.22078804347826086,
      "grad_norm": 1.4777661561965942,
      "learning_rate": 1.9733901277501292e-05,
      "loss": 0.2077,
      "step": 325
    },
    {
      "epoch": 0.22146739130434784,
      "grad_norm": 1.4599759578704834,
      "learning_rate": 1.9732268585205465e-05,
      "loss": 0.2085,
      "step": 326
    },
    {
      "epoch": 0.22214673913043478,
      "grad_norm": 1.1896307468414307,
      "learning_rate": 1.973063096734885e-05,
      "loss": 0.1939,
      "step": 327
    },
    {
      "epoch": 0.22282608695652173,
      "grad_norm": 3.012990951538086,
      "learning_rate": 1.972898842476025e-05,
      "loss": 0.3809,
      "step": 328
    },
    {
      "epoch": 0.2235054347826087,
      "grad_norm": 0.5529952049255371,
      "learning_rate": 1.9727340958270968e-05,
      "loss": 0.0301,
      "step": 329
    },
    {
      "epoch": 0.22418478260869565,
      "grad_norm": 1.6697055101394653,
      "learning_rate": 1.97256885687148e-05,
      "loss": 0.2151,
      "step": 330
    },
    {
      "epoch": 0.22486413043478262,
      "grad_norm": 2.464301824569702,
      "learning_rate": 1.9724031256928028e-05,
      "loss": 0.1434,
      "step": 331
    },
    {
      "epoch": 0.22554347826086957,
      "grad_norm": 1.5583477020263672,
      "learning_rate": 1.9722369023749426e-05,
      "loss": 0.2796,
      "step": 332
    },
    {
      "epoch": 0.2262228260869565,
      "grad_norm": 0.7522010803222656,
      "learning_rate": 1.972070187002026e-05,
      "loss": 0.0447,
      "step": 333
    },
    {
      "epoch": 0.2269021739130435,
      "grad_norm": 0.8753514885902405,
      "learning_rate": 1.9719029796584293e-05,
      "loss": 0.0513,
      "step": 334
    },
    {
      "epoch": 0.22758152173913043,
      "grad_norm": 1.4518892765045166,
      "learning_rate": 1.9717352804287766e-05,
      "loss": 0.1615,
      "step": 335
    },
    {
      "epoch": 0.22826086956521738,
      "grad_norm": 0.9907203316688538,
      "learning_rate": 1.9715670893979416e-05,
      "loss": 0.0739,
      "step": 336
    },
    {
      "epoch": 0.22894021739130435,
      "grad_norm": 0.9251623749732971,
      "learning_rate": 1.971398406651047e-05,
      "loss": 0.0551,
      "step": 337
    },
    {
      "epoch": 0.2296195652173913,
      "grad_norm": 1.7248015403747559,
      "learning_rate": 1.971229232273464e-05,
      "loss": 0.2776,
      "step": 338
    },
    {
      "epoch": 0.23029891304347827,
      "grad_norm": 0.9257630705833435,
      "learning_rate": 1.9710595663508125e-05,
      "loss": 0.0503,
      "step": 339
    },
    {
      "epoch": 0.23097826086956522,
      "grad_norm": 1.1112852096557617,
      "learning_rate": 1.9708894089689622e-05,
      "loss": 0.0472,
      "step": 340
    },
    {
      "epoch": 0.23165760869565216,
      "grad_norm": 1.4261395931243896,
      "learning_rate": 1.9707187602140304e-05,
      "loss": 0.2343,
      "step": 341
    },
    {
      "epoch": 0.23233695652173914,
      "grad_norm": 0.8194274306297302,
      "learning_rate": 1.970547620172383e-05,
      "loss": 0.0487,
      "step": 342
    },
    {
      "epoch": 0.23301630434782608,
      "grad_norm": 2.2938687801361084,
      "learning_rate": 1.970375988930636e-05,
      "loss": 0.2358,
      "step": 343
    },
    {
      "epoch": 0.23369565217391305,
      "grad_norm": 0.8445358872413635,
      "learning_rate": 1.9702038665756522e-05,
      "loss": 0.0397,
      "step": 344
    },
    {
      "epoch": 0.234375,
      "grad_norm": 1.0759131908416748,
      "learning_rate": 1.9700312531945444e-05,
      "loss": 0.0625,
      "step": 345
    },
    {
      "epoch": 0.23505434782608695,
      "grad_norm": 0.9313134551048279,
      "learning_rate": 1.9698581488746728e-05,
      "loss": 0.0576,
      "step": 346
    },
    {
      "epoch": 0.23573369565217392,
      "grad_norm": 1.8193248510360718,
      "learning_rate": 1.9696845537036463e-05,
      "loss": 0.1134,
      "step": 347
    },
    {
      "epoch": 0.23641304347826086,
      "grad_norm": 1.5965299606323242,
      "learning_rate": 1.9695104677693234e-05,
      "loss": 0.2031,
      "step": 348
    },
    {
      "epoch": 0.23709239130434784,
      "grad_norm": 1.0754693746566772,
      "learning_rate": 1.9693358911598097e-05,
      "loss": 0.1415,
      "step": 349
    },
    {
      "epoch": 0.23777173913043478,
      "grad_norm": 5.369004726409912,
      "learning_rate": 1.969160823963459e-05,
      "loss": 0.3664,
      "step": 350
    },
    {
      "epoch": 0.23845108695652173,
      "grad_norm": 1.2215638160705566,
      "learning_rate": 1.9689852662688743e-05,
      "loss": 0.1742,
      "step": 351
    },
    {
      "epoch": 0.2391304347826087,
      "grad_norm": 1.0105043649673462,
      "learning_rate": 1.9688092181649065e-05,
      "loss": 0.0565,
      "step": 352
    },
    {
      "epoch": 0.23980978260869565,
      "grad_norm": 2.7701683044433594,
      "learning_rate": 1.9686326797406547e-05,
      "loss": 0.196,
      "step": 353
    },
    {
      "epoch": 0.24048913043478262,
      "grad_norm": 1.8562105894088745,
      "learning_rate": 1.9684556510854655e-05,
      "loss": 0.1802,
      "step": 354
    },
    {
      "epoch": 0.24116847826086957,
      "grad_norm": 3.238758087158203,
      "learning_rate": 1.9682781322889344e-05,
      "loss": 0.3269,
      "step": 355
    },
    {
      "epoch": 0.2418478260869565,
      "grad_norm": 0.6670265197753906,
      "learning_rate": 1.9681001234409053e-05,
      "loss": 0.0452,
      "step": 356
    },
    {
      "epoch": 0.2425271739130435,
      "grad_norm": 2.327960968017578,
      "learning_rate": 1.9679216246314694e-05,
      "loss": 0.1828,
      "step": 357
    },
    {
      "epoch": 0.24320652173913043,
      "grad_norm": 1.0467109680175781,
      "learning_rate": 1.9677426359509653e-05,
      "loss": 0.0475,
      "step": 358
    },
    {
      "epoch": 0.24388586956521738,
      "grad_norm": 1.197495937347412,
      "learning_rate": 1.967563157489981e-05,
      "loss": 0.0567,
      "step": 359
    },
    {
      "epoch": 0.24456521739130435,
      "grad_norm": 0.7095301151275635,
      "learning_rate": 1.967383189339352e-05,
      "loss": 0.0361,
      "step": 360
    },
    {
      "epoch": 0.2452445652173913,
      "grad_norm": 1.2318767309188843,
      "learning_rate": 1.96720273159016e-05,
      "loss": 0.1868,
      "step": 361
    },
    {
      "epoch": 0.24592391304347827,
      "grad_norm": 0.5591127872467041,
      "learning_rate": 1.9670217843337366e-05,
      "loss": 0.0268,
      "step": 362
    },
    {
      "epoch": 0.24660326086956522,
      "grad_norm": 1.326413869857788,
      "learning_rate": 1.9668403476616604e-05,
      "loss": 0.1825,
      "step": 363
    },
    {
      "epoch": 0.24728260869565216,
      "grad_norm": 1.4237911701202393,
      "learning_rate": 1.9666584216657572e-05,
      "loss": 0.1958,
      "step": 364
    },
    {
      "epoch": 0.24796195652173914,
      "grad_norm": 1.4105992317199707,
      "learning_rate": 1.9664760064381015e-05,
      "loss": 0.1832,
      "step": 365
    },
    {
      "epoch": 0.24864130434782608,
      "grad_norm": 0.6117350459098816,
      "learning_rate": 1.9662931020710138e-05,
      "loss": 0.0267,
      "step": 366
    },
    {
      "epoch": 0.24932065217391305,
      "grad_norm": 1.290018916130066,
      "learning_rate": 1.9661097086570642e-05,
      "loss": 0.1546,
      "step": 367
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.0657002925872803,
      "learning_rate": 1.9659258262890683e-05,
      "loss": 0.0456,
      "step": 368
    },
    {
      "epoch": 0.250679347826087,
      "grad_norm": 1.3401182889938354,
      "learning_rate": 1.9657414550600907e-05,
      "loss": 0.0522,
      "step": 369
    },
    {
      "epoch": 0.2513586956521739,
      "grad_norm": 1.6838409900665283,
      "learning_rate": 1.9655565950634428e-05,
      "loss": 0.2599,
      "step": 370
    },
    {
      "epoch": 0.25203804347826086,
      "grad_norm": 1.137561559677124,
      "learning_rate": 1.965371246392683e-05,
      "loss": 0.174,
      "step": 371
    },
    {
      "epoch": 0.25271739130434784,
      "grad_norm": 3.1579294204711914,
      "learning_rate": 1.9651854091416175e-05,
      "loss": 0.2761,
      "step": 372
    },
    {
      "epoch": 0.25339673913043476,
      "grad_norm": 1.3937442302703857,
      "learning_rate": 1.9649990834042998e-05,
      "loss": 0.1608,
      "step": 373
    },
    {
      "epoch": 0.25407608695652173,
      "grad_norm": 1.2392075061798096,
      "learning_rate": 1.9648122692750307e-05,
      "loss": 0.1048,
      "step": 374
    },
    {
      "epoch": 0.2547554347826087,
      "grad_norm": 1.567928671836853,
      "learning_rate": 1.9646249668483575e-05,
      "loss": 0.1642,
      "step": 375
    },
    {
      "epoch": 0.2554347826086957,
      "grad_norm": 2.24039888381958,
      "learning_rate": 1.964437176219075e-05,
      "loss": 0.2409,
      "step": 376
    },
    {
      "epoch": 0.2561141304347826,
      "grad_norm": 0.9000020027160645,
      "learning_rate": 1.964248897482226e-05,
      "loss": 0.0414,
      "step": 377
    },
    {
      "epoch": 0.25679347826086957,
      "grad_norm": 1.5375487804412842,
      "learning_rate": 1.964060130733099e-05,
      "loss": 0.1831,
      "step": 378
    },
    {
      "epoch": 0.25747282608695654,
      "grad_norm": 1.077374815940857,
      "learning_rate": 1.96387087606723e-05,
      "loss": 0.0331,
      "step": 379
    },
    {
      "epoch": 0.25815217391304346,
      "grad_norm": 0.5705044865608215,
      "learning_rate": 1.963681133580402e-05,
      "loss": 0.0279,
      "step": 380
    },
    {
      "epoch": 0.25883152173913043,
      "grad_norm": 1.2541474103927612,
      "learning_rate": 1.963490903368645e-05,
      "loss": 0.069,
      "step": 381
    },
    {
      "epoch": 0.2595108695652174,
      "grad_norm": 2.0998775959014893,
      "learning_rate": 1.9633001855282353e-05,
      "loss": 0.2298,
      "step": 382
    },
    {
      "epoch": 0.2601902173913043,
      "grad_norm": 0.5135867595672607,
      "learning_rate": 1.9631089801556967e-05,
      "loss": 0.0303,
      "step": 383
    },
    {
      "epoch": 0.2608695652173913,
      "grad_norm": 0.9663612246513367,
      "learning_rate": 1.9629172873477995e-05,
      "loss": 0.1012,
      "step": 384
    },
    {
      "epoch": 0.26154891304347827,
      "grad_norm": 1.5480769872665405,
      "learning_rate": 1.9627251072015602e-05,
      "loss": 0.1179,
      "step": 385
    },
    {
      "epoch": 0.26222826086956524,
      "grad_norm": 1.2766773700714111,
      "learning_rate": 1.9625324398142425e-05,
      "loss": 0.059,
      "step": 386
    },
    {
      "epoch": 0.26290760869565216,
      "grad_norm": 4.208740711212158,
      "learning_rate": 1.962339285283357e-05,
      "loss": 0.4751,
      "step": 387
    },
    {
      "epoch": 0.26358695652173914,
      "grad_norm": 1.2800599336624146,
      "learning_rate": 1.9621456437066593e-05,
      "loss": 0.0469,
      "step": 388
    },
    {
      "epoch": 0.2642663043478261,
      "grad_norm": 3.1728382110595703,
      "learning_rate": 1.9619515151821537e-05,
      "loss": 0.2782,
      "step": 389
    },
    {
      "epoch": 0.264945652173913,
      "grad_norm": 4.51204252243042,
      "learning_rate": 1.9617568998080893e-05,
      "loss": 0.2658,
      "step": 390
    },
    {
      "epoch": 0.265625,
      "grad_norm": 1.3244339227676392,
      "learning_rate": 1.9615617976829622e-05,
      "loss": 0.0853,
      "step": 391
    },
    {
      "epoch": 0.266304347826087,
      "grad_norm": 2.7694756984710693,
      "learning_rate": 1.9613662089055148e-05,
      "loss": 0.2167,
      "step": 392
    },
    {
      "epoch": 0.2669836956521739,
      "grad_norm": 2.5211594104766846,
      "learning_rate": 1.961170133574736e-05,
      "loss": 0.2158,
      "step": 393
    },
    {
      "epoch": 0.26766304347826086,
      "grad_norm": 1.2326551675796509,
      "learning_rate": 1.9609735717898602e-05,
      "loss": 0.1386,
      "step": 394
    },
    {
      "epoch": 0.26834239130434784,
      "grad_norm": 2.104076385498047,
      "learning_rate": 1.9607765236503694e-05,
      "loss": 0.2242,
      "step": 395
    },
    {
      "epoch": 0.26902173913043476,
      "grad_norm": 0.6790170073509216,
      "learning_rate": 1.9605789892559902e-05,
      "loss": 0.028,
      "step": 396
    },
    {
      "epoch": 0.26970108695652173,
      "grad_norm": 0.7713321447372437,
      "learning_rate": 1.9603809687066958e-05,
      "loss": 0.0358,
      "step": 397
    },
    {
      "epoch": 0.2703804347826087,
      "grad_norm": 5.422430992126465,
      "learning_rate": 1.960182462102706e-05,
      "loss": 0.4452,
      "step": 398
    },
    {
      "epoch": 0.2710597826086957,
      "grad_norm": 0.7776135206222534,
      "learning_rate": 1.9599834695444863e-05,
      "loss": 0.0314,
      "step": 399
    },
    {
      "epoch": 0.2717391304347826,
      "grad_norm": 7.481050491333008,
      "learning_rate": 1.9597839911327475e-05,
      "loss": 0.4274,
      "step": 400
    },
    {
      "epoch": 0.27241847826086957,
      "grad_norm": 0.9621616005897522,
      "learning_rate": 1.9595840269684478e-05,
      "loss": 0.0356,
      "step": 401
    },
    {
      "epoch": 0.27309782608695654,
      "grad_norm": 0.47610604763031006,
      "learning_rate": 1.9593835771527893e-05,
      "loss": 0.022,
      "step": 402
    },
    {
      "epoch": 0.27377717391304346,
      "grad_norm": 0.46972236037254333,
      "learning_rate": 1.9591826417872214e-05,
      "loss": 0.0246,
      "step": 403
    },
    {
      "epoch": 0.27445652173913043,
      "grad_norm": 0.5751189589500427,
      "learning_rate": 1.9589812209734383e-05,
      "loss": 0.0248,
      "step": 404
    },
    {
      "epoch": 0.2751358695652174,
      "grad_norm": 1.1184841394424438,
      "learning_rate": 1.958779314813381e-05,
      "loss": 0.0402,
      "step": 405
    },
    {
      "epoch": 0.2758152173913043,
      "grad_norm": 1.3784470558166504,
      "learning_rate": 1.9585769234092354e-05,
      "loss": 0.1592,
      "step": 406
    },
    {
      "epoch": 0.2764945652173913,
      "grad_norm": 3.5018723011016846,
      "learning_rate": 1.958374046863432e-05,
      "loss": 0.281,
      "step": 407
    },
    {
      "epoch": 0.27717391304347827,
      "grad_norm": 2.821824550628662,
      "learning_rate": 1.9581706852786492e-05,
      "loss": 0.2981,
      "step": 408
    },
    {
      "epoch": 0.27785326086956524,
      "grad_norm": 2.9115450382232666,
      "learning_rate": 1.9579668387578083e-05,
      "loss": 0.1754,
      "step": 409
    },
    {
      "epoch": 0.27853260869565216,
      "grad_norm": 4.806290626525879,
      "learning_rate": 1.9577625074040782e-05,
      "loss": 0.2722,
      "step": 410
    },
    {
      "epoch": 0.27921195652173914,
      "grad_norm": 3.2324488162994385,
      "learning_rate": 1.9575576913208718e-05,
      "loss": 0.164,
      "step": 411
    },
    {
      "epoch": 0.2798913043478261,
      "grad_norm": 2.5275356769561768,
      "learning_rate": 1.957352390611848e-05,
      "loss": 0.1736,
      "step": 412
    },
    {
      "epoch": 0.280570652173913,
      "grad_norm": 0.461984246969223,
      "learning_rate": 1.9571466053809107e-05,
      "loss": 0.0214,
      "step": 413
    },
    {
      "epoch": 0.28125,
      "grad_norm": 1.413283109664917,
      "learning_rate": 1.956940335732209e-05,
      "loss": 0.1204,
      "step": 414
    },
    {
      "epoch": 0.281929347826087,
      "grad_norm": 0.44014662504196167,
      "learning_rate": 1.9567335817701373e-05,
      "loss": 0.0195,
      "step": 415
    },
    {
      "epoch": 0.2826086956521739,
      "grad_norm": 0.9943338632583618,
      "learning_rate": 1.956526343599335e-05,
      "loss": 0.0575,
      "step": 416
    },
    {
      "epoch": 0.28328804347826086,
      "grad_norm": 1.8198341131210327,
      "learning_rate": 1.9563186213246864e-05,
      "loss": 0.1394,
      "step": 417
    },
    {
      "epoch": 0.28396739130434784,
      "grad_norm": 3.188413381576538,
      "learning_rate": 1.9561104150513214e-05,
      "loss": 0.2043,
      "step": 418
    },
    {
      "epoch": 0.28464673913043476,
      "grad_norm": 4.437038898468018,
      "learning_rate": 1.955901724884614e-05,
      "loss": 0.2576,
      "step": 419
    },
    {
      "epoch": 0.28532608695652173,
      "grad_norm": 2.5036709308624268,
      "learning_rate": 1.9556925509301844e-05,
      "loss": 0.194,
      "step": 420
    },
    {
      "epoch": 0.2860054347826087,
      "grad_norm": 0.4386822283267975,
      "learning_rate": 1.9554828932938962e-05,
      "loss": 0.021,
      "step": 421
    },
    {
      "epoch": 0.2866847826086957,
      "grad_norm": 1.40709388256073,
      "learning_rate": 1.955272752081858e-05,
      "loss": 0.1484,
      "step": 422
    },
    {
      "epoch": 0.2873641304347826,
      "grad_norm": 3.352360248565674,
      "learning_rate": 1.9550621274004248e-05,
      "loss": 0.2577,
      "step": 423
    },
    {
      "epoch": 0.28804347826086957,
      "grad_norm": 0.8567245006561279,
      "learning_rate": 1.9548510193561938e-05,
      "loss": 0.0307,
      "step": 424
    },
    {
      "epoch": 0.28872282608695654,
      "grad_norm": 0.6641393899917603,
      "learning_rate": 1.9546394280560087e-05,
      "loss": 0.0309,
      "step": 425
    },
    {
      "epoch": 0.28940217391304346,
      "grad_norm": 2.235732078552246,
      "learning_rate": 1.9544273536069573e-05,
      "loss": 0.202,
      "step": 426
    },
    {
      "epoch": 0.29008152173913043,
      "grad_norm": 0.9557623267173767,
      "learning_rate": 1.9542147961163707e-05,
      "loss": 0.0384,
      "step": 427
    },
    {
      "epoch": 0.2907608695652174,
      "grad_norm": 0.4514029622077942,
      "learning_rate": 1.954001755691827e-05,
      "loss": 0.0159,
      "step": 428
    },
    {
      "epoch": 0.2914402173913043,
      "grad_norm": 1.5170985460281372,
      "learning_rate": 1.953788232441147e-05,
      "loss": 0.0891,
      "step": 429
    },
    {
      "epoch": 0.2921195652173913,
      "grad_norm": 2.690058946609497,
      "learning_rate": 1.953574226472395e-05,
      "loss": 0.2515,
      "step": 430
    },
    {
      "epoch": 0.29279891304347827,
      "grad_norm": 2.1615829467773438,
      "learning_rate": 1.9533597378938818e-05,
      "loss": 0.1085,
      "step": 431
    },
    {
      "epoch": 0.29347826086956524,
      "grad_norm": 1.5492682456970215,
      "learning_rate": 1.953144766814161e-05,
      "loss": 0.1202,
      "step": 432
    },
    {
      "epoch": 0.29415760869565216,
      "grad_norm": 1.1132396459579468,
      "learning_rate": 1.9529293133420307e-05,
      "loss": 0.0326,
      "step": 433
    },
    {
      "epoch": 0.29483695652173914,
      "grad_norm": 1.5013710260391235,
      "learning_rate": 1.952713377586534e-05,
      "loss": 0.068,
      "step": 434
    },
    {
      "epoch": 0.2955163043478261,
      "grad_norm": 1.2392630577087402,
      "learning_rate": 1.952496959656956e-05,
      "loss": 0.1211,
      "step": 435
    },
    {
      "epoch": 0.296195652173913,
      "grad_norm": 1.5210983753204346,
      "learning_rate": 1.9522800596628282e-05,
      "loss": 0.1417,
      "step": 436
    },
    {
      "epoch": 0.296875,
      "grad_norm": 1.3015326261520386,
      "learning_rate": 1.9520626777139243e-05,
      "loss": 0.0828,
      "step": 437
    },
    {
      "epoch": 0.297554347826087,
      "grad_norm": 3.644954204559326,
      "learning_rate": 1.9518448139202632e-05,
      "loss": 0.2273,
      "step": 438
    },
    {
      "epoch": 0.2982336956521739,
      "grad_norm": 3.7424585819244385,
      "learning_rate": 1.9516264683921073e-05,
      "loss": 0.2741,
      "step": 439
    },
    {
      "epoch": 0.29891304347826086,
      "grad_norm": 1.0776715278625488,
      "learning_rate": 1.9514076412399615e-05,
      "loss": 0.0336,
      "step": 440
    },
    {
      "epoch": 0.29959239130434784,
      "grad_norm": 0.3200100064277649,
      "learning_rate": 1.9511883325745767e-05,
      "loss": 0.0148,
      "step": 441
    },
    {
      "epoch": 0.30027173913043476,
      "grad_norm": 1.1897845268249512,
      "learning_rate": 1.9509685425069457e-05,
      "loss": 0.0376,
      "step": 442
    },
    {
      "epoch": 0.30095108695652173,
      "grad_norm": 2.0542619228363037,
      "learning_rate": 1.9507482711483057e-05,
      "loss": 0.213,
      "step": 443
    },
    {
      "epoch": 0.3016304347826087,
      "grad_norm": 1.9989492893218994,
      "learning_rate": 1.9505275186101378e-05,
      "loss": 0.2303,
      "step": 444
    },
    {
      "epoch": 0.3023097826086957,
      "grad_norm": 4.872838020324707,
      "learning_rate": 1.9503062850041655e-05,
      "loss": 0.3201,
      "step": 445
    },
    {
      "epoch": 0.3029891304347826,
      "grad_norm": 0.6773721575737,
      "learning_rate": 1.9500845704423574e-05,
      "loss": 0.0192,
      "step": 446
    },
    {
      "epoch": 0.30366847826086957,
      "grad_norm": 1.8177241086959839,
      "learning_rate": 1.949862375036924e-05,
      "loss": 0.1145,
      "step": 447
    },
    {
      "epoch": 0.30434782608695654,
      "grad_norm": 1.4188168048858643,
      "learning_rate": 1.9496396989003195e-05,
      "loss": 0.049,
      "step": 448
    },
    {
      "epoch": 0.30502717391304346,
      "grad_norm": 0.5531240105628967,
      "learning_rate": 1.9494165421452422e-05,
      "loss": 0.019,
      "step": 449
    },
    {
      "epoch": 0.30570652173913043,
      "grad_norm": 0.5458484292030334,
      "learning_rate": 1.9491929048846328e-05,
      "loss": 0.0205,
      "step": 450
    },
    {
      "epoch": 0.3063858695652174,
      "grad_norm": 0.8560680150985718,
      "learning_rate": 1.9489687872316757e-05,
      "loss": 0.0286,
      "step": 451
    },
    {
      "epoch": 0.3070652173913043,
      "grad_norm": 5.8344340324401855,
      "learning_rate": 1.948744189299798e-05,
      "loss": 0.3948,
      "step": 452
    },
    {
      "epoch": 0.3077445652173913,
      "grad_norm": 1.310665249824524,
      "learning_rate": 1.9485191112026707e-05,
      "loss": 0.1261,
      "step": 453
    },
    {
      "epoch": 0.30842391304347827,
      "grad_norm": 0.40651586651802063,
      "learning_rate": 1.9482935530542063e-05,
      "loss": 0.0147,
      "step": 454
    },
    {
      "epoch": 0.30910326086956524,
      "grad_norm": 0.8771533966064453,
      "learning_rate": 1.9480675149685616e-05,
      "loss": 0.0295,
      "step": 455
    },
    {
      "epoch": 0.30978260869565216,
      "grad_norm": 1.220866322517395,
      "learning_rate": 1.947840997060136e-05,
      "loss": 0.0399,
      "step": 456
    },
    {
      "epoch": 0.31046195652173914,
      "grad_norm": 1.8077634572982788,
      "learning_rate": 1.9476139994435713e-05,
      "loss": 0.1823,
      "step": 457
    },
    {
      "epoch": 0.3111413043478261,
      "grad_norm": 3.2565040588378906,
      "learning_rate": 1.9473865222337523e-05,
      "loss": 0.2308,
      "step": 458
    },
    {
      "epoch": 0.311820652173913,
      "grad_norm": 2.230694532394409,
      "learning_rate": 1.9471585655458073e-05,
      "loss": 0.1046,
      "step": 459
    },
    {
      "epoch": 0.3125,
      "grad_norm": 3.4257423877716064,
      "learning_rate": 1.946930129495106e-05,
      "loss": 0.2531,
      "step": 460
    },
    {
      "epoch": 0.313179347826087,
      "grad_norm": 1.5117030143737793,
      "learning_rate": 1.946701214197261e-05,
      "loss": 0.064,
      "step": 461
    },
    {
      "epoch": 0.3138586956521739,
      "grad_norm": 4.956887722015381,
      "learning_rate": 1.9464718197681284e-05,
      "loss": 0.2509,
      "step": 462
    },
    {
      "epoch": 0.31453804347826086,
      "grad_norm": 1.8797688484191895,
      "learning_rate": 1.9462419463238057e-05,
      "loss": 0.1952,
      "step": 463
    },
    {
      "epoch": 0.31521739130434784,
      "grad_norm": 4.407315731048584,
      "learning_rate": 1.946011593980634e-05,
      "loss": 0.3181,
      "step": 464
    },
    {
      "epoch": 0.31589673913043476,
      "grad_norm": 4.6306867599487305,
      "learning_rate": 1.9457807628551947e-05,
      "loss": 0.3345,
      "step": 465
    },
    {
      "epoch": 0.31657608695652173,
      "grad_norm": 8.112420082092285,
      "learning_rate": 1.945549453064314e-05,
      "loss": 0.421,
      "step": 466
    },
    {
      "epoch": 0.3172554347826087,
      "grad_norm": 0.2607767581939697,
      "learning_rate": 1.945317664725059e-05,
      "loss": 0.0122,
      "step": 467
    },
    {
      "epoch": 0.3179347826086957,
      "grad_norm": 3.055504083633423,
      "learning_rate": 1.9450853979547384e-05,
      "loss": 0.22,
      "step": 468
    },
    {
      "epoch": 0.3186141304347826,
      "grad_norm": 2.8360676765441895,
      "learning_rate": 1.944852652870905e-05,
      "loss": 0.1919,
      "step": 469
    },
    {
      "epoch": 0.31929347826086957,
      "grad_norm": 0.4950813353061676,
      "learning_rate": 1.9446194295913515e-05,
      "loss": 0.0168,
      "step": 470
    },
    {
      "epoch": 0.31997282608695654,
      "grad_norm": 1.612461805343628,
      "learning_rate": 1.9443857282341144e-05,
      "loss": 0.1233,
      "step": 471
    },
    {
      "epoch": 0.32065217391304346,
      "grad_norm": 1.0427840948104858,
      "learning_rate": 1.9441515489174708e-05,
      "loss": 0.0393,
      "step": 472
    },
    {
      "epoch": 0.32133152173913043,
      "grad_norm": 4.462986946105957,
      "learning_rate": 1.943916891759941e-05,
      "loss": 0.2086,
      "step": 473
    },
    {
      "epoch": 0.3220108695652174,
      "grad_norm": 0.9078941345214844,
      "learning_rate": 1.9436817568802854e-05,
      "loss": 0.029,
      "step": 474
    },
    {
      "epoch": 0.3226902173913043,
      "grad_norm": 6.199380397796631,
      "learning_rate": 1.9434461443975082e-05,
      "loss": 0.4389,
      "step": 475
    },
    {
      "epoch": 0.3233695652173913,
      "grad_norm": 1.2746126651763916,
      "learning_rate": 1.943210054430854e-05,
      "loss": 0.1344,
      "step": 476
    },
    {
      "epoch": 0.32404891304347827,
      "grad_norm": 1.9336389303207397,
      "learning_rate": 1.942973487099809e-05,
      "loss": 0.1633,
      "step": 477
    },
    {
      "epoch": 0.32472826086956524,
      "grad_norm": 2.0139057636260986,
      "learning_rate": 1.9427364425241017e-05,
      "loss": 0.1791,
      "step": 478
    },
    {
      "epoch": 0.32540760869565216,
      "grad_norm": 0.42893993854522705,
      "learning_rate": 1.942498920823702e-05,
      "loss": 0.0152,
      "step": 479
    },
    {
      "epoch": 0.32608695652173914,
      "grad_norm": 5.560685157775879,
      "learning_rate": 1.9422609221188208e-05,
      "loss": 0.4146,
      "step": 480
    },
    {
      "epoch": 0.3267663043478261,
      "grad_norm": 0.6039441823959351,
      "learning_rate": 1.9420224465299108e-05,
      "loss": 0.018,
      "step": 481
    },
    {
      "epoch": 0.327445652173913,
      "grad_norm": 1.0558208227157593,
      "learning_rate": 1.9417834941776657e-05,
      "loss": 0.0309,
      "step": 482
    },
    {
      "epoch": 0.328125,
      "grad_norm": 0.5969105362892151,
      "learning_rate": 1.941544065183021e-05,
      "loss": 0.0181,
      "step": 483
    },
    {
      "epoch": 0.328804347826087,
      "grad_norm": 2.766429901123047,
      "learning_rate": 1.941304159667153e-05,
      "loss": 0.1812,
      "step": 484
    },
    {
      "epoch": 0.3294836956521739,
      "grad_norm": 0.6718318462371826,
      "learning_rate": 1.94106377775148e-05,
      "loss": 0.0176,
      "step": 485
    },
    {
      "epoch": 0.33016304347826086,
      "grad_norm": 2.691527843475342,
      "learning_rate": 1.94082291955766e-05,
      "loss": 0.1693,
      "step": 486
    },
    {
      "epoch": 0.33084239130434784,
      "grad_norm": 1.4681744575500488,
      "learning_rate": 1.940581585207593e-05,
      "loss": 0.0982,
      "step": 487
    },
    {
      "epoch": 0.33152173913043476,
      "grad_norm": 2.006873369216919,
      "learning_rate": 1.94033977482342e-05,
      "loss": 0.1814,
      "step": 488
    },
    {
      "epoch": 0.33220108695652173,
      "grad_norm": 1.5807721614837646,
      "learning_rate": 1.9400974885275226e-05,
      "loss": 0.1442,
      "step": 489
    },
    {
      "epoch": 0.3328804347826087,
      "grad_norm": 3.141552209854126,
      "learning_rate": 1.9398547264425237e-05,
      "loss": 0.2163,
      "step": 490
    },
    {
      "epoch": 0.3335597826086957,
      "grad_norm": 0.42576077580451965,
      "learning_rate": 1.9396114886912858e-05,
      "loss": 0.0213,
      "step": 491
    },
    {
      "epoch": 0.3342391304347826,
      "grad_norm": 0.18392020463943481,
      "learning_rate": 1.9393677753969137e-05,
      "loss": 0.0071,
      "step": 492
    },
    {
      "epoch": 0.33491847826086957,
      "grad_norm": 1.8604487180709839,
      "learning_rate": 1.9391235866827522e-05,
      "loss": 0.1634,
      "step": 493
    },
    {
      "epoch": 0.33559782608695654,
      "grad_norm": 3.247429609298706,
      "learning_rate": 1.9388789226723865e-05,
      "loss": 0.2487,
      "step": 494
    },
    {
      "epoch": 0.33627717391304346,
      "grad_norm": 1.2917593717575073,
      "learning_rate": 1.9386337834896428e-05,
      "loss": 0.0606,
      "step": 495
    },
    {
      "epoch": 0.33695652173913043,
      "grad_norm": 1.5396620035171509,
      "learning_rate": 1.938388169258587e-05,
      "loss": 0.0774,
      "step": 496
    },
    {
      "epoch": 0.3376358695652174,
      "grad_norm": 1.1381877660751343,
      "learning_rate": 1.9381420801035265e-05,
      "loss": 0.0348,
      "step": 497
    },
    {
      "epoch": 0.3383152173913043,
      "grad_norm": 1.4955791234970093,
      "learning_rate": 1.9378955161490086e-05,
      "loss": 0.2166,
      "step": 498
    },
    {
      "epoch": 0.3389945652173913,
      "grad_norm": 2.3471312522888184,
      "learning_rate": 1.9376484775198203e-05,
      "loss": 0.1383,
      "step": 499
    },
    {
      "epoch": 0.33967391304347827,
      "grad_norm": 1.4533374309539795,
      "learning_rate": 1.9374009643409895e-05,
      "loss": 0.0916,
      "step": 500
    },
    {
      "epoch": 0.34035326086956524,
      "grad_norm": 2.1084647178649902,
      "learning_rate": 1.937152976737785e-05,
      "loss": 0.2026,
      "step": 501
    },
    {
      "epoch": 0.34103260869565216,
      "grad_norm": 0.5431498289108276,
      "learning_rate": 1.9369045148357136e-05,
      "loss": 0.0203,
      "step": 502
    },
    {
      "epoch": 0.34171195652173914,
      "grad_norm": 3.804941415786743,
      "learning_rate": 1.936655578760524e-05,
      "loss": 0.2458,
      "step": 503
    },
    {
      "epoch": 0.3423913043478261,
      "grad_norm": 0.6782809495925903,
      "learning_rate": 1.9364061686382042e-05,
      "loss": 0.0191,
      "step": 504
    },
    {
      "epoch": 0.343070652173913,
      "grad_norm": 5.000776290893555,
      "learning_rate": 1.9361562845949823e-05,
      "loss": 0.2131,
      "step": 505
    },
    {
      "epoch": 0.34375,
      "grad_norm": 4.144392490386963,
      "learning_rate": 1.935905926757326e-05,
      "loss": 0.2901,
      "step": 506
    },
    {
      "epoch": 0.344429347826087,
      "grad_norm": 0.6764158010482788,
      "learning_rate": 1.935655095251943e-05,
      "loss": 0.0181,
      "step": 507
    },
    {
      "epoch": 0.3451086956521739,
      "grad_norm": 2.589512586593628,
      "learning_rate": 1.9354037902057806e-05,
      "loss": 0.1903,
      "step": 508
    },
    {
      "epoch": 0.34578804347826086,
      "grad_norm": 1.566525936126709,
      "learning_rate": 1.9351520117460255e-05,
      "loss": 0.1382,
      "step": 509
    },
    {
      "epoch": 0.34646739130434784,
      "grad_norm": 7.847790241241455,
      "learning_rate": 1.9348997600001052e-05,
      "loss": 0.4224,
      "step": 510
    },
    {
      "epoch": 0.34714673913043476,
      "grad_norm": 3.1992292404174805,
      "learning_rate": 1.9346470350956853e-05,
      "loss": 0.148,
      "step": 511
    },
    {
      "epoch": 0.34782608695652173,
      "grad_norm": 8.085498809814453,
      "learning_rate": 1.9343938371606714e-05,
      "loss": 0.4689,
      "step": 512
    },
    {
      "epoch": 0.3485054347826087,
      "grad_norm": 1.0684093236923218,
      "learning_rate": 1.9341401663232083e-05,
      "loss": 0.1778,
      "step": 513
    },
    {
      "epoch": 0.3491847826086957,
      "grad_norm": 0.42795228958129883,
      "learning_rate": 1.933886022711681e-05,
      "loss": 0.0132,
      "step": 514
    },
    {
      "epoch": 0.3498641304347826,
      "grad_norm": 1.7957491874694824,
      "learning_rate": 1.9336314064547127e-05,
      "loss": 0.17,
      "step": 515
    },
    {
      "epoch": 0.35054347826086957,
      "grad_norm": 1.338282585144043,
      "learning_rate": 1.9333763176811663e-05,
      "loss": 0.0377,
      "step": 516
    },
    {
      "epoch": 0.35122282608695654,
      "grad_norm": 0.39153507351875305,
      "learning_rate": 1.933120756520144e-05,
      "loss": 0.0128,
      "step": 517
    },
    {
      "epoch": 0.35190217391304346,
      "grad_norm": 0.6418756246566772,
      "learning_rate": 1.9328647231009868e-05,
      "loss": 0.0153,
      "step": 518
    },
    {
      "epoch": 0.35258152173913043,
      "grad_norm": 1.437606930732727,
      "learning_rate": 1.9326082175532744e-05,
      "loss": 0.1385,
      "step": 519
    },
    {
      "epoch": 0.3532608695652174,
      "grad_norm": 1.5271989107131958,
      "learning_rate": 1.9323512400068262e-05,
      "loss": 0.0694,
      "step": 520
    },
    {
      "epoch": 0.3539402173913043,
      "grad_norm": 4.393085956573486,
      "learning_rate": 1.9320937905917002e-05,
      "loss": 0.2448,
      "step": 521
    },
    {
      "epoch": 0.3546195652173913,
      "grad_norm": 1.423867106437683,
      "learning_rate": 1.9318358694381926e-05,
      "loss": 0.1391,
      "step": 522
    },
    {
      "epoch": 0.35529891304347827,
      "grad_norm": 1.0587389469146729,
      "learning_rate": 1.9315774766768394e-05,
      "loss": 0.1452,
      "step": 523
    },
    {
      "epoch": 0.35597826086956524,
      "grad_norm": 1.1387988328933716,
      "learning_rate": 1.9313186124384147e-05,
      "loss": 0.0287,
      "step": 524
    },
    {
      "epoch": 0.35665760869565216,
      "grad_norm": 0.5148639678955078,
      "learning_rate": 1.9310592768539315e-05,
      "loss": 0.0145,
      "step": 525
    },
    {
      "epoch": 0.35733695652173914,
      "grad_norm": 1.091637134552002,
      "learning_rate": 1.93079947005464e-05,
      "loss": 0.1085,
      "step": 526
    },
    {
      "epoch": 0.3580163043478261,
      "grad_norm": 1.44889497756958,
      "learning_rate": 1.9305391921720313e-05,
      "loss": 0.152,
      "step": 527
    },
    {
      "epoch": 0.358695652173913,
      "grad_norm": 1.4275919198989868,
      "learning_rate": 1.9302784433378333e-05,
      "loss": 0.1066,
      "step": 528
    },
    {
      "epoch": 0.359375,
      "grad_norm": 4.244147300720215,
      "learning_rate": 1.930017223684012e-05,
      "loss": 0.2091,
      "step": 529
    },
    {
      "epoch": 0.360054347826087,
      "grad_norm": 0.9992043972015381,
      "learning_rate": 1.9297555333427733e-05,
      "loss": 0.0247,
      "step": 530
    },
    {
      "epoch": 0.3607336956521739,
      "grad_norm": 6.221271991729736,
      "learning_rate": 1.9294933724465593e-05,
      "loss": 0.3357,
      "step": 531
    },
    {
      "epoch": 0.36141304347826086,
      "grad_norm": 0.36063218116760254,
      "learning_rate": 1.9292307411280514e-05,
      "loss": 0.0086,
      "step": 532
    },
    {
      "epoch": 0.36209239130434784,
      "grad_norm": 1.3353253602981567,
      "learning_rate": 1.9289676395201697e-05,
      "loss": 0.1838,
      "step": 533
    },
    {
      "epoch": 0.36277173913043476,
      "grad_norm": 1.4965168237686157,
      "learning_rate": 1.928704067756071e-05,
      "loss": 0.1746,
      "step": 534
    },
    {
      "epoch": 0.36345108695652173,
      "grad_norm": 2.6023099422454834,
      "learning_rate": 1.92844002596915e-05,
      "loss": 0.1413,
      "step": 535
    },
    {
      "epoch": 0.3641304347826087,
      "grad_norm": 0.27426400780677795,
      "learning_rate": 1.928175514293041e-05,
      "loss": 0.0085,
      "step": 536
    },
    {
      "epoch": 0.3648097826086957,
      "grad_norm": 1.6183513402938843,
      "learning_rate": 1.927910532861614e-05,
      "loss": 0.1338,
      "step": 537
    },
    {
      "epoch": 0.3654891304347826,
      "grad_norm": 1.6788859367370605,
      "learning_rate": 1.927645081808978e-05,
      "loss": 0.1473,
      "step": 538
    },
    {
      "epoch": 0.36616847826086957,
      "grad_norm": 0.4930700361728668,
      "learning_rate": 1.9273791612694798e-05,
      "loss": 0.0131,
      "step": 539
    },
    {
      "epoch": 0.36684782608695654,
      "grad_norm": 3.3625662326812744,
      "learning_rate": 1.9271127713777033e-05,
      "loss": 0.2163,
      "step": 540
    },
    {
      "epoch": 0.36752717391304346,
      "grad_norm": 5.284022808074951,
      "learning_rate": 1.92684591226847e-05,
      "loss": 0.2809,
      "step": 541
    },
    {
      "epoch": 0.36820652173913043,
      "grad_norm": 10.581930160522461,
      "learning_rate": 1.9265785840768387e-05,
      "loss": 0.4702,
      "step": 542
    },
    {
      "epoch": 0.3688858695652174,
      "grad_norm": 1.3323478698730469,
      "learning_rate": 1.926310786938106e-05,
      "loss": 0.1321,
      "step": 543
    },
    {
      "epoch": 0.3695652173913043,
      "grad_norm": 1.2166821956634521,
      "learning_rate": 1.9260425209878052e-05,
      "loss": 0.0373,
      "step": 544
    },
    {
      "epoch": 0.3702445652173913,
      "grad_norm": 0.4348542094230652,
      "learning_rate": 1.925773786361708e-05,
      "loss": 0.0094,
      "step": 545
    },
    {
      "epoch": 0.37092391304347827,
      "grad_norm": 7.143784046173096,
      "learning_rate": 1.925504583195823e-05,
      "loss": 0.3355,
      "step": 546
    },
    {
      "epoch": 0.37160326086956524,
      "grad_norm": 0.47185930609703064,
      "learning_rate": 1.9252349116263945e-05,
      "loss": 0.0134,
      "step": 547
    },
    {
      "epoch": 0.37228260869565216,
      "grad_norm": 1.4811902046203613,
      "learning_rate": 1.924964771789906e-05,
      "loss": 0.0371,
      "step": 548
    },
    {
      "epoch": 0.37296195652173914,
      "grad_norm": 2.191068172454834,
      "learning_rate": 1.924694163823076e-05,
      "loss": 0.2222,
      "step": 549
    },
    {
      "epoch": 0.3736413043478261,
      "grad_norm": 2.6159427165985107,
      "learning_rate": 1.924423087862861e-05,
      "loss": 0.1921,
      "step": 550
    },
    {
      "epoch": 0.374320652173913,
      "grad_norm": 0.3626011312007904,
      "learning_rate": 1.924151544046455e-05,
      "loss": 0.0101,
      "step": 551
    },
    {
      "epoch": 0.375,
      "grad_norm": 7.345860958099365,
      "learning_rate": 1.9238795325112867e-05,
      "loss": 0.3511,
      "step": 552
    },
    {
      "epoch": 0.375679347826087,
      "grad_norm": 2.95796537399292,
      "learning_rate": 1.9236070533950242e-05,
      "loss": 0.1524,
      "step": 553
    },
    {
      "epoch": 0.3763586956521739,
      "grad_norm": 4.678280353546143,
      "learning_rate": 1.92333410683557e-05,
      "loss": 0.2648,
      "step": 554
    },
    {
      "epoch": 0.37703804347826086,
      "grad_norm": 2.181612968444824,
      "learning_rate": 1.923060692971064e-05,
      "loss": 0.092,
      "step": 555
    },
    {
      "epoch": 0.37771739130434784,
      "grad_norm": 1.9241719245910645,
      "learning_rate": 1.922786811939883e-05,
      "loss": 0.1525,
      "step": 556
    },
    {
      "epoch": 0.37839673913043476,
      "grad_norm": 1.6688683032989502,
      "learning_rate": 1.9225124638806396e-05,
      "loss": 0.1264,
      "step": 557
    },
    {
      "epoch": 0.37907608695652173,
      "grad_norm": 0.5007317066192627,
      "learning_rate": 1.922237648932183e-05,
      "loss": 0.0137,
      "step": 558
    },
    {
      "epoch": 0.3797554347826087,
      "grad_norm": 1.769177794456482,
      "learning_rate": 1.9219623672335994e-05,
      "loss": 0.1746,
      "step": 559
    },
    {
      "epoch": 0.3804347826086957,
      "grad_norm": 0.27674633264541626,
      "learning_rate": 1.9216866189242095e-05,
      "loss": 0.0081,
      "step": 560
    },
    {
      "epoch": 0.3811141304347826,
      "grad_norm": 0.23018965125083923,
      "learning_rate": 1.921410404143572e-05,
      "loss": 0.0072,
      "step": 561
    },
    {
      "epoch": 0.38179347826086957,
      "grad_norm": 1.3300201892852783,
      "learning_rate": 1.921133723031481e-05,
      "loss": 0.0952,
      "step": 562
    },
    {
      "epoch": 0.38247282608695654,
      "grad_norm": 1.3689161539077759,
      "learning_rate": 1.9208565757279654e-05,
      "loss": 0.1471,
      "step": 563
    },
    {
      "epoch": 0.38315217391304346,
      "grad_norm": 3.2851762771606445,
      "learning_rate": 1.9205789623732923e-05,
      "loss": 0.1765,
      "step": 564
    },
    {
      "epoch": 0.38383152173913043,
      "grad_norm": 0.5543853044509888,
      "learning_rate": 1.920300883107963e-05,
      "loss": 0.0152,
      "step": 565
    },
    {
      "epoch": 0.3845108695652174,
      "grad_norm": 0.41788721084594727,
      "learning_rate": 1.9200223380727153e-05,
      "loss": 0.0113,
      "step": 566
    },
    {
      "epoch": 0.3851902173913043,
      "grad_norm": 2.9386191368103027,
      "learning_rate": 1.9197433274085225e-05,
      "loss": 0.1953,
      "step": 567
    },
    {
      "epoch": 0.3858695652173913,
      "grad_norm": 0.46214503049850464,
      "learning_rate": 1.9194638512565937e-05,
      "loss": 0.0126,
      "step": 568
    },
    {
      "epoch": 0.38654891304347827,
      "grad_norm": 1.9869389533996582,
      "learning_rate": 1.919183909758373e-05,
      "loss": 0.1428,
      "step": 569
    },
    {
      "epoch": 0.38722826086956524,
      "grad_norm": 0.7006274461746216,
      "learning_rate": 1.918903503055541e-05,
      "loss": 0.0222,
      "step": 570
    },
    {
      "epoch": 0.38790760869565216,
      "grad_norm": 0.4564627707004547,
      "learning_rate": 1.9186226312900134e-05,
      "loss": 0.011,
      "step": 571
    },
    {
      "epoch": 0.38858695652173914,
      "grad_norm": 3.090909242630005,
      "learning_rate": 1.918341294603941e-05,
      "loss": 0.1896,
      "step": 572
    },
    {
      "epoch": 0.3892663043478261,
      "grad_norm": 4.482759475708008,
      "learning_rate": 1.9180594931397094e-05,
      "loss": 0.214,
      "step": 573
    },
    {
      "epoch": 0.389945652173913,
      "grad_norm": 1.998465657234192,
      "learning_rate": 1.917777227039941e-05,
      "loss": 0.2142,
      "step": 574
    },
    {
      "epoch": 0.390625,
      "grad_norm": 2.0936460494995117,
      "learning_rate": 1.9174944964474914e-05,
      "loss": 0.1662,
      "step": 575
    },
    {
      "epoch": 0.391304347826087,
      "grad_norm": 3.08070707321167,
      "learning_rate": 1.917211301505453e-05,
      "loss": 0.2107,
      "step": 576
    },
    {
      "epoch": 0.3919836956521739,
      "grad_norm": 5.0787506103515625,
      "learning_rate": 1.9169276423571525e-05,
      "loss": 0.3065,
      "step": 577
    },
    {
      "epoch": 0.39266304347826086,
      "grad_norm": 3.134056806564331,
      "learning_rate": 1.9166435191461514e-05,
      "loss": 0.119,
      "step": 578
    },
    {
      "epoch": 0.39334239130434784,
      "grad_norm": 1.8442487716674805,
      "learning_rate": 1.916358932016246e-05,
      "loss": 0.1132,
      "step": 579
    },
    {
      "epoch": 0.39402173913043476,
      "grad_norm": 6.140950679779053,
      "learning_rate": 1.916073881111468e-05,
      "loss": 0.334,
      "step": 580
    },
    {
      "epoch": 0.39470108695652173,
      "grad_norm": 1.127659797668457,
      "learning_rate": 1.9157883665760827e-05,
      "loss": 0.1199,
      "step": 581
    },
    {
      "epoch": 0.3953804347826087,
      "grad_norm": 1.4611198902130127,
      "learning_rate": 1.9155023885545914e-05,
      "loss": 0.1217,
      "step": 582
    },
    {
      "epoch": 0.3960597826086957,
      "grad_norm": 2.722665548324585,
      "learning_rate": 1.9152159471917292e-05,
      "loss": 0.0673,
      "step": 583
    },
    {
      "epoch": 0.3967391304347826,
      "grad_norm": 0.8781061172485352,
      "learning_rate": 1.9149290426324658e-05,
      "loss": 0.0234,
      "step": 584
    },
    {
      "epoch": 0.39741847826086957,
      "grad_norm": 5.131327152252197,
      "learning_rate": 1.914641675022005e-05,
      "loss": 0.2586,
      "step": 585
    },
    {
      "epoch": 0.39809782608695654,
      "grad_norm": 0.3007233440876007,
      "learning_rate": 1.914353844505786e-05,
      "loss": 0.0075,
      "step": 586
    },
    {
      "epoch": 0.39877717391304346,
      "grad_norm": 0.8502815365791321,
      "learning_rate": 1.914065551229481e-05,
      "loss": 0.0205,
      "step": 587
    },
    {
      "epoch": 0.39945652173913043,
      "grad_norm": 6.0153398513793945,
      "learning_rate": 1.913776795338998e-05,
      "loss": 0.2275,
      "step": 588
    },
    {
      "epoch": 0.4001358695652174,
      "grad_norm": 0.499432235956192,
      "learning_rate": 1.9134875769804763e-05,
      "loss": 0.0107,
      "step": 589
    },
    {
      "epoch": 0.4008152173913043,
      "grad_norm": 4.210350513458252,
      "learning_rate": 1.9131978963002927e-05,
      "loss": 0.2408,
      "step": 590
    },
    {
      "epoch": 0.4014945652173913,
      "grad_norm": 1.119102120399475,
      "learning_rate": 1.9129077534450556e-05,
      "loss": 0.1088,
      "step": 591
    },
    {
      "epoch": 0.40217391304347827,
      "grad_norm": 1.5809413194656372,
      "learning_rate": 1.912617148561608e-05,
      "loss": 0.0325,
      "step": 592
    },
    {
      "epoch": 0.40285326086956524,
      "grad_norm": 1.287590503692627,
      "learning_rate": 1.912326081797028e-05,
      "loss": 0.1061,
      "step": 593
    },
    {
      "epoch": 0.40353260869565216,
      "grad_norm": 3.12845778465271,
      "learning_rate": 1.9120345532986243e-05,
      "loss": 0.2046,
      "step": 594
    },
    {
      "epoch": 0.40421195652173914,
      "grad_norm": 1.0073944330215454,
      "learning_rate": 1.911742563213943e-05,
      "loss": 0.0198,
      "step": 595
    },
    {
      "epoch": 0.4048913043478261,
      "grad_norm": 0.5446677207946777,
      "learning_rate": 1.911450111690761e-05,
      "loss": 0.008,
      "step": 596
    },
    {
      "epoch": 0.405570652173913,
      "grad_norm": 4.136183738708496,
      "learning_rate": 1.9111571988770903e-05,
      "loss": 0.0959,
      "step": 597
    },
    {
      "epoch": 0.40625,
      "grad_norm": 2.2513670921325684,
      "learning_rate": 1.910863824921176e-05,
      "loss": 0.092,
      "step": 598
    },
    {
      "epoch": 0.406929347826087,
      "grad_norm": 0.6235161423683167,
      "learning_rate": 1.910569989971496e-05,
      "loss": 0.0141,
      "step": 599
    },
    {
      "epoch": 0.4076086956521739,
      "grad_norm": 2.635260820388794,
      "learning_rate": 1.9102756941767625e-05,
      "loss": 0.1886,
      "step": 600
    },
    {
      "epoch": 0.40828804347826086,
      "grad_norm": 1.093279242515564,
      "learning_rate": 1.9099809376859196e-05,
      "loss": 0.0218,
      "step": 601
    },
    {
      "epoch": 0.40896739130434784,
      "grad_norm": 1.252023458480835,
      "learning_rate": 1.909685720648146e-05,
      "loss": 0.0306,
      "step": 602
    },
    {
      "epoch": 0.40964673913043476,
      "grad_norm": 3.1366920471191406,
      "learning_rate": 1.9093900432128532e-05,
      "loss": 0.1942,
      "step": 603
    },
    {
      "epoch": 0.41032608695652173,
      "grad_norm": 4.325490951538086,
      "learning_rate": 1.9090939055296846e-05,
      "loss": 0.2316,
      "step": 604
    },
    {
      "epoch": 0.4110054347826087,
      "grad_norm": 2.713503360748291,
      "learning_rate": 1.9087973077485175e-05,
      "loss": 0.1207,
      "step": 605
    },
    {
      "epoch": 0.4116847826086957,
      "grad_norm": 1.1674367189407349,
      "learning_rate": 1.908500250019462e-05,
      "loss": 0.0234,
      "step": 606
    },
    {
      "epoch": 0.4123641304347826,
      "grad_norm": 2.583686351776123,
      "learning_rate": 1.9082027324928603e-05,
      "loss": 0.065,
      "step": 607
    },
    {
      "epoch": 0.41304347826086957,
      "grad_norm": 1.5718210935592651,
      "learning_rate": 1.907904755319289e-05,
      "loss": 0.0905,
      "step": 608
    },
    {
      "epoch": 0.41372282608695654,
      "grad_norm": 1.7242790460586548,
      "learning_rate": 1.907606318649555e-05,
      "loss": 0.1122,
      "step": 609
    },
    {
      "epoch": 0.41440217391304346,
      "grad_norm": 4.01684045791626,
      "learning_rate": 1.9073074226347e-05,
      "loss": 0.173,
      "step": 610
    },
    {
      "epoch": 0.41508152173913043,
      "grad_norm": 3.7143802642822266,
      "learning_rate": 1.9070080674259962e-05,
      "loss": 0.1442,
      "step": 611
    },
    {
      "epoch": 0.4157608695652174,
      "grad_norm": 2.8454501628875732,
      "learning_rate": 1.9067082531749496e-05,
      "loss": 0.0754,
      "step": 612
    },
    {
      "epoch": 0.4164402173913043,
      "grad_norm": 0.9492709040641785,
      "learning_rate": 1.9064079800332977e-05,
      "loss": 0.0178,
      "step": 613
    },
    {
      "epoch": 0.4171195652173913,
      "grad_norm": 3.2718231678009033,
      "learning_rate": 1.906107248153011e-05,
      "loss": 0.1933,
      "step": 614
    },
    {
      "epoch": 0.41779891304347827,
      "grad_norm": 0.2631895840167999,
      "learning_rate": 1.9058060576862912e-05,
      "loss": 0.0051,
      "step": 615
    },
    {
      "epoch": 0.41847826086956524,
      "grad_norm": 0.41246986389160156,
      "learning_rate": 1.9055044087855728e-05,
      "loss": 0.0095,
      "step": 616
    },
    {
      "epoch": 0.41915760869565216,
      "grad_norm": 6.97009801864624,
      "learning_rate": 1.9052023016035224e-05,
      "loss": 0.2811,
      "step": 617
    },
    {
      "epoch": 0.41983695652173914,
      "grad_norm": 1.6281028985977173,
      "learning_rate": 1.9048997362930384e-05,
      "loss": 0.1433,
      "step": 618
    },
    {
      "epoch": 0.4205163043478261,
      "grad_norm": 7.872243404388428,
      "learning_rate": 1.9045967130072504e-05,
      "loss": 0.3137,
      "step": 619
    },
    {
      "epoch": 0.421195652173913,
      "grad_norm": 2.392484664916992,
      "learning_rate": 1.904293231899521e-05,
      "loss": 0.183,
      "step": 620
    },
    {
      "epoch": 0.421875,
      "grad_norm": 2.2302606105804443,
      "learning_rate": 1.9039892931234434e-05,
      "loss": 0.1537,
      "step": 621
    },
    {
      "epoch": 0.422554347826087,
      "grad_norm": 2.894423246383667,
      "learning_rate": 1.9036848968328433e-05,
      "loss": 0.1935,
      "step": 622
    },
    {
      "epoch": 0.4232336956521739,
      "grad_norm": 1.372302532196045,
      "learning_rate": 1.903380043181777e-05,
      "loss": 0.0868,
      "step": 623
    },
    {
      "epoch": 0.42391304347826086,
      "grad_norm": 0.11422084271907806,
      "learning_rate": 1.903074732324533e-05,
      "loss": 0.0045,
      "step": 624
    },
    {
      "epoch": 0.42459239130434784,
      "grad_norm": 3.7331745624542236,
      "learning_rate": 1.9027689644156312e-05,
      "loss": 0.1571,
      "step": 625
    },
    {
      "epoch": 0.42527173913043476,
      "grad_norm": 0.4717932343482971,
      "learning_rate": 1.9024627396098222e-05,
      "loss": 0.0119,
      "step": 626
    },
    {
      "epoch": 0.42595108695652173,
      "grad_norm": 0.3712172508239746,
      "learning_rate": 1.9021560580620883e-05,
      "loss": 0.0084,
      "step": 627
    },
    {
      "epoch": 0.4266304347826087,
      "grad_norm": 3.4192774295806885,
      "learning_rate": 1.9018489199276438e-05,
      "loss": 0.1495,
      "step": 628
    },
    {
      "epoch": 0.4273097826086957,
      "grad_norm": 2.9603564739227295,
      "learning_rate": 1.901541325361932e-05,
      "loss": 0.1178,
      "step": 629
    },
    {
      "epoch": 0.4279891304347826,
      "grad_norm": 2.417884588241577,
      "learning_rate": 1.901233274520629e-05,
      "loss": 0.0182,
      "step": 630
    },
    {
      "epoch": 0.42866847826086957,
      "grad_norm": 3.565743923187256,
      "learning_rate": 1.9009247675596412e-05,
      "loss": 0.1359,
      "step": 631
    },
    {
      "epoch": 0.42934782608695654,
      "grad_norm": 1.816211462020874,
      "learning_rate": 1.900615804635106e-05,
      "loss": 0.1656,
      "step": 632
    },
    {
      "epoch": 0.43002717391304346,
      "grad_norm": 0.14913980662822723,
      "learning_rate": 1.9003063859033906e-05,
      "loss": 0.0052,
      "step": 633
    },
    {
      "epoch": 0.43070652173913043,
      "grad_norm": 2.316849708557129,
      "learning_rate": 1.899996511521095e-05,
      "loss": 0.1235,
      "step": 634
    },
    {
      "epoch": 0.4313858695652174,
      "grad_norm": 9.156477928161621,
      "learning_rate": 1.8996861816450475e-05,
      "loss": 0.5524,
      "step": 635
    },
    {
      "epoch": 0.4320652173913043,
      "grad_norm": 2.754814624786377,
      "learning_rate": 1.8993753964323086e-05,
      "loss": 0.1618,
      "step": 636
    },
    {
      "epoch": 0.4327445652173913,
      "grad_norm": 2.0512535572052,
      "learning_rate": 1.899064156040168e-05,
      "loss": 0.2144,
      "step": 637
    },
    {
      "epoch": 0.43342391304347827,
      "grad_norm": 2.3691892623901367,
      "learning_rate": 1.8987524606261467e-05,
      "loss": 0.1999,
      "step": 638
    },
    {
      "epoch": 0.43410326086956524,
      "grad_norm": 3.04901385307312,
      "learning_rate": 1.8984403103479957e-05,
      "loss": 0.2142,
      "step": 639
    },
    {
      "epoch": 0.43478260869565216,
      "grad_norm": 0.47599732875823975,
      "learning_rate": 1.8981277053636963e-05,
      "loss": 0.0081,
      "step": 640
    },
    {
      "epoch": 0.43546195652173914,
      "grad_norm": 4.721704483032227,
      "learning_rate": 1.8978146458314596e-05,
      "loss": 0.1827,
      "step": 641
    },
    {
      "epoch": 0.4361413043478261,
      "grad_norm": 0.15646089613437653,
      "learning_rate": 1.8975011319097264e-05,
      "loss": 0.0045,
      "step": 642
    },
    {
      "epoch": 0.436820652173913,
      "grad_norm": 5.124727725982666,
      "learning_rate": 1.8971871637571692e-05,
      "loss": 0.113,
      "step": 643
    },
    {
      "epoch": 0.4375,
      "grad_norm": 0.72275710105896,
      "learning_rate": 1.8968727415326885e-05,
      "loss": 0.0161,
      "step": 644
    },
    {
      "epoch": 0.438179347826087,
      "grad_norm": 0.1566963493824005,
      "learning_rate": 1.8965578653954152e-05,
      "loss": 0.0059,
      "step": 645
    },
    {
      "epoch": 0.4388586956521739,
      "grad_norm": 6.5192742347717285,
      "learning_rate": 1.8962425355047106e-05,
      "loss": 0.3132,
      "step": 646
    },
    {
      "epoch": 0.43953804347826086,
      "grad_norm": 1.6490628719329834,
      "learning_rate": 1.8959267520201642e-05,
      "loss": 0.1295,
      "step": 647
    },
    {
      "epoch": 0.44021739130434784,
      "grad_norm": 5.286221504211426,
      "learning_rate": 1.8956105151015966e-05,
      "loss": 0.2061,
      "step": 648
    },
    {
      "epoch": 0.44089673913043476,
      "grad_norm": 0.8523200154304504,
      "learning_rate": 1.8952938249090574e-05,
      "loss": 0.0176,
      "step": 649
    },
    {
      "epoch": 0.44157608695652173,
      "grad_norm": 0.5310885310173035,
      "learning_rate": 1.894976681602825e-05,
      "loss": 0.0131,
      "step": 650
    },
    {
      "epoch": 0.4422554347826087,
      "grad_norm": 0.17202892899513245,
      "learning_rate": 1.894659085343408e-05,
      "loss": 0.0049,
      "step": 651
    },
    {
      "epoch": 0.4429347826086957,
      "grad_norm": 1.500489354133606,
      "learning_rate": 1.8943410362915437e-05,
      "loss": 0.1444,
      "step": 652
    },
    {
      "epoch": 0.4436141304347826,
      "grad_norm": 1.4257875680923462,
      "learning_rate": 1.894022534608198e-05,
      "loss": 0.1343,
      "step": 653
    },
    {
      "epoch": 0.44429347826086957,
      "grad_norm": 0.4301231801509857,
      "learning_rate": 1.893703580454567e-05,
      "loss": 0.0102,
      "step": 654
    },
    {
      "epoch": 0.44497282608695654,
      "grad_norm": 6.748326778411865,
      "learning_rate": 1.893384173992076e-05,
      "loss": 0.3588,
      "step": 655
    },
    {
      "epoch": 0.44565217391304346,
      "grad_norm": 7.88975191116333,
      "learning_rate": 1.8930643153823777e-05,
      "loss": 0.3031,
      "step": 656
    },
    {
      "epoch": 0.44633152173913043,
      "grad_norm": 2.0417542457580566,
      "learning_rate": 1.892744004787355e-05,
      "loss": 0.1563,
      "step": 657
    },
    {
      "epoch": 0.4470108695652174,
      "grad_norm": 3.8049821853637695,
      "learning_rate": 1.8924232423691188e-05,
      "loss": 0.2075,
      "step": 658
    },
    {
      "epoch": 0.4476902173913043,
      "grad_norm": 7.186004161834717,
      "learning_rate": 1.8921020282900092e-05,
      "loss": 0.2576,
      "step": 659
    },
    {
      "epoch": 0.4483695652173913,
      "grad_norm": 2.8770854473114014,
      "learning_rate": 1.891780362712594e-05,
      "loss": 0.1619,
      "step": 660
    },
    {
      "epoch": 0.44904891304347827,
      "grad_norm": 0.21306906640529633,
      "learning_rate": 1.8914582457996706e-05,
      "loss": 0.0065,
      "step": 661
    },
    {
      "epoch": 0.44972826086956524,
      "grad_norm": 6.958935737609863,
      "learning_rate": 1.8911356777142646e-05,
      "loss": 0.2775,
      "step": 662
    },
    {
      "epoch": 0.45040760869565216,
      "grad_norm": 3.542699098587036,
      "learning_rate": 1.890812658619629e-05,
      "loss": 0.0938,
      "step": 663
    },
    {
      "epoch": 0.45108695652173914,
      "grad_norm": 1.088838815689087,
      "learning_rate": 1.8904891886792465e-05,
      "loss": 0.1277,
      "step": 664
    },
    {
      "epoch": 0.4517663043478261,
      "grad_norm": 1.1758891344070435,
      "learning_rate": 1.8901652680568267e-05,
      "loss": 0.1249,
      "step": 665
    },
    {
      "epoch": 0.452445652173913,
      "grad_norm": 2.4261889457702637,
      "learning_rate": 1.8898408969163078e-05,
      "loss": 0.1141,
      "step": 666
    },
    {
      "epoch": 0.453125,
      "grad_norm": 4.872663974761963,
      "learning_rate": 1.8895160754218562e-05,
      "loss": 0.2318,
      "step": 667
    },
    {
      "epoch": 0.453804347826087,
      "grad_norm": 0.8247165083885193,
      "learning_rate": 1.889190803737866e-05,
      "loss": 0.0168,
      "step": 668
    },
    {
      "epoch": 0.4544836956521739,
      "grad_norm": 2.101238965988159,
      "learning_rate": 1.8888650820289594e-05,
      "loss": 0.2145,
      "step": 669
    },
    {
      "epoch": 0.45516304347826086,
      "grad_norm": 6.965130805969238,
      "learning_rate": 1.888538910459986e-05,
      "loss": 0.1933,
      "step": 670
    },
    {
      "epoch": 0.45584239130434784,
      "grad_norm": 0.6168774366378784,
      "learning_rate": 1.8882122891960226e-05,
      "loss": 0.0143,
      "step": 671
    },
    {
      "epoch": 0.45652173913043476,
      "grad_norm": 1.4666815996170044,
      "learning_rate": 1.8878852184023754e-05,
      "loss": 0.1519,
      "step": 672
    },
    {
      "epoch": 0.45720108695652173,
      "grad_norm": 0.2954407036304474,
      "learning_rate": 1.8875576982445764e-05,
      "loss": 0.007,
      "step": 673
    },
    {
      "epoch": 0.4578804347826087,
      "grad_norm": 1.556180715560913,
      "learning_rate": 1.887229728888385e-05,
      "loss": 0.1084,
      "step": 674
    },
    {
      "epoch": 0.4585597826086957,
      "grad_norm": 3.689924716949463,
      "learning_rate": 1.8869013104997896e-05,
      "loss": 0.2227,
      "step": 675
    },
    {
      "epoch": 0.4592391304347826,
      "grad_norm": 6.608108043670654,
      "learning_rate": 1.8865724432450036e-05,
      "loss": 0.1917,
      "step": 676
    },
    {
      "epoch": 0.45991847826086957,
      "grad_norm": 1.70066499710083,
      "learning_rate": 1.8862431272904697e-05,
      "loss": 0.048,
      "step": 677
    },
    {
      "epoch": 0.46059782608695654,
      "grad_norm": 8.383636474609375,
      "learning_rate": 1.8859133628028564e-05,
      "loss": 0.3217,
      "step": 678
    },
    {
      "epoch": 0.46127717391304346,
      "grad_norm": 1.3977272510528564,
      "learning_rate": 1.885583149949059e-05,
      "loss": 0.135,
      "step": 679
    },
    {
      "epoch": 0.46195652173913043,
      "grad_norm": 1.7194957733154297,
      "learning_rate": 1.885252488896201e-05,
      "loss": 0.1459,
      "step": 680
    },
    {
      "epoch": 0.4626358695652174,
      "grad_norm": 3.5008761882781982,
      "learning_rate": 1.8849213798116318e-05,
      "loss": 0.2188,
      "step": 681
    },
    {
      "epoch": 0.4633152173913043,
      "grad_norm": 0.6077522039413452,
      "learning_rate": 1.8845898228629273e-05,
      "loss": 0.0121,
      "step": 682
    },
    {
      "epoch": 0.4639945652173913,
      "grad_norm": 0.644625186920166,
      "learning_rate": 1.8842578182178912e-05,
      "loss": 0.0119,
      "step": 683
    },
    {
      "epoch": 0.46467391304347827,
      "grad_norm": 0.5081691741943359,
      "learning_rate": 1.8839253660445523e-05,
      "loss": 0.0105,
      "step": 684
    },
    {
      "epoch": 0.46535326086956524,
      "grad_norm": 5.103195667266846,
      "learning_rate": 1.8835924665111672e-05,
      "loss": 0.2162,
      "step": 685
    },
    {
      "epoch": 0.46603260869565216,
      "grad_norm": 3.2258989810943604,
      "learning_rate": 1.8832591197862186e-05,
      "loss": 0.1214,
      "step": 686
    },
    {
      "epoch": 0.46671195652173914,
      "grad_norm": 0.9971039891242981,
      "learning_rate": 1.882925326038415e-05,
      "loss": 0.017,
      "step": 687
    },
    {
      "epoch": 0.4673913043478261,
      "grad_norm": 2.3522791862487793,
      "learning_rate": 1.8825910854366914e-05,
      "loss": 0.097,
      "step": 688
    },
    {
      "epoch": 0.468070652173913,
      "grad_norm": 1.9994726181030273,
      "learning_rate": 1.8822563981502088e-05,
      "loss": 0.143,
      "step": 689
    },
    {
      "epoch": 0.46875,
      "grad_norm": 4.253862380981445,
      "learning_rate": 1.881921264348355e-05,
      "loss": 0.1051,
      "step": 690
    },
    {
      "epoch": 0.469429347826087,
      "grad_norm": 2.1231462955474854,
      "learning_rate": 1.8815856842007433e-05,
      "loss": 0.0493,
      "step": 691
    },
    {
      "epoch": 0.4701086956521739,
      "grad_norm": 1.998197078704834,
      "learning_rate": 1.8812496578772123e-05,
      "loss": 0.1346,
      "step": 692
    },
    {
      "epoch": 0.47078804347826086,
      "grad_norm": 1.0495343208312988,
      "learning_rate": 1.8809131855478276e-05,
      "loss": 0.0197,
      "step": 693
    },
    {
      "epoch": 0.47146739130434784,
      "grad_norm": 6.807335376739502,
      "learning_rate": 1.8805762673828792e-05,
      "loss": 0.3065,
      "step": 694
    },
    {
      "epoch": 0.47214673913043476,
      "grad_norm": 3.628615140914917,
      "learning_rate": 1.8802389035528842e-05,
      "loss": 0.1696,
      "step": 695
    },
    {
      "epoch": 0.47282608695652173,
      "grad_norm": 1.3323190212249756,
      "learning_rate": 1.879901094228584e-05,
      "loss": 0.1018,
      "step": 696
    },
    {
      "epoch": 0.4735054347826087,
      "grad_norm": 5.691460132598877,
      "learning_rate": 1.8795628395809464e-05,
      "loss": 0.208,
      "step": 697
    },
    {
      "epoch": 0.4741847826086957,
      "grad_norm": 2.9563143253326416,
      "learning_rate": 1.8792241397811634e-05,
      "loss": 0.0913,
      "step": 698
    },
    {
      "epoch": 0.4748641304347826,
      "grad_norm": 1.5397793054580688,
      "learning_rate": 1.878884995000654e-05,
      "loss": 0.0402,
      "step": 699
    },
    {
      "epoch": 0.47554347826086957,
      "grad_norm": 2.965841293334961,
      "learning_rate": 1.878545405411061e-05,
      "loss": 0.1151,
      "step": 700
    },
    {
      "epoch": 0.47622282608695654,
      "grad_norm": 2.052156448364258,
      "learning_rate": 1.8782053711842524e-05,
      "loss": 0.0471,
      "step": 701
    },
    {
      "epoch": 0.47690217391304346,
      "grad_norm": 2.0075907707214355,
      "learning_rate": 1.8778648924923222e-05,
      "loss": 0.0327,
      "step": 702
    },
    {
      "epoch": 0.47758152173913043,
      "grad_norm": 7.919178009033203,
      "learning_rate": 1.8775239695075883e-05,
      "loss": 0.0935,
      "step": 703
    },
    {
      "epoch": 0.4782608695652174,
      "grad_norm": 1.8663249015808105,
      "learning_rate": 1.8771826024025944e-05,
      "loss": 0.1157,
      "step": 704
    },
    {
      "epoch": 0.4789402173913043,
      "grad_norm": 2.7283074855804443,
      "learning_rate": 1.876840791350108e-05,
      "loss": 0.1179,
      "step": 705
    },
    {
      "epoch": 0.4796195652173913,
      "grad_norm": 5.516951084136963,
      "learning_rate": 1.876498536523122e-05,
      "loss": 0.2639,
      "step": 706
    },
    {
      "epoch": 0.48029891304347827,
      "grad_norm": 5.406129837036133,
      "learning_rate": 1.876155838094854e-05,
      "loss": 0.2325,
      "step": 707
    },
    {
      "epoch": 0.48097826086956524,
      "grad_norm": 2.412506580352783,
      "learning_rate": 1.875812696238745e-05,
      "loss": 0.1828,
      "step": 708
    },
    {
      "epoch": 0.48165760869565216,
      "grad_norm": 2.7659103870391846,
      "learning_rate": 1.875469111128462e-05,
      "loss": 0.1882,
      "step": 709
    },
    {
      "epoch": 0.48233695652173914,
      "grad_norm": 0.6169165372848511,
      "learning_rate": 1.875125082937895e-05,
      "loss": 0.013,
      "step": 710
    },
    {
      "epoch": 0.4830163043478261,
      "grad_norm": 0.3171866834163666,
      "learning_rate": 1.8747806118411588e-05,
      "loss": 0.0087,
      "step": 711
    },
    {
      "epoch": 0.483695652173913,
      "grad_norm": 6.893442153930664,
      "learning_rate": 1.8744356980125922e-05,
      "loss": 0.258,
      "step": 712
    },
    {
      "epoch": 0.484375,
      "grad_norm": 5.78602409362793,
      "learning_rate": 1.874090341626759e-05,
      "loss": 0.2304,
      "step": 713
    },
    {
      "epoch": 0.485054347826087,
      "grad_norm": 6.429765701293945,
      "learning_rate": 1.8737445428584456e-05,
      "loss": 0.1404,
      "step": 714
    },
    {
      "epoch": 0.4857336956521739,
      "grad_norm": 7.690478801727295,
      "learning_rate": 1.8733983018826626e-05,
      "loss": 0.2852,
      "step": 715
    },
    {
      "epoch": 0.48641304347826086,
      "grad_norm": 0.708670437335968,
      "learning_rate": 1.8730516188746452e-05,
      "loss": 0.0146,
      "step": 716
    },
    {
      "epoch": 0.48709239130434784,
      "grad_norm": 2.527399778366089,
      "learning_rate": 1.8727044940098516e-05,
      "loss": 0.1628,
      "step": 717
    },
    {
      "epoch": 0.48777173913043476,
      "grad_norm": 1.9840773344039917,
      "learning_rate": 1.872356927463964e-05,
      "loss": 0.1561,
      "step": 718
    },
    {
      "epoch": 0.48845108695652173,
      "grad_norm": 2.9898738861083984,
      "learning_rate": 1.8720089194128873e-05,
      "loss": 0.2224,
      "step": 719
    },
    {
      "epoch": 0.4891304347826087,
      "grad_norm": 9.473040580749512,
      "learning_rate": 1.8716604700327516e-05,
      "loss": 0.3482,
      "step": 720
    },
    {
      "epoch": 0.4898097826086957,
      "grad_norm": 2.9339687824249268,
      "learning_rate": 1.8713115794999083e-05,
      "loss": 0.1985,
      "step": 721
    },
    {
      "epoch": 0.4904891304347826,
      "grad_norm": 2.181488275527954,
      "learning_rate": 1.8709622479909333e-05,
      "loss": 0.13,
      "step": 722
    },
    {
      "epoch": 0.49116847826086957,
      "grad_norm": 3.7268197536468506,
      "learning_rate": 1.8706124756826255e-05,
      "loss": 0.1454,
      "step": 723
    },
    {
      "epoch": 0.49184782608695654,
      "grad_norm": 2.5108230113983154,
      "learning_rate": 1.870262262752007e-05,
      "loss": 0.1182,
      "step": 724
    },
    {
      "epoch": 0.49252717391304346,
      "grad_norm": 0.2653244137763977,
      "learning_rate": 1.8699116093763226e-05,
      "loss": 0.0058,
      "step": 725
    },
    {
      "epoch": 0.49320652173913043,
      "grad_norm": 1.6480015516281128,
      "learning_rate": 1.8695605157330398e-05,
      "loss": 0.0278,
      "step": 726
    },
    {
      "epoch": 0.4938858695652174,
      "grad_norm": 6.335744857788086,
      "learning_rate": 1.8692089819998498e-05,
      "loss": 0.1221,
      "step": 727
    },
    {
      "epoch": 0.4945652173913043,
      "grad_norm": 0.2638895511627197,
      "learning_rate": 1.8688570083546658e-05,
      "loss": 0.0067,
      "step": 728
    },
    {
      "epoch": 0.4952445652173913,
      "grad_norm": 0.14438198506832123,
      "learning_rate": 1.8685045949756232e-05,
      "loss": 0.0035,
      "step": 729
    },
    {
      "epoch": 0.49592391304347827,
      "grad_norm": 2.1074576377868652,
      "learning_rate": 1.8681517420410814e-05,
      "loss": 0.0394,
      "step": 730
    },
    {
      "epoch": 0.49660326086956524,
      "grad_norm": 3.490870475769043,
      "learning_rate": 1.8677984497296207e-05,
      "loss": 0.1854,
      "step": 731
    },
    {
      "epoch": 0.49728260869565216,
      "grad_norm": 0.9609547853469849,
      "learning_rate": 1.8674447182200457e-05,
      "loss": 0.0206,
      "step": 732
    },
    {
      "epoch": 0.49796195652173914,
      "grad_norm": 7.278867244720459,
      "learning_rate": 1.8670905476913805e-05,
      "loss": 0.2927,
      "step": 733
    },
    {
      "epoch": 0.4986413043478261,
      "grad_norm": 3.2039802074432373,
      "learning_rate": 1.8667359383228745e-05,
      "loss": 0.2352,
      "step": 734
    },
    {
      "epoch": 0.499320652173913,
      "grad_norm": 0.37418028712272644,
      "learning_rate": 1.8663808902939965e-05,
      "loss": 0.0091,
      "step": 735
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3617258071899414,
      "learning_rate": 1.866025403784439e-05,
      "loss": 0.0087,
      "step": 736
    },
    {
      "epoch": 0.5006793478260869,
      "grad_norm": 0.5102481245994568,
      "learning_rate": 1.8656694789741157e-05,
      "loss": 0.0094,
      "step": 737
    },
    {
      "epoch": 0.501358695652174,
      "grad_norm": 2.1267037391662598,
      "learning_rate": 1.8653131160431622e-05,
      "loss": 0.123,
      "step": 738
    },
    {
      "epoch": 0.5020380434782609,
      "grad_norm": 1.594632863998413,
      "learning_rate": 1.864956315171937e-05,
      "loss": 0.15,
      "step": 739
    },
    {
      "epoch": 0.5027173913043478,
      "grad_norm": 3.8084323406219482,
      "learning_rate": 1.864599076541018e-05,
      "loss": 0.2482,
      "step": 740
    },
    {
      "epoch": 0.5033967391304348,
      "grad_norm": 5.005724906921387,
      "learning_rate": 1.8642414003312063e-05,
      "loss": 0.1009,
      "step": 741
    },
    {
      "epoch": 0.5040760869565217,
      "grad_norm": 5.884949207305908,
      "learning_rate": 1.8638832867235238e-05,
      "loss": 0.2709,
      "step": 742
    },
    {
      "epoch": 0.5047554347826086,
      "grad_norm": 0.35056206583976746,
      "learning_rate": 1.8635247358992146e-05,
      "loss": 0.0073,
      "step": 743
    },
    {
      "epoch": 0.5054347826086957,
      "grad_norm": 2.4111404418945312,
      "learning_rate": 1.863165748039743e-05,
      "loss": 0.199,
      "step": 744
    },
    {
      "epoch": 0.5061141304347826,
      "grad_norm": 0.24007080495357513,
      "learning_rate": 1.8628063233267948e-05,
      "loss": 0.0049,
      "step": 745
    },
    {
      "epoch": 0.5067934782608695,
      "grad_norm": 1.3715686798095703,
      "learning_rate": 1.8624464619422776e-05,
      "loss": 0.071,
      "step": 746
    },
    {
      "epoch": 0.5074728260869565,
      "grad_norm": 6.4624505043029785,
      "learning_rate": 1.862086164068319e-05,
      "loss": 0.2368,
      "step": 747
    },
    {
      "epoch": 0.5081521739130435,
      "grad_norm": 0.11452465504407883,
      "learning_rate": 1.861725429887268e-05,
      "loss": 0.0033,
      "step": 748
    },
    {
      "epoch": 0.5088315217391305,
      "grad_norm": 0.5612211227416992,
      "learning_rate": 1.8613642595816947e-05,
      "loss": 0.0125,
      "step": 749
    },
    {
      "epoch": 0.5095108695652174,
      "grad_norm": 2.572366952896118,
      "learning_rate": 1.861002653334389e-05,
      "loss": 0.1698,
      "step": 750
    },
    {
      "epoch": 0.5101902173913043,
      "grad_norm": 0.5835549831390381,
      "learning_rate": 1.8606406113283625e-05,
      "loss": 0.0126,
      "step": 751
    },
    {
      "epoch": 0.5108695652173914,
      "grad_norm": 0.2820935547351837,
      "learning_rate": 1.8602781337468472e-05,
      "loss": 0.0055,
      "step": 752
    },
    {
      "epoch": 0.5115489130434783,
      "grad_norm": 0.25888752937316895,
      "learning_rate": 1.8599152207732945e-05,
      "loss": 0.0059,
      "step": 753
    },
    {
      "epoch": 0.5122282608695652,
      "grad_norm": 0.5500969290733337,
      "learning_rate": 1.8595518725913773e-05,
      "loss": 0.01,
      "step": 754
    },
    {
      "epoch": 0.5129076086956522,
      "grad_norm": 2.4511470794677734,
      "learning_rate": 1.859188089384988e-05,
      "loss": 0.0733,
      "step": 755
    },
    {
      "epoch": 0.5135869565217391,
      "grad_norm": 2.0124261379241943,
      "learning_rate": 1.85882387133824e-05,
      "loss": 0.1083,
      "step": 756
    },
    {
      "epoch": 0.514266304347826,
      "grad_norm": 2.412287712097168,
      "learning_rate": 1.858459218635466e-05,
      "loss": 0.0864,
      "step": 757
    },
    {
      "epoch": 0.5149456521739131,
      "grad_norm": 1.423462152481079,
      "learning_rate": 1.8580941314612193e-05,
      "loss": 0.0843,
      "step": 758
    },
    {
      "epoch": 0.515625,
      "grad_norm": 1.3518439531326294,
      "learning_rate": 1.8577286100002723e-05,
      "loss": 0.0977,
      "step": 759
    },
    {
      "epoch": 0.5163043478260869,
      "grad_norm": 1.3750958442687988,
      "learning_rate": 1.857362654437618e-05,
      "loss": 0.1249,
      "step": 760
    },
    {
      "epoch": 0.516983695652174,
      "grad_norm": 1.0452303886413574,
      "learning_rate": 1.856996264958468e-05,
      "loss": 0.0205,
      "step": 761
    },
    {
      "epoch": 0.5176630434782609,
      "grad_norm": 5.898455619812012,
      "learning_rate": 1.8566294417482552e-05,
      "loss": 0.2365,
      "step": 762
    },
    {
      "epoch": 0.5183423913043478,
      "grad_norm": 7.378596305847168,
      "learning_rate": 1.856262184992631e-05,
      "loss": 0.1651,
      "step": 763
    },
    {
      "epoch": 0.5190217391304348,
      "grad_norm": 3.1020760536193848,
      "learning_rate": 1.8558944948774655e-05,
      "loss": 0.1801,
      "step": 764
    },
    {
      "epoch": 0.5197010869565217,
      "grad_norm": 2.9433045387268066,
      "learning_rate": 1.8555263715888493e-05,
      "loss": 0.1294,
      "step": 765
    },
    {
      "epoch": 0.5203804347826086,
      "grad_norm": 3.115222215652466,
      "learning_rate": 1.8551578153130926e-05,
      "loss": 0.1988,
      "step": 766
    },
    {
      "epoch": 0.5210597826086957,
      "grad_norm": 1.2918567657470703,
      "learning_rate": 1.8547888262367232e-05,
      "loss": 0.1037,
      "step": 767
    },
    {
      "epoch": 0.5217391304347826,
      "grad_norm": 0.39493700861930847,
      "learning_rate": 1.8544194045464888e-05,
      "loss": 0.007,
      "step": 768
    },
    {
      "epoch": 0.5224184782608695,
      "grad_norm": 5.18803071975708,
      "learning_rate": 1.854049550429356e-05,
      "loss": 0.2744,
      "step": 769
    },
    {
      "epoch": 0.5230978260869565,
      "grad_norm": 11.27304744720459,
      "learning_rate": 1.8536792640725103e-05,
      "loss": 0.643,
      "step": 770
    },
    {
      "epoch": 0.5237771739130435,
      "grad_norm": 2.3973960876464844,
      "learning_rate": 1.853308545663356e-05,
      "loss": 0.1744,
      "step": 771
    },
    {
      "epoch": 0.5244565217391305,
      "grad_norm": 0.12273354083299637,
      "learning_rate": 1.852937395389516e-05,
      "loss": 0.0035,
      "step": 772
    },
    {
      "epoch": 0.5251358695652174,
      "grad_norm": 13.511280059814453,
      "learning_rate": 1.852565813438832e-05,
      "loss": 0.4414,
      "step": 773
    },
    {
      "epoch": 0.5258152173913043,
      "grad_norm": 1.532664179801941,
      "learning_rate": 1.8521937999993627e-05,
      "loss": 0.1521,
      "step": 774
    },
    {
      "epoch": 0.5264945652173914,
      "grad_norm": 9.339057922363281,
      "learning_rate": 1.8518213552593877e-05,
      "loss": 0.2188,
      "step": 775
    },
    {
      "epoch": 0.5271739130434783,
      "grad_norm": 9.21480655670166,
      "learning_rate": 1.8514484794074028e-05,
      "loss": 0.3375,
      "step": 776
    },
    {
      "epoch": 0.5278532608695652,
      "grad_norm": 1.881701111793518,
      "learning_rate": 1.8510751726321233e-05,
      "loss": 0.0293,
      "step": 777
    },
    {
      "epoch": 0.5285326086956522,
      "grad_norm": 2.226717233657837,
      "learning_rate": 1.8507014351224816e-05,
      "loss": 0.1179,
      "step": 778
    },
    {
      "epoch": 0.5292119565217391,
      "grad_norm": 0.18796002864837646,
      "learning_rate": 1.8503272670676286e-05,
      "loss": 0.0035,
      "step": 779
    },
    {
      "epoch": 0.529891304347826,
      "grad_norm": 3.69610333442688,
      "learning_rate": 1.849952668656933e-05,
      "loss": 0.1172,
      "step": 780
    },
    {
      "epoch": 0.5305706521739131,
      "grad_norm": 13.652363777160645,
      "learning_rate": 1.849577640079982e-05,
      "loss": 0.7182,
      "step": 781
    },
    {
      "epoch": 0.53125,
      "grad_norm": 1.921983003616333,
      "learning_rate": 1.849202181526579e-05,
      "loss": 0.0751,
      "step": 782
    },
    {
      "epoch": 0.5319293478260869,
      "grad_norm": 6.986213684082031,
      "learning_rate": 1.8488262931867464e-05,
      "loss": 0.2657,
      "step": 783
    },
    {
      "epoch": 0.532608695652174,
      "grad_norm": 5.593765735626221,
      "learning_rate": 1.8484499752507234e-05,
      "loss": 0.2943,
      "step": 784
    },
    {
      "epoch": 0.5332880434782609,
      "grad_norm": 1.9383563995361328,
      "learning_rate": 1.8480732279089667e-05,
      "loss": 0.043,
      "step": 785
    },
    {
      "epoch": 0.5339673913043478,
      "grad_norm": 3.778822422027588,
      "learning_rate": 1.847696051352151e-05,
      "loss": 0.1238,
      "step": 786
    },
    {
      "epoch": 0.5346467391304348,
      "grad_norm": 0.5697230696678162,
      "learning_rate": 1.847318445771167e-05,
      "loss": 0.0092,
      "step": 787
    },
    {
      "epoch": 0.5353260869565217,
      "grad_norm": 0.2962706685066223,
      "learning_rate": 1.8469404113571235e-05,
      "loss": 0.005,
      "step": 788
    },
    {
      "epoch": 0.5360054347826086,
      "grad_norm": 4.9029035568237305,
      "learning_rate": 1.846561948301346e-05,
      "loss": 0.202,
      "step": 789
    },
    {
      "epoch": 0.5366847826086957,
      "grad_norm": 1.1046650409698486,
      "learning_rate": 1.846183056795377e-05,
      "loss": 0.0233,
      "step": 790
    },
    {
      "epoch": 0.5373641304347826,
      "grad_norm": 9.365485191345215,
      "learning_rate": 1.8458037370309757e-05,
      "loss": 0.3431,
      "step": 791
    },
    {
      "epoch": 0.5380434782608695,
      "grad_norm": 3.2406885623931885,
      "learning_rate": 1.845423989200118e-05,
      "loss": 0.1899,
      "step": 792
    },
    {
      "epoch": 0.5387228260869565,
      "grad_norm": 3.444983959197998,
      "learning_rate": 1.845043813494997e-05,
      "loss": 0.2323,
      "step": 793
    },
    {
      "epoch": 0.5394021739130435,
      "grad_norm": 0.8185479640960693,
      "learning_rate": 1.844663210108022e-05,
      "loss": 0.0126,
      "step": 794
    },
    {
      "epoch": 0.5400815217391305,
      "grad_norm": 0.6327653527259827,
      "learning_rate": 1.8442821792318183e-05,
      "loss": 0.0098,
      "step": 795
    },
    {
      "epoch": 0.5407608695652174,
      "grad_norm": 2.9986989498138428,
      "learning_rate": 1.8439007210592282e-05,
      "loss": 0.0712,
      "step": 796
    },
    {
      "epoch": 0.5414402173913043,
      "grad_norm": 0.30741143226623535,
      "learning_rate": 1.84351883578331e-05,
      "loss": 0.0058,
      "step": 797
    },
    {
      "epoch": 0.5421195652173914,
      "grad_norm": 0.25297120213508606,
      "learning_rate": 1.8431365235973383e-05,
      "loss": 0.0049,
      "step": 798
    },
    {
      "epoch": 0.5427989130434783,
      "grad_norm": 3.062774419784546,
      "learning_rate": 1.842753784694803e-05,
      "loss": 0.1639,
      "step": 799
    },
    {
      "epoch": 0.5434782608695652,
      "grad_norm": 3.159968137741089,
      "learning_rate": 1.8423706192694118e-05,
      "loss": 0.1229,
      "step": 800
    },
    {
      "epoch": 0.5441576086956522,
      "grad_norm": 0.08574248105287552,
      "learning_rate": 1.841987027515086e-05,
      "loss": 0.0022,
      "step": 801
    },
    {
      "epoch": 0.5448369565217391,
      "grad_norm": 3.0111796855926514,
      "learning_rate": 1.8416030096259643e-05,
      "loss": 0.1555,
      "step": 802
    },
    {
      "epoch": 0.545516304347826,
      "grad_norm": 9.070019721984863,
      "learning_rate": 1.8412185657964e-05,
      "loss": 0.389,
      "step": 803
    },
    {
      "epoch": 0.5461956521739131,
      "grad_norm": 5.534566402435303,
      "learning_rate": 1.840833696220963e-05,
      "loss": 0.2561,
      "step": 804
    },
    {
      "epoch": 0.546875,
      "grad_norm": 6.618236541748047,
      "learning_rate": 1.840448401094438e-05,
      "loss": 0.4007,
      "step": 805
    },
    {
      "epoch": 0.5475543478260869,
      "grad_norm": 1.6895800828933716,
      "learning_rate": 1.8400626806118253e-05,
      "loss": 0.1312,
      "step": 806
    },
    {
      "epoch": 0.548233695652174,
      "grad_norm": 0.7066085934638977,
      "learning_rate": 1.8396765349683404e-05,
      "loss": 0.0107,
      "step": 807
    },
    {
      "epoch": 0.5489130434782609,
      "grad_norm": 5.445889472961426,
      "learning_rate": 1.8392899643594135e-05,
      "loss": 0.2203,
      "step": 808
    },
    {
      "epoch": 0.5495923913043478,
      "grad_norm": 6.7023115158081055,
      "learning_rate": 1.8389029689806907e-05,
      "loss": 0.3241,
      "step": 809
    },
    {
      "epoch": 0.5502717391304348,
      "grad_norm": 1.4085577726364136,
      "learning_rate": 1.8385155490280327e-05,
      "loss": 0.0796,
      "step": 810
    },
    {
      "epoch": 0.5509510869565217,
      "grad_norm": 2.491903066635132,
      "learning_rate": 1.8381277046975156e-05,
      "loss": 0.1634,
      "step": 811
    },
    {
      "epoch": 0.5516304347826086,
      "grad_norm": 2.8261609077453613,
      "learning_rate": 1.837739436185429e-05,
      "loss": 0.1813,
      "step": 812
    },
    {
      "epoch": 0.5523097826086957,
      "grad_norm": 5.248758316040039,
      "learning_rate": 1.8373507436882784e-05,
      "loss": 0.3003,
      "step": 813
    },
    {
      "epoch": 0.5529891304347826,
      "grad_norm": 2.1793692111968994,
      "learning_rate": 1.836961627402783e-05,
      "loss": 0.1119,
      "step": 814
    },
    {
      "epoch": 0.5536684782608695,
      "grad_norm": 2.6624057292938232,
      "learning_rate": 1.8365720875258783e-05,
      "loss": 0.1744,
      "step": 815
    },
    {
      "epoch": 0.5543478260869565,
      "grad_norm": 7.516827583312988,
      "learning_rate": 1.836182124254711e-05,
      "loss": 0.393,
      "step": 816
    },
    {
      "epoch": 0.5550271739130435,
      "grad_norm": 1.42111337184906,
      "learning_rate": 1.835791737786645e-05,
      "loss": 0.1622,
      "step": 817
    },
    {
      "epoch": 0.5557065217391305,
      "grad_norm": 3.0704054832458496,
      "learning_rate": 1.835400928319257e-05,
      "loss": 0.1299,
      "step": 818
    },
    {
      "epoch": 0.5563858695652174,
      "grad_norm": 0.34382328391075134,
      "learning_rate": 1.8350096960503383e-05,
      "loss": 0.0044,
      "step": 819
    },
    {
      "epoch": 0.5570652173913043,
      "grad_norm": 0.7250897884368896,
      "learning_rate": 1.8346180411778934e-05,
      "loss": 0.0105,
      "step": 820
    },
    {
      "epoch": 0.5577445652173914,
      "grad_norm": 2.240427017211914,
      "learning_rate": 1.8342259639001415e-05,
      "loss": 0.1605,
      "step": 821
    },
    {
      "epoch": 0.5584239130434783,
      "grad_norm": 5.259670734405518,
      "learning_rate": 1.833833464415516e-05,
      "loss": 0.1279,
      "step": 822
    },
    {
      "epoch": 0.5591032608695652,
      "grad_norm": 0.9082669019699097,
      "learning_rate": 1.833440542922662e-05,
      "loss": 0.0169,
      "step": 823
    },
    {
      "epoch": 0.5597826086956522,
      "grad_norm": 2.9027512073516846,
      "learning_rate": 1.8330471996204408e-05,
      "loss": 0.1901,
      "step": 824
    },
    {
      "epoch": 0.5604619565217391,
      "grad_norm": 3.8283097743988037,
      "learning_rate": 1.832653434707925e-05,
      "loss": 0.1169,
      "step": 825
    },
    {
      "epoch": 0.561141304347826,
      "grad_norm": 0.6217104196548462,
      "learning_rate": 1.832259248384401e-05,
      "loss": 0.0092,
      "step": 826
    },
    {
      "epoch": 0.5618206521739131,
      "grad_norm": 1.7470431327819824,
      "learning_rate": 1.8318646408493704e-05,
      "loss": 0.1246,
      "step": 827
    },
    {
      "epoch": 0.5625,
      "grad_norm": 8.565500259399414,
      "learning_rate": 1.8314696123025456e-05,
      "loss": 0.341,
      "step": 828
    },
    {
      "epoch": 0.5631793478260869,
      "grad_norm": 1.8469804525375366,
      "learning_rate": 1.8310741629438528e-05,
      "loss": 0.1028,
      "step": 829
    },
    {
      "epoch": 0.563858695652174,
      "grad_norm": 2.9101030826568604,
      "learning_rate": 1.8306782929734313e-05,
      "loss": 0.1846,
      "step": 830
    },
    {
      "epoch": 0.5645380434782609,
      "grad_norm": 2.2642219066619873,
      "learning_rate": 1.830282002591634e-05,
      "loss": 0.1864,
      "step": 831
    },
    {
      "epoch": 0.5652173913043478,
      "grad_norm": 6.641324520111084,
      "learning_rate": 1.8298852919990254e-05,
      "loss": 0.3283,
      "step": 832
    },
    {
      "epoch": 0.5658967391304348,
      "grad_norm": 2.550204277038574,
      "learning_rate": 1.829488161396383e-05,
      "loss": 0.0974,
      "step": 833
    },
    {
      "epoch": 0.5665760869565217,
      "grad_norm": 2.326948404312134,
      "learning_rate": 1.8290906109846974e-05,
      "loss": 0.1793,
      "step": 834
    },
    {
      "epoch": 0.5672554347826086,
      "grad_norm": 1.519120216369629,
      "learning_rate": 1.8286926409651714e-05,
      "loss": 0.1087,
      "step": 835
    },
    {
      "epoch": 0.5679347826086957,
      "grad_norm": 2.4797775745391846,
      "learning_rate": 1.82829425153922e-05,
      "loss": 0.2164,
      "step": 836
    },
    {
      "epoch": 0.5686141304347826,
      "grad_norm": 3.2982125282287598,
      "learning_rate": 1.82789544290847e-05,
      "loss": 0.1243,
      "step": 837
    },
    {
      "epoch": 0.5692934782608695,
      "grad_norm": 1.3184937238693237,
      "learning_rate": 1.8274962152747613e-05,
      "loss": 0.108,
      "step": 838
    },
    {
      "epoch": 0.5699728260869565,
      "grad_norm": 2.792006015777588,
      "learning_rate": 1.8270965688401453e-05,
      "loss": 0.1744,
      "step": 839
    },
    {
      "epoch": 0.5706521739130435,
      "grad_norm": 20.74385643005371,
      "learning_rate": 1.8266965038068856e-05,
      "loss": 0.2867,
      "step": 840
    },
    {
      "epoch": 0.5713315217391305,
      "grad_norm": 3.378324031829834,
      "learning_rate": 1.8262960203774584e-05,
      "loss": 0.1909,
      "step": 841
    },
    {
      "epoch": 0.5720108695652174,
      "grad_norm": 2.5839552879333496,
      "learning_rate": 1.825895118754549e-05,
      "loss": 0.1871,
      "step": 842
    },
    {
      "epoch": 0.5726902173913043,
      "grad_norm": 1.8033745288848877,
      "learning_rate": 1.825493799141058e-05,
      "loss": 0.0949,
      "step": 843
    },
    {
      "epoch": 0.5733695652173914,
      "grad_norm": 3.367683172225952,
      "learning_rate": 1.8250920617400943e-05,
      "loss": 0.0398,
      "step": 844
    },
    {
      "epoch": 0.5740489130434783,
      "grad_norm": 3.4347472190856934,
      "learning_rate": 1.8246899067549804e-05,
      "loss": 0.0782,
      "step": 845
    },
    {
      "epoch": 0.5747282608695652,
      "grad_norm": 1.714568018913269,
      "learning_rate": 1.8242873343892494e-05,
      "loss": 0.021,
      "step": 846
    },
    {
      "epoch": 0.5754076086956522,
      "grad_norm": 3.712477922439575,
      "learning_rate": 1.8238843448466456e-05,
      "loss": 0.1555,
      "step": 847
    },
    {
      "epoch": 0.5760869565217391,
      "grad_norm": 5.175590515136719,
      "learning_rate": 1.823480938331124e-05,
      "loss": 0.3663,
      "step": 848
    },
    {
      "epoch": 0.576766304347826,
      "grad_norm": 1.3086578845977783,
      "learning_rate": 1.8230771150468517e-05,
      "loss": 0.019,
      "step": 849
    },
    {
      "epoch": 0.5774456521739131,
      "grad_norm": 1.6538610458374023,
      "learning_rate": 1.822672875198206e-05,
      "loss": 0.0856,
      "step": 850
    },
    {
      "epoch": 0.578125,
      "grad_norm": 1.1633819341659546,
      "learning_rate": 1.822268218989775e-05,
      "loss": 0.0854,
      "step": 851
    },
    {
      "epoch": 0.5788043478260869,
      "grad_norm": 3.8816144466400146,
      "learning_rate": 1.8218631466263584e-05,
      "loss": 0.1019,
      "step": 852
    },
    {
      "epoch": 0.579483695652174,
      "grad_norm": 1.5104639530181885,
      "learning_rate": 1.8214576583129646e-05,
      "loss": 0.0878,
      "step": 853
    },
    {
      "epoch": 0.5801630434782609,
      "grad_norm": 1.7743433713912964,
      "learning_rate": 1.8210517542548145e-05,
      "loss": 0.0277,
      "step": 854
    },
    {
      "epoch": 0.5808423913043478,
      "grad_norm": 0.36843180656433105,
      "learning_rate": 1.820645434657338e-05,
      "loss": 0.0079,
      "step": 855
    },
    {
      "epoch": 0.5815217391304348,
      "grad_norm": 0.3802299499511719,
      "learning_rate": 1.820238699726177e-05,
      "loss": 0.0071,
      "step": 856
    },
    {
      "epoch": 0.5822010869565217,
      "grad_norm": 0.7924767136573792,
      "learning_rate": 1.8198315496671815e-05,
      "loss": 0.0264,
      "step": 857
    },
    {
      "epoch": 0.5828804347826086,
      "grad_norm": 2.638817310333252,
      "learning_rate": 1.8194239846864133e-05,
      "loss": 0.1623,
      "step": 858
    },
    {
      "epoch": 0.5835597826086957,
      "grad_norm": 1.772749662399292,
      "learning_rate": 1.819016004990143e-05,
      "loss": 0.1064,
      "step": 859
    },
    {
      "epoch": 0.5842391304347826,
      "grad_norm": 0.12084918469190598,
      "learning_rate": 1.8186076107848524e-05,
      "loss": 0.0025,
      "step": 860
    },
    {
      "epoch": 0.5849184782608695,
      "grad_norm": 4.59947395324707,
      "learning_rate": 1.8181988022772315e-05,
      "loss": 0.2184,
      "step": 861
    },
    {
      "epoch": 0.5855978260869565,
      "grad_norm": 1.3146941661834717,
      "learning_rate": 1.817789579674181e-05,
      "loss": 0.0241,
      "step": 862
    },
    {
      "epoch": 0.5862771739130435,
      "grad_norm": 5.122148036956787,
      "learning_rate": 1.8173799431828116e-05,
      "loss": 0.2141,
      "step": 863
    },
    {
      "epoch": 0.5869565217391305,
      "grad_norm": 2.548367977142334,
      "learning_rate": 1.816969893010442e-05,
      "loss": 0.127,
      "step": 864
    },
    {
      "epoch": 0.5876358695652174,
      "grad_norm": 0.3191685676574707,
      "learning_rate": 1.8165594293646016e-05,
      "loss": 0.0066,
      "step": 865
    },
    {
      "epoch": 0.5883152173913043,
      "grad_norm": 2.5538365840911865,
      "learning_rate": 1.8161485524530283e-05,
      "loss": 0.0718,
      "step": 866
    },
    {
      "epoch": 0.5889945652173914,
      "grad_norm": 3.019099712371826,
      "learning_rate": 1.81573726248367e-05,
      "loss": 0.2563,
      "step": 867
    },
    {
      "epoch": 0.5896739130434783,
      "grad_norm": 16.566831588745117,
      "learning_rate": 1.8153255596646818e-05,
      "loss": 0.7615,
      "step": 868
    },
    {
      "epoch": 0.5903532608695652,
      "grad_norm": 6.290346622467041,
      "learning_rate": 1.8149134442044305e-05,
      "loss": 0.2216,
      "step": 869
    },
    {
      "epoch": 0.5910326086956522,
      "grad_norm": 4.875074863433838,
      "learning_rate": 1.8145009163114894e-05,
      "loss": 0.1861,
      "step": 870
    },
    {
      "epoch": 0.5917119565217391,
      "grad_norm": 0.46973085403442383,
      "learning_rate": 1.8140879761946414e-05,
      "loss": 0.0086,
      "step": 871
    },
    {
      "epoch": 0.592391304347826,
      "grad_norm": 9.561877250671387,
      "learning_rate": 1.8136746240628783e-05,
      "loss": 0.381,
      "step": 872
    },
    {
      "epoch": 0.5930706521739131,
      "grad_norm": 0.12731611728668213,
      "learning_rate": 1.8132608601254003e-05,
      "loss": 0.0017,
      "step": 873
    },
    {
      "epoch": 0.59375,
      "grad_norm": 1.7262276411056519,
      "learning_rate": 1.8128466845916156e-05,
      "loss": 0.0404,
      "step": 874
    },
    {
      "epoch": 0.5944293478260869,
      "grad_norm": 6.667882919311523,
      "learning_rate": 1.8124320976711404e-05,
      "loss": 0.2422,
      "step": 875
    },
    {
      "epoch": 0.595108695652174,
      "grad_norm": 0.2987211048603058,
      "learning_rate": 1.812017099573801e-05,
      "loss": 0.0053,
      "step": 876
    },
    {
      "epoch": 0.5957880434782609,
      "grad_norm": 0.25474026799201965,
      "learning_rate": 1.8116016905096295e-05,
      "loss": 0.0056,
      "step": 877
    },
    {
      "epoch": 0.5964673913043478,
      "grad_norm": 0.6601653695106506,
      "learning_rate": 1.8111858706888673e-05,
      "loss": 0.0098,
      "step": 878
    },
    {
      "epoch": 0.5971467391304348,
      "grad_norm": 4.131824016571045,
      "learning_rate": 1.810769640321963e-05,
      "loss": 0.2219,
      "step": 879
    },
    {
      "epoch": 0.5978260869565217,
      "grad_norm": 2.3094990253448486,
      "learning_rate": 1.810352999619574e-05,
      "loss": 0.1105,
      "step": 880
    },
    {
      "epoch": 0.5985054347826086,
      "grad_norm": 4.653017044067383,
      "learning_rate": 1.8099359487925644e-05,
      "loss": 0.1143,
      "step": 881
    },
    {
      "epoch": 0.5991847826086957,
      "grad_norm": 9.388370513916016,
      "learning_rate": 1.8095184880520058e-05,
      "loss": 0.5389,
      "step": 882
    },
    {
      "epoch": 0.5998641304347826,
      "grad_norm": 3.295137882232666,
      "learning_rate": 1.809100617609178e-05,
      "loss": 0.0701,
      "step": 883
    },
    {
      "epoch": 0.6005434782608695,
      "grad_norm": 2.1643457412719727,
      "learning_rate": 1.808682337675568e-05,
      "loss": 0.1146,
      "step": 884
    },
    {
      "epoch": 0.6012228260869565,
      "grad_norm": 1.453335165977478,
      "learning_rate": 1.80826364846287e-05,
      "loss": 0.0213,
      "step": 885
    },
    {
      "epoch": 0.6019021739130435,
      "grad_norm": 6.513629913330078,
      "learning_rate": 1.807844550182984e-05,
      "loss": 0.2617,
      "step": 886
    },
    {
      "epoch": 0.6025815217391305,
      "grad_norm": 2.462620496749878,
      "learning_rate": 1.8074250430480193e-05,
      "loss": 0.0805,
      "step": 887
    },
    {
      "epoch": 0.6032608695652174,
      "grad_norm": 0.5183205008506775,
      "learning_rate": 1.8070051272702905e-05,
      "loss": 0.0094,
      "step": 888
    },
    {
      "epoch": 0.6039402173913043,
      "grad_norm": 2.3548741340637207,
      "learning_rate": 1.8065848030623203e-05,
      "loss": 0.0528,
      "step": 889
    },
    {
      "epoch": 0.6046195652173914,
      "grad_norm": 0.12090139091014862,
      "learning_rate": 1.8061640706368364e-05,
      "loss": 0.0024,
      "step": 890
    },
    {
      "epoch": 0.6052989130434783,
      "grad_norm": 3.988654613494873,
      "learning_rate": 1.8057429302067748e-05,
      "loss": 0.1391,
      "step": 891
    },
    {
      "epoch": 0.6059782608695652,
      "grad_norm": 1.8573414087295532,
      "learning_rate": 1.8053213819852765e-05,
      "loss": 0.0697,
      "step": 892
    },
    {
      "epoch": 0.6066576086956522,
      "grad_norm": 0.28648829460144043,
      "learning_rate": 1.8048994261856908e-05,
      "loss": 0.0055,
      "step": 893
    },
    {
      "epoch": 0.6073369565217391,
      "grad_norm": 2.8574538230895996,
      "learning_rate": 1.8044770630215706e-05,
      "loss": 0.2472,
      "step": 894
    },
    {
      "epoch": 0.608016304347826,
      "grad_norm": 6.209839344024658,
      "learning_rate": 1.804054292706678e-05,
      "loss": 0.357,
      "step": 895
    },
    {
      "epoch": 0.6086956521739131,
      "grad_norm": 1.6857858896255493,
      "learning_rate": 1.8036311154549783e-05,
      "loss": 0.0606,
      "step": 896
    },
    {
      "epoch": 0.609375,
      "grad_norm": 0.21960432827472687,
      "learning_rate": 1.803207531480645e-05,
      "loss": 0.0038,
      "step": 897
    },
    {
      "epoch": 0.6100543478260869,
      "grad_norm": 1.0373133420944214,
      "learning_rate": 1.8027835409980565e-05,
      "loss": 0.0195,
      "step": 898
    },
    {
      "epoch": 0.610733695652174,
      "grad_norm": 0.8970218300819397,
      "learning_rate": 1.8023591442217965e-05,
      "loss": 0.014,
      "step": 899
    },
    {
      "epoch": 0.6114130434782609,
      "grad_norm": 5.167877197265625,
      "learning_rate": 1.801934341366655e-05,
      "loss": 0.2388,
      "step": 900
    },
    {
      "epoch": 0.6120923913043478,
      "grad_norm": 2.776660919189453,
      "learning_rate": 1.8015091326476275e-05,
      "loss": 0.1858,
      "step": 901
    },
    {
      "epoch": 0.6127717391304348,
      "grad_norm": 3.81021785736084,
      "learning_rate": 1.801083518279915e-05,
      "loss": 0.1605,
      "step": 902
    },
    {
      "epoch": 0.6134510869565217,
      "grad_norm": 0.34359675645828247,
      "learning_rate": 1.8006574984789226e-05,
      "loss": 0.0066,
      "step": 903
    },
    {
      "epoch": 0.6141304347826086,
      "grad_norm": 5.462629795074463,
      "learning_rate": 1.8002310734602625e-05,
      "loss": 0.1794,
      "step": 904
    },
    {
      "epoch": 0.6148097826086957,
      "grad_norm": 0.8566439151763916,
      "learning_rate": 1.7998042434397507e-05,
      "loss": 0.0124,
      "step": 905
    },
    {
      "epoch": 0.6154891304347826,
      "grad_norm": 0.4430759847164154,
      "learning_rate": 1.7993770086334082e-05,
      "loss": 0.0076,
      "step": 906
    },
    {
      "epoch": 0.6161684782608695,
      "grad_norm": 7.481510639190674,
      "learning_rate": 1.7989493692574614e-05,
      "loss": 0.2041,
      "step": 907
    },
    {
      "epoch": 0.6168478260869565,
      "grad_norm": 0.5370191335678101,
      "learning_rate": 1.7985213255283412e-05,
      "loss": 0.0082,
      "step": 908
    },
    {
      "epoch": 0.6175271739130435,
      "grad_norm": 1.369408130645752,
      "learning_rate": 1.7980928776626833e-05,
      "loss": 0.097,
      "step": 909
    },
    {
      "epoch": 0.6182065217391305,
      "grad_norm": 10.49467658996582,
      "learning_rate": 1.797664025877327e-05,
      "loss": 0.4652,
      "step": 910
    },
    {
      "epoch": 0.6188858695652174,
      "grad_norm": 7.459201812744141,
      "learning_rate": 1.7972347703893184e-05,
      "loss": 0.2686,
      "step": 911
    },
    {
      "epoch": 0.6195652173913043,
      "grad_norm": 2.549595355987549,
      "learning_rate": 1.7968051114159046e-05,
      "loss": 0.0825,
      "step": 912
    },
    {
      "epoch": 0.6202445652173914,
      "grad_norm": 0.23113900423049927,
      "learning_rate": 1.79637504917454e-05,
      "loss": 0.0039,
      "step": 913
    },
    {
      "epoch": 0.6209239130434783,
      "grad_norm": 1.7641565799713135,
      "learning_rate": 1.795944583882881e-05,
      "loss": 0.1085,
      "step": 914
    },
    {
      "epoch": 0.6216032608695652,
      "grad_norm": 2.3925118446350098,
      "learning_rate": 1.7955137157587886e-05,
      "loss": 0.198,
      "step": 915
    },
    {
      "epoch": 0.6222826086956522,
      "grad_norm": 2.195929765701294,
      "learning_rate": 1.7950824450203283e-05,
      "loss": 0.0298,
      "step": 916
    },
    {
      "epoch": 0.6229619565217391,
      "grad_norm": 0.7544885277748108,
      "learning_rate": 1.7946507718857686e-05,
      "loss": 0.0114,
      "step": 917
    },
    {
      "epoch": 0.623641304347826,
      "grad_norm": 10.821837425231934,
      "learning_rate": 1.794218696573582e-05,
      "loss": 0.3959,
      "step": 918
    },
    {
      "epoch": 0.6243206521739131,
      "grad_norm": 1.9312658309936523,
      "learning_rate": 1.7937862193024446e-05,
      "loss": 0.053,
      "step": 919
    },
    {
      "epoch": 0.625,
      "grad_norm": 0.3890345096588135,
      "learning_rate": 1.7933533402912354e-05,
      "loss": 0.0058,
      "step": 920
    },
    {
      "epoch": 0.6256793478260869,
      "grad_norm": 2.45635986328125,
      "learning_rate": 1.7929200597590375e-05,
      "loss": 0.1466,
      "step": 921
    },
    {
      "epoch": 0.626358695652174,
      "grad_norm": 0.2902440130710602,
      "learning_rate": 1.7924863779251366e-05,
      "loss": 0.0037,
      "step": 922
    },
    {
      "epoch": 0.6270380434782609,
      "grad_norm": 0.10351379215717316,
      "learning_rate": 1.792052295009022e-05,
      "loss": 0.0023,
      "step": 923
    },
    {
      "epoch": 0.6277173913043478,
      "grad_norm": 3.3704864978790283,
      "learning_rate": 1.791617811230385e-05,
      "loss": 0.1339,
      "step": 924
    },
    {
      "epoch": 0.6283967391304348,
      "grad_norm": 1.9023146629333496,
      "learning_rate": 1.7911829268091213e-05,
      "loss": 0.1789,
      "step": 925
    },
    {
      "epoch": 0.6290760869565217,
      "grad_norm": 2.6770219802856445,
      "learning_rate": 1.7907476419653287e-05,
      "loss": 0.1757,
      "step": 926
    },
    {
      "epoch": 0.6297554347826086,
      "grad_norm": 10.237358093261719,
      "learning_rate": 1.7903119569193066e-05,
      "loss": 0.6639,
      "step": 927
    },
    {
      "epoch": 0.6304347826086957,
      "grad_norm": 1.9718611240386963,
      "learning_rate": 1.789875871891559e-05,
      "loss": 0.1267,
      "step": 928
    },
    {
      "epoch": 0.6311141304347826,
      "grad_norm": 1.9627394676208496,
      "learning_rate": 1.7894393871027903e-05,
      "loss": 0.1138,
      "step": 929
    },
    {
      "epoch": 0.6317934782608695,
      "grad_norm": 5.060145378112793,
      "learning_rate": 1.7890025027739084e-05,
      "loss": 0.1783,
      "step": 930
    },
    {
      "epoch": 0.6324728260869565,
      "grad_norm": 5.3144073486328125,
      "learning_rate": 1.788565219126023e-05,
      "loss": 0.1694,
      "step": 931
    },
    {
      "epoch": 0.6331521739130435,
      "grad_norm": 2.919147491455078,
      "learning_rate": 1.7881275363804465e-05,
      "loss": 0.1213,
      "step": 932
    },
    {
      "epoch": 0.6338315217391305,
      "grad_norm": 0.23288217186927795,
      "learning_rate": 1.7876894547586924e-05,
      "loss": 0.003,
      "step": 933
    },
    {
      "epoch": 0.6345108695652174,
      "grad_norm": 8.187686920166016,
      "learning_rate": 1.787250974482477e-05,
      "loss": 0.3481,
      "step": 934
    },
    {
      "epoch": 0.6351902173913043,
      "grad_norm": 2.751857280731201,
      "learning_rate": 1.7868120957737173e-05,
      "loss": 0.1569,
      "step": 935
    },
    {
      "epoch": 0.6358695652173914,
      "grad_norm": 7.448591709136963,
      "learning_rate": 1.7863728188545326e-05,
      "loss": 0.1857,
      "step": 936
    },
    {
      "epoch": 0.6365489130434783,
      "grad_norm": 2.3180201053619385,
      "learning_rate": 1.7859331439472438e-05,
      "loss": 0.1707,
      "step": 937
    },
    {
      "epoch": 0.6372282608695652,
      "grad_norm": 8.341523170471191,
      "learning_rate": 1.785493071274373e-05,
      "loss": 0.4335,
      "step": 938
    },
    {
      "epoch": 0.6379076086956522,
      "grad_norm": 4.284582614898682,
      "learning_rate": 1.7850526010586437e-05,
      "loss": 0.1296,
      "step": 939
    },
    {
      "epoch": 0.6385869565217391,
      "grad_norm": 0.20366549491882324,
      "learning_rate": 1.7846117335229808e-05,
      "loss": 0.0028,
      "step": 940
    },
    {
      "epoch": 0.639266304347826,
      "grad_norm": 4.297479152679443,
      "learning_rate": 1.7841704688905093e-05,
      "loss": 0.0606,
      "step": 941
    },
    {
      "epoch": 0.6399456521739131,
      "grad_norm": 7.831717491149902,
      "learning_rate": 1.7837288073845566e-05,
      "loss": 0.2027,
      "step": 942
    },
    {
      "epoch": 0.640625,
      "grad_norm": 2.591339588165283,
      "learning_rate": 1.7832867492286506e-05,
      "loss": 0.0383,
      "step": 943
    },
    {
      "epoch": 0.6413043478260869,
      "grad_norm": 0.7783703804016113,
      "learning_rate": 1.7828442946465188e-05,
      "loss": 0.0143,
      "step": 944
    },
    {
      "epoch": 0.641983695652174,
      "grad_norm": 4.6908063888549805,
      "learning_rate": 1.7824014438620906e-05,
      "loss": 0.1409,
      "step": 945
    },
    {
      "epoch": 0.6426630434782609,
      "grad_norm": 1.7292088270187378,
      "learning_rate": 1.7819581970994955e-05,
      "loss": 0.0818,
      "step": 946
    },
    {
      "epoch": 0.6433423913043478,
      "grad_norm": 1.672053575515747,
      "learning_rate": 1.7815145545830638e-05,
      "loss": 0.1117,
      "step": 947
    },
    {
      "epoch": 0.6440217391304348,
      "grad_norm": 1.566396951675415,
      "learning_rate": 1.7810705165373245e-05,
      "loss": 0.0266,
      "step": 948
    },
    {
      "epoch": 0.6447010869565217,
      "grad_norm": 3.623753547668457,
      "learning_rate": 1.7806260831870092e-05,
      "loss": 0.1523,
      "step": 949
    },
    {
      "epoch": 0.6453804347826086,
      "grad_norm": 1.1454353332519531,
      "learning_rate": 1.780181254757048e-05,
      "loss": 0.0931,
      "step": 950
    },
    {
      "epoch": 0.6460597826086957,
      "grad_norm": 0.23725134134292603,
      "learning_rate": 1.7797360314725707e-05,
      "loss": 0.0046,
      "step": 951
    },
    {
      "epoch": 0.6467391304347826,
      "grad_norm": 3.656200647354126,
      "learning_rate": 1.7792904135589085e-05,
      "loss": 0.2251,
      "step": 952
    },
    {
      "epoch": 0.6474184782608695,
      "grad_norm": 6.435878276824951,
      "learning_rate": 1.7788444012415905e-05,
      "loss": 0.1225,
      "step": 953
    },
    {
      "epoch": 0.6480978260869565,
      "grad_norm": 5.447897434234619,
      "learning_rate": 1.778397994746347e-05,
      "loss": 0.2168,
      "step": 954
    },
    {
      "epoch": 0.6487771739130435,
      "grad_norm": 2.506646156311035,
      "learning_rate": 1.7779511942991065e-05,
      "loss": 0.1017,
      "step": 955
    },
    {
      "epoch": 0.6494565217391305,
      "grad_norm": 2.915440797805786,
      "learning_rate": 1.7775040001259976e-05,
      "loss": 0.1613,
      "step": 956
    },
    {
      "epoch": 0.6501358695652174,
      "grad_norm": 0.30580657720565796,
      "learning_rate": 1.777056412453348e-05,
      "loss": 0.0049,
      "step": 957
    },
    {
      "epoch": 0.6508152173913043,
      "grad_norm": 1.6706401109695435,
      "learning_rate": 1.776608431507685e-05,
      "loss": 0.1401,
      "step": 958
    },
    {
      "epoch": 0.6514945652173914,
      "grad_norm": 2.7661495208740234,
      "learning_rate": 1.776160057515734e-05,
      "loss": 0.1716,
      "step": 959
    },
    {
      "epoch": 0.6521739130434783,
      "grad_norm": 1.8283413648605347,
      "learning_rate": 1.77571129070442e-05,
      "loss": 0.1101,
      "step": 960
    },
    {
      "epoch": 0.6528532608695652,
      "grad_norm": 2.736116886138916,
      "learning_rate": 1.7752621313008663e-05,
      "loss": 0.0422,
      "step": 961
    },
    {
      "epoch": 0.6535326086956522,
      "grad_norm": 6.538624286651611,
      "learning_rate": 1.774812579532396e-05,
      "loss": 0.2072,
      "step": 962
    },
    {
      "epoch": 0.6542119565217391,
      "grad_norm": 4.254975318908691,
      "learning_rate": 1.7743626356265292e-05,
      "loss": 0.2514,
      "step": 963
    },
    {
      "epoch": 0.654891304347826,
      "grad_norm": 1.424915075302124,
      "learning_rate": 1.7739122998109857e-05,
      "loss": 0.0219,
      "step": 964
    },
    {
      "epoch": 0.6555706521739131,
      "grad_norm": 1.660454511642456,
      "learning_rate": 1.773461572313683e-05,
      "loss": 0.0976,
      "step": 965
    },
    {
      "epoch": 0.65625,
      "grad_norm": 0.8338518142700195,
      "learning_rate": 1.773010453362737e-05,
      "loss": 0.0142,
      "step": 966
    },
    {
      "epoch": 0.6569293478260869,
      "grad_norm": 1.473418116569519,
      "learning_rate": 1.7725589431864622e-05,
      "loss": 0.0279,
      "step": 967
    },
    {
      "epoch": 0.657608695652174,
      "grad_norm": 10.794342994689941,
      "learning_rate": 1.7721070420133702e-05,
      "loss": 0.3751,
      "step": 968
    },
    {
      "epoch": 0.6582880434782609,
      "grad_norm": 8.282292366027832,
      "learning_rate": 1.7716547500721715e-05,
      "loss": 0.4195,
      "step": 969
    },
    {
      "epoch": 0.6589673913043478,
      "grad_norm": 0.3366484045982361,
      "learning_rate": 1.7712020675917734e-05,
      "loss": 0.0057,
      "step": 970
    },
    {
      "epoch": 0.6596467391304348,
      "grad_norm": 2.342379093170166,
      "learning_rate": 1.770748994801281e-05,
      "loss": 0.1206,
      "step": 971
    },
    {
      "epoch": 0.6603260869565217,
      "grad_norm": 1.753244161605835,
      "learning_rate": 1.770295531929998e-05,
      "loss": 0.1244,
      "step": 972
    },
    {
      "epoch": 0.6610054347826086,
      "grad_norm": 10.659745216369629,
      "learning_rate": 1.769841679207424e-05,
      "loss": 0.1769,
      "step": 973
    },
    {
      "epoch": 0.6616847826086957,
      "grad_norm": 0.35605180263519287,
      "learning_rate": 1.769387436863257e-05,
      "loss": 0.0054,
      "step": 974
    },
    {
      "epoch": 0.6623641304347826,
      "grad_norm": 2.888089418411255,
      "learning_rate": 1.768932805127392e-05,
      "loss": 0.1676,
      "step": 975
    },
    {
      "epoch": 0.6630434782608695,
      "grad_norm": 2.424016237258911,
      "learning_rate": 1.7684777842299206e-05,
      "loss": 0.1666,
      "step": 976
    },
    {
      "epoch": 0.6637228260869565,
      "grad_norm": 10.430634498596191,
      "learning_rate": 1.7680223744011315e-05,
      "loss": 0.5518,
      "step": 977
    },
    {
      "epoch": 0.6644021739130435,
      "grad_norm": 7.277503490447998,
      "learning_rate": 1.767566575871511e-05,
      "loss": 0.1589,
      "step": 978
    },
    {
      "epoch": 0.6650815217391305,
      "grad_norm": 0.7949795126914978,
      "learning_rate": 1.767110388871741e-05,
      "loss": 0.0133,
      "step": 979
    },
    {
      "epoch": 0.6657608695652174,
      "grad_norm": 0.11521564424037933,
      "learning_rate": 1.7666538136327007e-05,
      "loss": 0.0025,
      "step": 980
    },
    {
      "epoch": 0.6664402173913043,
      "grad_norm": 4.1320695877075195,
      "learning_rate": 1.766196850385466e-05,
      "loss": 0.0968,
      "step": 981
    },
    {
      "epoch": 0.6671195652173914,
      "grad_norm": 4.061481952667236,
      "learning_rate": 1.7657394993613078e-05,
      "loss": 0.1801,
      "step": 982
    },
    {
      "epoch": 0.6677989130434783,
      "grad_norm": 0.14562994241714478,
      "learning_rate": 1.7652817607916957e-05,
      "loss": 0.0033,
      "step": 983
    },
    {
      "epoch": 0.6684782608695652,
      "grad_norm": 3.143812894821167,
      "learning_rate": 1.7648236349082928e-05,
      "loss": 0.1714,
      "step": 984
    },
    {
      "epoch": 0.6691576086956522,
      "grad_norm": 5.291377544403076,
      "learning_rate": 1.7643651219429602e-05,
      "loss": 0.0709,
      "step": 985
    },
    {
      "epoch": 0.6698369565217391,
      "grad_norm": 0.6291341781616211,
      "learning_rate": 1.7639062221277533e-05,
      "loss": 0.0076,
      "step": 986
    },
    {
      "epoch": 0.670516304347826,
      "grad_norm": 0.4412548542022705,
      "learning_rate": 1.7634469356949246e-05,
      "loss": 0.0074,
      "step": 987
    },
    {
      "epoch": 0.6711956521739131,
      "grad_norm": 2.4200632572174072,
      "learning_rate": 1.7629872628769222e-05,
      "loss": 0.1189,
      "step": 988
    },
    {
      "epoch": 0.671875,
      "grad_norm": 0.18157246708869934,
      "learning_rate": 1.7625272039063884e-05,
      "loss": 0.0032,
      "step": 989
    },
    {
      "epoch": 0.6725543478260869,
      "grad_norm": 3.0951390266418457,
      "learning_rate": 1.7620667590161626e-05,
      "loss": 0.1957,
      "step": 990
    },
    {
      "epoch": 0.673233695652174,
      "grad_norm": 2.214404344558716,
      "learning_rate": 1.7616059284392783e-05,
      "loss": 0.139,
      "step": 991
    },
    {
      "epoch": 0.6739130434782609,
      "grad_norm": 1.489464282989502,
      "learning_rate": 1.761144712408965e-05,
      "loss": 0.0959,
      "step": 992
    },
    {
      "epoch": 0.6745923913043478,
      "grad_norm": 1.3049050569534302,
      "learning_rate": 1.7606831111586467e-05,
      "loss": 0.1176,
      "step": 993
    },
    {
      "epoch": 0.6752717391304348,
      "grad_norm": 0.6657692790031433,
      "learning_rate": 1.7602211249219433e-05,
      "loss": 0.0102,
      "step": 994
    },
    {
      "epoch": 0.6759510869565217,
      "grad_norm": 5.225462436676025,
      "learning_rate": 1.7597587539326677e-05,
      "loss": 0.2202,
      "step": 995
    },
    {
      "epoch": 0.6766304347826086,
      "grad_norm": 4.013315677642822,
      "learning_rate": 1.75929599842483e-05,
      "loss": 0.1668,
      "step": 996
    },
    {
      "epoch": 0.6773097826086957,
      "grad_norm": 2.2487831115722656,
      "learning_rate": 1.7588328586326325e-05,
      "loss": 0.1527,
      "step": 997
    },
    {
      "epoch": 0.6779891304347826,
      "grad_norm": 0.08471913635730743,
      "learning_rate": 1.7583693347904736e-05,
      "loss": 0.0016,
      "step": 998
    },
    {
      "epoch": 0.6786684782608695,
      "grad_norm": 1.668096661567688,
      "learning_rate": 1.7579054271329457e-05,
      "loss": 0.03,
      "step": 999
    },
    {
      "epoch": 0.6793478260869565,
      "grad_norm": 2.2133078575134277,
      "learning_rate": 1.7574411358948347e-05,
      "loss": 0.1949,
      "step": 1000
    },
    {
      "epoch": 0.6800271739130435,
      "grad_norm": 0.31200510263442993,
      "learning_rate": 1.7569764613111216e-05,
      "loss": 0.0057,
      "step": 1001
    },
    {
      "epoch": 0.6807065217391305,
      "grad_norm": 1.0799757242202759,
      "learning_rate": 1.756511403616982e-05,
      "loss": 0.0138,
      "step": 1002
    },
    {
      "epoch": 0.6813858695652174,
      "grad_norm": 0.14103512465953827,
      "learning_rate": 1.7560459630477828e-05,
      "loss": 0.003,
      "step": 1003
    },
    {
      "epoch": 0.6820652173913043,
      "grad_norm": 1.7757130861282349,
      "learning_rate": 1.755580139839087e-05,
      "loss": 0.0943,
      "step": 1004
    },
    {
      "epoch": 0.6827445652173914,
      "grad_norm": 2.1105923652648926,
      "learning_rate": 1.755113934226651e-05,
      "loss": 0.0777,
      "step": 1005
    },
    {
      "epoch": 0.6834239130434783,
      "grad_norm": 2.461766481399536,
      "learning_rate": 1.7546473464464237e-05,
      "loss": 0.1804,
      "step": 1006
    },
    {
      "epoch": 0.6841032608695652,
      "grad_norm": 1.8677605390548706,
      "learning_rate": 1.7541803767345484e-05,
      "loss": 0.092,
      "step": 1007
    },
    {
      "epoch": 0.6847826086956522,
      "grad_norm": 15.180623054504395,
      "learning_rate": 1.7537130253273613e-05,
      "loss": 0.7865,
      "step": 1008
    },
    {
      "epoch": 0.6854619565217391,
      "grad_norm": 1.4932783842086792,
      "learning_rate": 1.753245292461392e-05,
      "loss": 0.1098,
      "step": 1009
    },
    {
      "epoch": 0.686141304347826,
      "grad_norm": 1.955390453338623,
      "learning_rate": 1.7527771783733622e-05,
      "loss": 0.1427,
      "step": 1010
    },
    {
      "epoch": 0.6868206521739131,
      "grad_norm": 0.16110637784004211,
      "learning_rate": 1.752308683300188e-05,
      "loss": 0.0026,
      "step": 1011
    },
    {
      "epoch": 0.6875,
      "grad_norm": 0.3732569217681885,
      "learning_rate": 1.7518398074789776e-05,
      "loss": 0.0051,
      "step": 1012
    },
    {
      "epoch": 0.6881793478260869,
      "grad_norm": 7.466121196746826,
      "learning_rate": 1.7513705511470317e-05,
      "loss": 0.451,
      "step": 1013
    },
    {
      "epoch": 0.688858695652174,
      "grad_norm": 0.1068253293633461,
      "learning_rate": 1.750900914541844e-05,
      "loss": 0.0023,
      "step": 1014
    },
    {
      "epoch": 0.6895380434782609,
      "grad_norm": 5.716109752655029,
      "learning_rate": 1.7504308979011004e-05,
      "loss": 0.1074,
      "step": 1015
    },
    {
      "epoch": 0.6902173913043478,
      "grad_norm": 3.8481643199920654,
      "learning_rate": 1.7499605014626786e-05,
      "loss": 0.1194,
      "step": 1016
    },
    {
      "epoch": 0.6908967391304348,
      "grad_norm": 0.3500465750694275,
      "learning_rate": 1.7494897254646503e-05,
      "loss": 0.0043,
      "step": 1017
    },
    {
      "epoch": 0.6915760869565217,
      "grad_norm": 9.872237205505371,
      "learning_rate": 1.7490185701452774e-05,
      "loss": 0.4262,
      "step": 1018
    },
    {
      "epoch": 0.6922554347826086,
      "grad_norm": 2.049639940261841,
      "learning_rate": 1.7485470357430145e-05,
      "loss": 0.0607,
      "step": 1019
    },
    {
      "epoch": 0.6929347826086957,
      "grad_norm": 1.5448683500289917,
      "learning_rate": 1.7480751224965083e-05,
      "loss": 0.0861,
      "step": 1020
    },
    {
      "epoch": 0.6936141304347826,
      "grad_norm": 4.607586860656738,
      "learning_rate": 1.7476028306445966e-05,
      "loss": 0.2668,
      "step": 1021
    },
    {
      "epoch": 0.6942934782608695,
      "grad_norm": 3.194918155670166,
      "learning_rate": 1.7471301604263095e-05,
      "loss": 0.1141,
      "step": 1022
    },
    {
      "epoch": 0.6949728260869565,
      "grad_norm": 7.255068302154541,
      "learning_rate": 1.7466571120808684e-05,
      "loss": 0.3602,
      "step": 1023
    },
    {
      "epoch": 0.6956521739130435,
      "grad_norm": 2.1098804473876953,
      "learning_rate": 1.7461836858476858e-05,
      "loss": 0.1625,
      "step": 1024
    },
    {
      "epoch": 0.6963315217391305,
      "grad_norm": 2.896996259689331,
      "learning_rate": 1.7457098819663653e-05,
      "loss": 0.1586,
      "step": 1025
    },
    {
      "epoch": 0.6970108695652174,
      "grad_norm": 2.9317479133605957,
      "learning_rate": 1.7452357006767026e-05,
      "loss": 0.1624,
      "step": 1026
    },
    {
      "epoch": 0.6976902173913043,
      "grad_norm": 0.7197354435920715,
      "learning_rate": 1.744761142218683e-05,
      "loss": 0.0088,
      "step": 1027
    },
    {
      "epoch": 0.6983695652173914,
      "grad_norm": 2.2944557666778564,
      "learning_rate": 1.7442862068324843e-05,
      "loss": 0.1276,
      "step": 1028
    },
    {
      "epoch": 0.6990489130434783,
      "grad_norm": 3.5169031620025635,
      "learning_rate": 1.7438108947584737e-05,
      "loss": 0.0508,
      "step": 1029
    },
    {
      "epoch": 0.6997282608695652,
      "grad_norm": 0.19536049664020538,
      "learning_rate": 1.7433352062372098e-05,
      "loss": 0.0033,
      "step": 1030
    },
    {
      "epoch": 0.7004076086956522,
      "grad_norm": 2.9928717613220215,
      "learning_rate": 1.7428591415094408e-05,
      "loss": 0.2179,
      "step": 1031
    },
    {
      "epoch": 0.7010869565217391,
      "grad_norm": 4.8219733238220215,
      "learning_rate": 1.742382700816107e-05,
      "loss": 0.1128,
      "step": 1032
    },
    {
      "epoch": 0.701766304347826,
      "grad_norm": 0.3019430637359619,
      "learning_rate": 1.741905884398337e-05,
      "loss": 0.0058,
      "step": 1033
    },
    {
      "epoch": 0.7024456521739131,
      "grad_norm": 2.265186309814453,
      "learning_rate": 1.7414286924974516e-05,
      "loss": 0.1104,
      "step": 1034
    },
    {
      "epoch": 0.703125,
      "grad_norm": 0.8478704690933228,
      "learning_rate": 1.7409511253549592e-05,
      "loss": 0.0107,
      "step": 1035
    },
    {
      "epoch": 0.7038043478260869,
      "grad_norm": 3.211376905441284,
      "learning_rate": 1.7404731832125606e-05,
      "loss": 0.1232,
      "step": 1036
    },
    {
      "epoch": 0.704483695652174,
      "grad_norm": 6.9048943519592285,
      "learning_rate": 1.7399948663121448e-05,
      "loss": 0.2834,
      "step": 1037
    },
    {
      "epoch": 0.7051630434782609,
      "grad_norm": 5.966614246368408,
      "learning_rate": 1.7395161748957905e-05,
      "loss": 0.3349,
      "step": 1038
    },
    {
      "epoch": 0.7058423913043478,
      "grad_norm": 0.9917185306549072,
      "learning_rate": 1.739037109205767e-05,
      "loss": 0.0187,
      "step": 1039
    },
    {
      "epoch": 0.7065217391304348,
      "grad_norm": 0.19176876544952393,
      "learning_rate": 1.7385576694845324e-05,
      "loss": 0.0036,
      "step": 1040
    },
    {
      "epoch": 0.7072010869565217,
      "grad_norm": 1.0220638513565063,
      "learning_rate": 1.7380778559747335e-05,
      "loss": 0.0142,
      "step": 1041
    },
    {
      "epoch": 0.7078804347826086,
      "grad_norm": 3.528041124343872,
      "learning_rate": 1.7375976689192076e-05,
      "loss": 0.1967,
      "step": 1042
    },
    {
      "epoch": 0.7085597826086957,
      "grad_norm": 4.3585429191589355,
      "learning_rate": 1.7371171085609794e-05,
      "loss": 0.1685,
      "step": 1043
    },
    {
      "epoch": 0.7092391304347826,
      "grad_norm": 3.1279361248016357,
      "learning_rate": 1.7366361751432645e-05,
      "loss": 0.101,
      "step": 1044
    },
    {
      "epoch": 0.7099184782608695,
      "grad_norm": 7.083420753479004,
      "learning_rate": 1.7361548689094653e-05,
      "loss": 0.2525,
      "step": 1045
    },
    {
      "epoch": 0.7105978260869565,
      "grad_norm": 5.325175762176514,
      "learning_rate": 1.7356731901031746e-05,
      "loss": 0.1556,
      "step": 1046
    },
    {
      "epoch": 0.7112771739130435,
      "grad_norm": 3.6273772716522217,
      "learning_rate": 1.7351911389681725e-05,
      "loss": 0.1834,
      "step": 1047
    },
    {
      "epoch": 0.7119565217391305,
      "grad_norm": 0.07070977985858917,
      "learning_rate": 1.7347087157484282e-05,
      "loss": 0.0014,
      "step": 1048
    },
    {
      "epoch": 0.7126358695652174,
      "grad_norm": 0.13074269890785217,
      "learning_rate": 1.734225920688099e-05,
      "loss": 0.0024,
      "step": 1049
    },
    {
      "epoch": 0.7133152173913043,
      "grad_norm": 1.6717244386672974,
      "learning_rate": 1.7337427540315305e-05,
      "loss": 0.0894,
      "step": 1050
    },
    {
      "epoch": 0.7139945652173914,
      "grad_norm": 1.2198786735534668,
      "learning_rate": 1.733259216023256e-05,
      "loss": 0.0155,
      "step": 1051
    },
    {
      "epoch": 0.7146739130434783,
      "grad_norm": 0.04934064298868179,
      "learning_rate": 1.7327753069079977e-05,
      "loss": 0.0013,
      "step": 1052
    },
    {
      "epoch": 0.7153532608695652,
      "grad_norm": 3.8426592350006104,
      "learning_rate": 1.7322910269306645e-05,
      "loss": 0.1647,
      "step": 1053
    },
    {
      "epoch": 0.7160326086956522,
      "grad_norm": 3.878661870956421,
      "learning_rate": 1.7318063763363536e-05,
      "loss": 0.2084,
      "step": 1054
    },
    {
      "epoch": 0.7167119565217391,
      "grad_norm": 2.8978936672210693,
      "learning_rate": 1.7313213553703494e-05,
      "loss": 0.1894,
      "step": 1055
    },
    {
      "epoch": 0.717391304347826,
      "grad_norm": 3.0604331493377686,
      "learning_rate": 1.730835964278124e-05,
      "loss": 0.1232,
      "step": 1056
    },
    {
      "epoch": 0.7180706521739131,
      "grad_norm": 1.3584548234939575,
      "learning_rate": 1.7303502033053377e-05,
      "loss": 0.0343,
      "step": 1057
    },
    {
      "epoch": 0.71875,
      "grad_norm": 0.5312973856925964,
      "learning_rate": 1.7298640726978357e-05,
      "loss": 0.0077,
      "step": 1058
    },
    {
      "epoch": 0.7194293478260869,
      "grad_norm": 0.1713312268257141,
      "learning_rate": 1.729377572701653e-05,
      "loss": 0.0026,
      "step": 1059
    },
    {
      "epoch": 0.720108695652174,
      "grad_norm": 8.569366455078125,
      "learning_rate": 1.728890703563009e-05,
      "loss": 0.1568,
      "step": 1060
    },
    {
      "epoch": 0.7207880434782609,
      "grad_norm": 5.27705192565918,
      "learning_rate": 1.728403465528312e-05,
      "loss": 0.2974,
      "step": 1061
    },
    {
      "epoch": 0.7214673913043478,
      "grad_norm": 15.63265609741211,
      "learning_rate": 1.7279158588441558e-05,
      "loss": 0.6222,
      "step": 1062
    },
    {
      "epoch": 0.7221467391304348,
      "grad_norm": 2.1220285892486572,
      "learning_rate": 1.7274278837573214e-05,
      "loss": 0.1196,
      "step": 1063
    },
    {
      "epoch": 0.7228260869565217,
      "grad_norm": 7.619104862213135,
      "learning_rate": 1.726939540514776e-05,
      "loss": 0.1571,
      "step": 1064
    },
    {
      "epoch": 0.7235054347826086,
      "grad_norm": 3.3683555126190186,
      "learning_rate": 1.7264508293636726e-05,
      "loss": 0.1826,
      "step": 1065
    },
    {
      "epoch": 0.7241847826086957,
      "grad_norm": 3.973228693008423,
      "learning_rate": 1.7259617505513515e-05,
      "loss": 0.1153,
      "step": 1066
    },
    {
      "epoch": 0.7248641304347826,
      "grad_norm": 2.5718252658843994,
      "learning_rate": 1.7254723043253384e-05,
      "loss": 0.167,
      "step": 1067
    },
    {
      "epoch": 0.7255434782608695,
      "grad_norm": 1.678924560546875,
      "learning_rate": 1.7249824909333445e-05,
      "loss": 0.1928,
      "step": 1068
    },
    {
      "epoch": 0.7262228260869565,
      "grad_norm": 3.0514800548553467,
      "learning_rate": 1.7244923106232678e-05,
      "loss": 0.1655,
      "step": 1069
    },
    {
      "epoch": 0.7269021739130435,
      "grad_norm": 0.4921325147151947,
      "learning_rate": 1.7240017636431914e-05,
      "loss": 0.0056,
      "step": 1070
    },
    {
      "epoch": 0.7275815217391305,
      "grad_norm": 0.14819329977035522,
      "learning_rate": 1.7235108502413844e-05,
      "loss": 0.0025,
      "step": 1071
    },
    {
      "epoch": 0.7282608695652174,
      "grad_norm": 5.192578315734863,
      "learning_rate": 1.723019570666301e-05,
      "loss": 0.1789,
      "step": 1072
    },
    {
      "epoch": 0.7289402173913043,
      "grad_norm": 12.051061630249023,
      "learning_rate": 1.7225279251665803e-05,
      "loss": 0.5638,
      "step": 1073
    },
    {
      "epoch": 0.7296195652173914,
      "grad_norm": 0.5430495142936707,
      "learning_rate": 1.722035913991048e-05,
      "loss": 0.0083,
      "step": 1074
    },
    {
      "epoch": 0.7302989130434783,
      "grad_norm": 2.427717447280884,
      "learning_rate": 1.7215435373887133e-05,
      "loss": 0.1956,
      "step": 1075
    },
    {
      "epoch": 0.7309782608695652,
      "grad_norm": 0.16638892889022827,
      "learning_rate": 1.721050795608771e-05,
      "loss": 0.0026,
      "step": 1076
    },
    {
      "epoch": 0.7316576086956522,
      "grad_norm": 3.1234753131866455,
      "learning_rate": 1.720557688900601e-05,
      "loss": 0.1526,
      "step": 1077
    },
    {
      "epoch": 0.7323369565217391,
      "grad_norm": 2.343897819519043,
      "learning_rate": 1.720064217513768e-05,
      "loss": 0.1158,
      "step": 1078
    },
    {
      "epoch": 0.733016304347826,
      "grad_norm": 7.55082368850708,
      "learning_rate": 1.71957038169802e-05,
      "loss": 0.2796,
      "step": 1079
    },
    {
      "epoch": 0.7336956521739131,
      "grad_norm": 6.202287197113037,
      "learning_rate": 1.719076181703291e-05,
      "loss": 0.1483,
      "step": 1080
    },
    {
      "epoch": 0.734375,
      "grad_norm": 2.0268502235412598,
      "learning_rate": 1.718581617779698e-05,
      "loss": 0.0823,
      "step": 1081
    },
    {
      "epoch": 0.7350543478260869,
      "grad_norm": 9.505512237548828,
      "learning_rate": 1.7180866901775437e-05,
      "loss": 0.4643,
      "step": 1082
    },
    {
      "epoch": 0.735733695652174,
      "grad_norm": 2.463404893875122,
      "learning_rate": 1.7175913991473137e-05,
      "loss": 0.0875,
      "step": 1083
    },
    {
      "epoch": 0.7364130434782609,
      "grad_norm": 2.061037540435791,
      "learning_rate": 1.7170957449396774e-05,
      "loss": 0.1146,
      "step": 1084
    },
    {
      "epoch": 0.7370923913043478,
      "grad_norm": 0.7649016380310059,
      "learning_rate": 1.716599727805489e-05,
      "loss": 0.0094,
      "step": 1085
    },
    {
      "epoch": 0.7377717391304348,
      "grad_norm": 6.913917064666748,
      "learning_rate": 1.716103347995785e-05,
      "loss": 0.1268,
      "step": 1086
    },
    {
      "epoch": 0.7384510869565217,
      "grad_norm": 3.0594241619110107,
      "learning_rate": 1.715606605761787e-05,
      "loss": 0.145,
      "step": 1087
    },
    {
      "epoch": 0.7391304347826086,
      "grad_norm": 0.4419129490852356,
      "learning_rate": 1.7151095013548996e-05,
      "loss": 0.0075,
      "step": 1088
    },
    {
      "epoch": 0.7398097826086957,
      "grad_norm": 1.0447492599487305,
      "learning_rate": 1.7146120350267094e-05,
      "loss": 0.0175,
      "step": 1089
    },
    {
      "epoch": 0.7404891304347826,
      "grad_norm": 3.9391369819641113,
      "learning_rate": 1.7141142070289876e-05,
      "loss": 0.0918,
      "step": 1090
    },
    {
      "epoch": 0.7411684782608695,
      "grad_norm": 1.9695448875427246,
      "learning_rate": 1.7136160176136884e-05,
      "loss": 0.0355,
      "step": 1091
    },
    {
      "epoch": 0.7418478260869565,
      "grad_norm": 3.113593578338623,
      "learning_rate": 1.713117467032948e-05,
      "loss": 0.0574,
      "step": 1092
    },
    {
      "epoch": 0.7425271739130435,
      "grad_norm": 1.3055686950683594,
      "learning_rate": 1.7126185555390858e-05,
      "loss": 0.0213,
      "step": 1093
    },
    {
      "epoch": 0.7432065217391305,
      "grad_norm": 1.543623924255371,
      "learning_rate": 1.7121192833846046e-05,
      "loss": 0.1531,
      "step": 1094
    },
    {
      "epoch": 0.7438858695652174,
      "grad_norm": 1.3868567943572998,
      "learning_rate": 1.7116196508221886e-05,
      "loss": 0.0691,
      "step": 1095
    },
    {
      "epoch": 0.7445652173913043,
      "grad_norm": 0.1303005814552307,
      "learning_rate": 1.711119658104705e-05,
      "loss": 0.0021,
      "step": 1096
    },
    {
      "epoch": 0.7452445652173914,
      "grad_norm": 4.123091220855713,
      "learning_rate": 1.710619305485203e-05,
      "loss": 0.1489,
      "step": 1097
    },
    {
      "epoch": 0.7459239130434783,
      "grad_norm": 7.795462608337402,
      "learning_rate": 1.7101185932169147e-05,
      "loss": 0.2736,
      "step": 1098
    },
    {
      "epoch": 0.7466032608695652,
      "grad_norm": 0.20276133716106415,
      "learning_rate": 1.709617521553253e-05,
      "loss": 0.0039,
      "step": 1099
    },
    {
      "epoch": 0.7472826086956522,
      "grad_norm": 5.0433783531188965,
      "learning_rate": 1.7091160907478137e-05,
      "loss": 0.1639,
      "step": 1100
    },
    {
      "epoch": 0.7479619565217391,
      "grad_norm": 3.730026960372925,
      "learning_rate": 1.7086143010543737e-05,
      "loss": 0.1444,
      "step": 1101
    },
    {
      "epoch": 0.748641304347826,
      "grad_norm": 2.0025746822357178,
      "learning_rate": 1.7081121527268925e-05,
      "loss": 0.0307,
      "step": 1102
    },
    {
      "epoch": 0.7493206521739131,
      "grad_norm": 6.271449565887451,
      "learning_rate": 1.7076096460195097e-05,
      "loss": 0.3681,
      "step": 1103
    },
    {
      "epoch": 0.75,
      "grad_norm": 11.078523635864258,
      "learning_rate": 1.7071067811865477e-05,
      "loss": 0.4597,
      "step": 1104
    },
    {
      "epoch": 0.7506793478260869,
      "grad_norm": 2.279412031173706,
      "learning_rate": 1.706603558482509e-05,
      "loss": 0.1694,
      "step": 1105
    },
    {
      "epoch": 0.751358695652174,
      "grad_norm": 0.23419612646102905,
      "learning_rate": 1.7060999781620776e-05,
      "loss": 0.0028,
      "step": 1106
    },
    {
      "epoch": 0.7520380434782609,
      "grad_norm": 2.5688107013702393,
      "learning_rate": 1.7055960404801187e-05,
      "loss": 0.1243,
      "step": 1107
    },
    {
      "epoch": 0.7527173913043478,
      "grad_norm": 5.563319206237793,
      "learning_rate": 1.7050917456916788e-05,
      "loss": 0.2162,
      "step": 1108
    },
    {
      "epoch": 0.7533967391304348,
      "grad_norm": 2.585796356201172,
      "learning_rate": 1.7045870940519838e-05,
      "loss": 0.1549,
      "step": 1109
    },
    {
      "epoch": 0.7540760869565217,
      "grad_norm": 2.8662002086639404,
      "learning_rate": 1.7040820858164413e-05,
      "loss": 0.2111,
      "step": 1110
    },
    {
      "epoch": 0.7547554347826086,
      "grad_norm": 4.053638458251953,
      "learning_rate": 1.703576721240639e-05,
      "loss": 0.2447,
      "step": 1111
    },
    {
      "epoch": 0.7554347826086957,
      "grad_norm": 1.5232192277908325,
      "learning_rate": 1.7030710005803453e-05,
      "loss": 0.0996,
      "step": 1112
    },
    {
      "epoch": 0.7561141304347826,
      "grad_norm": 3.386795997619629,
      "learning_rate": 1.7025649240915085e-05,
      "loss": 0.055,
      "step": 1113
    },
    {
      "epoch": 0.7567934782608695,
      "grad_norm": 1.9401711225509644,
      "learning_rate": 1.7020584920302565e-05,
      "loss": 0.0772,
      "step": 1114
    },
    {
      "epoch": 0.7574728260869565,
      "grad_norm": 2.2804906368255615,
      "learning_rate": 1.701551704652898e-05,
      "loss": 0.1668,
      "step": 1115
    },
    {
      "epoch": 0.7581521739130435,
      "grad_norm": 4.477694034576416,
      "learning_rate": 1.7010445622159214e-05,
      "loss": 0.1793,
      "step": 1116
    },
    {
      "epoch": 0.7588315217391305,
      "grad_norm": 0.9410045146942139,
      "learning_rate": 1.7005370649759942e-05,
      "loss": 0.0303,
      "step": 1117
    },
    {
      "epoch": 0.7595108695652174,
      "grad_norm": 3.959747076034546,
      "learning_rate": 1.7000292131899644e-05,
      "loss": 0.0456,
      "step": 1118
    },
    {
      "epoch": 0.7601902173913043,
      "grad_norm": 8.266813278198242,
      "learning_rate": 1.6995210071148582e-05,
      "loss": 0.1075,
      "step": 1119
    },
    {
      "epoch": 0.7608695652173914,
      "grad_norm": 2.0234322547912598,
      "learning_rate": 1.699012447007882e-05,
      "loss": 0.1063,
      "step": 1120
    },
    {
      "epoch": 0.7615489130434783,
      "grad_norm": 6.158649921417236,
      "learning_rate": 1.6985035331264218e-05,
      "loss": 0.1804,
      "step": 1121
    },
    {
      "epoch": 0.7622282608695652,
      "grad_norm": 8.885403633117676,
      "learning_rate": 1.6979942657280414e-05,
      "loss": 0.6145,
      "step": 1122
    },
    {
      "epoch": 0.7629076086956522,
      "grad_norm": 6.229099750518799,
      "learning_rate": 1.6974846450704843e-05,
      "loss": 0.157,
      "step": 1123
    },
    {
      "epoch": 0.7635869565217391,
      "grad_norm": 0.09756318479776382,
      "learning_rate": 1.696974671411673e-05,
      "loss": 0.0016,
      "step": 1124
    },
    {
      "epoch": 0.764266304347826,
      "grad_norm": 6.5088887214660645,
      "learning_rate": 1.6964643450097077e-05,
      "loss": 0.0743,
      "step": 1125
    },
    {
      "epoch": 0.7649456521739131,
      "grad_norm": 1.05184006690979,
      "learning_rate": 1.6959536661228682e-05,
      "loss": 0.0128,
      "step": 1126
    },
    {
      "epoch": 0.765625,
      "grad_norm": 2.5289194583892822,
      "learning_rate": 1.6954426350096118e-05,
      "loss": 0.1034,
      "step": 1127
    },
    {
      "epoch": 0.7663043478260869,
      "grad_norm": 2.2584993839263916,
      "learning_rate": 1.694931251928575e-05,
      "loss": 0.0264,
      "step": 1128
    },
    {
      "epoch": 0.766983695652174,
      "grad_norm": 7.893395900726318,
      "learning_rate": 1.694419517138571e-05,
      "loss": 0.2066,
      "step": 1129
    },
    {
      "epoch": 0.7676630434782609,
      "grad_norm": 3.551856279373169,
      "learning_rate": 1.693907430898593e-05,
      "loss": 0.2542,
      "step": 1130
    },
    {
      "epoch": 0.7683423913043478,
      "grad_norm": 0.320976197719574,
      "learning_rate": 1.6933949934678104e-05,
      "loss": 0.0048,
      "step": 1131
    },
    {
      "epoch": 0.7690217391304348,
      "grad_norm": 4.968226909637451,
      "learning_rate": 1.6928822051055714e-05,
      "loss": 0.056,
      "step": 1132
    },
    {
      "epoch": 0.7697010869565217,
      "grad_norm": 3.803015947341919,
      "learning_rate": 1.6923690660714e-05,
      "loss": 0.3489,
      "step": 1133
    },
    {
      "epoch": 0.7703804347826086,
      "grad_norm": 0.7817215323448181,
      "learning_rate": 1.691855576625001e-05,
      "loss": 0.0076,
      "step": 1134
    },
    {
      "epoch": 0.7710597826086957,
      "grad_norm": 1.6759624481201172,
      "learning_rate": 1.691341737026253e-05,
      "loss": 0.0423,
      "step": 1135
    },
    {
      "epoch": 0.7717391304347826,
      "grad_norm": 3.386540174484253,
      "learning_rate": 1.690827547535214e-05,
      "loss": 0.1891,
      "step": 1136
    },
    {
      "epoch": 0.7724184782608695,
      "grad_norm": 3.1274030208587646,
      "learning_rate": 1.6903130084121183e-05,
      "loss": 0.0754,
      "step": 1137
    },
    {
      "epoch": 0.7730978260869565,
      "grad_norm": 2.658874273300171,
      "learning_rate": 1.6897981199173775e-05,
      "loss": 0.118,
      "step": 1138
    },
    {
      "epoch": 0.7737771739130435,
      "grad_norm": 0.28400516510009766,
      "learning_rate": 1.6892828823115798e-05,
      "loss": 0.004,
      "step": 1139
    },
    {
      "epoch": 0.7744565217391305,
      "grad_norm": 3.4474213123321533,
      "learning_rate": 1.68876729585549e-05,
      "loss": 0.1872,
      "step": 1140
    },
    {
      "epoch": 0.7751358695652174,
      "grad_norm": 4.102928161621094,
      "learning_rate": 1.688251360810049e-05,
      "loss": 0.1038,
      "step": 1141
    },
    {
      "epoch": 0.7758152173913043,
      "grad_norm": 0.33852720260620117,
      "learning_rate": 1.6877350774363757e-05,
      "loss": 0.0059,
      "step": 1142
    },
    {
      "epoch": 0.7764945652173914,
      "grad_norm": 2.0611653327941895,
      "learning_rate": 1.6872184459957637e-05,
      "loss": 0.0384,
      "step": 1143
    },
    {
      "epoch": 0.7771739130434783,
      "grad_norm": 2.631136178970337,
      "learning_rate": 1.6867014667496838e-05,
      "loss": 0.095,
      "step": 1144
    },
    {
      "epoch": 0.7778532608695652,
      "grad_norm": 0.4947011172771454,
      "learning_rate": 1.6861841399597816e-05,
      "loss": 0.0063,
      "step": 1145
    },
    {
      "epoch": 0.7785326086956522,
      "grad_norm": 10.506284713745117,
      "learning_rate": 1.6856664658878797e-05,
      "loss": 0.2902,
      "step": 1146
    },
    {
      "epoch": 0.7792119565217391,
      "grad_norm": 4.347623348236084,
      "learning_rate": 1.6851484447959767e-05,
      "loss": 0.095,
      "step": 1147
    },
    {
      "epoch": 0.779891304347826,
      "grad_norm": 0.17410753667354584,
      "learning_rate": 1.6846300769462454e-05,
      "loss": 0.0025,
      "step": 1148
    },
    {
      "epoch": 0.7805706521739131,
      "grad_norm": 4.4142937660217285,
      "learning_rate": 1.6841113626010358e-05,
      "loss": 0.1311,
      "step": 1149
    },
    {
      "epoch": 0.78125,
      "grad_norm": 6.79951810836792,
      "learning_rate": 1.6835923020228714e-05,
      "loss": 0.3816,
      "step": 1150
    },
    {
      "epoch": 0.7819293478260869,
      "grad_norm": 0.3942023813724518,
      "learning_rate": 1.6830728954744528e-05,
      "loss": 0.0051,
      "step": 1151
    },
    {
      "epoch": 0.782608695652174,
      "grad_norm": 3.0429251194000244,
      "learning_rate": 1.6825531432186545e-05,
      "loss": 0.1751,
      "step": 1152
    },
    {
      "epoch": 0.7832880434782609,
      "grad_norm": 8.125088691711426,
      "learning_rate": 1.682033045518526e-05,
      "loss": 0.1645,
      "step": 1153
    },
    {
      "epoch": 0.7839673913043478,
      "grad_norm": 2.8800482749938965,
      "learning_rate": 1.6815126026372922e-05,
      "loss": 0.1036,
      "step": 1154
    },
    {
      "epoch": 0.7846467391304348,
      "grad_norm": 4.994540214538574,
      "learning_rate": 1.6809918148383525e-05,
      "loss": 0.0512,
      "step": 1155
    },
    {
      "epoch": 0.7853260869565217,
      "grad_norm": 5.003114700317383,
      "learning_rate": 1.680470682385281e-05,
      "loss": 0.2237,
      "step": 1156
    },
    {
      "epoch": 0.7860054347826086,
      "grad_norm": 2.1830217838287354,
      "learning_rate": 1.679949205541826e-05,
      "loss": 0.0858,
      "step": 1157
    },
    {
      "epoch": 0.7866847826086957,
      "grad_norm": 4.322746276855469,
      "learning_rate": 1.6794273845719096e-05,
      "loss": 0.2435,
      "step": 1158
    },
    {
      "epoch": 0.7873641304347826,
      "grad_norm": 6.325995922088623,
      "learning_rate": 1.678905219739629e-05,
      "loss": 0.2345,
      "step": 1159
    },
    {
      "epoch": 0.7880434782608695,
      "grad_norm": 1.6628127098083496,
      "learning_rate": 1.6783827113092547e-05,
      "loss": 0.0839,
      "step": 1160
    },
    {
      "epoch": 0.7887228260869565,
      "grad_norm": 3.7720065116882324,
      "learning_rate": 1.6778598595452324e-05,
      "loss": 0.1329,
      "step": 1161
    },
    {
      "epoch": 0.7894021739130435,
      "grad_norm": 1.1316174268722534,
      "learning_rate": 1.6773366647121792e-05,
      "loss": 0.0187,
      "step": 1162
    },
    {
      "epoch": 0.7900815217391305,
      "grad_norm": 1.4082716703414917,
      "learning_rate": 1.676813127074888e-05,
      "loss": 0.1559,
      "step": 1163
    },
    {
      "epoch": 0.7907608695652174,
      "grad_norm": 3.1782891750335693,
      "learning_rate": 1.6762892468983237e-05,
      "loss": 0.0815,
      "step": 1164
    },
    {
      "epoch": 0.7914402173913043,
      "grad_norm": 4.29664945602417,
      "learning_rate": 1.6757650244476267e-05,
      "loss": 0.1292,
      "step": 1165
    },
    {
      "epoch": 0.7921195652173914,
      "grad_norm": 2.0011062622070312,
      "learning_rate": 1.675240459988108e-05,
      "loss": 0.1175,
      "step": 1166
    },
    {
      "epoch": 0.7927989130434783,
      "grad_norm": 15.4092378616333,
      "learning_rate": 1.674715553785253e-05,
      "loss": 0.4155,
      "step": 1167
    },
    {
      "epoch": 0.7934782608695652,
      "grad_norm": 0.5476647615432739,
      "learning_rate": 1.6741903061047204e-05,
      "loss": 0.0099,
      "step": 1168
    },
    {
      "epoch": 0.7941576086956522,
      "grad_norm": 3.456277847290039,
      "learning_rate": 1.6736647172123414e-05,
      "loss": 0.1653,
      "step": 1169
    },
    {
      "epoch": 0.7948369565217391,
      "grad_norm": 0.9210562109947205,
      "learning_rate": 1.673138787374119e-05,
      "loss": 0.017,
      "step": 1170
    },
    {
      "epoch": 0.795516304347826,
      "grad_norm": 7.095554351806641,
      "learning_rate": 1.6726125168562295e-05,
      "loss": 0.1729,
      "step": 1171
    },
    {
      "epoch": 0.7961956521739131,
      "grad_norm": 0.11429592221975327,
      "learning_rate": 1.6720859059250225e-05,
      "loss": 0.0019,
      "step": 1172
    },
    {
      "epoch": 0.796875,
      "grad_norm": 2.3340096473693848,
      "learning_rate": 1.6715589548470187e-05,
      "loss": 0.1507,
      "step": 1173
    },
    {
      "epoch": 0.7975543478260869,
      "grad_norm": 0.43553295731544495,
      "learning_rate": 1.6710316638889107e-05,
      "loss": 0.007,
      "step": 1174
    },
    {
      "epoch": 0.798233695652174,
      "grad_norm": 1.8844163417816162,
      "learning_rate": 1.6705040333175646e-05,
      "loss": 0.1179,
      "step": 1175
    },
    {
      "epoch": 0.7989130434782609,
      "grad_norm": 1.8057576417922974,
      "learning_rate": 1.6699760634000166e-05,
      "loss": 0.1519,
      "step": 1176
    },
    {
      "epoch": 0.7995923913043478,
      "grad_norm": 1.4276221990585327,
      "learning_rate": 1.6694477544034762e-05,
      "loss": 0.0759,
      "step": 1177
    },
    {
      "epoch": 0.8002717391304348,
      "grad_norm": 4.887430191040039,
      "learning_rate": 1.6689191065953233e-05,
      "loss": 0.3191,
      "step": 1178
    },
    {
      "epoch": 0.8009510869565217,
      "grad_norm": 2.3722422122955322,
      "learning_rate": 1.66839012024311e-05,
      "loss": 0.1716,
      "step": 1179
    },
    {
      "epoch": 0.8016304347826086,
      "grad_norm": 3.427405595779419,
      "learning_rate": 1.6678607956145596e-05,
      "loss": 0.2259,
      "step": 1180
    },
    {
      "epoch": 0.8023097826086957,
      "grad_norm": 2.7805683612823486,
      "learning_rate": 1.6673311329775664e-05,
      "loss": 0.1082,
      "step": 1181
    },
    {
      "epoch": 0.8029891304347826,
      "grad_norm": 5.169270038604736,
      "learning_rate": 1.6668011326001962e-05,
      "loss": 0.1747,
      "step": 1182
    },
    {
      "epoch": 0.8036684782608695,
      "grad_norm": 7.118748188018799,
      "learning_rate": 1.666270794750685e-05,
      "loss": 0.1605,
      "step": 1183
    },
    {
      "epoch": 0.8043478260869565,
      "grad_norm": 3.3340742588043213,
      "learning_rate": 1.6657401196974405e-05,
      "loss": 0.051,
      "step": 1184
    },
    {
      "epoch": 0.8050271739130435,
      "grad_norm": 3.326301097869873,
      "learning_rate": 1.6652091077090405e-05,
      "loss": 0.1134,
      "step": 1185
    },
    {
      "epoch": 0.8057065217391305,
      "grad_norm": 2.3053157329559326,
      "learning_rate": 1.664677759054233e-05,
      "loss": 0.1043,
      "step": 1186
    },
    {
      "epoch": 0.8063858695652174,
      "grad_norm": 0.5103456377983093,
      "learning_rate": 1.6641460740019374e-05,
      "loss": 0.0082,
      "step": 1187
    },
    {
      "epoch": 0.8070652173913043,
      "grad_norm": 4.423583030700684,
      "learning_rate": 1.6636140528212427e-05,
      "loss": 0.076,
      "step": 1188
    },
    {
      "epoch": 0.8077445652173914,
      "grad_norm": 2.1934099197387695,
      "learning_rate": 1.663081695781407e-05,
      "loss": 0.0432,
      "step": 1189
    },
    {
      "epoch": 0.8084239130434783,
      "grad_norm": 0.09625140577554703,
      "learning_rate": 1.662549003151861e-05,
      "loss": 0.0021,
      "step": 1190
    },
    {
      "epoch": 0.8091032608695652,
      "grad_norm": 2.376796245574951,
      "learning_rate": 1.662015975202203e-05,
      "loss": 0.1012,
      "step": 1191
    },
    {
      "epoch": 0.8097826086956522,
      "grad_norm": 4.077658653259277,
      "learning_rate": 1.6614826122022015e-05,
      "loss": 0.0845,
      "step": 1192
    },
    {
      "epoch": 0.8104619565217391,
      "grad_norm": 2.0476481914520264,
      "learning_rate": 1.6609489144217948e-05,
      "loss": 0.136,
      "step": 1193
    },
    {
      "epoch": 0.811141304347826,
      "grad_norm": 4.546004295349121,
      "learning_rate": 1.6604148821310912e-05,
      "loss": 0.0546,
      "step": 1194
    },
    {
      "epoch": 0.8118206521739131,
      "grad_norm": 2.2225780487060547,
      "learning_rate": 1.6598805156003673e-05,
      "loss": 0.0993,
      "step": 1195
    },
    {
      "epoch": 0.8125,
      "grad_norm": 2.152862071990967,
      "learning_rate": 1.659345815100069e-05,
      "loss": 0.0288,
      "step": 1196
    },
    {
      "epoch": 0.8131793478260869,
      "grad_norm": 10.106184959411621,
      "learning_rate": 1.658810780900812e-05,
      "loss": 0.3405,
      "step": 1197
    },
    {
      "epoch": 0.813858695652174,
      "grad_norm": 0.11634743213653564,
      "learning_rate": 1.6582754132733804e-05,
      "loss": 0.0018,
      "step": 1198
    },
    {
      "epoch": 0.8145380434782609,
      "grad_norm": 2.4634933471679688,
      "learning_rate": 1.6577397124887266e-05,
      "loss": 0.0302,
      "step": 1199
    },
    {
      "epoch": 0.8152173913043478,
      "grad_norm": 2.5803651809692383,
      "learning_rate": 1.6572036788179728e-05,
      "loss": 0.0978,
      "step": 1200
    },
    {
      "epoch": 0.8158967391304348,
      "grad_norm": 6.112914562225342,
      "learning_rate": 1.656667312532408e-05,
      "loss": 0.2876,
      "step": 1201
    },
    {
      "epoch": 0.8165760869565217,
      "grad_norm": 3.264925003051758,
      "learning_rate": 1.656130613903491e-05,
      "loss": 0.1177,
      "step": 1202
    },
    {
      "epoch": 0.8172554347826086,
      "grad_norm": 13.386710166931152,
      "learning_rate": 1.655593583202848e-05,
      "loss": 0.615,
      "step": 1203
    },
    {
      "epoch": 0.8179347826086957,
      "grad_norm": 0.377462238073349,
      "learning_rate": 1.655056220702274e-05,
      "loss": 0.005,
      "step": 1204
    },
    {
      "epoch": 0.8186141304347826,
      "grad_norm": 4.12667989730835,
      "learning_rate": 1.654518526673731e-05,
      "loss": 0.2577,
      "step": 1205
    },
    {
      "epoch": 0.8192934782608695,
      "grad_norm": 1.6597367525100708,
      "learning_rate": 1.6539805013893493e-05,
      "loss": 0.0623,
      "step": 1206
    },
    {
      "epoch": 0.8199728260869565,
      "grad_norm": 1.1954047679901123,
      "learning_rate": 1.653442145121427e-05,
      "loss": 0.0114,
      "step": 1207
    },
    {
      "epoch": 0.8206521739130435,
      "grad_norm": 1.8439573049545288,
      "learning_rate": 1.6529034581424293e-05,
      "loss": 0.0322,
      "step": 1208
    },
    {
      "epoch": 0.8213315217391305,
      "grad_norm": 5.829913139343262,
      "learning_rate": 1.6523644407249893e-05,
      "loss": 0.4223,
      "step": 1209
    },
    {
      "epoch": 0.8220108695652174,
      "grad_norm": 1.2379299402236938,
      "learning_rate": 1.6518250931419063e-05,
      "loss": 0.0178,
      "step": 1210
    },
    {
      "epoch": 0.8226902173913043,
      "grad_norm": 0.9710105657577515,
      "learning_rate": 1.6512854156661484e-05,
      "loss": 0.0115,
      "step": 1211
    },
    {
      "epoch": 0.8233695652173914,
      "grad_norm": 0.05835460498929024,
      "learning_rate": 1.650745408570849e-05,
      "loss": 0.001,
      "step": 1212
    },
    {
      "epoch": 0.8240489130434783,
      "grad_norm": 3.0861423015594482,
      "learning_rate": 1.6502050721293094e-05,
      "loss": 0.1651,
      "step": 1213
    },
    {
      "epoch": 0.8247282608695652,
      "grad_norm": 0.0689147338271141,
      "learning_rate": 1.6496644066149967e-05,
      "loss": 0.0012,
      "step": 1214
    },
    {
      "epoch": 0.8254076086956522,
      "grad_norm": 0.14690545201301575,
      "learning_rate": 1.6491234123015454e-05,
      "loss": 0.0022,
      "step": 1215
    },
    {
      "epoch": 0.8260869565217391,
      "grad_norm": 0.15622985363006592,
      "learning_rate": 1.648582089462756e-05,
      "loss": 0.0024,
      "step": 1216
    },
    {
      "epoch": 0.826766304347826,
      "grad_norm": 0.1481807678937912,
      "learning_rate": 1.6480404383725952e-05,
      "loss": 0.0021,
      "step": 1217
    },
    {
      "epoch": 0.8274456521739131,
      "grad_norm": 4.210184097290039,
      "learning_rate": 1.6474984593051965e-05,
      "loss": 0.0617,
      "step": 1218
    },
    {
      "epoch": 0.828125,
      "grad_norm": 10.949219703674316,
      "learning_rate": 1.6469561525348576e-05,
      "loss": 0.6933,
      "step": 1219
    },
    {
      "epoch": 0.8288043478260869,
      "grad_norm": 0.11575622111558914,
      "learning_rate": 1.6464135183360444e-05,
      "loss": 0.0025,
      "step": 1220
    },
    {
      "epoch": 0.829483695652174,
      "grad_norm": 9.350762367248535,
      "learning_rate": 1.6458705569833866e-05,
      "loss": 0.1539,
      "step": 1221
    },
    {
      "epoch": 0.8301630434782609,
      "grad_norm": 3.452056407928467,
      "learning_rate": 1.645327268751681e-05,
      "loss": 0.1592,
      "step": 1222
    },
    {
      "epoch": 0.8308423913043478,
      "grad_norm": 2.0625357627868652,
      "learning_rate": 1.6447836539158887e-05,
      "loss": 0.0466,
      "step": 1223
    },
    {
      "epoch": 0.8315217391304348,
      "grad_norm": 5.1906352043151855,
      "learning_rate": 1.6442397127511366e-05,
      "loss": 0.2037,
      "step": 1224
    },
    {
      "epoch": 0.8322010869565217,
      "grad_norm": 6.7566375732421875,
      "learning_rate": 1.6436954455327165e-05,
      "loss": 0.1268,
      "step": 1225
    },
    {
      "epoch": 0.8328804347826086,
      "grad_norm": 0.2287013828754425,
      "learning_rate": 1.6431508525360858e-05,
      "loss": 0.0034,
      "step": 1226
    },
    {
      "epoch": 0.8335597826086957,
      "grad_norm": 4.938503265380859,
      "learning_rate": 1.6426059340368653e-05,
      "loss": 0.2157,
      "step": 1227
    },
    {
      "epoch": 0.8342391304347826,
      "grad_norm": 0.38565850257873535,
      "learning_rate": 1.6420606903108432e-05,
      "loss": 0.0052,
      "step": 1228
    },
    {
      "epoch": 0.8349184782608695,
      "grad_norm": 6.581591606140137,
      "learning_rate": 1.6415151216339697e-05,
      "loss": 0.2509,
      "step": 1229
    },
    {
      "epoch": 0.8355978260869565,
      "grad_norm": 7.472212791442871,
      "learning_rate": 1.6409692282823604e-05,
      "loss": 0.1842,
      "step": 1230
    },
    {
      "epoch": 0.8362771739130435,
      "grad_norm": 0.7852874398231506,
      "learning_rate": 1.6404230105322953e-05,
      "loss": 0.0107,
      "step": 1231
    },
    {
      "epoch": 0.8369565217391305,
      "grad_norm": 13.075453758239746,
      "learning_rate": 1.6398764686602188e-05,
      "loss": 0.5634,
      "step": 1232
    },
    {
      "epoch": 0.8376358695652174,
      "grad_norm": 2.6350300312042236,
      "learning_rate": 1.6393296029427395e-05,
      "loss": 0.1251,
      "step": 1233
    },
    {
      "epoch": 0.8383152173913043,
      "grad_norm": 4.744679927825928,
      "learning_rate": 1.6387824136566287e-05,
      "loss": 0.1183,
      "step": 1234
    },
    {
      "epoch": 0.8389945652173914,
      "grad_norm": 0.028099199756979942,
      "learning_rate": 1.6382349010788223e-05,
      "loss": 0.0008,
      "step": 1235
    },
    {
      "epoch": 0.8396739130434783,
      "grad_norm": 6.105319023132324,
      "learning_rate": 1.63768706548642e-05,
      "loss": 0.1611,
      "step": 1236
    },
    {
      "epoch": 0.8403532608695652,
      "grad_norm": 3.7958407402038574,
      "learning_rate": 1.637138907156685e-05,
      "loss": 0.2452,
      "step": 1237
    },
    {
      "epoch": 0.8410326086956522,
      "grad_norm": 3.154655694961548,
      "learning_rate": 1.6365904263670436e-05,
      "loss": 0.1603,
      "step": 1238
    },
    {
      "epoch": 0.8417119565217391,
      "grad_norm": 1.3796658515930176,
      "learning_rate": 1.636041623395085e-05,
      "loss": 0.1418,
      "step": 1239
    },
    {
      "epoch": 0.842391304347826,
      "grad_norm": 5.3495283126831055,
      "learning_rate": 1.6354924985185614e-05,
      "loss": 0.1112,
      "step": 1240
    },
    {
      "epoch": 0.8430706521739131,
      "grad_norm": 11.869421005249023,
      "learning_rate": 1.634943052015389e-05,
      "loss": 0.372,
      "step": 1241
    },
    {
      "epoch": 0.84375,
      "grad_norm": 8.658032417297363,
      "learning_rate": 1.6343932841636455e-05,
      "loss": 0.2347,
      "step": 1242
    },
    {
      "epoch": 0.8444293478260869,
      "grad_norm": 2.3893749713897705,
      "learning_rate": 1.6338431952415722e-05,
      "loss": 0.1754,
      "step": 1243
    },
    {
      "epoch": 0.845108695652174,
      "grad_norm": 3.772458076477051,
      "learning_rate": 1.6332927855275724e-05,
      "loss": 0.0818,
      "step": 1244
    },
    {
      "epoch": 0.8457880434782609,
      "grad_norm": 11.96020793914795,
      "learning_rate": 1.6327420553002113e-05,
      "loss": 0.7097,
      "step": 1245
    },
    {
      "epoch": 0.8464673913043478,
      "grad_norm": 0.20975100994110107,
      "learning_rate": 1.6321910048382174e-05,
      "loss": 0.0034,
      "step": 1246
    },
    {
      "epoch": 0.8471467391304348,
      "grad_norm": 4.95899772644043,
      "learning_rate": 1.6316396344204805e-05,
      "loss": 0.1367,
      "step": 1247
    },
    {
      "epoch": 0.8478260869565217,
      "grad_norm": 2.3842198848724365,
      "learning_rate": 1.631087944326053e-05,
      "loss": 0.1982,
      "step": 1248
    },
    {
      "epoch": 0.8485054347826086,
      "grad_norm": 11.97751522064209,
      "learning_rate": 1.630535934834148e-05,
      "loss": 0.2862,
      "step": 1249
    },
    {
      "epoch": 0.8491847826086957,
      "grad_norm": 1.8204529285430908,
      "learning_rate": 1.629983606224141e-05,
      "loss": 0.0212,
      "step": 1250
    },
    {
      "epoch": 0.8498641304347826,
      "grad_norm": 1.6680773496627808,
      "learning_rate": 1.6294309587755693e-05,
      "loss": 0.0626,
      "step": 1251
    },
    {
      "epoch": 0.8505434782608695,
      "grad_norm": 4.495962142944336,
      "learning_rate": 1.6288779927681307e-05,
      "loss": 0.2017,
      "step": 1252
    },
    {
      "epoch": 0.8512228260869565,
      "grad_norm": 3.6688995361328125,
      "learning_rate": 1.6283247084816847e-05,
      "loss": 0.1553,
      "step": 1253
    },
    {
      "epoch": 0.8519021739130435,
      "grad_norm": 6.72568416595459,
      "learning_rate": 1.6277711061962525e-05,
      "loss": 0.2468,
      "step": 1254
    },
    {
      "epoch": 0.8525815217391305,
      "grad_norm": 8.253103256225586,
      "learning_rate": 1.6272171861920148e-05,
      "loss": 0.1935,
      "step": 1255
    },
    {
      "epoch": 0.8532608695652174,
      "grad_norm": 0.9595584869384766,
      "learning_rate": 1.6266629487493144e-05,
      "loss": 0.0388,
      "step": 1256
    },
    {
      "epoch": 0.8539402173913043,
      "grad_norm": 2.264111280441284,
      "learning_rate": 1.6261083941486543e-05,
      "loss": 0.1326,
      "step": 1257
    },
    {
      "epoch": 0.8546195652173914,
      "grad_norm": 8.325216293334961,
      "learning_rate": 1.6255535226706975e-05,
      "loss": 0.1814,
      "step": 1258
    },
    {
      "epoch": 0.8552989130434783,
      "grad_norm": 2.150705099105835,
      "learning_rate": 1.6249983345962685e-05,
      "loss": 0.1044,
      "step": 1259
    },
    {
      "epoch": 0.8559782608695652,
      "grad_norm": 6.255360126495361,
      "learning_rate": 1.6244428302063506e-05,
      "loss": 0.3432,
      "step": 1260
    },
    {
      "epoch": 0.8566576086956522,
      "grad_norm": 1.918216586112976,
      "learning_rate": 1.623887009782089e-05,
      "loss": 0.0888,
      "step": 1261
    },
    {
      "epoch": 0.8573369565217391,
      "grad_norm": 3.608975648880005,
      "learning_rate": 1.6233308736047868e-05,
      "loss": 0.0974,
      "step": 1262
    },
    {
      "epoch": 0.858016304347826,
      "grad_norm": 0.7802101373672485,
      "learning_rate": 1.6227744219559086e-05,
      "loss": 0.0164,
      "step": 1263
    },
    {
      "epoch": 0.8586956521739131,
      "grad_norm": 4.737270355224609,
      "learning_rate": 1.622217655117078e-05,
      "loss": 0.1317,
      "step": 1264
    },
    {
      "epoch": 0.859375,
      "grad_norm": 5.29575777053833,
      "learning_rate": 1.6216605733700776e-05,
      "loss": 0.1446,
      "step": 1265
    },
    {
      "epoch": 0.8600543478260869,
      "grad_norm": 6.188937664031982,
      "learning_rate": 1.6211031769968503e-05,
      "loss": 0.2691,
      "step": 1266
    },
    {
      "epoch": 0.860733695652174,
      "grad_norm": 2.358220338821411,
      "learning_rate": 1.6205454662794977e-05,
      "loss": 0.1567,
      "step": 1267
    },
    {
      "epoch": 0.8614130434782609,
      "grad_norm": 3.3858063220977783,
      "learning_rate": 1.6199874415002806e-05,
      "loss": 0.1805,
      "step": 1268
    },
    {
      "epoch": 0.8620923913043478,
      "grad_norm": 3.139417886734009,
      "learning_rate": 1.6194291029416188e-05,
      "loss": 0.1281,
      "step": 1269
    },
    {
      "epoch": 0.8627717391304348,
      "grad_norm": 5.007575511932373,
      "learning_rate": 1.6188704508860905e-05,
      "loss": 0.1949,
      "step": 1270
    },
    {
      "epoch": 0.8634510869565217,
      "grad_norm": 1.8170887231826782,
      "learning_rate": 1.6183114856164338e-05,
      "loss": 0.0334,
      "step": 1271
    },
    {
      "epoch": 0.8641304347826086,
      "grad_norm": 3.0678229331970215,
      "learning_rate": 1.6177522074155436e-05,
      "loss": 0.0532,
      "step": 1272
    },
    {
      "epoch": 0.8648097826086957,
      "grad_norm": 0.45637205243110657,
      "learning_rate": 1.6171926165664745e-05,
      "loss": 0.0055,
      "step": 1273
    },
    {
      "epoch": 0.8654891304347826,
      "grad_norm": 6.781618595123291,
      "learning_rate": 1.6166327133524385e-05,
      "loss": 0.1326,
      "step": 1274
    },
    {
      "epoch": 0.8661684782608695,
      "grad_norm": 1.274399757385254,
      "learning_rate": 1.6160724980568066e-05,
      "loss": 0.0153,
      "step": 1275
    },
    {
      "epoch": 0.8668478260869565,
      "grad_norm": 2.67352294921875,
      "learning_rate": 1.6155119709631067e-05,
      "loss": 0.12,
      "step": 1276
    },
    {
      "epoch": 0.8675271739130435,
      "grad_norm": 1.5090985298156738,
      "learning_rate": 1.614951132355025e-05,
      "loss": 0.0254,
      "step": 1277
    },
    {
      "epoch": 0.8682065217391305,
      "grad_norm": 13.165255546569824,
      "learning_rate": 1.6143899825164058e-05,
      "loss": 0.5564,
      "step": 1278
    },
    {
      "epoch": 0.8688858695652174,
      "grad_norm": 5.697802543640137,
      "learning_rate": 1.61382852173125e-05,
      "loss": 0.1526,
      "step": 1279
    },
    {
      "epoch": 0.8695652173913043,
      "grad_norm": 0.9439249634742737,
      "learning_rate": 1.6132667502837164e-05,
      "loss": 0.0138,
      "step": 1280
    },
    {
      "epoch": 0.8702445652173914,
      "grad_norm": 1.0942814350128174,
      "learning_rate": 1.6127046684581212e-05,
      "loss": 0.0269,
      "step": 1281
    },
    {
      "epoch": 0.8709239130434783,
      "grad_norm": 0.6483169198036194,
      "learning_rate": 1.6121422765389377e-05,
      "loss": 0.0066,
      "step": 1282
    },
    {
      "epoch": 0.8716032608695652,
      "grad_norm": 1.7377299070358276,
      "learning_rate": 1.611579574810795e-05,
      "loss": 0.1358,
      "step": 1283
    },
    {
      "epoch": 0.8722826086956522,
      "grad_norm": 4.326443672180176,
      "learning_rate": 1.6110165635584807e-05,
      "loss": 0.0599,
      "step": 1284
    },
    {
      "epoch": 0.8729619565217391,
      "grad_norm": 2.3095545768737793,
      "learning_rate": 1.610453243066938e-05,
      "loss": 0.0833,
      "step": 1285
    },
    {
      "epoch": 0.873641304347826,
      "grad_norm": 3.5470170974731445,
      "learning_rate": 1.609889613621267e-05,
      "loss": 0.1358,
      "step": 1286
    },
    {
      "epoch": 0.8743206521739131,
      "grad_norm": 2.0894718170166016,
      "learning_rate": 1.6093256755067236e-05,
      "loss": 0.0276,
      "step": 1287
    },
    {
      "epoch": 0.875,
      "grad_norm": 3.1288719177246094,
      "learning_rate": 1.608761429008721e-05,
      "loss": 0.1447,
      "step": 1288
    },
    {
      "epoch": 0.8756793478260869,
      "grad_norm": 2.3026227951049805,
      "learning_rate": 1.608196874412827e-05,
      "loss": 0.0823,
      "step": 1289
    },
    {
      "epoch": 0.876358695652174,
      "grad_norm": 5.376462459564209,
      "learning_rate": 1.6076320120047667e-05,
      "loss": 0.2638,
      "step": 1290
    },
    {
      "epoch": 0.8770380434782609,
      "grad_norm": 0.3238861858844757,
      "learning_rate": 1.6070668420704203e-05,
      "loss": 0.0043,
      "step": 1291
    },
    {
      "epoch": 0.8777173913043478,
      "grad_norm": 3.516524314880371,
      "learning_rate": 1.6065013648958238e-05,
      "loss": 0.0658,
      "step": 1292
    },
    {
      "epoch": 0.8783967391304348,
      "grad_norm": 1.6089285612106323,
      "learning_rate": 1.6059355807671683e-05,
      "loss": 0.109,
      "step": 1293
    },
    {
      "epoch": 0.8790760869565217,
      "grad_norm": 0.18726782500743866,
      "learning_rate": 1.6053694899708014e-05,
      "loss": 0.0025,
      "step": 1294
    },
    {
      "epoch": 0.8797554347826086,
      "grad_norm": 2.5949580669403076,
      "learning_rate": 1.6048030927932242e-05,
      "loss": 0.144,
      "step": 1295
    },
    {
      "epoch": 0.8804347826086957,
      "grad_norm": 4.116728782653809,
      "learning_rate": 1.6042363895210948e-05,
      "loss": 0.1296,
      "step": 1296
    },
    {
      "epoch": 0.8811141304347826,
      "grad_norm": 11.998641967773438,
      "learning_rate": 1.603669380441224e-05,
      "loss": 0.2415,
      "step": 1297
    },
    {
      "epoch": 0.8817934782608695,
      "grad_norm": 5.457826137542725,
      "learning_rate": 1.60310206584058e-05,
      "loss": 0.1581,
      "step": 1298
    },
    {
      "epoch": 0.8824728260869565,
      "grad_norm": 2.4022936820983887,
      "learning_rate": 1.6025344460062826e-05,
      "loss": 0.106,
      "step": 1299
    },
    {
      "epoch": 0.8831521739130435,
      "grad_norm": 7.3972907066345215,
      "learning_rate": 1.601966521225609e-05,
      "loss": 0.2061,
      "step": 1300
    },
    {
      "epoch": 0.8838315217391305,
      "grad_norm": 5.703345775604248,
      "learning_rate": 1.6013982917859884e-05,
      "loss": 0.3937,
      "step": 1301
    },
    {
      "epoch": 0.8845108695652174,
      "grad_norm": 10.791214942932129,
      "learning_rate": 1.6008297579750063e-05,
      "loss": 0.2238,
      "step": 1302
    },
    {
      "epoch": 0.8851902173913043,
      "grad_norm": 6.076932907104492,
      "learning_rate": 1.6002609200804003e-05,
      "loss": 0.252,
      "step": 1303
    },
    {
      "epoch": 0.8858695652173914,
      "grad_norm": 0.09868742525577545,
      "learning_rate": 1.5996917783900633e-05,
      "loss": 0.0019,
      "step": 1304
    },
    {
      "epoch": 0.8865489130434783,
      "grad_norm": 3.9237072467803955,
      "learning_rate": 1.59912233319204e-05,
      "loss": 0.0645,
      "step": 1305
    },
    {
      "epoch": 0.8872282608695652,
      "grad_norm": 0.19290049374103546,
      "learning_rate": 1.5985525847745322e-05,
      "loss": 0.0029,
      "step": 1306
    },
    {
      "epoch": 0.8879076086956522,
      "grad_norm": 0.9907317161560059,
      "learning_rate": 1.597982533425892e-05,
      "loss": 0.013,
      "step": 1307
    },
    {
      "epoch": 0.8885869565217391,
      "grad_norm": 3.527364492416382,
      "learning_rate": 1.597412179434626e-05,
      "loss": 0.1421,
      "step": 1308
    },
    {
      "epoch": 0.889266304347826,
      "grad_norm": 2.584656238555908,
      "learning_rate": 1.5968415230893933e-05,
      "loss": 0.1131,
      "step": 1309
    },
    {
      "epoch": 0.8899456521739131,
      "grad_norm": 2.6943163871765137,
      "learning_rate": 1.596270564679007e-05,
      "loss": 0.0403,
      "step": 1310
    },
    {
      "epoch": 0.890625,
      "grad_norm": 0.09519722312688828,
      "learning_rate": 1.5956993044924334e-05,
      "loss": 0.0016,
      "step": 1311
    },
    {
      "epoch": 0.8913043478260869,
      "grad_norm": 1.2753654718399048,
      "learning_rate": 1.59512774281879e-05,
      "loss": 0.014,
      "step": 1312
    },
    {
      "epoch": 0.891983695652174,
      "grad_norm": 0.4046708643436432,
      "learning_rate": 1.5945558799473474e-05,
      "loss": 0.0055,
      "step": 1313
    },
    {
      "epoch": 0.8926630434782609,
      "grad_norm": 2.5653581619262695,
      "learning_rate": 1.5939837161675297e-05,
      "loss": 0.1038,
      "step": 1314
    },
    {
      "epoch": 0.8933423913043478,
      "grad_norm": 0.5015807151794434,
      "learning_rate": 1.5934112517689116e-05,
      "loss": 0.0053,
      "step": 1315
    },
    {
      "epoch": 0.8940217391304348,
      "grad_norm": 2.3578391075134277,
      "learning_rate": 1.5928384870412213e-05,
      "loss": 0.1178,
      "step": 1316
    },
    {
      "epoch": 0.8947010869565217,
      "grad_norm": 3.626117706298828,
      "learning_rate": 1.592265422274339e-05,
      "loss": 0.0925,
      "step": 1317
    },
    {
      "epoch": 0.8953804347826086,
      "grad_norm": 2.7732105255126953,
      "learning_rate": 1.5916920577582956e-05,
      "loss": 0.1959,
      "step": 1318
    },
    {
      "epoch": 0.8960597826086957,
      "grad_norm": 5.221782207489014,
      "learning_rate": 1.5911183937832746e-05,
      "loss": 0.344,
      "step": 1319
    },
    {
      "epoch": 0.8967391304347826,
      "grad_norm": 1.4223157167434692,
      "learning_rate": 1.590544430639611e-05,
      "loss": 0.0603,
      "step": 1320
    },
    {
      "epoch": 0.8974184782608695,
      "grad_norm": 2.445943832397461,
      "learning_rate": 1.589970168617791e-05,
      "loss": 0.1539,
      "step": 1321
    },
    {
      "epoch": 0.8980978260869565,
      "grad_norm": 4.270816802978516,
      "learning_rate": 1.589395608008452e-05,
      "loss": 0.1866,
      "step": 1322
    },
    {
      "epoch": 0.8987771739130435,
      "grad_norm": 0.21755638718605042,
      "learning_rate": 1.5888207491023824e-05,
      "loss": 0.003,
      "step": 1323
    },
    {
      "epoch": 0.8994565217391305,
      "grad_norm": 1.229182243347168,
      "learning_rate": 1.5882455921905228e-05,
      "loss": 0.0128,
      "step": 1324
    },
    {
      "epoch": 0.9001358695652174,
      "grad_norm": 0.2901119291782379,
      "learning_rate": 1.5876701375639626e-05,
      "loss": 0.0046,
      "step": 1325
    },
    {
      "epoch": 0.9008152173913043,
      "grad_norm": 0.25912877917289734,
      "learning_rate": 1.5870943855139437e-05,
      "loss": 0.0041,
      "step": 1326
    },
    {
      "epoch": 0.9014945652173914,
      "grad_norm": 5.721938133239746,
      "learning_rate": 1.586518336331857e-05,
      "loss": 0.0796,
      "step": 1327
    },
    {
      "epoch": 0.9021739130434783,
      "grad_norm": 0.19369111955165863,
      "learning_rate": 1.585941990309245e-05,
      "loss": 0.0022,
      "step": 1328
    },
    {
      "epoch": 0.9028532608695652,
      "grad_norm": 3.363542318344116,
      "learning_rate": 1.5853653477377996e-05,
      "loss": 0.2007,
      "step": 1329
    },
    {
      "epoch": 0.9035326086956522,
      "grad_norm": 0.10174233466386795,
      "learning_rate": 1.5847884089093633e-05,
      "loss": 0.002,
      "step": 1330
    },
    {
      "epoch": 0.9042119565217391,
      "grad_norm": 4.917313098907471,
      "learning_rate": 1.5842111741159286e-05,
      "loss": 0.1845,
      "step": 1331
    },
    {
      "epoch": 0.904891304347826,
      "grad_norm": 7.995621681213379,
      "learning_rate": 1.5836336436496377e-05,
      "loss": 0.7376,
      "step": 1332
    },
    {
      "epoch": 0.9055706521739131,
      "grad_norm": 0.5187114477157593,
      "learning_rate": 1.583055817802782e-05,
      "loss": 0.0053,
      "step": 1333
    },
    {
      "epoch": 0.90625,
      "grad_norm": 5.926273822784424,
      "learning_rate": 1.5824776968678024e-05,
      "loss": 0.1955,
      "step": 1334
    },
    {
      "epoch": 0.9069293478260869,
      "grad_norm": 8.109807014465332,
      "learning_rate": 1.5818992811372898e-05,
      "loss": 0.2977,
      "step": 1335
    },
    {
      "epoch": 0.907608695652174,
      "grad_norm": 0.2794247567653656,
      "learning_rate": 1.5813205709039842e-05,
      "loss": 0.0042,
      "step": 1336
    },
    {
      "epoch": 0.9082880434782609,
      "grad_norm": 2.2790815830230713,
      "learning_rate": 1.5807415664607737e-05,
      "loss": 0.0637,
      "step": 1337
    },
    {
      "epoch": 0.9089673913043478,
      "grad_norm": 3.1525049209594727,
      "learning_rate": 1.5801622681006966e-05,
      "loss": 0.1046,
      "step": 1338
    },
    {
      "epoch": 0.9096467391304348,
      "grad_norm": 4.6230878829956055,
      "learning_rate": 1.5795826761169393e-05,
      "loss": 0.1582,
      "step": 1339
    },
    {
      "epoch": 0.9103260869565217,
      "grad_norm": 3.482593297958374,
      "learning_rate": 1.5790027908028366e-05,
      "loss": 0.2293,
      "step": 1340
    },
    {
      "epoch": 0.9110054347826086,
      "grad_norm": 0.38501834869384766,
      "learning_rate": 1.5784226124518724e-05,
      "loss": 0.0073,
      "step": 1341
    },
    {
      "epoch": 0.9116847826086957,
      "grad_norm": 2.139173746109009,
      "learning_rate": 1.5778421413576778e-05,
      "loss": 0.1795,
      "step": 1342
    },
    {
      "epoch": 0.9123641304347826,
      "grad_norm": 4.752762794494629,
      "learning_rate": 1.5772613778140337e-05,
      "loss": 0.3807,
      "step": 1343
    },
    {
      "epoch": 0.9130434782608695,
      "grad_norm": 1.3522573709487915,
      "learning_rate": 1.5766803221148676e-05,
      "loss": 0.0193,
      "step": 1344
    },
    {
      "epoch": 0.9137228260869565,
      "grad_norm": 1.3952442407608032,
      "learning_rate": 1.5760989745542547e-05,
      "loss": 0.0212,
      "step": 1345
    },
    {
      "epoch": 0.9144021739130435,
      "grad_norm": 10.342241287231445,
      "learning_rate": 1.57551733542642e-05,
      "loss": 0.5245,
      "step": 1346
    },
    {
      "epoch": 0.9150815217391305,
      "grad_norm": 1.7144321203231812,
      "learning_rate": 1.5749354050257334e-05,
      "loss": 0.1053,
      "step": 1347
    },
    {
      "epoch": 0.9157608695652174,
      "grad_norm": 3.4002153873443604,
      "learning_rate": 1.574353183646714e-05,
      "loss": 0.2295,
      "step": 1348
    },
    {
      "epoch": 0.9164402173913043,
      "grad_norm": 6.2355875968933105,
      "learning_rate": 1.5737706715840276e-05,
      "loss": 0.1164,
      "step": 1349
    },
    {
      "epoch": 0.9171195652173914,
      "grad_norm": 4.140244960784912,
      "learning_rate": 1.5731878691324874e-05,
      "loss": 0.2055,
      "step": 1350
    },
    {
      "epoch": 0.9177989130434783,
      "grad_norm": 0.41874563694000244,
      "learning_rate": 1.5726047765870525e-05,
      "loss": 0.0061,
      "step": 1351
    },
    {
      "epoch": 0.9184782608695652,
      "grad_norm": 4.309288501739502,
      "learning_rate": 1.57202139424283e-05,
      "loss": 0.1409,
      "step": 1352
    },
    {
      "epoch": 0.9191576086956522,
      "grad_norm": 4.739232063293457,
      "learning_rate": 1.5714377223950734e-05,
      "loss": 0.1881,
      "step": 1353
    },
    {
      "epoch": 0.9198369565217391,
      "grad_norm": 7.977144241333008,
      "learning_rate": 1.5708537613391826e-05,
      "loss": 0.2704,
      "step": 1354
    },
    {
      "epoch": 0.920516304347826,
      "grad_norm": 0.4190326929092407,
      "learning_rate": 1.570269511370704e-05,
      "loss": 0.0065,
      "step": 1355
    },
    {
      "epoch": 0.9211956521739131,
      "grad_norm": 2.012848377227783,
      "learning_rate": 1.5696849727853297e-05,
      "loss": 0.1343,
      "step": 1356
    },
    {
      "epoch": 0.921875,
      "grad_norm": 0.14605434238910675,
      "learning_rate": 1.5691001458788984e-05,
      "loss": 0.0024,
      "step": 1357
    },
    {
      "epoch": 0.9225543478260869,
      "grad_norm": 9.175707817077637,
      "learning_rate": 1.5685150309473947e-05,
      "loss": 0.5016,
      "step": 1358
    },
    {
      "epoch": 0.923233695652174,
      "grad_norm": 4.68433952331543,
      "learning_rate": 1.567929628286949e-05,
      "loss": 0.2323,
      "step": 1359
    },
    {
      "epoch": 0.9239130434782609,
      "grad_norm": 1.9469913244247437,
      "learning_rate": 1.5673439381938365e-05,
      "loss": 0.0599,
      "step": 1360
    },
    {
      "epoch": 0.9245923913043478,
      "grad_norm": 0.06258512288331985,
      "learning_rate": 1.5667579609644793e-05,
      "loss": 0.0014,
      "step": 1361
    },
    {
      "epoch": 0.9252717391304348,
      "grad_norm": 1.8937327861785889,
      "learning_rate": 1.5661716968954436e-05,
      "loss": 0.1348,
      "step": 1362
    },
    {
      "epoch": 0.9259510869565217,
      "grad_norm": 7.01574182510376,
      "learning_rate": 1.5655851462834414e-05,
      "loss": 0.396,
      "step": 1363
    },
    {
      "epoch": 0.9266304347826086,
      "grad_norm": 4.79996395111084,
      "learning_rate": 1.56499830942533e-05,
      "loss": 0.202,
      "step": 1364
    },
    {
      "epoch": 0.9273097826086957,
      "grad_norm": 2.7674779891967773,
      "learning_rate": 1.56441118661811e-05,
      "loss": 0.1793,
      "step": 1365
    },
    {
      "epoch": 0.9279891304347826,
      "grad_norm": 0.22814974188804626,
      "learning_rate": 1.563823778158929e-05,
      "loss": 0.0023,
      "step": 1366
    },
    {
      "epoch": 0.9286684782608695,
      "grad_norm": 8.013402938842773,
      "learning_rate": 1.563236084345078e-05,
      "loss": 0.2934,
      "step": 1367
    },
    {
      "epoch": 0.9293478260869565,
      "grad_norm": 3.7985165119171143,
      "learning_rate": 1.5626481054739916e-05,
      "loss": 0.1352,
      "step": 1368
    },
    {
      "epoch": 0.9300271739130435,
      "grad_norm": 0.0723981186747551,
      "learning_rate": 1.56205984184325e-05,
      "loss": 0.0013,
      "step": 1369
    },
    {
      "epoch": 0.9307065217391305,
      "grad_norm": 4.4031662940979,
      "learning_rate": 1.5614712937505767e-05,
      "loss": 0.1751,
      "step": 1370
    },
    {
      "epoch": 0.9313858695652174,
      "grad_norm": 2.0293290615081787,
      "learning_rate": 1.56088246149384e-05,
      "loss": 0.0975,
      "step": 1371
    },
    {
      "epoch": 0.9320652173913043,
      "grad_norm": 2.1659982204437256,
      "learning_rate": 1.560293345371051e-05,
      "loss": 0.1096,
      "step": 1372
    },
    {
      "epoch": 0.9327445652173914,
      "grad_norm": 3.485015630722046,
      "learning_rate": 1.559703945680366e-05,
      "loss": 0.0375,
      "step": 1373
    },
    {
      "epoch": 0.9334239130434783,
      "grad_norm": 0.2646472752094269,
      "learning_rate": 1.5591142627200825e-05,
      "loss": 0.0035,
      "step": 1374
    },
    {
      "epoch": 0.9341032608695652,
      "grad_norm": 1.7092710733413696,
      "learning_rate": 1.5585242967886432e-05,
      "loss": 0.0234,
      "step": 1375
    },
    {
      "epoch": 0.9347826086956522,
      "grad_norm": 0.25594067573547363,
      "learning_rate": 1.5579340481846338e-05,
      "loss": 0.0038,
      "step": 1376
    },
    {
      "epoch": 0.9354619565217391,
      "grad_norm": 0.26532942056655884,
      "learning_rate": 1.557343517206782e-05,
      "loss": 0.0036,
      "step": 1377
    },
    {
      "epoch": 0.936141304347826,
      "grad_norm": 3.18265962600708,
      "learning_rate": 1.5567527041539597e-05,
      "loss": 0.1477,
      "step": 1378
    },
    {
      "epoch": 0.9368206521739131,
      "grad_norm": 0.0731281116604805,
      "learning_rate": 1.556161609325181e-05,
      "loss": 0.0011,
      "step": 1379
    },
    {
      "epoch": 0.9375,
      "grad_norm": 12.691439628601074,
      "learning_rate": 1.5555702330196024e-05,
      "loss": 0.4827,
      "step": 1380
    },
    {
      "epoch": 0.9381793478260869,
      "grad_norm": 3.8921897411346436,
      "learning_rate": 1.5549785755365233e-05,
      "loss": 0.1618,
      "step": 1381
    },
    {
      "epoch": 0.938858695652174,
      "grad_norm": 4.355643272399902,
      "learning_rate": 1.5543866371753852e-05,
      "loss": 0.1425,
      "step": 1382
    },
    {
      "epoch": 0.9395380434782609,
      "grad_norm": 0.2915983498096466,
      "learning_rate": 1.553794418235771e-05,
      "loss": 0.0044,
      "step": 1383
    },
    {
      "epoch": 0.9402173913043478,
      "grad_norm": 1.8095200061798096,
      "learning_rate": 1.5532019190174074e-05,
      "loss": 0.0257,
      "step": 1384
    },
    {
      "epoch": 0.9408967391304348,
      "grad_norm": 6.169997215270996,
      "learning_rate": 1.5526091398201612e-05,
      "loss": 0.4273,
      "step": 1385
    },
    {
      "epoch": 0.9415760869565217,
      "grad_norm": 6.119411945343018,
      "learning_rate": 1.552016080944042e-05,
      "loss": 0.1751,
      "step": 1386
    },
    {
      "epoch": 0.9422554347826086,
      "grad_norm": 4.820570945739746,
      "learning_rate": 1.5514227426892e-05,
      "loss": 0.2603,
      "step": 1387
    },
    {
      "epoch": 0.9429347826086957,
      "grad_norm": 1.725374698638916,
      "learning_rate": 1.550829125355928e-05,
      "loss": 0.0323,
      "step": 1388
    },
    {
      "epoch": 0.9436141304347826,
      "grad_norm": 0.4839443564414978,
      "learning_rate": 1.550235229244659e-05,
      "loss": 0.0057,
      "step": 1389
    },
    {
      "epoch": 0.9442934782608695,
      "grad_norm": 1.219775915145874,
      "learning_rate": 1.549641054655967e-05,
      "loss": 0.0127,
      "step": 1390
    },
    {
      "epoch": 0.9449728260869565,
      "grad_norm": 1.612433671951294,
      "learning_rate": 1.5490466018905684e-05,
      "loss": 0.0595,
      "step": 1391
    },
    {
      "epoch": 0.9456521739130435,
      "grad_norm": 28.526214599609375,
      "learning_rate": 1.5484518712493188e-05,
      "loss": 0.0915,
      "step": 1392
    },
    {
      "epoch": 0.9463315217391305,
      "grad_norm": 0.11433087289333344,
      "learning_rate": 1.547856863033215e-05,
      "loss": 0.0023,
      "step": 1393
    },
    {
      "epoch": 0.9470108695652174,
      "grad_norm": 3.5893735885620117,
      "learning_rate": 1.547261577543395e-05,
      "loss": 0.2111,
      "step": 1394
    },
    {
      "epoch": 0.9476902173913043,
      "grad_norm": 1.6231921911239624,
      "learning_rate": 1.546666015081135e-05,
      "loss": 0.0141,
      "step": 1395
    },
    {
      "epoch": 0.9483695652173914,
      "grad_norm": 8.756699562072754,
      "learning_rate": 1.5460701759478538e-05,
      "loss": 0.1279,
      "step": 1396
    },
    {
      "epoch": 0.9490489130434783,
      "grad_norm": 0.18652263283729553,
      "learning_rate": 1.5454740604451092e-05,
      "loss": 0.0027,
      "step": 1397
    },
    {
      "epoch": 0.9497282608695652,
      "grad_norm": 2.2383341789245605,
      "learning_rate": 1.544877668874599e-05,
      "loss": 0.026,
      "step": 1398
    },
    {
      "epoch": 0.9504076086956522,
      "grad_norm": 8.32702350616455,
      "learning_rate": 1.54428100153816e-05,
      "loss": 0.4711,
      "step": 1399
    },
    {
      "epoch": 0.9510869565217391,
      "grad_norm": 3.2621867656707764,
      "learning_rate": 1.54368405873777e-05,
      "loss": 0.1726,
      "step": 1400
    },
    {
      "epoch": 0.951766304347826,
      "grad_norm": 11.59145736694336,
      "learning_rate": 1.543086840775545e-05,
      "loss": 0.224,
      "step": 1401
    },
    {
      "epoch": 0.9524456521739131,
      "grad_norm": 0.09271034598350525,
      "learning_rate": 1.542489347953741e-05,
      "loss": 0.0013,
      "step": 1402
    },
    {
      "epoch": 0.953125,
      "grad_norm": 0.0516352653503418,
      "learning_rate": 1.5418915805747518e-05,
      "loss": 0.0011,
      "step": 1403
    },
    {
      "epoch": 0.9538043478260869,
      "grad_norm": 1.4728039503097534,
      "learning_rate": 1.5412935389411124e-05,
      "loss": 0.0581,
      "step": 1404
    },
    {
      "epoch": 0.954483695652174,
      "grad_norm": 3.219475746154785,
      "learning_rate": 1.5406952233554945e-05,
      "loss": 0.1245,
      "step": 1405
    },
    {
      "epoch": 0.9551630434782609,
      "grad_norm": 5.010410308837891,
      "learning_rate": 1.5400966341207095e-05,
      "loss": 0.0689,
      "step": 1406
    },
    {
      "epoch": 0.9558423913043478,
      "grad_norm": 1.9193545579910278,
      "learning_rate": 1.5394977715397073e-05,
      "loss": 0.1013,
      "step": 1407
    },
    {
      "epoch": 0.9565217391304348,
      "grad_norm": 12.131631851196289,
      "learning_rate": 1.538898635915576e-05,
      "loss": 0.3816,
      "step": 1408
    },
    {
      "epoch": 0.9572010869565217,
      "grad_norm": 1.5076907873153687,
      "learning_rate": 1.5382992275515406e-05,
      "loss": 0.0136,
      "step": 1409
    },
    {
      "epoch": 0.9578804347826086,
      "grad_norm": 1.5367690324783325,
      "learning_rate": 1.5376995467509673e-05,
      "loss": 0.1136,
      "step": 1410
    },
    {
      "epoch": 0.9585597826086957,
      "grad_norm": 1.9775853157043457,
      "learning_rate": 1.5370995938173566e-05,
      "loss": 0.0197,
      "step": 1411
    },
    {
      "epoch": 0.9592391304347826,
      "grad_norm": 1.0298393964767456,
      "learning_rate": 1.5364993690543495e-05,
      "loss": 0.0083,
      "step": 1412
    },
    {
      "epoch": 0.9599184782608695,
      "grad_norm": 2.9253249168395996,
      "learning_rate": 1.5358988727657227e-05,
      "loss": 0.2184,
      "step": 1413
    },
    {
      "epoch": 0.9605978260869565,
      "grad_norm": 1.8814918994903564,
      "learning_rate": 1.5352981052553913e-05,
      "loss": 0.024,
      "step": 1414
    },
    {
      "epoch": 0.9612771739130435,
      "grad_norm": 1.3153156042099,
      "learning_rate": 1.5346970668274076e-05,
      "loss": 0.0184,
      "step": 1415
    },
    {
      "epoch": 0.9619565217391305,
      "grad_norm": 0.5216849446296692,
      "learning_rate": 1.5340957577859605e-05,
      "loss": 0.0056,
      "step": 1416
    },
    {
      "epoch": 0.9626358695652174,
      "grad_norm": 1.4897547960281372,
      "learning_rate": 1.533494178435376e-05,
      "loss": 0.0203,
      "step": 1417
    },
    {
      "epoch": 0.9633152173913043,
      "grad_norm": 3.1214683055877686,
      "learning_rate": 1.5328923290801177e-05,
      "loss": 0.1089,
      "step": 1418
    },
    {
      "epoch": 0.9639945652173914,
      "grad_norm": 2.0721707344055176,
      "learning_rate": 1.532290210024785e-05,
      "loss": 0.11,
      "step": 1419
    },
    {
      "epoch": 0.9646739130434783,
      "grad_norm": 8.888567924499512,
      "learning_rate": 1.531687821574114e-05,
      "loss": 0.2583,
      "step": 1420
    },
    {
      "epoch": 0.9653532608695652,
      "grad_norm": 17.0009822845459,
      "learning_rate": 1.531085164032977e-05,
      "loss": 0.2365,
      "step": 1421
    },
    {
      "epoch": 0.9660326086956522,
      "grad_norm": 3.2054848670959473,
      "learning_rate": 1.530482237706383e-05,
      "loss": 0.2355,
      "step": 1422
    },
    {
      "epoch": 0.9667119565217391,
      "grad_norm": 2.96315598487854,
      "learning_rate": 1.529879042899477e-05,
      "loss": 0.1957,
      "step": 1423
    },
    {
      "epoch": 0.967391304347826,
      "grad_norm": 2.673245429992676,
      "learning_rate": 1.529275579917539e-05,
      "loss": 0.1303,
      "step": 1424
    },
    {
      "epoch": 0.9680706521739131,
      "grad_norm": 13.4135103225708,
      "learning_rate": 1.5286718490659854e-05,
      "loss": 0.5975,
      "step": 1425
    },
    {
      "epoch": 0.96875,
      "grad_norm": 0.039391111582517624,
      "learning_rate": 1.528067850650368e-05,
      "loss": 0.0009,
      "step": 1426
    },
    {
      "epoch": 0.9694293478260869,
      "grad_norm": 9.68433666229248,
      "learning_rate": 1.5274635849763744e-05,
      "loss": 0.3026,
      "step": 1427
    },
    {
      "epoch": 0.970108695652174,
      "grad_norm": 2.267730474472046,
      "learning_rate": 1.526859052349827e-05,
      "loss": 0.1202,
      "step": 1428
    },
    {
      "epoch": 0.9707880434782609,
      "grad_norm": 11.704648971557617,
      "learning_rate": 1.526254253076684e-05,
      "loss": 0.3935,
      "step": 1429
    },
    {
      "epoch": 0.9714673913043478,
      "grad_norm": 6.773514747619629,
      "learning_rate": 1.525649187463037e-05,
      "loss": 0.2959,
      "step": 1430
    },
    {
      "epoch": 0.9721467391304348,
      "grad_norm": 3.744154691696167,
      "learning_rate": 1.5250438558151142e-05,
      "loss": 0.107,
      "step": 1431
    },
    {
      "epoch": 0.9728260869565217,
      "grad_norm": 1.2610846757888794,
      "learning_rate": 1.5244382584392772e-05,
      "loss": 0.0947,
      "step": 1432
    },
    {
      "epoch": 0.9735054347826086,
      "grad_norm": 0.5458475351333618,
      "learning_rate": 1.523832395642023e-05,
      "loss": 0.0073,
      "step": 1433
    },
    {
      "epoch": 0.9741847826086957,
      "grad_norm": 0.9353652596473694,
      "learning_rate": 1.5232262677299816e-05,
      "loss": 0.0081,
      "step": 1434
    },
    {
      "epoch": 0.9748641304347826,
      "grad_norm": 10.527609825134277,
      "learning_rate": 1.5226198750099194e-05,
      "loss": 0.5745,
      "step": 1435
    },
    {
      "epoch": 0.9755434782608695,
      "grad_norm": 5.553571701049805,
      "learning_rate": 1.5220132177887345e-05,
      "loss": 0.1119,
      "step": 1436
    },
    {
      "epoch": 0.9762228260869565,
      "grad_norm": 2.8323769569396973,
      "learning_rate": 1.5214062963734599e-05,
      "loss": 0.0735,
      "step": 1437
    },
    {
      "epoch": 0.9769021739130435,
      "grad_norm": 2.2384755611419678,
      "learning_rate": 1.5207991110712628e-05,
      "loss": 0.1349,
      "step": 1438
    },
    {
      "epoch": 0.9775815217391305,
      "grad_norm": 0.39119184017181396,
      "learning_rate": 1.5201916621894425e-05,
      "loss": 0.004,
      "step": 1439
    },
    {
      "epoch": 0.9782608695652174,
      "grad_norm": 0.45842689275741577,
      "learning_rate": 1.5195839500354337e-05,
      "loss": 0.0052,
      "step": 1440
    },
    {
      "epoch": 0.9789402173913043,
      "grad_norm": 1.1535452604293823,
      "learning_rate": 1.5189759749168027e-05,
      "loss": 0.016,
      "step": 1441
    },
    {
      "epoch": 0.9796195652173914,
      "grad_norm": 5.3760223388671875,
      "learning_rate": 1.518367737141249e-05,
      "loss": 0.034,
      "step": 1442
    },
    {
      "epoch": 0.9802989130434783,
      "grad_norm": 0.16998697817325592,
      "learning_rate": 1.517759237016606e-05,
      "loss": 0.0022,
      "step": 1443
    },
    {
      "epoch": 0.9809782608695652,
      "grad_norm": 4.783424377441406,
      "learning_rate": 1.5171504748508394e-05,
      "loss": 0.1086,
      "step": 1444
    },
    {
      "epoch": 0.9816576086956522,
      "grad_norm": 1.9343348741531372,
      "learning_rate": 1.5165414509520473e-05,
      "loss": 0.0213,
      "step": 1445
    },
    {
      "epoch": 0.9823369565217391,
      "grad_norm": 0.47566521167755127,
      "learning_rate": 1.5159321656284602e-05,
      "loss": 0.0058,
      "step": 1446
    },
    {
      "epoch": 0.983016304347826,
      "grad_norm": 3.8348770141601562,
      "learning_rate": 1.5153226191884417e-05,
      "loss": 0.1107,
      "step": 1447
    },
    {
      "epoch": 0.9836956521739131,
      "grad_norm": 1.754945993423462,
      "learning_rate": 1.5147128119404863e-05,
      "loss": 0.103,
      "step": 1448
    },
    {
      "epoch": 0.984375,
      "grad_norm": 2.9463510513305664,
      "learning_rate": 1.5141027441932217e-05,
      "loss": 0.1089,
      "step": 1449
    },
    {
      "epoch": 0.9850543478260869,
      "grad_norm": 4.893955707550049,
      "learning_rate": 1.513492416255407e-05,
      "loss": 0.0484,
      "step": 1450
    },
    {
      "epoch": 0.985733695652174,
      "grad_norm": 0.028525391593575478,
      "learning_rate": 1.5128818284359326e-05,
      "loss": 0.0008,
      "step": 1451
    },
    {
      "epoch": 0.9864130434782609,
      "grad_norm": 0.47931164503097534,
      "learning_rate": 1.5122709810438205e-05,
      "loss": 0.005,
      "step": 1452
    },
    {
      "epoch": 0.9870923913043478,
      "grad_norm": 1.3596457242965698,
      "learning_rate": 1.5116598743882247e-05,
      "loss": 0.0672,
      "step": 1453
    },
    {
      "epoch": 0.9877717391304348,
      "grad_norm": 0.6984943151473999,
      "learning_rate": 1.5110485087784302e-05,
      "loss": 0.0071,
      "step": 1454
    },
    {
      "epoch": 0.9884510869565217,
      "grad_norm": 1.2223610877990723,
      "learning_rate": 1.5104368845238525e-05,
      "loss": 0.0202,
      "step": 1455
    },
    {
      "epoch": 0.9891304347826086,
      "grad_norm": 3.450603485107422,
      "learning_rate": 1.5098250019340385e-05,
      "loss": 0.0425,
      "step": 1456
    },
    {
      "epoch": 0.9898097826086957,
      "grad_norm": 0.10870871692895889,
      "learning_rate": 1.5092128613186658e-05,
      "loss": 0.0014,
      "step": 1457
    },
    {
      "epoch": 0.9904891304347826,
      "grad_norm": 5.7792582511901855,
      "learning_rate": 1.5086004629875426e-05,
      "loss": 0.2289,
      "step": 1458
    },
    {
      "epoch": 0.9911684782608695,
      "grad_norm": 0.0764269307255745,
      "learning_rate": 1.507987807250607e-05,
      "loss": 0.0012,
      "step": 1459
    },
    {
      "epoch": 0.9918478260869565,
      "grad_norm": 3.5533792972564697,
      "learning_rate": 1.5073748944179282e-05,
      "loss": 0.0927,
      "step": 1460
    },
    {
      "epoch": 0.9925271739130435,
      "grad_norm": 2.4111173152923584,
      "learning_rate": 1.5067617247997053e-05,
      "loss": 0.1277,
      "step": 1461
    },
    {
      "epoch": 0.9932065217391305,
      "grad_norm": 0.027327407151460648,
      "learning_rate": 1.5061482987062668e-05,
      "loss": 0.0008,
      "step": 1462
    },
    {
      "epoch": 0.9938858695652174,
      "grad_norm": 0.02859019674360752,
      "learning_rate": 1.5055346164480717e-05,
      "loss": 0.0008,
      "step": 1463
    },
    {
      "epoch": 0.9945652173913043,
      "grad_norm": 4.184196472167969,
      "learning_rate": 1.5049206783357082e-05,
      "loss": 0.0618,
      "step": 1464
    },
    {
      "epoch": 0.9952445652173914,
      "grad_norm": 7.3559250831604,
      "learning_rate": 1.504306484679894e-05,
      "loss": 0.425,
      "step": 1465
    },
    {
      "epoch": 0.9959239130434783,
      "grad_norm": 3.4072744846343994,
      "learning_rate": 1.5036920357914766e-05,
      "loss": 0.2185,
      "step": 1466
    },
    {
      "epoch": 0.9966032608695652,
      "grad_norm": 1.3670642375946045,
      "learning_rate": 1.5030773319814324e-05,
      "loss": 0.0447,
      "step": 1467
    },
    {
      "epoch": 0.9972826086956522,
      "grad_norm": 3.223696231842041,
      "learning_rate": 1.5024623735608663e-05,
      "loss": 0.1357,
      "step": 1468
    },
    {
      "epoch": 0.9979619565217391,
      "grad_norm": 1.4096317291259766,
      "learning_rate": 1.5018471608410128e-05,
      "loss": 0.0112,
      "step": 1469
    },
    {
      "epoch": 0.998641304347826,
      "grad_norm": 6.162574291229248,
      "learning_rate": 1.501231694133235e-05,
      "loss": 0.1587,
      "step": 1470
    },
    {
      "epoch": 0.9993206521739131,
      "grad_norm": 1.8112132549285889,
      "learning_rate": 1.500615973749024e-05,
      "loss": 0.1204,
      "step": 1471
    },
    {
      "epoch": 1.0,
      "grad_norm": 12.896378517150879,
      "learning_rate": 1.5000000000000002e-05,
      "loss": 0.2373,
      "step": 1472
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.4268292682926829,
      "eval_loss": 0.1681247353553772,
      "eval_runtime": 153.7392,
      "eval_samples_per_second": 1.067,
      "eval_steps_per_second": 1.067,
      "step": 1472
    },
    {
      "epoch": 1.000679347826087,
      "grad_norm": 0.0386698879301548,
      "learning_rate": 1.499383773197911e-05,
      "loss": 0.001,
      "step": 1473
    },
    {
      "epoch": 1.0013586956521738,
      "grad_norm": 6.267481803894043,
      "learning_rate": 1.4987672936546331e-05,
      "loss": 0.038,
      "step": 1474
    },
    {
      "epoch": 1.002038043478261,
      "grad_norm": 10.553966522216797,
      "learning_rate": 1.4981505616821705e-05,
      "loss": 0.4188,
      "step": 1475
    },
    {
      "epoch": 1.002717391304348,
      "grad_norm": 1.703957438468933,
      "learning_rate": 1.4975335775926547e-05,
      "loss": 0.061,
      "step": 1476
    },
    {
      "epoch": 1.0033967391304348,
      "grad_norm": 6.648805141448975,
      "learning_rate": 1.4969163416983457e-05,
      "loss": 0.3101,
      "step": 1477
    },
    {
      "epoch": 1.0040760869565217,
      "grad_norm": 3.134371280670166,
      "learning_rate": 1.4962988543116295e-05,
      "loss": 0.1475,
      "step": 1478
    },
    {
      "epoch": 1.0047554347826086,
      "grad_norm": 2.5793135166168213,
      "learning_rate": 1.495681115745021e-05,
      "loss": 0.1491,
      "step": 1479
    },
    {
      "epoch": 1.0054347826086956,
      "grad_norm": 3.6675243377685547,
      "learning_rate": 1.4950631263111615e-05,
      "loss": 0.2494,
      "step": 1480
    },
    {
      "epoch": 1.0061141304347827,
      "grad_norm": 1.0573880672454834,
      "learning_rate": 1.4944448863228187e-05,
      "loss": 0.0354,
      "step": 1481
    },
    {
      "epoch": 1.0067934782608696,
      "grad_norm": 0.3678439259529114,
      "learning_rate": 1.4938263960928878e-05,
      "loss": 0.0041,
      "step": 1482
    },
    {
      "epoch": 1.0074728260869565,
      "grad_norm": 2.9070873260498047,
      "learning_rate": 1.493207655934391e-05,
      "loss": 0.1651,
      "step": 1483
    },
    {
      "epoch": 1.0081521739130435,
      "grad_norm": 5.206474781036377,
      "learning_rate": 1.492588666160476e-05,
      "loss": 0.1486,
      "step": 1484
    },
    {
      "epoch": 1.0088315217391304,
      "grad_norm": 2.3321943283081055,
      "learning_rate": 1.4919694270844176e-05,
      "loss": 0.0773,
      "step": 1485
    },
    {
      "epoch": 1.0095108695652173,
      "grad_norm": 11.897998809814453,
      "learning_rate": 1.4913499390196162e-05,
      "loss": 0.3891,
      "step": 1486
    },
    {
      "epoch": 1.0101902173913044,
      "grad_norm": 0.08692791312932968,
      "learning_rate": 1.4907302022795987e-05,
      "loss": 0.0016,
      "step": 1487
    },
    {
      "epoch": 1.0108695652173914,
      "grad_norm": 6.637722015380859,
      "learning_rate": 1.4901102171780175e-05,
      "loss": 0.0432,
      "step": 1488
    },
    {
      "epoch": 1.0115489130434783,
      "grad_norm": 0.21529796719551086,
      "learning_rate": 1.4894899840286507e-05,
      "loss": 0.0029,
      "step": 1489
    },
    {
      "epoch": 1.0122282608695652,
      "grad_norm": 3.5429515838623047,
      "learning_rate": 1.4888695031454028e-05,
      "loss": 0.1793,
      "step": 1490
    },
    {
      "epoch": 1.012907608695652,
      "grad_norm": 5.928258419036865,
      "learning_rate": 1.4882487748423025e-05,
      "loss": 0.3371,
      "step": 1491
    },
    {
      "epoch": 1.013586956521739,
      "grad_norm": 0.15443193912506104,
      "learning_rate": 1.4876277994335042e-05,
      "loss": 0.0018,
      "step": 1492
    },
    {
      "epoch": 1.0142663043478262,
      "grad_norm": 0.4187157154083252,
      "learning_rate": 1.4870065772332874e-05,
      "loss": 0.0036,
      "step": 1493
    },
    {
      "epoch": 1.014945652173913,
      "grad_norm": 4.33620023727417,
      "learning_rate": 1.4863851085560563e-05,
      "loss": 0.2758,
      "step": 1494
    },
    {
      "epoch": 1.015625,
      "grad_norm": 0.0699692964553833,
      "learning_rate": 1.4857633937163402e-05,
      "loss": 0.0012,
      "step": 1495
    },
    {
      "epoch": 1.016304347826087,
      "grad_norm": 1.3102625608444214,
      "learning_rate": 1.485141433028793e-05,
      "loss": 0.047,
      "step": 1496
    },
    {
      "epoch": 1.0169836956521738,
      "grad_norm": 2.9615638256073,
      "learning_rate": 1.4845192268081924e-05,
      "loss": 0.0747,
      "step": 1497
    },
    {
      "epoch": 1.017663043478261,
      "grad_norm": 0.09271642565727234,
      "learning_rate": 1.4838967753694409e-05,
      "loss": 0.0012,
      "step": 1498
    },
    {
      "epoch": 1.018342391304348,
      "grad_norm": 5.2135844230651855,
      "learning_rate": 1.483274079027565e-05,
      "loss": 0.136,
      "step": 1499
    },
    {
      "epoch": 1.0190217391304348,
      "grad_norm": 0.03654714301228523,
      "learning_rate": 1.4826511380977155e-05,
      "loss": 0.0009,
      "step": 1500
    },
    {
      "epoch": 1.0197010869565217,
      "grad_norm": 0.039148781448602676,
      "learning_rate": 1.4820279528951662e-05,
      "loss": 0.001,
      "step": 1501
    },
    {
      "epoch": 1.0203804347826086,
      "grad_norm": 2.2519938945770264,
      "learning_rate": 1.4814045237353152e-05,
      "loss": 0.1206,
      "step": 1502
    },
    {
      "epoch": 1.0210597826086956,
      "grad_norm": 11.288369178771973,
      "learning_rate": 1.4807808509336831e-05,
      "loss": 0.3547,
      "step": 1503
    },
    {
      "epoch": 1.0217391304347827,
      "grad_norm": 1.783503532409668,
      "learning_rate": 1.4801569348059158e-05,
      "loss": 0.074,
      "step": 1504
    },
    {
      "epoch": 1.0224184782608696,
      "grad_norm": 3.510781764984131,
      "learning_rate": 1.4795327756677799e-05,
      "loss": 0.1806,
      "step": 1505
    },
    {
      "epoch": 1.0230978260869565,
      "grad_norm": 0.43913909792900085,
      "learning_rate": 1.478908373835167e-05,
      "loss": 0.0041,
      "step": 1506
    },
    {
      "epoch": 1.0237771739130435,
      "grad_norm": 6.195324420928955,
      "learning_rate": 1.4782837296240905e-05,
      "loss": 0.3077,
      "step": 1507
    },
    {
      "epoch": 1.0244565217391304,
      "grad_norm": 5.086591720581055,
      "learning_rate": 1.4776588433506857e-05,
      "loss": 0.0261,
      "step": 1508
    },
    {
      "epoch": 1.0251358695652173,
      "grad_norm": 11.48946762084961,
      "learning_rate": 1.4770337153312131e-05,
      "loss": 0.3673,
      "step": 1509
    },
    {
      "epoch": 1.0258152173913044,
      "grad_norm": 6.585954666137695,
      "learning_rate": 1.4764083458820524e-05,
      "loss": 0.0735,
      "step": 1510
    },
    {
      "epoch": 1.0264945652173914,
      "grad_norm": 5.244779586791992,
      "learning_rate": 1.4757827353197076e-05,
      "loss": 0.1867,
      "step": 1511
    },
    {
      "epoch": 1.0271739130434783,
      "grad_norm": 12.059982299804688,
      "learning_rate": 1.4751568839608036e-05,
      "loss": 0.4216,
      "step": 1512
    },
    {
      "epoch": 1.0278532608695652,
      "grad_norm": 2.1292717456817627,
      "learning_rate": 1.4745307921220882e-05,
      "loss": 0.1043,
      "step": 1513
    },
    {
      "epoch": 1.028532608695652,
      "grad_norm": 4.204764366149902,
      "learning_rate": 1.47390446012043e-05,
      "loss": 0.1749,
      "step": 1514
    },
    {
      "epoch": 1.029211956521739,
      "grad_norm": 0.2187405377626419,
      "learning_rate": 1.4732778882728193e-05,
      "loss": 0.0031,
      "step": 1515
    },
    {
      "epoch": 1.0298913043478262,
      "grad_norm": 11.134397506713867,
      "learning_rate": 1.4726510768963682e-05,
      "loss": 0.2158,
      "step": 1516
    },
    {
      "epoch": 1.030570652173913,
      "grad_norm": 8.01919937133789,
      "learning_rate": 1.4720240263083097e-05,
      "loss": 0.1402,
      "step": 1517
    },
    {
      "epoch": 1.03125,
      "grad_norm": 11.991043090820312,
      "learning_rate": 1.4713967368259981e-05,
      "loss": 0.4077,
      "step": 1518
    },
    {
      "epoch": 1.031929347826087,
      "grad_norm": 0.8426144123077393,
      "learning_rate": 1.4707692087669077e-05,
      "loss": 0.0166,
      "step": 1519
    },
    {
      "epoch": 1.0326086956521738,
      "grad_norm": 2.5488405227661133,
      "learning_rate": 1.4701414424486353e-05,
      "loss": 0.0978,
      "step": 1520
    },
    {
      "epoch": 1.033288043478261,
      "grad_norm": 0.7772096395492554,
      "learning_rate": 1.4695134381888969e-05,
      "loss": 0.0086,
      "step": 1521
    },
    {
      "epoch": 1.033967391304348,
      "grad_norm": 13.344507217407227,
      "learning_rate": 1.468885196305529e-05,
      "loss": 0.1637,
      "step": 1522
    },
    {
      "epoch": 1.0346467391304348,
      "grad_norm": 2.467529773712158,
      "learning_rate": 1.4682567171164891e-05,
      "loss": 0.1433,
      "step": 1523
    },
    {
      "epoch": 1.0353260869565217,
      "grad_norm": 2.24607253074646,
      "learning_rate": 1.4676280009398544e-05,
      "loss": 0.0954,
      "step": 1524
    },
    {
      "epoch": 1.0360054347826086,
      "grad_norm": 8.448923110961914,
      "learning_rate": 1.4669990480938217e-05,
      "loss": 0.2593,
      "step": 1525
    },
    {
      "epoch": 1.0366847826086956,
      "grad_norm": 1.5438177585601807,
      "learning_rate": 1.466369858896708e-05,
      "loss": 0.1272,
      "step": 1526
    },
    {
      "epoch": 1.0373641304347827,
      "grad_norm": 1.726686716079712,
      "learning_rate": 1.4657404336669498e-05,
      "loss": 0.0487,
      "step": 1527
    },
    {
      "epoch": 1.0380434782608696,
      "grad_norm": 12.83139419555664,
      "learning_rate": 1.4651107727231032e-05,
      "loss": 0.5317,
      "step": 1528
    },
    {
      "epoch": 1.0387228260869565,
      "grad_norm": 3.4135727882385254,
      "learning_rate": 1.464480876383843e-05,
      "loss": 0.0328,
      "step": 1529
    },
    {
      "epoch": 1.0394021739130435,
      "grad_norm": 4.010159015655518,
      "learning_rate": 1.4638507449679642e-05,
      "loss": 0.2144,
      "step": 1530
    },
    {
      "epoch": 1.0400815217391304,
      "grad_norm": 1.3027390241622925,
      "learning_rate": 1.46322037879438e-05,
      "loss": 0.0235,
      "step": 1531
    },
    {
      "epoch": 1.0407608695652173,
      "grad_norm": 3.6522207260131836,
      "learning_rate": 1.4625897781821222e-05,
      "loss": 0.1477,
      "step": 1532
    },
    {
      "epoch": 1.0414402173913044,
      "grad_norm": 12.932816505432129,
      "learning_rate": 1.4619589434503426e-05,
      "loss": 0.2409,
      "step": 1533
    },
    {
      "epoch": 1.0421195652173914,
      "grad_norm": 4.1533613204956055,
      "learning_rate": 1.461327874918309e-05,
      "loss": 0.1912,
      "step": 1534
    },
    {
      "epoch": 1.0427989130434783,
      "grad_norm": 0.48354893922805786,
      "learning_rate": 1.4606965729054106e-05,
      "loss": 0.0041,
      "step": 1535
    },
    {
      "epoch": 1.0434782608695652,
      "grad_norm": 3.2643983364105225,
      "learning_rate": 1.4600650377311523e-05,
      "loss": 0.0362,
      "step": 1536
    },
    {
      "epoch": 1.044157608695652,
      "grad_norm": 2.8356940746307373,
      "learning_rate": 1.4594332697151581e-05,
      "loss": 0.2094,
      "step": 1537
    },
    {
      "epoch": 1.044836956521739,
      "grad_norm": 0.45366916060447693,
      "learning_rate": 1.4588012691771697e-05,
      "loss": 0.0048,
      "step": 1538
    },
    {
      "epoch": 1.0455163043478262,
      "grad_norm": 0.08649103343486786,
      "learning_rate": 1.4581690364370466e-05,
      "loss": 0.0013,
      "step": 1539
    },
    {
      "epoch": 1.046195652173913,
      "grad_norm": 4.594336986541748,
      "learning_rate": 1.4575365718147655e-05,
      "loss": 0.1142,
      "step": 1540
    },
    {
      "epoch": 1.046875,
      "grad_norm": 4.131957054138184,
      "learning_rate": 1.4569038756304209e-05,
      "loss": 0.0459,
      "step": 1541
    },
    {
      "epoch": 1.047554347826087,
      "grad_norm": 2.0264010429382324,
      "learning_rate": 1.4562709482042237e-05,
      "loss": 0.0645,
      "step": 1542
    },
    {
      "epoch": 1.0482336956521738,
      "grad_norm": 2.3911495208740234,
      "learning_rate": 1.4556377898565026e-05,
      "loss": 0.0872,
      "step": 1543
    },
    {
      "epoch": 1.048913043478261,
      "grad_norm": 3.327784299850464,
      "learning_rate": 1.455004400907703e-05,
      "loss": 0.1942,
      "step": 1544
    },
    {
      "epoch": 1.049592391304348,
      "grad_norm": 2.818577527999878,
      "learning_rate": 1.454370781678387e-05,
      "loss": 0.1299,
      "step": 1545
    },
    {
      "epoch": 1.0502717391304348,
      "grad_norm": 5.871493339538574,
      "learning_rate": 1.4537369324892332e-05,
      "loss": 0.0879,
      "step": 1546
    },
    {
      "epoch": 1.0509510869565217,
      "grad_norm": 3.4597206115722656,
      "learning_rate": 1.4531028536610361e-05,
      "loss": 0.1407,
      "step": 1547
    },
    {
      "epoch": 1.0516304347826086,
      "grad_norm": 2.5524439811706543,
      "learning_rate": 1.4524685455147071e-05,
      "loss": 0.0975,
      "step": 1548
    },
    {
      "epoch": 1.0523097826086956,
      "grad_norm": 3.2906062602996826,
      "learning_rate": 1.4518340083712738e-05,
      "loss": 0.2057,
      "step": 1549
    },
    {
      "epoch": 1.0529891304347827,
      "grad_norm": 0.15465395152568817,
      "learning_rate": 1.451199242551879e-05,
      "loss": 0.002,
      "step": 1550
    },
    {
      "epoch": 1.0536684782608696,
      "grad_norm": 3.651526689529419,
      "learning_rate": 1.450564248377782e-05,
      "loss": 0.0639,
      "step": 1551
    },
    {
      "epoch": 1.0543478260869565,
      "grad_norm": 1.4463657140731812,
      "learning_rate": 1.4499290261703565e-05,
      "loss": 0.0563,
      "step": 1552
    },
    {
      "epoch": 1.0550271739130435,
      "grad_norm": 0.03945529833436012,
      "learning_rate": 1.4492935762510928e-05,
      "loss": 0.0007,
      "step": 1553
    },
    {
      "epoch": 1.0557065217391304,
      "grad_norm": 1.464286208152771,
      "learning_rate": 1.448657898941596e-05,
      "loss": 0.0572,
      "step": 1554
    },
    {
      "epoch": 1.0563858695652173,
      "grad_norm": 3.2689290046691895,
      "learning_rate": 1.448021994563586e-05,
      "loss": 0.1584,
      "step": 1555
    },
    {
      "epoch": 1.0570652173913044,
      "grad_norm": 3.1553099155426025,
      "learning_rate": 1.4473858634388984e-05,
      "loss": 0.2388,
      "step": 1556
    },
    {
      "epoch": 1.0577445652173914,
      "grad_norm": 0.47410109639167786,
      "learning_rate": 1.4467495058894829e-05,
      "loss": 0.006,
      "step": 1557
    },
    {
      "epoch": 1.0584239130434783,
      "grad_norm": 6.51955509185791,
      "learning_rate": 1.4461129222374037e-05,
      "loss": 0.1807,
      "step": 1558
    },
    {
      "epoch": 1.0591032608695652,
      "grad_norm": 10.824169158935547,
      "learning_rate": 1.4454761128048397e-05,
      "loss": 0.3688,
      "step": 1559
    },
    {
      "epoch": 1.059782608695652,
      "grad_norm": 2.2165720462799072,
      "learning_rate": 1.4448390779140844e-05,
      "loss": 0.1689,
      "step": 1560
    },
    {
      "epoch": 1.060461956521739,
      "grad_norm": 1.0005277395248413,
      "learning_rate": 1.444201817887545e-05,
      "loss": 0.01,
      "step": 1561
    },
    {
      "epoch": 1.0611413043478262,
      "grad_norm": 0.18363134562969208,
      "learning_rate": 1.4435643330477423e-05,
      "loss": 0.0031,
      "step": 1562
    },
    {
      "epoch": 1.061820652173913,
      "grad_norm": 1.6764110326766968,
      "learning_rate": 1.4429266237173116e-05,
      "loss": 0.0134,
      "step": 1563
    },
    {
      "epoch": 1.0625,
      "grad_norm": 1.0156583786010742,
      "learning_rate": 1.4422886902190014e-05,
      "loss": 0.0192,
      "step": 1564
    },
    {
      "epoch": 1.063179347826087,
      "grad_norm": 9.15739917755127,
      "learning_rate": 1.441650532875674e-05,
      "loss": 0.1081,
      "step": 1565
    },
    {
      "epoch": 1.0638586956521738,
      "grad_norm": 5.3593854904174805,
      "learning_rate": 1.4410121520103045e-05,
      "loss": 0.3206,
      "step": 1566
    },
    {
      "epoch": 1.0645380434782608,
      "grad_norm": 1.6505341529846191,
      "learning_rate": 1.4403735479459813e-05,
      "loss": 0.0566,
      "step": 1567
    },
    {
      "epoch": 1.065217391304348,
      "grad_norm": 0.18911823630332947,
      "learning_rate": 1.4397347210059059e-05,
      "loss": 0.003,
      "step": 1568
    },
    {
      "epoch": 1.0658967391304348,
      "grad_norm": 8.52869701385498,
      "learning_rate": 1.4390956715133928e-05,
      "loss": 0.2151,
      "step": 1569
    },
    {
      "epoch": 1.0665760869565217,
      "grad_norm": 3.0287861824035645,
      "learning_rate": 1.4384563997918685e-05,
      "loss": 0.1964,
      "step": 1570
    },
    {
      "epoch": 1.0672554347826086,
      "grad_norm": 0.12350034713745117,
      "learning_rate": 1.4378169061648727e-05,
      "loss": 0.0023,
      "step": 1571
    },
    {
      "epoch": 1.0679347826086956,
      "grad_norm": 0.9448423981666565,
      "learning_rate": 1.4371771909560566e-05,
      "loss": 0.031,
      "step": 1572
    },
    {
      "epoch": 1.0686141304347827,
      "grad_norm": 5.0092620849609375,
      "learning_rate": 1.4365372544891843e-05,
      "loss": 0.111,
      "step": 1573
    },
    {
      "epoch": 1.0692934782608696,
      "grad_norm": 3.4455034732818604,
      "learning_rate": 1.4358970970881315e-05,
      "loss": 0.1158,
      "step": 1574
    },
    {
      "epoch": 1.0699728260869565,
      "grad_norm": 8.658254623413086,
      "learning_rate": 1.4352567190768859e-05,
      "loss": 0.2143,
      "step": 1575
    },
    {
      "epoch": 1.0706521739130435,
      "grad_norm": 1.750406265258789,
      "learning_rate": 1.4346161207795464e-05,
      "loss": 0.0237,
      "step": 1576
    },
    {
      "epoch": 1.0713315217391304,
      "grad_norm": 0.05511968210339546,
      "learning_rate": 1.4339753025203238e-05,
      "loss": 0.0012,
      "step": 1577
    },
    {
      "epoch": 1.0720108695652173,
      "grad_norm": 1.5426973104476929,
      "learning_rate": 1.4333342646235407e-05,
      "loss": 0.0818,
      "step": 1578
    },
    {
      "epoch": 1.0726902173913044,
      "grad_norm": 7.604528427124023,
      "learning_rate": 1.4326930074136298e-05,
      "loss": 0.2133,
      "step": 1579
    },
    {
      "epoch": 1.0733695652173914,
      "grad_norm": 0.09489694237709045,
      "learning_rate": 1.4320515312151352e-05,
      "loss": 0.0015,
      "step": 1580
    },
    {
      "epoch": 1.0740489130434783,
      "grad_norm": 0.03655076399445534,
      "learning_rate": 1.4314098363527122e-05,
      "loss": 0.0007,
      "step": 1581
    },
    {
      "epoch": 1.0747282608695652,
      "grad_norm": 3.1152994632720947,
      "learning_rate": 1.4307679231511267e-05,
      "loss": 0.115,
      "step": 1582
    },
    {
      "epoch": 1.075407608695652,
      "grad_norm": 0.3195188641548157,
      "learning_rate": 1.4301257919352545e-05,
      "loss": 0.003,
      "step": 1583
    },
    {
      "epoch": 1.0760869565217392,
      "grad_norm": 6.43013858795166,
      "learning_rate": 1.4294834430300822e-05,
      "loss": 0.0613,
      "step": 1584
    },
    {
      "epoch": 1.0767663043478262,
      "grad_norm": 13.029594421386719,
      "learning_rate": 1.4288408767607065e-05,
      "loss": 0.6464,
      "step": 1585
    },
    {
      "epoch": 1.077445652173913,
      "grad_norm": 0.0699692890048027,
      "learning_rate": 1.4281980934523345e-05,
      "loss": 0.0009,
      "step": 1586
    },
    {
      "epoch": 1.078125,
      "grad_norm": 4.6214141845703125,
      "learning_rate": 1.4275550934302822e-05,
      "loss": 0.1729,
      "step": 1587
    },
    {
      "epoch": 1.078804347826087,
      "grad_norm": 7.878176689147949,
      "learning_rate": 1.4269118770199764e-05,
      "loss": 0.2806,
      "step": 1588
    },
    {
      "epoch": 1.0794836956521738,
      "grad_norm": 3.657811403274536,
      "learning_rate": 1.4262684445469527e-05,
      "loss": 0.1055,
      "step": 1589
    },
    {
      "epoch": 1.0801630434782608,
      "grad_norm": 0.20588241517543793,
      "learning_rate": 1.425624796336856e-05,
      "loss": 0.0025,
      "step": 1590
    },
    {
      "epoch": 1.080842391304348,
      "grad_norm": 5.710750579833984,
      "learning_rate": 1.4249809327154407e-05,
      "loss": 0.2109,
      "step": 1591
    },
    {
      "epoch": 1.0815217391304348,
      "grad_norm": 3.4062654972076416,
      "learning_rate": 1.4243368540085702e-05,
      "loss": 0.1946,
      "step": 1592
    },
    {
      "epoch": 1.0822010869565217,
      "grad_norm": 0.11638425290584564,
      "learning_rate": 1.423692560542217e-05,
      "loss": 0.0019,
      "step": 1593
    },
    {
      "epoch": 1.0828804347826086,
      "grad_norm": 3.106300115585327,
      "learning_rate": 1.4230480526424611e-05,
      "loss": 0.1822,
      "step": 1594
    },
    {
      "epoch": 1.0835597826086956,
      "grad_norm": 0.47245705127716064,
      "learning_rate": 1.4224033306354927e-05,
      "loss": 0.0047,
      "step": 1595
    },
    {
      "epoch": 1.0842391304347827,
      "grad_norm": 4.644242763519287,
      "learning_rate": 1.4217583948476094e-05,
      "loss": 0.1949,
      "step": 1596
    },
    {
      "epoch": 1.0849184782608696,
      "grad_norm": 3.4172356128692627,
      "learning_rate": 1.421113245605217e-05,
      "loss": 0.0886,
      "step": 1597
    },
    {
      "epoch": 1.0855978260869565,
      "grad_norm": 6.0598931312561035,
      "learning_rate": 1.4204678832348292e-05,
      "loss": 0.3056,
      "step": 1598
    },
    {
      "epoch": 1.0862771739130435,
      "grad_norm": 0.7749778628349304,
      "learning_rate": 1.4198223080630686e-05,
      "loss": 0.0103,
      "step": 1599
    },
    {
      "epoch": 1.0869565217391304,
      "grad_norm": 7.968981742858887,
      "learning_rate": 1.4191765204166643e-05,
      "loss": 0.3013,
      "step": 1600
    },
    {
      "epoch": 1.0876358695652173,
      "grad_norm": 0.026581473648548126,
      "learning_rate": 1.4185305206224533e-05,
      "loss": 0.0006,
      "step": 1601
    },
    {
      "epoch": 1.0883152173913044,
      "grad_norm": 12.573328971862793,
      "learning_rate": 1.4178843090073802e-05,
      "loss": 0.3115,
      "step": 1602
    },
    {
      "epoch": 1.0889945652173914,
      "grad_norm": 4.457128047943115,
      "learning_rate": 1.4172378858984965e-05,
      "loss": 0.1336,
      "step": 1603
    },
    {
      "epoch": 1.0896739130434783,
      "grad_norm": 2.975219964981079,
      "learning_rate": 1.4165912516229614e-05,
      "loss": 0.1384,
      "step": 1604
    },
    {
      "epoch": 1.0903532608695652,
      "grad_norm": 3.8906826972961426,
      "learning_rate": 1.4159444065080398e-05,
      "loss": 0.0916,
      "step": 1605
    },
    {
      "epoch": 1.091032608695652,
      "grad_norm": 6.842403411865234,
      "learning_rate": 1.4152973508811046e-05,
      "loss": 0.2527,
      "step": 1606
    },
    {
      "epoch": 1.0917119565217392,
      "grad_norm": 6.3198113441467285,
      "learning_rate": 1.4146500850696338e-05,
      "loss": 0.262,
      "step": 1607
    },
    {
      "epoch": 1.0923913043478262,
      "grad_norm": 3.581780433654785,
      "learning_rate": 1.4140026094012136e-05,
      "loss": 0.2243,
      "step": 1608
    },
    {
      "epoch": 1.093070652173913,
      "grad_norm": 11.611924171447754,
      "learning_rate": 1.4133549242035347e-05,
      "loss": 0.4697,
      "step": 1609
    },
    {
      "epoch": 1.09375,
      "grad_norm": 9.183282852172852,
      "learning_rate": 1.4127070298043949e-05,
      "loss": 0.329,
      "step": 1610
    },
    {
      "epoch": 1.094429347826087,
      "grad_norm": 0.18176546692848206,
      "learning_rate": 1.4120589265316974e-05,
      "loss": 0.0019,
      "step": 1611
    },
    {
      "epoch": 1.0951086956521738,
      "grad_norm": 1.9564772844314575,
      "learning_rate": 1.411410614713451e-05,
      "loss": 0.1171,
      "step": 1612
    },
    {
      "epoch": 1.0957880434782608,
      "grad_norm": 0.14710798859596252,
      "learning_rate": 1.4107620946777707e-05,
      "loss": 0.0023,
      "step": 1613
    },
    {
      "epoch": 1.096467391304348,
      "grad_norm": 10.064451217651367,
      "learning_rate": 1.4101133667528761e-05,
      "loss": 0.2459,
      "step": 1614
    },
    {
      "epoch": 1.0971467391304348,
      "grad_norm": 3.717512607574463,
      "learning_rate": 1.4094644312670926e-05,
      "loss": 0.1786,
      "step": 1615
    },
    {
      "epoch": 1.0978260869565217,
      "grad_norm": 3.173199415206909,
      "learning_rate": 1.4088152885488504e-05,
      "loss": 0.1861,
      "step": 1616
    },
    {
      "epoch": 1.0985054347826086,
      "grad_norm": 11.910953521728516,
      "learning_rate": 1.4081659389266846e-05,
      "loss": 0.426,
      "step": 1617
    },
    {
      "epoch": 1.0991847826086956,
      "grad_norm": 3.714050054550171,
      "learning_rate": 1.407516382729235e-05,
      "loss": 0.1431,
      "step": 1618
    },
    {
      "epoch": 1.0998641304347827,
      "grad_norm": 0.0989343672990799,
      "learning_rate": 1.4068666202852461e-05,
      "loss": 0.0014,
      "step": 1619
    },
    {
      "epoch": 1.1005434782608696,
      "grad_norm": 4.43759822845459,
      "learning_rate": 1.4062166519235665e-05,
      "loss": 0.1671,
      "step": 1620
    },
    {
      "epoch": 1.1012228260869565,
      "grad_norm": 2.8075597286224365,
      "learning_rate": 1.405566477973149e-05,
      "loss": 0.1635,
      "step": 1621
    },
    {
      "epoch": 1.1019021739130435,
      "grad_norm": 8.055166244506836,
      "learning_rate": 1.4049160987630513e-05,
      "loss": 0.3762,
      "step": 1622
    },
    {
      "epoch": 1.1025815217391304,
      "grad_norm": 1.2447658777236938,
      "learning_rate": 1.4042655146224333e-05,
      "loss": 0.0159,
      "step": 1623
    },
    {
      "epoch": 1.1032608695652173,
      "grad_norm": 0.24908050894737244,
      "learning_rate": 1.4036147258805604e-05,
      "loss": 0.0029,
      "step": 1624
    },
    {
      "epoch": 1.1039402173913044,
      "grad_norm": 2.2626843452453613,
      "learning_rate": 1.4029637328668004e-05,
      "loss": 0.1372,
      "step": 1625
    },
    {
      "epoch": 1.1046195652173914,
      "grad_norm": 0.48279574513435364,
      "learning_rate": 1.4023125359106253e-05,
      "loss": 0.0053,
      "step": 1626
    },
    {
      "epoch": 1.1052989130434783,
      "grad_norm": 1.8813719749450684,
      "learning_rate": 1.4016611353416094e-05,
      "loss": 0.0442,
      "step": 1627
    },
    {
      "epoch": 1.1059782608695652,
      "grad_norm": 1.5560953617095947,
      "learning_rate": 1.4010095314894305e-05,
      "loss": 0.0089,
      "step": 1628
    },
    {
      "epoch": 1.106657608695652,
      "grad_norm": 5.222922325134277,
      "learning_rate": 1.40035772468387e-05,
      "loss": 0.3928,
      "step": 1629
    },
    {
      "epoch": 1.1073369565217392,
      "grad_norm": 5.205123424530029,
      "learning_rate": 1.3997057152548104e-05,
      "loss": 0.1275,
      "step": 1630
    },
    {
      "epoch": 1.1080163043478262,
      "grad_norm": 2.7455644607543945,
      "learning_rate": 1.3990535035322382e-05,
      "loss": 0.0287,
      "step": 1631
    },
    {
      "epoch": 1.108695652173913,
      "grad_norm": 2.088946580886841,
      "learning_rate": 1.3984010898462417e-05,
      "loss": 0.1039,
      "step": 1632
    },
    {
      "epoch": 1.109375,
      "grad_norm": 1.3842453956604004,
      "learning_rate": 1.3977484745270112e-05,
      "loss": 0.0706,
      "step": 1633
    },
    {
      "epoch": 1.110054347826087,
      "grad_norm": 6.848758220672607,
      "learning_rate": 1.3970956579048396e-05,
      "loss": 0.2655,
      "step": 1634
    },
    {
      "epoch": 1.1107336956521738,
      "grad_norm": 2.663114547729492,
      "learning_rate": 1.3964426403101212e-05,
      "loss": 0.0278,
      "step": 1635
    },
    {
      "epoch": 1.1114130434782608,
      "grad_norm": 2.5236141681671143,
      "learning_rate": 1.3957894220733526e-05,
      "loss": 0.0465,
      "step": 1636
    },
    {
      "epoch": 1.112092391304348,
      "grad_norm": 4.5026140213012695,
      "learning_rate": 1.395136003525131e-05,
      "loss": 0.1191,
      "step": 1637
    },
    {
      "epoch": 1.1127717391304348,
      "grad_norm": 2.6396384239196777,
      "learning_rate": 1.3944823849961557e-05,
      "loss": 0.127,
      "step": 1638
    },
    {
      "epoch": 1.1134510869565217,
      "grad_norm": 3.2801811695098877,
      "learning_rate": 1.3938285668172273e-05,
      "loss": 0.1439,
      "step": 1639
    },
    {
      "epoch": 1.1141304347826086,
      "grad_norm": 1.9403166770935059,
      "learning_rate": 1.3931745493192473e-05,
      "loss": 0.0233,
      "step": 1640
    },
    {
      "epoch": 1.1148097826086956,
      "grad_norm": 0.12068234384059906,
      "learning_rate": 1.3925203328332173e-05,
      "loss": 0.0013,
      "step": 1641
    },
    {
      "epoch": 1.1154891304347827,
      "grad_norm": 1.8563165664672852,
      "learning_rate": 1.391865917690241e-05,
      "loss": 0.0731,
      "step": 1642
    },
    {
      "epoch": 1.1161684782608696,
      "grad_norm": 2.447176218032837,
      "learning_rate": 1.3912113042215215e-05,
      "loss": 0.1808,
      "step": 1643
    },
    {
      "epoch": 1.1168478260869565,
      "grad_norm": 0.9832605719566345,
      "learning_rate": 1.3905564927583625e-05,
      "loss": 0.0135,
      "step": 1644
    },
    {
      "epoch": 1.1175271739130435,
      "grad_norm": 0.12634412944316864,
      "learning_rate": 1.3899014836321687e-05,
      "loss": 0.0015,
      "step": 1645
    },
    {
      "epoch": 1.1182065217391304,
      "grad_norm": 6.870077133178711,
      "learning_rate": 1.3892462771744435e-05,
      "loss": 0.3432,
      "step": 1646
    },
    {
      "epoch": 1.1188858695652173,
      "grad_norm": 3.442138910293579,
      "learning_rate": 1.3885908737167918e-05,
      "loss": 0.0393,
      "step": 1647
    },
    {
      "epoch": 1.1195652173913044,
      "grad_norm": 1.1589405536651611,
      "learning_rate": 1.3879352735909163e-05,
      "loss": 0.0598,
      "step": 1648
    },
    {
      "epoch": 1.1202445652173914,
      "grad_norm": 3.004300594329834,
      "learning_rate": 1.3872794771286212e-05,
      "loss": 0.1071,
      "step": 1649
    },
    {
      "epoch": 1.1209239130434783,
      "grad_norm": 4.150504112243652,
      "learning_rate": 1.3866234846618083e-05,
      "loss": 0.0682,
      "step": 1650
    },
    {
      "epoch": 1.1216032608695652,
      "grad_norm": 0.35675597190856934,
      "learning_rate": 1.38596729652248e-05,
      "loss": 0.0044,
      "step": 1651
    },
    {
      "epoch": 1.122282608695652,
      "grad_norm": 2.320326566696167,
      "learning_rate": 1.3853109130427369e-05,
      "loss": 0.0361,
      "step": 1652
    },
    {
      "epoch": 1.1229619565217392,
      "grad_norm": 3.5895047187805176,
      "learning_rate": 1.3846543345547787e-05,
      "loss": 0.1352,
      "step": 1653
    },
    {
      "epoch": 1.1236413043478262,
      "grad_norm": 1.052176833152771,
      "learning_rate": 1.3839975613909036e-05,
      "loss": 0.0133,
      "step": 1654
    },
    {
      "epoch": 1.124320652173913,
      "grad_norm": 1.8796207904815674,
      "learning_rate": 1.3833405938835089e-05,
      "loss": 0.1542,
      "step": 1655
    },
    {
      "epoch": 1.125,
      "grad_norm": 2.615309953689575,
      "learning_rate": 1.3826834323650899e-05,
      "loss": 0.1669,
      "step": 1656
    },
    {
      "epoch": 1.125679347826087,
      "grad_norm": 2.1396217346191406,
      "learning_rate": 1.3820260771682398e-05,
      "loss": 0.1101,
      "step": 1657
    },
    {
      "epoch": 1.1263586956521738,
      "grad_norm": 1.4913262128829956,
      "learning_rate": 1.3813685286256503e-05,
      "loss": 0.0596,
      "step": 1658
    },
    {
      "epoch": 1.1270380434782608,
      "grad_norm": 1.9631178379058838,
      "learning_rate": 1.3807107870701102e-05,
      "loss": 0.0194,
      "step": 1659
    },
    {
      "epoch": 1.127717391304348,
      "grad_norm": 0.9440773129463196,
      "learning_rate": 1.3800528528345074e-05,
      "loss": 0.0309,
      "step": 1660
    },
    {
      "epoch": 1.1283967391304348,
      "grad_norm": 13.275338172912598,
      "learning_rate": 1.3793947262518259e-05,
      "loss": 0.6589,
      "step": 1661
    },
    {
      "epoch": 1.1290760869565217,
      "grad_norm": 1.81687331199646,
      "learning_rate": 1.3787364076551478e-05,
      "loss": 0.0639,
      "step": 1662
    },
    {
      "epoch": 1.1297554347826086,
      "grad_norm": 0.21359248459339142,
      "learning_rate": 1.3780778973776518e-05,
      "loss": 0.0023,
      "step": 1663
    },
    {
      "epoch": 1.1304347826086956,
      "grad_norm": 3.83048677444458,
      "learning_rate": 1.3774191957526144e-05,
      "loss": 0.2541,
      "step": 1664
    },
    {
      "epoch": 1.1311141304347827,
      "grad_norm": 0.04449383541941643,
      "learning_rate": 1.3767603031134087e-05,
      "loss": 0.001,
      "step": 1665
    },
    {
      "epoch": 1.1317934782608696,
      "grad_norm": 2.4657957553863525,
      "learning_rate": 1.3761012197935037e-05,
      "loss": 0.2004,
      "step": 1666
    },
    {
      "epoch": 1.1324728260869565,
      "grad_norm": 10.497796058654785,
      "learning_rate": 1.3754419461264658e-05,
      "loss": 0.4189,
      "step": 1667
    },
    {
      "epoch": 1.1331521739130435,
      "grad_norm": 3.1990387439727783,
      "learning_rate": 1.3747824824459577e-05,
      "loss": 0.056,
      "step": 1668
    },
    {
      "epoch": 1.1338315217391304,
      "grad_norm": 0.7618774771690369,
      "learning_rate": 1.3741228290857378e-05,
      "loss": 0.009,
      "step": 1669
    },
    {
      "epoch": 1.1345108695652173,
      "grad_norm": 11.433905601501465,
      "learning_rate": 1.3734629863796607e-05,
      "loss": 0.6517,
      "step": 1670
    },
    {
      "epoch": 1.1351902173913044,
      "grad_norm": 5.44443416595459,
      "learning_rate": 1.3728029546616769e-05,
      "loss": 0.1945,
      "step": 1671
    },
    {
      "epoch": 1.1358695652173914,
      "grad_norm": 2.8696656227111816,
      "learning_rate": 1.3721427342658322e-05,
      "loss": 0.0454,
      "step": 1672
    },
    {
      "epoch": 1.1365489130434783,
      "grad_norm": 0.0966453030705452,
      "learning_rate": 1.3714823255262687e-05,
      "loss": 0.0014,
      "step": 1673
    },
    {
      "epoch": 1.1372282608695652,
      "grad_norm": 5.4131550788879395,
      "learning_rate": 1.3708217287772227e-05,
      "loss": 0.0733,
      "step": 1674
    },
    {
      "epoch": 1.137907608695652,
      "grad_norm": 0.9931442141532898,
      "learning_rate": 1.3701609443530269e-05,
      "loss": 0.027,
      "step": 1675
    },
    {
      "epoch": 1.1385869565217392,
      "grad_norm": 0.8374810814857483,
      "learning_rate": 1.3694999725881075e-05,
      "loss": 0.0111,
      "step": 1676
    },
    {
      "epoch": 1.1392663043478262,
      "grad_norm": 3.3850491046905518,
      "learning_rate": 1.3688388138169873e-05,
      "loss": 0.2056,
      "step": 1677
    },
    {
      "epoch": 1.139945652173913,
      "grad_norm": 4.320815563201904,
      "learning_rate": 1.3681774683742824e-05,
      "loss": 0.1542,
      "step": 1678
    },
    {
      "epoch": 1.140625,
      "grad_norm": 2.103461980819702,
      "learning_rate": 1.3675159365947038e-05,
      "loss": 0.1998,
      "step": 1679
    },
    {
      "epoch": 1.141304347826087,
      "grad_norm": 10.616896629333496,
      "learning_rate": 1.3668542188130567e-05,
      "loss": 0.2058,
      "step": 1680
    },
    {
      "epoch": 1.1419836956521738,
      "grad_norm": 0.9188172221183777,
      "learning_rate": 1.3661923153642407e-05,
      "loss": 0.0079,
      "step": 1681
    },
    {
      "epoch": 1.1426630434782608,
      "grad_norm": 4.595179557800293,
      "learning_rate": 1.3655302265832492e-05,
      "loss": 0.0535,
      "step": 1682
    },
    {
      "epoch": 1.143342391304348,
      "grad_norm": 3.7229504585266113,
      "learning_rate": 1.3648679528051689e-05,
      "loss": 0.2744,
      "step": 1683
    },
    {
      "epoch": 1.1440217391304348,
      "grad_norm": 1.5519551038742065,
      "learning_rate": 1.3642054943651814e-05,
      "loss": 0.0292,
      "step": 1684
    },
    {
      "epoch": 1.1447010869565217,
      "grad_norm": 0.12605957686901093,
      "learning_rate": 1.3635428515985602e-05,
      "loss": 0.0021,
      "step": 1685
    },
    {
      "epoch": 1.1453804347826086,
      "grad_norm": 13.178443908691406,
      "learning_rate": 1.3628800248406738e-05,
      "loss": 0.1612,
      "step": 1686
    },
    {
      "epoch": 1.1460597826086956,
      "grad_norm": 1.7717809677124023,
      "learning_rate": 1.3622170144269819e-05,
      "loss": 0.0354,
      "step": 1687
    },
    {
      "epoch": 1.1467391304347827,
      "grad_norm": 5.215643405914307,
      "learning_rate": 1.3615538206930387e-05,
      "loss": 0.1464,
      "step": 1688
    },
    {
      "epoch": 1.1474184782608696,
      "grad_norm": 4.079456806182861,
      "learning_rate": 1.3608904439744905e-05,
      "loss": 0.0671,
      "step": 1689
    },
    {
      "epoch": 1.1480978260869565,
      "grad_norm": 5.569900035858154,
      "learning_rate": 1.3602268846070763e-05,
      "loss": 0.2009,
      "step": 1690
    },
    {
      "epoch": 1.1487771739130435,
      "grad_norm": 0.40831223130226135,
      "learning_rate": 1.3595631429266276e-05,
      "loss": 0.0048,
      "step": 1691
    },
    {
      "epoch": 1.1494565217391304,
      "grad_norm": 3.027675151824951,
      "learning_rate": 1.3588992192690683e-05,
      "loss": 0.031,
      "step": 1692
    },
    {
      "epoch": 1.1501358695652173,
      "grad_norm": 2.6918413639068604,
      "learning_rate": 1.3582351139704137e-05,
      "loss": 0.1272,
      "step": 1693
    },
    {
      "epoch": 1.1508152173913044,
      "grad_norm": 3.704312324523926,
      "learning_rate": 1.357570827366772e-05,
      "loss": 0.0485,
      "step": 1694
    },
    {
      "epoch": 1.1514945652173914,
      "grad_norm": 0.7044626474380493,
      "learning_rate": 1.3569063597943428e-05,
      "loss": 0.0108,
      "step": 1695
    },
    {
      "epoch": 1.1521739130434783,
      "grad_norm": 2.9437057971954346,
      "learning_rate": 1.356241711589417e-05,
      "loss": 0.0873,
      "step": 1696
    },
    {
      "epoch": 1.1528532608695652,
      "grad_norm": 3.001908302307129,
      "learning_rate": 1.3555768830883768e-05,
      "loss": 0.2013,
      "step": 1697
    },
    {
      "epoch": 1.153532608695652,
      "grad_norm": 4.379121780395508,
      "learning_rate": 1.3549118746276968e-05,
      "loss": 0.23,
      "step": 1698
    },
    {
      "epoch": 1.1542119565217392,
      "grad_norm": 8.51967716217041,
      "learning_rate": 1.3542466865439412e-05,
      "loss": 0.3022,
      "step": 1699
    },
    {
      "epoch": 1.1548913043478262,
      "grad_norm": 1.4863102436065674,
      "learning_rate": 1.3535813191737663e-05,
      "loss": 0.0231,
      "step": 1700
    },
    {
      "epoch": 1.155570652173913,
      "grad_norm": 0.02087375894188881,
      "learning_rate": 1.3529157728539179e-05,
      "loss": 0.0005,
      "step": 1701
    },
    {
      "epoch": 1.15625,
      "grad_norm": 1.7050005197525024,
      "learning_rate": 1.3522500479212337e-05,
      "loss": 0.019,
      "step": 1702
    },
    {
      "epoch": 1.156929347826087,
      "grad_norm": 6.74899435043335,
      "learning_rate": 1.3515841447126408e-05,
      "loss": 0.3817,
      "step": 1703
    },
    {
      "epoch": 1.1576086956521738,
      "grad_norm": 4.525218963623047,
      "learning_rate": 1.350918063565157e-05,
      "loss": 0.2436,
      "step": 1704
    },
    {
      "epoch": 1.1582880434782608,
      "grad_norm": 0.28836268186569214,
      "learning_rate": 1.3502518048158901e-05,
      "loss": 0.0034,
      "step": 1705
    },
    {
      "epoch": 1.158967391304348,
      "grad_norm": 2.153296947479248,
      "learning_rate": 1.3495853688020377e-05,
      "loss": 0.0243,
      "step": 1706
    },
    {
      "epoch": 1.1596467391304348,
      "grad_norm": 1.3556337356567383,
      "learning_rate": 1.3489187558608871e-05,
      "loss": 0.0133,
      "step": 1707
    },
    {
      "epoch": 1.1603260869565217,
      "grad_norm": 3.8730013370513916,
      "learning_rate": 1.3482519663298156e-05,
      "loss": 0.193,
      "step": 1708
    },
    {
      "epoch": 1.1610054347826086,
      "grad_norm": 1.5929847955703735,
      "learning_rate": 1.3475850005462887e-05,
      "loss": 0.028,
      "step": 1709
    },
    {
      "epoch": 1.1616847826086956,
      "grad_norm": 0.21378478407859802,
      "learning_rate": 1.3469178588478621e-05,
      "loss": 0.0026,
      "step": 1710
    },
    {
      "epoch": 1.1623641304347827,
      "grad_norm": 3.4371113777160645,
      "learning_rate": 1.346250541572181e-05,
      "loss": 0.096,
      "step": 1711
    },
    {
      "epoch": 1.1630434782608696,
      "grad_norm": 3.461824417114258,
      "learning_rate": 1.3455830490569782e-05,
      "loss": 0.0293,
      "step": 1712
    },
    {
      "epoch": 1.1637228260869565,
      "grad_norm": 5.155466079711914,
      "learning_rate": 1.3449153816400758e-05,
      "loss": 0.2624,
      "step": 1713
    },
    {
      "epoch": 1.1644021739130435,
      "grad_norm": 1.5496293306350708,
      "learning_rate": 1.3442475396593842e-05,
      "loss": 0.0702,
      "step": 1714
    },
    {
      "epoch": 1.1650815217391304,
      "grad_norm": 1.9343862533569336,
      "learning_rate": 1.3435795234529026e-05,
      "loss": 0.0732,
      "step": 1715
    },
    {
      "epoch": 1.1657608695652173,
      "grad_norm": 0.6287455558776855,
      "learning_rate": 1.3429113333587181e-05,
      "loss": 0.0073,
      "step": 1716
    },
    {
      "epoch": 1.1664402173913044,
      "grad_norm": 0.659855842590332,
      "learning_rate": 1.3422429697150055e-05,
      "loss": 0.0069,
      "step": 1717
    },
    {
      "epoch": 1.1671195652173914,
      "grad_norm": 2.7508137226104736,
      "learning_rate": 1.341574432860028e-05,
      "loss": 0.0751,
      "step": 1718
    },
    {
      "epoch": 1.1677989130434783,
      "grad_norm": 0.3538942337036133,
      "learning_rate": 1.3409057231321363e-05,
      "loss": 0.0038,
      "step": 1719
    },
    {
      "epoch": 1.1684782608695652,
      "grad_norm": 2.4968514442443848,
      "learning_rate": 1.3402368408697681e-05,
      "loss": 0.1159,
      "step": 1720
    },
    {
      "epoch": 1.169157608695652,
      "grad_norm": 5.02803373336792,
      "learning_rate": 1.3395677864114493e-05,
      "loss": 0.1956,
      "step": 1721
    },
    {
      "epoch": 1.1698369565217392,
      "grad_norm": 6.506546974182129,
      "learning_rate": 1.3388985600957922e-05,
      "loss": 0.0803,
      "step": 1722
    },
    {
      "epoch": 1.1705163043478262,
      "grad_norm": 14.421422958374023,
      "learning_rate": 1.338229162261496e-05,
      "loss": 0.8742,
      "step": 1723
    },
    {
      "epoch": 1.171195652173913,
      "grad_norm": 5.549502372741699,
      "learning_rate": 1.337559593247348e-05,
      "loss": 0.2143,
      "step": 1724
    },
    {
      "epoch": 1.171875,
      "grad_norm": 2.2292263507843018,
      "learning_rate": 1.3368898533922202e-05,
      "loss": 0.0916,
      "step": 1725
    },
    {
      "epoch": 1.172554347826087,
      "grad_norm": 3.7390644550323486,
      "learning_rate": 1.3362199430350726e-05,
      "loss": 0.1429,
      "step": 1726
    },
    {
      "epoch": 1.1732336956521738,
      "grad_norm": 12.983353614807129,
      "learning_rate": 1.3355498625149506e-05,
      "loss": 0.2125,
      "step": 1727
    },
    {
      "epoch": 1.1739130434782608,
      "grad_norm": 4.174078941345215,
      "learning_rate": 1.3348796121709862e-05,
      "loss": 0.1721,
      "step": 1728
    },
    {
      "epoch": 1.174592391304348,
      "grad_norm": 0.1847754567861557,
      "learning_rate": 1.3342091923423975e-05,
      "loss": 0.0024,
      "step": 1729
    },
    {
      "epoch": 1.1752717391304348,
      "grad_norm": 12.62940788269043,
      "learning_rate": 1.3335386033684877e-05,
      "loss": 0.1088,
      "step": 1730
    },
    {
      "epoch": 1.1759510869565217,
      "grad_norm": 6.8360443115234375,
      "learning_rate": 1.3328678455886461e-05,
      "loss": 0.1561,
      "step": 1731
    },
    {
      "epoch": 1.1766304347826086,
      "grad_norm": 2.2730636596679688,
      "learning_rate": 1.3321969193423472e-05,
      "loss": 0.0987,
      "step": 1732
    },
    {
      "epoch": 1.1773097826086956,
      "grad_norm": 4.260518550872803,
      "learning_rate": 1.3315258249691514e-05,
      "loss": 0.0918,
      "step": 1733
    },
    {
      "epoch": 1.1779891304347827,
      "grad_norm": 7.058551788330078,
      "learning_rate": 1.3308545628087029e-05,
      "loss": 0.3229,
      "step": 1734
    },
    {
      "epoch": 1.1786684782608696,
      "grad_norm": 0.18282519280910492,
      "learning_rate": 1.3301831332007322e-05,
      "loss": 0.0027,
      "step": 1735
    },
    {
      "epoch": 1.1793478260869565,
      "grad_norm": 2.8162732124328613,
      "learning_rate": 1.3295115364850535e-05,
      "loss": 0.1256,
      "step": 1736
    },
    {
      "epoch": 1.1800271739130435,
      "grad_norm": 12.362473487854004,
      "learning_rate": 1.3288397730015666e-05,
      "loss": 0.1366,
      "step": 1737
    },
    {
      "epoch": 1.1807065217391304,
      "grad_norm": 2.634817361831665,
      "learning_rate": 1.3281678430902545e-05,
      "loss": 0.117,
      "step": 1738
    },
    {
      "epoch": 1.1813858695652173,
      "grad_norm": 3.770338535308838,
      "learning_rate": 1.3274957470911856e-05,
      "loss": 0.2031,
      "step": 1739
    },
    {
      "epoch": 1.1820652173913044,
      "grad_norm": 5.039254665374756,
      "learning_rate": 1.3268234853445113e-05,
      "loss": 0.1968,
      "step": 1740
    },
    {
      "epoch": 1.1827445652173914,
      "grad_norm": 5.060910701751709,
      "learning_rate": 1.3261510581904675e-05,
      "loss": 0.1206,
      "step": 1741
    },
    {
      "epoch": 1.1834239130434783,
      "grad_norm": 4.433869361877441,
      "learning_rate": 1.3254784659693739e-05,
      "loss": 0.1694,
      "step": 1742
    },
    {
      "epoch": 1.1841032608695652,
      "grad_norm": 3.858640193939209,
      "learning_rate": 1.3248057090216336e-05,
      "loss": 0.0866,
      "step": 1743
    },
    {
      "epoch": 1.184782608695652,
      "grad_norm": 1.747695803642273,
      "learning_rate": 1.3241327876877328e-05,
      "loss": 0.0652,
      "step": 1744
    },
    {
      "epoch": 1.1854619565217392,
      "grad_norm": 0.09552811086177826,
      "learning_rate": 1.3234597023082409e-05,
      "loss": 0.0012,
      "step": 1745
    },
    {
      "epoch": 1.1861413043478262,
      "grad_norm": 0.28071752190589905,
      "learning_rate": 1.3227864532238113e-05,
      "loss": 0.0023,
      "step": 1746
    },
    {
      "epoch": 1.186820652173913,
      "grad_norm": 0.2943286895751953,
      "learning_rate": 1.3221130407751788e-05,
      "loss": 0.0044,
      "step": 1747
    },
    {
      "epoch": 1.1875,
      "grad_norm": 0.1312142163515091,
      "learning_rate": 1.3214394653031616e-05,
      "loss": 0.0024,
      "step": 1748
    },
    {
      "epoch": 1.188179347826087,
      "grad_norm": 0.09103143960237503,
      "learning_rate": 1.3207657271486607e-05,
      "loss": 0.0014,
      "step": 1749
    },
    {
      "epoch": 1.1888586956521738,
      "grad_norm": 0.9393269419670105,
      "learning_rate": 1.3200918266526593e-05,
      "loss": 0.0118,
      "step": 1750
    },
    {
      "epoch": 1.1895380434782608,
      "grad_norm": 0.03721277788281441,
      "learning_rate": 1.3194177641562218e-05,
      "loss": 0.0007,
      "step": 1751
    },
    {
      "epoch": 1.190217391304348,
      "grad_norm": 0.13248974084854126,
      "learning_rate": 1.318743540000496e-05,
      "loss": 0.0013,
      "step": 1752
    },
    {
      "epoch": 1.1908967391304348,
      "grad_norm": 4.242633819580078,
      "learning_rate": 1.3180691545267105e-05,
      "loss": 0.1337,
      "step": 1753
    },
    {
      "epoch": 1.1915760869565217,
      "grad_norm": 5.8093461990356445,
      "learning_rate": 1.3173946080761764e-05,
      "loss": 0.1332,
      "step": 1754
    },
    {
      "epoch": 1.1922554347826086,
      "grad_norm": 1.470458745956421,
      "learning_rate": 1.316719900990285e-05,
      "loss": 0.0158,
      "step": 1755
    },
    {
      "epoch": 1.1929347826086956,
      "grad_norm": 2.2277026176452637,
      "learning_rate": 1.3160450336105108e-05,
      "loss": 0.0724,
      "step": 1756
    },
    {
      "epoch": 1.1936141304347827,
      "grad_norm": 9.510653495788574,
      "learning_rate": 1.3153700062784073e-05,
      "loss": 0.4645,
      "step": 1757
    },
    {
      "epoch": 1.1942934782608696,
      "grad_norm": 8.654502868652344,
      "learning_rate": 1.3146948193356105e-05,
      "loss": 0.0687,
      "step": 1758
    },
    {
      "epoch": 1.1949728260869565,
      "grad_norm": 0.05509725585579872,
      "learning_rate": 1.3140194731238367e-05,
      "loss": 0.0011,
      "step": 1759
    },
    {
      "epoch": 1.1956521739130435,
      "grad_norm": 0.14971011877059937,
      "learning_rate": 1.3133439679848824e-05,
      "loss": 0.0024,
      "step": 1760
    },
    {
      "epoch": 1.1963315217391304,
      "grad_norm": 3.3676817417144775,
      "learning_rate": 1.3126683042606251e-05,
      "loss": 0.0931,
      "step": 1761
    },
    {
      "epoch": 1.1970108695652173,
      "grad_norm": 1.5569064617156982,
      "learning_rate": 1.3119924822930223e-05,
      "loss": 0.0625,
      "step": 1762
    },
    {
      "epoch": 1.1976902173913044,
      "grad_norm": 2.365957736968994,
      "learning_rate": 1.3113165024241117e-05,
      "loss": 0.1019,
      "step": 1763
    },
    {
      "epoch": 1.1983695652173914,
      "grad_norm": 1.556482195854187,
      "learning_rate": 1.3106403649960109e-05,
      "loss": 0.0148,
      "step": 1764
    },
    {
      "epoch": 1.1990489130434783,
      "grad_norm": 0.44176918268203735,
      "learning_rate": 1.3099640703509169e-05,
      "loss": 0.0053,
      "step": 1765
    },
    {
      "epoch": 1.1997282608695652,
      "grad_norm": 0.01891586370766163,
      "learning_rate": 1.309287618831107e-05,
      "loss": 0.0006,
      "step": 1766
    },
    {
      "epoch": 1.200407608695652,
      "grad_norm": 3.2093162536621094,
      "learning_rate": 1.3086110107789371e-05,
      "loss": 0.1019,
      "step": 1767
    },
    {
      "epoch": 1.2010869565217392,
      "grad_norm": 3.942854404449463,
      "learning_rate": 1.307934246536843e-05,
      "loss": 0.1174,
      "step": 1768
    },
    {
      "epoch": 1.2017663043478262,
      "grad_norm": 4.437279224395752,
      "learning_rate": 1.307257326447339e-05,
      "loss": 0.1084,
      "step": 1769
    },
    {
      "epoch": 1.202445652173913,
      "grad_norm": 0.04673841968178749,
      "learning_rate": 1.3065802508530186e-05,
      "loss": 0.0009,
      "step": 1770
    },
    {
      "epoch": 1.203125,
      "grad_norm": 2.540116548538208,
      "learning_rate": 1.3059030200965536e-05,
      "loss": 0.0555,
      "step": 1771
    },
    {
      "epoch": 1.203804347826087,
      "grad_norm": 0.8764828443527222,
      "learning_rate": 1.3052256345206953e-05,
      "loss": 0.0122,
      "step": 1772
    },
    {
      "epoch": 1.2044836956521738,
      "grad_norm": 4.120761394500732,
      "learning_rate": 1.304548094468272e-05,
      "loss": 0.2369,
      "step": 1773
    },
    {
      "epoch": 1.2051630434782608,
      "grad_norm": 0.9784111976623535,
      "learning_rate": 1.3038704002821914e-05,
      "loss": 0.0246,
      "step": 1774
    },
    {
      "epoch": 1.205842391304348,
      "grad_norm": 7.9199066162109375,
      "learning_rate": 1.3031925523054383e-05,
      "loss": 0.3415,
      "step": 1775
    },
    {
      "epoch": 1.2065217391304348,
      "grad_norm": 0.03221484646201134,
      "learning_rate": 1.302514550881076e-05,
      "loss": 0.0008,
      "step": 1776
    },
    {
      "epoch": 1.2072010869565217,
      "grad_norm": 5.0774993896484375,
      "learning_rate": 1.3018363963522449e-05,
      "loss": 0.1816,
      "step": 1777
    },
    {
      "epoch": 1.2078804347826086,
      "grad_norm": 0.06972938030958176,
      "learning_rate": 1.3011580890621635e-05,
      "loss": 0.0012,
      "step": 1778
    },
    {
      "epoch": 1.2085597826086956,
      "grad_norm": 0.13529817759990692,
      "learning_rate": 1.3004796293541269e-05,
      "loss": 0.0018,
      "step": 1779
    },
    {
      "epoch": 1.2092391304347827,
      "grad_norm": 1.662483811378479,
      "learning_rate": 1.2998010175715081e-05,
      "loss": 0.0454,
      "step": 1780
    },
    {
      "epoch": 1.2099184782608696,
      "grad_norm": 13.987974166870117,
      "learning_rate": 1.2991222540577566e-05,
      "loss": 0.1885,
      "step": 1781
    },
    {
      "epoch": 1.2105978260869565,
      "grad_norm": 0.07795852422714233,
      "learning_rate": 1.2984433391563984e-05,
      "loss": 0.0008,
      "step": 1782
    },
    {
      "epoch": 1.2112771739130435,
      "grad_norm": 0.024853654205799103,
      "learning_rate": 1.2977642732110369e-05,
      "loss": 0.0005,
      "step": 1783
    },
    {
      "epoch": 1.2119565217391304,
      "grad_norm": 3.1605472564697266,
      "learning_rate": 1.2970850565653515e-05,
      "loss": 0.1091,
      "step": 1784
    },
    {
      "epoch": 1.2126358695652173,
      "grad_norm": 9.776285171508789,
      "learning_rate": 1.2964056895630976e-05,
      "loss": 0.2619,
      "step": 1785
    },
    {
      "epoch": 1.2133152173913044,
      "grad_norm": 11.814192771911621,
      "learning_rate": 1.2957261725481074e-05,
      "loss": 0.6594,
      "step": 1786
    },
    {
      "epoch": 1.2139945652173914,
      "grad_norm": 0.6449089050292969,
      "learning_rate": 1.2950465058642884e-05,
      "loss": 0.0067,
      "step": 1787
    },
    {
      "epoch": 1.2146739130434783,
      "grad_norm": 0.20839470624923706,
      "learning_rate": 1.294366689855624e-05,
      "loss": 0.0019,
      "step": 1788
    },
    {
      "epoch": 1.2153532608695652,
      "grad_norm": 0.042892273515462875,
      "learning_rate": 1.2936867248661736e-05,
      "loss": 0.0007,
      "step": 1789
    },
    {
      "epoch": 1.216032608695652,
      "grad_norm": 5.289866924285889,
      "learning_rate": 1.2930066112400712e-05,
      "loss": 0.1164,
      "step": 1790
    },
    {
      "epoch": 1.2167119565217392,
      "grad_norm": 0.16558897495269775,
      "learning_rate": 1.292326349321527e-05,
      "loss": 0.0015,
      "step": 1791
    },
    {
      "epoch": 1.2173913043478262,
      "grad_norm": 0.10340464860200882,
      "learning_rate": 1.291645939454825e-05,
      "loss": 0.0014,
      "step": 1792
    },
    {
      "epoch": 1.218070652173913,
      "grad_norm": 5.487437725067139,
      "learning_rate": 1.2909653819843255e-05,
      "loss": 0.0813,
      "step": 1793
    },
    {
      "epoch": 1.21875,
      "grad_norm": 0.04967862740159035,
      "learning_rate": 1.2902846772544625e-05,
      "loss": 0.0006,
      "step": 1794
    },
    {
      "epoch": 1.219429347826087,
      "grad_norm": 5.786463737487793,
      "learning_rate": 1.2896038256097447e-05,
      "loss": 0.194,
      "step": 1795
    },
    {
      "epoch": 1.2201086956521738,
      "grad_norm": 0.016694245859980583,
      "learning_rate": 1.2889228273947559e-05,
      "loss": 0.0004,
      "step": 1796
    },
    {
      "epoch": 1.2207880434782608,
      "grad_norm": 4.390775203704834,
      "learning_rate": 1.2882416829541526e-05,
      "loss": 0.1787,
      "step": 1797
    },
    {
      "epoch": 1.221467391304348,
      "grad_norm": 1.6463072299957275,
      "learning_rate": 1.2875603926326667e-05,
      "loss": 0.0237,
      "step": 1798
    },
    {
      "epoch": 1.2221467391304348,
      "grad_norm": 15.345881462097168,
      "learning_rate": 1.2868789567751034e-05,
      "loss": 0.1547,
      "step": 1799
    },
    {
      "epoch": 1.2228260869565217,
      "grad_norm": 0.019754037261009216,
      "learning_rate": 1.2861973757263416e-05,
      "loss": 0.0005,
      "step": 1800
    },
    {
      "epoch": 1.2235054347826086,
      "grad_norm": 15.241154670715332,
      "learning_rate": 1.2855156498313333e-05,
      "loss": 0.2615,
      "step": 1801
    },
    {
      "epoch": 1.2241847826086956,
      "grad_norm": 3.678419828414917,
      "learning_rate": 1.2848337794351045e-05,
      "loss": 0.0627,
      "step": 1802
    },
    {
      "epoch": 1.2248641304347827,
      "grad_norm": 4.639533042907715,
      "learning_rate": 1.2841517648827538e-05,
      "loss": 0.1638,
      "step": 1803
    },
    {
      "epoch": 1.2255434782608696,
      "grad_norm": 4.457126617431641,
      "learning_rate": 1.283469606519453e-05,
      "loss": 0.097,
      "step": 1804
    },
    {
      "epoch": 1.2262228260869565,
      "grad_norm": 16.477182388305664,
      "learning_rate": 1.2827873046904467e-05,
      "loss": 0.4886,
      "step": 1805
    },
    {
      "epoch": 1.2269021739130435,
      "grad_norm": 14.154598236083984,
      "learning_rate": 1.282104859741052e-05,
      "loss": 0.2316,
      "step": 1806
    },
    {
      "epoch": 1.2275815217391304,
      "grad_norm": 13.952414512634277,
      "learning_rate": 1.2814222720166582e-05,
      "loss": 0.3437,
      "step": 1807
    },
    {
      "epoch": 1.2282608695652173,
      "grad_norm": 6.591752529144287,
      "learning_rate": 1.2807395418627278e-05,
      "loss": 0.1665,
      "step": 1808
    },
    {
      "epoch": 1.2289402173913044,
      "grad_norm": 5.120952129364014,
      "learning_rate": 1.2800566696247943e-05,
      "loss": 0.1632,
      "step": 1809
    },
    {
      "epoch": 1.2296195652173914,
      "grad_norm": 0.12630851566791534,
      "learning_rate": 1.279373655648463e-05,
      "loss": 0.0014,
      "step": 1810
    },
    {
      "epoch": 1.2302989130434783,
      "grad_norm": 0.047785062342882156,
      "learning_rate": 1.2786905002794123e-05,
      "loss": 0.0009,
      "step": 1811
    },
    {
      "epoch": 1.2309782608695652,
      "grad_norm": 9.389952659606934,
      "learning_rate": 1.2780072038633913e-05,
      "loss": 0.4117,
      "step": 1812
    },
    {
      "epoch": 1.231657608695652,
      "grad_norm": 0.06687026470899582,
      "learning_rate": 1.2773237667462199e-05,
      "loss": 0.001,
      "step": 1813
    },
    {
      "epoch": 1.2323369565217392,
      "grad_norm": 4.554103851318359,
      "learning_rate": 1.2766401892737901e-05,
      "loss": 0.2281,
      "step": 1814
    },
    {
      "epoch": 1.2330163043478262,
      "grad_norm": 2.005826711654663,
      "learning_rate": 1.2759564717920649e-05,
      "loss": 0.1604,
      "step": 1815
    },
    {
      "epoch": 1.233695652173913,
      "grad_norm": 0.16131842136383057,
      "learning_rate": 1.2752726146470775e-05,
      "loss": 0.0019,
      "step": 1816
    },
    {
      "epoch": 1.234375,
      "grad_norm": 3.8552863597869873,
      "learning_rate": 1.2745886181849325e-05,
      "loss": 0.1031,
      "step": 1817
    },
    {
      "epoch": 1.235054347826087,
      "grad_norm": 0.10601165145635605,
      "learning_rate": 1.2739044827518043e-05,
      "loss": 0.0022,
      "step": 1818
    },
    {
      "epoch": 1.2357336956521738,
      "grad_norm": 1.3609647750854492,
      "learning_rate": 1.2732202086939387e-05,
      "loss": 0.0221,
      "step": 1819
    },
    {
      "epoch": 1.2364130434782608,
      "grad_norm": 5.231108665466309,
      "learning_rate": 1.2725357963576506e-05,
      "loss": 0.1701,
      "step": 1820
    },
    {
      "epoch": 1.237092391304348,
      "grad_norm": 1.3040900230407715,
      "learning_rate": 1.271851246089325e-05,
      "loss": 0.0078,
      "step": 1821
    },
    {
      "epoch": 1.2377717391304348,
      "grad_norm": 0.6262805461883545,
      "learning_rate": 1.2711665582354175e-05,
      "loss": 0.0085,
      "step": 1822
    },
    {
      "epoch": 1.2384510869565217,
      "grad_norm": 0.04528588429093361,
      "learning_rate": 1.2704817331424526e-05,
      "loss": 0.001,
      "step": 1823
    },
    {
      "epoch": 1.2391304347826086,
      "grad_norm": 5.2241716384887695,
      "learning_rate": 1.2697967711570243e-05,
      "loss": 0.2306,
      "step": 1824
    },
    {
      "epoch": 1.2398097826086956,
      "grad_norm": 3.6956326961517334,
      "learning_rate": 1.2691116726257963e-05,
      "loss": 0.1004,
      "step": 1825
    },
    {
      "epoch": 1.2404891304347827,
      "grad_norm": 0.03503790870308876,
      "learning_rate": 1.2684264378955014e-05,
      "loss": 0.0006,
      "step": 1826
    },
    {
      "epoch": 1.2411684782608696,
      "grad_norm": 7.5194244384765625,
      "learning_rate": 1.2677410673129406e-05,
      "loss": 0.3691,
      "step": 1827
    },
    {
      "epoch": 1.2418478260869565,
      "grad_norm": 3.026578903198242,
      "learning_rate": 1.2670555612249845e-05,
      "loss": 0.1285,
      "step": 1828
    },
    {
      "epoch": 1.2425271739130435,
      "grad_norm": 3.631525754928589,
      "learning_rate": 1.2663699199785715e-05,
      "loss": 0.1274,
      "step": 1829
    },
    {
      "epoch": 1.2432065217391304,
      "grad_norm": 1.495621681213379,
      "learning_rate": 1.2656841439207093e-05,
      "loss": 0.0124,
      "step": 1830
    },
    {
      "epoch": 1.2438858695652173,
      "grad_norm": 4.650481700897217,
      "learning_rate": 1.264998233398473e-05,
      "loss": 0.2138,
      "step": 1831
    },
    {
      "epoch": 1.2445652173913044,
      "grad_norm": 2.8249258995056152,
      "learning_rate": 1.2643121887590064e-05,
      "loss": 0.1082,
      "step": 1832
    },
    {
      "epoch": 1.2452445652173914,
      "grad_norm": 1.5844035148620605,
      "learning_rate": 1.2636260103495209e-05,
      "loss": 0.0483,
      "step": 1833
    },
    {
      "epoch": 1.2459239130434783,
      "grad_norm": 7.5474443435668945,
      "learning_rate": 1.2629396985172954e-05,
      "loss": 0.3117,
      "step": 1834
    },
    {
      "epoch": 1.2466032608695652,
      "grad_norm": 0.028673458844423294,
      "learning_rate": 1.2622532536096767e-05,
      "loss": 0.0007,
      "step": 1835
    },
    {
      "epoch": 1.247282608695652,
      "grad_norm": 0.20846784114837646,
      "learning_rate": 1.2615666759740788e-05,
      "loss": 0.0028,
      "step": 1836
    },
    {
      "epoch": 1.2479619565217392,
      "grad_norm": 5.345550537109375,
      "learning_rate": 1.2608799659579827e-05,
      "loss": 0.2146,
      "step": 1837
    },
    {
      "epoch": 1.2486413043478262,
      "grad_norm": 0.02982162870466709,
      "learning_rate": 1.2601931239089366e-05,
      "loss": 0.0008,
      "step": 1838
    },
    {
      "epoch": 1.249320652173913,
      "grad_norm": 3.8396778106689453,
      "learning_rate": 1.2595061501745556e-05,
      "loss": 0.1603,
      "step": 1839
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.06082294136285782,
      "learning_rate": 1.2588190451025209e-05,
      "loss": 0.0007,
      "step": 1840
    },
    {
      "epoch": 1.250679347826087,
      "grad_norm": 0.02753588929772377,
      "learning_rate": 1.258131809040581e-05,
      "loss": 0.0005,
      "step": 1841
    },
    {
      "epoch": 1.2513586956521738,
      "grad_norm": 0.032005541026592255,
      "learning_rate": 1.2574444423365503e-05,
      "loss": 0.0006,
      "step": 1842
    },
    {
      "epoch": 1.2520380434782608,
      "grad_norm": 5.814450740814209,
      "learning_rate": 1.2567569453383092e-05,
      "loss": 0.1915,
      "step": 1843
    },
    {
      "epoch": 1.252717391304348,
      "grad_norm": 0.2742081880569458,
      "learning_rate": 1.256069318393804e-05,
      "loss": 0.0032,
      "step": 1844
    },
    {
      "epoch": 1.2533967391304348,
      "grad_norm": 12.048319816589355,
      "learning_rate": 1.255381561851047e-05,
      "loss": 0.4118,
      "step": 1845
    },
    {
      "epoch": 1.2540760869565217,
      "grad_norm": 3.4075119495391846,
      "learning_rate": 1.2546936760581162e-05,
      "loss": 0.1363,
      "step": 1846
    },
    {
      "epoch": 1.2547554347826086,
      "grad_norm": 4.888524055480957,
      "learning_rate": 1.2540056613631547e-05,
      "loss": 0.0858,
      "step": 1847
    },
    {
      "epoch": 1.2554347826086958,
      "grad_norm": 12.537954330444336,
      "learning_rate": 1.2533175181143704e-05,
      "loss": 0.486,
      "step": 1848
    },
    {
      "epoch": 1.2561141304347827,
      "grad_norm": 0.4549165368080139,
      "learning_rate": 1.2526292466600378e-05,
      "loss": 0.0069,
      "step": 1849
    },
    {
      "epoch": 1.2567934782608696,
      "grad_norm": 17.218307495117188,
      "learning_rate": 1.2519408473484947e-05,
      "loss": 0.5664,
      "step": 1850
    },
    {
      "epoch": 1.2574728260869565,
      "grad_norm": 1.507737398147583,
      "learning_rate": 1.2512523205281444e-05,
      "loss": 0.0511,
      "step": 1851
    },
    {
      "epoch": 1.2581521739130435,
      "grad_norm": 0.12489794939756393,
      "learning_rate": 1.2505636665474545e-05,
      "loss": 0.0017,
      "step": 1852
    },
    {
      "epoch": 1.2588315217391304,
      "grad_norm": 14.607177734375,
      "learning_rate": 1.2498748857549567e-05,
      "loss": 0.4229,
      "step": 1853
    },
    {
      "epoch": 1.2595108695652173,
      "grad_norm": 7.52933406829834,
      "learning_rate": 1.2491859784992477e-05,
      "loss": 0.4899,
      "step": 1854
    },
    {
      "epoch": 1.2601902173913042,
      "grad_norm": 0.030017558485269547,
      "learning_rate": 1.2484969451289874e-05,
      "loss": 0.0006,
      "step": 1855
    },
    {
      "epoch": 1.2608695652173914,
      "grad_norm": 3.6962924003601074,
      "learning_rate": 1.2478077859929e-05,
      "loss": 0.2077,
      "step": 1856
    },
    {
      "epoch": 1.2615489130434783,
      "grad_norm": 6.8216071128845215,
      "learning_rate": 1.2471185014397728e-05,
      "loss": 0.3701,
      "step": 1857
    },
    {
      "epoch": 1.2622282608695652,
      "grad_norm": 0.11351682245731354,
      "learning_rate": 1.2464290918184573e-05,
      "loss": 0.001,
      "step": 1858
    },
    {
      "epoch": 1.262907608695652,
      "grad_norm": 3.67922043800354,
      "learning_rate": 1.2457395574778679e-05,
      "loss": 0.0325,
      "step": 1859
    },
    {
      "epoch": 1.2635869565217392,
      "grad_norm": 12.140222549438477,
      "learning_rate": 1.245049898766982e-05,
      "loss": 0.5771,
      "step": 1860
    },
    {
      "epoch": 1.2642663043478262,
      "grad_norm": 0.16494616866111755,
      "learning_rate": 1.24436011603484e-05,
      "loss": 0.0015,
      "step": 1861
    },
    {
      "epoch": 1.264945652173913,
      "grad_norm": 2.3866331577301025,
      "learning_rate": 1.2436702096305455e-05,
      "loss": 0.1068,
      "step": 1862
    },
    {
      "epoch": 1.265625,
      "grad_norm": 4.2909417152404785,
      "learning_rate": 1.242980179903264e-05,
      "loss": 0.1498,
      "step": 1863
    },
    {
      "epoch": 1.266304347826087,
      "grad_norm": 4.4862542152404785,
      "learning_rate": 1.2422900272022242e-05,
      "loss": 0.2039,
      "step": 1864
    },
    {
      "epoch": 1.2669836956521738,
      "grad_norm": 0.1579635739326477,
      "learning_rate": 1.2415997518767163e-05,
      "loss": 0.0025,
      "step": 1865
    },
    {
      "epoch": 1.2676630434782608,
      "grad_norm": 4.831131935119629,
      "learning_rate": 1.2409093542760925e-05,
      "loss": 0.1907,
      "step": 1866
    },
    {
      "epoch": 1.268342391304348,
      "grad_norm": 0.12027762830257416,
      "learning_rate": 1.2402188347497684e-05,
      "loss": 0.0013,
      "step": 1867
    },
    {
      "epoch": 1.2690217391304348,
      "grad_norm": 4.575292110443115,
      "learning_rate": 1.239528193647219e-05,
      "loss": 0.1933,
      "step": 1868
    },
    {
      "epoch": 1.2697010869565217,
      "grad_norm": 1.4973828792572021,
      "learning_rate": 1.2388374313179828e-05,
      "loss": 0.0165,
      "step": 1869
    },
    {
      "epoch": 1.2703804347826086,
      "grad_norm": 4.206248760223389,
      "learning_rate": 1.2381465481116582e-05,
      "loss": 0.0725,
      "step": 1870
    },
    {
      "epoch": 1.2710597826086958,
      "grad_norm": 0.13070319592952728,
      "learning_rate": 1.2374555443779057e-05,
      "loss": 0.0016,
      "step": 1871
    },
    {
      "epoch": 1.2717391304347827,
      "grad_norm": 6.059530735015869,
      "learning_rate": 1.2367644204664468e-05,
      "loss": 0.0943,
      "step": 1872
    },
    {
      "epoch": 1.2724184782608696,
      "grad_norm": 4.744563579559326,
      "learning_rate": 1.2360731767270634e-05,
      "loss": 0.2105,
      "step": 1873
    },
    {
      "epoch": 1.2730978260869565,
      "grad_norm": 0.10362188518047333,
      "learning_rate": 1.2353818135095978e-05,
      "loss": 0.0011,
      "step": 1874
    },
    {
      "epoch": 1.2737771739130435,
      "grad_norm": 7.353875160217285,
      "learning_rate": 1.2346903311639537e-05,
      "loss": 0.3152,
      "step": 1875
    },
    {
      "epoch": 1.2744565217391304,
      "grad_norm": 0.014716909267008305,
      "learning_rate": 1.2339987300400941e-05,
      "loss": 0.0004,
      "step": 1876
    },
    {
      "epoch": 1.2751358695652173,
      "grad_norm": 2.394313097000122,
      "learning_rate": 1.2333070104880431e-05,
      "loss": 0.1006,
      "step": 1877
    },
    {
      "epoch": 1.2758152173913042,
      "grad_norm": 13.49340534210205,
      "learning_rate": 1.2326151728578839e-05,
      "loss": 0.3714,
      "step": 1878
    },
    {
      "epoch": 1.2764945652173914,
      "grad_norm": 4.230466365814209,
      "learning_rate": 1.2319232174997593e-05,
      "loss": 0.1327,
      "step": 1879
    },
    {
      "epoch": 1.2771739130434783,
      "grad_norm": 0.16862860321998596,
      "learning_rate": 1.2312311447638731e-05,
      "loss": 0.002,
      "step": 1880
    },
    {
      "epoch": 1.2778532608695652,
      "grad_norm": 1.174490213394165,
      "learning_rate": 1.230538955000487e-05,
      "loss": 0.0109,
      "step": 1881
    },
    {
      "epoch": 1.278532608695652,
      "grad_norm": 3.2347042560577393,
      "learning_rate": 1.2298466485599223e-05,
      "loss": 0.0873,
      "step": 1882
    },
    {
      "epoch": 1.2792119565217392,
      "grad_norm": 4.741337776184082,
      "learning_rate": 1.2291542257925597e-05,
      "loss": 0.234,
      "step": 1883
    },
    {
      "epoch": 1.2798913043478262,
      "grad_norm": 0.9748762249946594,
      "learning_rate": 1.228461687048839e-05,
      "loss": 0.0075,
      "step": 1884
    },
    {
      "epoch": 1.280570652173913,
      "grad_norm": 0.14396853744983673,
      "learning_rate": 1.2277690326792579e-05,
      "loss": 0.0014,
      "step": 1885
    },
    {
      "epoch": 1.28125,
      "grad_norm": 1.9164155721664429,
      "learning_rate": 1.2270762630343734e-05,
      "loss": 0.0863,
      "step": 1886
    },
    {
      "epoch": 1.281929347826087,
      "grad_norm": 4.600218296051025,
      "learning_rate": 1.2263833784647998e-05,
      "loss": 0.135,
      "step": 1887
    },
    {
      "epoch": 1.2826086956521738,
      "grad_norm": 1.858610987663269,
      "learning_rate": 1.2256903793212107e-05,
      "loss": 0.0748,
      "step": 1888
    },
    {
      "epoch": 1.2832880434782608,
      "grad_norm": 6.790582180023193,
      "learning_rate": 1.2249972659543375e-05,
      "loss": 0.131,
      "step": 1889
    },
    {
      "epoch": 1.283967391304348,
      "grad_norm": 2.312811851501465,
      "learning_rate": 1.2243040387149682e-05,
      "loss": 0.069,
      "step": 1890
    },
    {
      "epoch": 1.2846467391304348,
      "grad_norm": 7.380097389221191,
      "learning_rate": 1.2236106979539501e-05,
      "loss": 0.4194,
      "step": 1891
    },
    {
      "epoch": 1.2853260869565217,
      "grad_norm": 7.412759780883789,
      "learning_rate": 1.2229172440221867e-05,
      "loss": 0.2759,
      "step": 1892
    },
    {
      "epoch": 1.2860054347826086,
      "grad_norm": 3.1500372886657715,
      "learning_rate": 1.2222236772706402e-05,
      "loss": 0.1737,
      "step": 1893
    },
    {
      "epoch": 1.2866847826086958,
      "grad_norm": 0.30608463287353516,
      "learning_rate": 1.2215299980503282e-05,
      "loss": 0.0037,
      "step": 1894
    },
    {
      "epoch": 1.2873641304347827,
      "grad_norm": 1.6852829456329346,
      "learning_rate": 1.220836206712326e-05,
      "loss": 0.0158,
      "step": 1895
    },
    {
      "epoch": 1.2880434782608696,
      "grad_norm": 10.96826171875,
      "learning_rate": 1.2201423036077657e-05,
      "loss": 0.3019,
      "step": 1896
    },
    {
      "epoch": 1.2887228260869565,
      "grad_norm": 3.046499729156494,
      "learning_rate": 1.2194482890878363e-05,
      "loss": 0.12,
      "step": 1897
    },
    {
      "epoch": 1.2894021739130435,
      "grad_norm": 4.736580848693848,
      "learning_rate": 1.2187541635037824e-05,
      "loss": 0.1807,
      "step": 1898
    },
    {
      "epoch": 1.2900815217391304,
      "grad_norm": 1.718117356300354,
      "learning_rate": 1.2180599272069058e-05,
      "loss": 0.0507,
      "step": 1899
    },
    {
      "epoch": 1.2907608695652173,
      "grad_norm": 7.5239481925964355,
      "learning_rate": 1.2173655805485627e-05,
      "loss": 0.1478,
      "step": 1900
    },
    {
      "epoch": 1.2914402173913042,
      "grad_norm": 0.11820193380117416,
      "learning_rate": 1.2166711238801671e-05,
      "loss": 0.0014,
      "step": 1901
    },
    {
      "epoch": 1.2921195652173914,
      "grad_norm": 0.4040030539035797,
      "learning_rate": 1.2159765575531877e-05,
      "loss": 0.0046,
      "step": 1902
    },
    {
      "epoch": 1.2927989130434783,
      "grad_norm": 1.7880322933197021,
      "learning_rate": 1.2152818819191483e-05,
      "loss": 0.0565,
      "step": 1903
    },
    {
      "epoch": 1.2934782608695652,
      "grad_norm": 2.1870200634002686,
      "learning_rate": 1.2145870973296288e-05,
      "loss": 0.0266,
      "step": 1904
    },
    {
      "epoch": 1.294157608695652,
      "grad_norm": 6.05285120010376,
      "learning_rate": 1.213892204136264e-05,
      "loss": 0.313,
      "step": 1905
    },
    {
      "epoch": 1.2948369565217392,
      "grad_norm": 11.81578540802002,
      "learning_rate": 1.2131972026907433e-05,
      "loss": 0.5385,
      "step": 1906
    },
    {
      "epoch": 1.2955163043478262,
      "grad_norm": 0.8968212604522705,
      "learning_rate": 1.2125020933448117e-05,
      "loss": 0.0301,
      "step": 1907
    },
    {
      "epoch": 1.296195652173913,
      "grad_norm": 4.187569618225098,
      "learning_rate": 1.2118068764502677e-05,
      "loss": 0.099,
      "step": 1908
    },
    {
      "epoch": 1.296875,
      "grad_norm": 3.036386489868164,
      "learning_rate": 1.2111115523589651e-05,
      "loss": 0.1108,
      "step": 1909
    },
    {
      "epoch": 1.297554347826087,
      "grad_norm": 4.273458957672119,
      "learning_rate": 1.210416121422812e-05,
      "loss": 0.2366,
      "step": 1910
    },
    {
      "epoch": 1.2982336956521738,
      "grad_norm": 8.587656021118164,
      "learning_rate": 1.20972058399377e-05,
      "loss": 0.3944,
      "step": 1911
    },
    {
      "epoch": 1.2989130434782608,
      "grad_norm": 4.147975444793701,
      "learning_rate": 1.2090249404238548e-05,
      "loss": 0.2028,
      "step": 1912
    },
    {
      "epoch": 1.299592391304348,
      "grad_norm": 1.1310491561889648,
      "learning_rate": 1.2083291910651356e-05,
      "loss": 0.0112,
      "step": 1913
    },
    {
      "epoch": 1.3002717391304348,
      "grad_norm": 0.04394715279340744,
      "learning_rate": 1.2076333362697358e-05,
      "loss": 0.0007,
      "step": 1914
    },
    {
      "epoch": 1.3009510869565217,
      "grad_norm": 4.268918514251709,
      "learning_rate": 1.206937376389832e-05,
      "loss": 0.1177,
      "step": 1915
    },
    {
      "epoch": 1.3016304347826086,
      "grad_norm": 2.051515817642212,
      "learning_rate": 1.2062413117776535e-05,
      "loss": 0.0649,
      "step": 1916
    },
    {
      "epoch": 1.3023097826086958,
      "grad_norm": 2.1717631816864014,
      "learning_rate": 1.2055451427854825e-05,
      "loss": 0.0241,
      "step": 1917
    },
    {
      "epoch": 1.3029891304347827,
      "grad_norm": 0.20406974852085114,
      "learning_rate": 1.2048488697656548e-05,
      "loss": 0.0023,
      "step": 1918
    },
    {
      "epoch": 1.3036684782608696,
      "grad_norm": 2.967155694961548,
      "learning_rate": 1.2041524930705586e-05,
      "loss": 0.2176,
      "step": 1919
    },
    {
      "epoch": 1.3043478260869565,
      "grad_norm": 0.4181709885597229,
      "learning_rate": 1.2034560130526341e-05,
      "loss": 0.0033,
      "step": 1920
    },
    {
      "epoch": 1.3050271739130435,
      "grad_norm": 1.7970733642578125,
      "learning_rate": 1.2027594300643742e-05,
      "loss": 0.014,
      "step": 1921
    },
    {
      "epoch": 1.3057065217391304,
      "grad_norm": 10.991625785827637,
      "learning_rate": 1.2020627444583235e-05,
      "loss": 0.1652,
      "step": 1922
    },
    {
      "epoch": 1.3063858695652173,
      "grad_norm": 0.2506333887577057,
      "learning_rate": 1.2013659565870795e-05,
      "loss": 0.0027,
      "step": 1923
    },
    {
      "epoch": 1.3070652173913042,
      "grad_norm": 0.019094618037343025,
      "learning_rate": 1.2006690668032902e-05,
      "loss": 0.0004,
      "step": 1924
    },
    {
      "epoch": 1.3077445652173914,
      "grad_norm": 1.768149495124817,
      "learning_rate": 1.1999720754596565e-05,
      "loss": 0.037,
      "step": 1925
    },
    {
      "epoch": 1.3084239130434783,
      "grad_norm": 0.05546976253390312,
      "learning_rate": 1.199274982908929e-05,
      "loss": 0.001,
      "step": 1926
    },
    {
      "epoch": 1.3091032608695652,
      "grad_norm": 4.504258632659912,
      "learning_rate": 1.1985777895039114e-05,
      "loss": 0.04,
      "step": 1927
    },
    {
      "epoch": 1.309782608695652,
      "grad_norm": 16.524681091308594,
      "learning_rate": 1.1978804955974573e-05,
      "loss": 0.7338,
      "step": 1928
    },
    {
      "epoch": 1.3104619565217392,
      "grad_norm": 5.162591934204102,
      "learning_rate": 1.1971831015424713e-05,
      "loss": 0.2936,
      "step": 1929
    },
    {
      "epoch": 1.3111413043478262,
      "grad_norm": 0.28711026906967163,
      "learning_rate": 1.1964856076919087e-05,
      "loss": 0.0025,
      "step": 1930
    },
    {
      "epoch": 1.311820652173913,
      "grad_norm": 0.36473748087882996,
      "learning_rate": 1.1957880143987757e-05,
      "loss": 0.0039,
      "step": 1931
    },
    {
      "epoch": 1.3125,
      "grad_norm": 8.230680465698242,
      "learning_rate": 1.1950903220161286e-05,
      "loss": 0.1279,
      "step": 1932
    },
    {
      "epoch": 1.313179347826087,
      "grad_norm": 9.083857536315918,
      "learning_rate": 1.1943925308970732e-05,
      "loss": 0.1193,
      "step": 1933
    },
    {
      "epoch": 1.3138586956521738,
      "grad_norm": 2.341914653778076,
      "learning_rate": 1.1936946413947666e-05,
      "loss": 0.0291,
      "step": 1934
    },
    {
      "epoch": 1.3145380434782608,
      "grad_norm": 4.603158950805664,
      "learning_rate": 1.1929966538624143e-05,
      "loss": 0.0493,
      "step": 1935
    },
    {
      "epoch": 1.315217391304348,
      "grad_norm": 0.28507551550865173,
      "learning_rate": 1.1922985686532726e-05,
      "loss": 0.0029,
      "step": 1936
    },
    {
      "epoch": 1.3158967391304348,
      "grad_norm": 0.03924207389354706,
      "learning_rate": 1.1916003861206467e-05,
      "loss": 0.0007,
      "step": 1937
    },
    {
      "epoch": 1.3165760869565217,
      "grad_norm": 0.07558830827474594,
      "learning_rate": 1.1909021066178906e-05,
      "loss": 0.001,
      "step": 1938
    },
    {
      "epoch": 1.3172554347826086,
      "grad_norm": 0.016204647719860077,
      "learning_rate": 1.1902037304984079e-05,
      "loss": 0.0004,
      "step": 1939
    },
    {
      "epoch": 1.3179347826086958,
      "grad_norm": 5.362240791320801,
      "learning_rate": 1.1895052581156516e-05,
      "loss": 0.119,
      "step": 1940
    },
    {
      "epoch": 1.3186141304347827,
      "grad_norm": 0.056847043335437775,
      "learning_rate": 1.1888066898231223e-05,
      "loss": 0.0008,
      "step": 1941
    },
    {
      "epoch": 1.3192934782608696,
      "grad_norm": 3.7419273853302,
      "learning_rate": 1.1881080259743701e-05,
      "loss": 0.1305,
      "step": 1942
    },
    {
      "epoch": 1.3199728260869565,
      "grad_norm": 4.2772321701049805,
      "learning_rate": 1.1874092669229924e-05,
      "loss": 0.1936,
      "step": 1943
    },
    {
      "epoch": 1.3206521739130435,
      "grad_norm": 0.14200933277606964,
      "learning_rate": 1.1867104130226363e-05,
      "loss": 0.0015,
      "step": 1944
    },
    {
      "epoch": 1.3213315217391304,
      "grad_norm": 5.48867130279541,
      "learning_rate": 1.1860114646269955e-05,
      "loss": 0.1584,
      "step": 1945
    },
    {
      "epoch": 1.3220108695652173,
      "grad_norm": 3.23264479637146,
      "learning_rate": 1.1853124220898123e-05,
      "loss": 0.1983,
      "step": 1946
    },
    {
      "epoch": 1.3226902173913042,
      "grad_norm": 4.957242965698242,
      "learning_rate": 1.184613285764876e-05,
      "loss": 0.0318,
      "step": 1947
    },
    {
      "epoch": 1.3233695652173914,
      "grad_norm": 1.4733728170394897,
      "learning_rate": 1.1839140560060242e-05,
      "loss": 0.058,
      "step": 1948
    },
    {
      "epoch": 1.3240489130434783,
      "grad_norm": 3.2504723072052,
      "learning_rate": 1.1832147331671416e-05,
      "loss": 0.1071,
      "step": 1949
    },
    {
      "epoch": 1.3247282608695652,
      "grad_norm": 0.0314222052693367,
      "learning_rate": 1.1825153176021591e-05,
      "loss": 0.0006,
      "step": 1950
    },
    {
      "epoch": 1.325407608695652,
      "grad_norm": 6.523285388946533,
      "learning_rate": 1.1818158096650554e-05,
      "loss": 0.2884,
      "step": 1951
    },
    {
      "epoch": 1.3260869565217392,
      "grad_norm": 16.284242630004883,
      "learning_rate": 1.1811162097098559e-05,
      "loss": 0.3787,
      "step": 1952
    },
    {
      "epoch": 1.3267663043478262,
      "grad_norm": 5.376440525054932,
      "learning_rate": 1.1804165180906326e-05,
      "loss": 0.0679,
      "step": 1953
    },
    {
      "epoch": 1.327445652173913,
      "grad_norm": 5.842519760131836,
      "learning_rate": 1.1797167351615032e-05,
      "loss": 0.1,
      "step": 1954
    },
    {
      "epoch": 1.328125,
      "grad_norm": 2.224674701690674,
      "learning_rate": 1.1790168612766331e-05,
      "loss": 0.0853,
      "step": 1955
    },
    {
      "epoch": 1.328804347826087,
      "grad_norm": 3.7305054664611816,
      "learning_rate": 1.1783168967902314e-05,
      "loss": 0.094,
      "step": 1956
    },
    {
      "epoch": 1.3294836956521738,
      "grad_norm": 4.849003791809082,
      "learning_rate": 1.1776168420565555e-05,
      "loss": 0.0873,
      "step": 1957
    },
    {
      "epoch": 1.3301630434782608,
      "grad_norm": 0.6813185811042786,
      "learning_rate": 1.1769166974299071e-05,
      "loss": 0.0075,
      "step": 1958
    },
    {
      "epoch": 1.330842391304348,
      "grad_norm": 3.9263830184936523,
      "learning_rate": 1.1762164632646334e-05,
      "loss": 0.1196,
      "step": 1959
    },
    {
      "epoch": 1.3315217391304348,
      "grad_norm": 10.083174705505371,
      "learning_rate": 1.1755161399151277e-05,
      "loss": 0.0872,
      "step": 1960
    },
    {
      "epoch": 1.3322010869565217,
      "grad_norm": 0.08684451878070831,
      "learning_rate": 1.1748157277358272e-05,
      "loss": 0.0012,
      "step": 1961
    },
    {
      "epoch": 1.3328804347826086,
      "grad_norm": 0.15703393518924713,
      "learning_rate": 1.1741152270812155e-05,
      "loss": 0.0019,
      "step": 1962
    },
    {
      "epoch": 1.3335597826086958,
      "grad_norm": 3.0380892753601074,
      "learning_rate": 1.17341463830582e-05,
      "loss": 0.1633,
      "step": 1963
    },
    {
      "epoch": 1.3342391304347827,
      "grad_norm": 13.802443504333496,
      "learning_rate": 1.1727139617642132e-05,
      "loss": 0.6714,
      "step": 1964
    },
    {
      "epoch": 1.3349184782608696,
      "grad_norm": 7.833949089050293,
      "learning_rate": 1.1720131978110115e-05,
      "loss": 0.3894,
      "step": 1965
    },
    {
      "epoch": 1.3355978260869565,
      "grad_norm": 2.033989429473877,
      "learning_rate": 1.1713123468008757e-05,
      "loss": 0.0381,
      "step": 1966
    },
    {
      "epoch": 1.3362771739130435,
      "grad_norm": 0.49758949875831604,
      "learning_rate": 1.1706114090885112e-05,
      "loss": 0.005,
      "step": 1967
    },
    {
      "epoch": 1.3369565217391304,
      "grad_norm": 0.24522456526756287,
      "learning_rate": 1.1699103850286668e-05,
      "loss": 0.0026,
      "step": 1968
    },
    {
      "epoch": 1.3376358695652173,
      "grad_norm": 4.3309431076049805,
      "learning_rate": 1.1692092749761348e-05,
      "loss": 0.0839,
      "step": 1969
    },
    {
      "epoch": 1.3383152173913042,
      "grad_norm": 21.125099182128906,
      "learning_rate": 1.1685080792857516e-05,
      "loss": 0.19,
      "step": 1970
    },
    {
      "epoch": 1.3389945652173914,
      "grad_norm": 0.4648301303386688,
      "learning_rate": 1.1678067983123965e-05,
      "loss": 0.0036,
      "step": 1971
    },
    {
      "epoch": 1.3396739130434783,
      "grad_norm": 0.8243235945701599,
      "learning_rate": 1.167105432410992e-05,
      "loss": 0.0083,
      "step": 1972
    },
    {
      "epoch": 1.3403532608695652,
      "grad_norm": 0.9871039986610413,
      "learning_rate": 1.1664039819365037e-05,
      "loss": 0.0079,
      "step": 1973
    },
    {
      "epoch": 1.341032608695652,
      "grad_norm": 2.528550863265991,
      "learning_rate": 1.1657024472439402e-05,
      "loss": 0.0223,
      "step": 1974
    },
    {
      "epoch": 1.3417119565217392,
      "grad_norm": 0.7530818581581116,
      "learning_rate": 1.1650008286883526e-05,
      "loss": 0.0092,
      "step": 1975
    },
    {
      "epoch": 1.3423913043478262,
      "grad_norm": 3.8858253955841064,
      "learning_rate": 1.1642991266248338e-05,
      "loss": 0.1861,
      "step": 1976
    },
    {
      "epoch": 1.343070652173913,
      "grad_norm": 3.2281301021575928,
      "learning_rate": 1.16359734140852e-05,
      "loss": 0.0914,
      "step": 1977
    },
    {
      "epoch": 1.34375,
      "grad_norm": 3.4414494037628174,
      "learning_rate": 1.162895473394589e-05,
      "loss": 0.1074,
      "step": 1978
    },
    {
      "epoch": 1.344429347826087,
      "grad_norm": 0.6394018530845642,
      "learning_rate": 1.16219352293826e-05,
      "loss": 0.0052,
      "step": 1979
    },
    {
      "epoch": 1.3451086956521738,
      "grad_norm": 0.08186981081962585,
      "learning_rate": 1.1614914903947952e-05,
      "loss": 0.0007,
      "step": 1980
    },
    {
      "epoch": 1.3457880434782608,
      "grad_norm": 7.419538497924805,
      "learning_rate": 1.1607893761194967e-05,
      "loss": 0.2994,
      "step": 1981
    },
    {
      "epoch": 1.346467391304348,
      "grad_norm": 1.9850776195526123,
      "learning_rate": 1.1600871804677094e-05,
      "loss": 0.0153,
      "step": 1982
    },
    {
      "epoch": 1.3471467391304348,
      "grad_norm": 1.2536132335662842,
      "learning_rate": 1.1593849037948189e-05,
      "loss": 0.0288,
      "step": 1983
    },
    {
      "epoch": 1.3478260869565217,
      "grad_norm": 4.083506107330322,
      "learning_rate": 1.1586825464562515e-05,
      "loss": 0.0876,
      "step": 1984
    },
    {
      "epoch": 1.3485054347826086,
      "grad_norm": 0.024691719561815262,
      "learning_rate": 1.1579801088074747e-05,
      "loss": 0.0005,
      "step": 1985
    },
    {
      "epoch": 1.3491847826086958,
      "grad_norm": 3.6450095176696777,
      "learning_rate": 1.157277591203996e-05,
      "loss": 0.1344,
      "step": 1986
    },
    {
      "epoch": 1.3498641304347827,
      "grad_norm": 0.04457026347517967,
      "learning_rate": 1.1565749940013647e-05,
      "loss": 0.0009,
      "step": 1987
    },
    {
      "epoch": 1.3505434782608696,
      "grad_norm": 5.936779975891113,
      "learning_rate": 1.155872317555169e-05,
      "loss": 0.1271,
      "step": 1988
    },
    {
      "epoch": 1.3512228260869565,
      "grad_norm": 5.096804141998291,
      "learning_rate": 1.1551695622210377e-05,
      "loss": 0.1625,
      "step": 1989
    },
    {
      "epoch": 1.3519021739130435,
      "grad_norm": 4.580049991607666,
      "learning_rate": 1.15446672835464e-05,
      "loss": 0.084,
      "step": 1990
    },
    {
      "epoch": 1.3525815217391304,
      "grad_norm": 5.663804531097412,
      "learning_rate": 1.1537638163116838e-05,
      "loss": 0.229,
      "step": 1991
    },
    {
      "epoch": 1.3532608695652173,
      "grad_norm": 0.015425951220095158,
      "learning_rate": 1.153060826447918e-05,
      "loss": 0.0003,
      "step": 1992
    },
    {
      "epoch": 1.3539402173913042,
      "grad_norm": 1.8525558710098267,
      "learning_rate": 1.1523577591191292e-05,
      "loss": 0.1153,
      "step": 1993
    },
    {
      "epoch": 1.3546195652173914,
      "grad_norm": 5.104584217071533,
      "learning_rate": 1.1516546146811452e-05,
      "loss": 0.1808,
      "step": 1994
    },
    {
      "epoch": 1.3552989130434783,
      "grad_norm": 2.997560739517212,
      "learning_rate": 1.1509513934898303e-05,
      "loss": 0.1029,
      "step": 1995
    },
    {
      "epoch": 1.3559782608695652,
      "grad_norm": 5.23486852645874,
      "learning_rate": 1.1502480959010902e-05,
      "loss": 0.3182,
      "step": 1996
    },
    {
      "epoch": 1.356657608695652,
      "grad_norm": 10.076081275939941,
      "learning_rate": 1.1495447222708677e-05,
      "loss": 0.3087,
      "step": 1997
    },
    {
      "epoch": 1.3573369565217392,
      "grad_norm": 0.05629908666014671,
      "learning_rate": 1.1488412729551449e-05,
      "loss": 0.0009,
      "step": 1998
    },
    {
      "epoch": 1.3580163043478262,
      "grad_norm": 15.502449035644531,
      "learning_rate": 1.1481377483099407e-05,
      "loss": 0.7303,
      "step": 1999
    },
    {
      "epoch": 1.358695652173913,
      "grad_norm": 5.466350555419922,
      "learning_rate": 1.1474341486913146e-05,
      "loss": 0.079,
      "step": 2000
    },
    {
      "epoch": 1.359375,
      "grad_norm": 4.674613952636719,
      "learning_rate": 1.1467304744553618e-05,
      "loss": 0.1188,
      "step": 2001
    },
    {
      "epoch": 1.360054347826087,
      "grad_norm": 1.2237836122512817,
      "learning_rate": 1.1460267259582165e-05,
      "loss": 0.0143,
      "step": 2002
    },
    {
      "epoch": 1.3607336956521738,
      "grad_norm": 0.15028929710388184,
      "learning_rate": 1.14532290355605e-05,
      "loss": 0.0024,
      "step": 2003
    },
    {
      "epoch": 1.3614130434782608,
      "grad_norm": 0.057036370038986206,
      "learning_rate": 1.144619007605071e-05,
      "loss": 0.0009,
      "step": 2004
    },
    {
      "epoch": 1.362092391304348,
      "grad_norm": 2.6634063720703125,
      "learning_rate": 1.1439150384615261e-05,
      "loss": 0.219,
      "step": 2005
    },
    {
      "epoch": 1.3627717391304348,
      "grad_norm": 3.2738304138183594,
      "learning_rate": 1.1432109964816978e-05,
      "loss": 0.1205,
      "step": 2006
    },
    {
      "epoch": 1.3634510869565217,
      "grad_norm": 8.595719337463379,
      "learning_rate": 1.1425068820219063e-05,
      "loss": 0.1483,
      "step": 2007
    },
    {
      "epoch": 1.3641304347826086,
      "grad_norm": 2.6388955116271973,
      "learning_rate": 1.1418026954385082e-05,
      "loss": 0.0728,
      "step": 2008
    },
    {
      "epoch": 1.3648097826086958,
      "grad_norm": 3.5402913093566895,
      "learning_rate": 1.1410984370878967e-05,
      "loss": 0.1707,
      "step": 2009
    },
    {
      "epoch": 1.3654891304347827,
      "grad_norm": 2.504591464996338,
      "learning_rate": 1.1403941073265014e-05,
      "loss": 0.1418,
      "step": 2010
    },
    {
      "epoch": 1.3661684782608696,
      "grad_norm": 3.167356491088867,
      "learning_rate": 1.1396897065107876e-05,
      "loss": 0.1085,
      "step": 2011
    },
    {
      "epoch": 1.3668478260869565,
      "grad_norm": 7.101724147796631,
      "learning_rate": 1.1389852349972568e-05,
      "loss": 0.1377,
      "step": 2012
    },
    {
      "epoch": 1.3675271739130435,
      "grad_norm": 7.775720119476318,
      "learning_rate": 1.1382806931424468e-05,
      "loss": 0.2325,
      "step": 2013
    },
    {
      "epoch": 1.3682065217391304,
      "grad_norm": 5.323667049407959,
      "learning_rate": 1.1375760813029304e-05,
      "loss": 0.3047,
      "step": 2014
    },
    {
      "epoch": 1.3688858695652173,
      "grad_norm": 0.1745976060628891,
      "learning_rate": 1.1368713998353158e-05,
      "loss": 0.0016,
      "step": 2015
    },
    {
      "epoch": 1.3695652173913042,
      "grad_norm": 4.426980018615723,
      "learning_rate": 1.1361666490962468e-05,
      "loss": 0.1853,
      "step": 2016
    },
    {
      "epoch": 1.3702445652173914,
      "grad_norm": 0.10170415788888931,
      "learning_rate": 1.1354618294424018e-05,
      "loss": 0.0015,
      "step": 2017
    },
    {
      "epoch": 1.3709239130434783,
      "grad_norm": 0.2438325732946396,
      "learning_rate": 1.1347569412304945e-05,
      "loss": 0.0021,
      "step": 2018
    },
    {
      "epoch": 1.3716032608695652,
      "grad_norm": 1.9934731721878052,
      "learning_rate": 1.1340519848172735e-05,
      "loss": 0.048,
      "step": 2019
    },
    {
      "epoch": 1.372282608695652,
      "grad_norm": 8.57118034362793,
      "learning_rate": 1.133346960559521e-05,
      "loss": 0.217,
      "step": 2020
    },
    {
      "epoch": 1.3729619565217392,
      "grad_norm": 0.15657253563404083,
      "learning_rate": 1.1326418688140544e-05,
      "loss": 0.0024,
      "step": 2021
    },
    {
      "epoch": 1.3736413043478262,
      "grad_norm": 5.481986045837402,
      "learning_rate": 1.1319367099377248e-05,
      "loss": 0.2062,
      "step": 2022
    },
    {
      "epoch": 1.374320652173913,
      "grad_norm": 4.8201398849487305,
      "learning_rate": 1.1312314842874176e-05,
      "loss": 0.2655,
      "step": 2023
    },
    {
      "epoch": 1.375,
      "grad_norm": 4.114363670349121,
      "learning_rate": 1.130526192220052e-05,
      "loss": 0.1945,
      "step": 2024
    },
    {
      "epoch": 1.375679347826087,
      "grad_norm": 0.7895565032958984,
      "learning_rate": 1.1298208340925798e-05,
      "loss": 0.0058,
      "step": 2025
    },
    {
      "epoch": 1.3763586956521738,
      "grad_norm": 4.932925701141357,
      "learning_rate": 1.1291154102619878e-05,
      "loss": 0.2764,
      "step": 2026
    },
    {
      "epoch": 1.3770380434782608,
      "grad_norm": 4.418572902679443,
      "learning_rate": 1.1284099210852955e-05,
      "loss": 0.1855,
      "step": 2027
    },
    {
      "epoch": 1.377717391304348,
      "grad_norm": 4.434443950653076,
      "learning_rate": 1.1277043669195549e-05,
      "loss": 0.0429,
      "step": 2028
    },
    {
      "epoch": 1.3783967391304348,
      "grad_norm": 0.0254831425845623,
      "learning_rate": 1.1269987481218511e-05,
      "loss": 0.0006,
      "step": 2029
    },
    {
      "epoch": 1.3790760869565217,
      "grad_norm": 11.753997802734375,
      "learning_rate": 1.1262930650493025e-05,
      "loss": 0.5636,
      "step": 2030
    },
    {
      "epoch": 1.3797554347826086,
      "grad_norm": 2.236287832260132,
      "learning_rate": 1.1255873180590595e-05,
      "loss": 0.0198,
      "step": 2031
    },
    {
      "epoch": 1.3804347826086958,
      "grad_norm": 1.579302191734314,
      "learning_rate": 1.1248815075083051e-05,
      "loss": 0.0368,
      "step": 2032
    },
    {
      "epoch": 1.3811141304347827,
      "grad_norm": 1.468278408050537,
      "learning_rate": 1.1241756337542542e-05,
      "loss": 0.0185,
      "step": 2033
    },
    {
      "epoch": 1.3817934782608696,
      "grad_norm": 5.992639064788818,
      "learning_rate": 1.1234696971541534e-05,
      "loss": 0.2036,
      "step": 2034
    },
    {
      "epoch": 1.3824728260869565,
      "grad_norm": 0.07896474748849869,
      "learning_rate": 1.1227636980652826e-05,
      "loss": 0.001,
      "step": 2035
    },
    {
      "epoch": 1.3831521739130435,
      "grad_norm": 0.08339963853359222,
      "learning_rate": 1.1220576368449513e-05,
      "loss": 0.0009,
      "step": 2036
    },
    {
      "epoch": 1.3838315217391304,
      "grad_norm": 4.062647342681885,
      "learning_rate": 1.121351513850502e-05,
      "loss": 0.266,
      "step": 2037
    },
    {
      "epoch": 1.3845108695652173,
      "grad_norm": 3.7880733013153076,
      "learning_rate": 1.1206453294393074e-05,
      "loss": 0.1188,
      "step": 2038
    },
    {
      "epoch": 1.3851902173913042,
      "grad_norm": 7.055561542510986,
      "learning_rate": 1.1199390839687722e-05,
      "loss": 0.313,
      "step": 2039
    },
    {
      "epoch": 1.3858695652173914,
      "grad_norm": 2.500974655151367,
      "learning_rate": 1.1192327777963313e-05,
      "loss": 0.1434,
      "step": 2040
    },
    {
      "epoch": 1.3865489130434783,
      "grad_norm": 2.8585994243621826,
      "learning_rate": 1.1185264112794505e-05,
      "loss": 0.1815,
      "step": 2041
    },
    {
      "epoch": 1.3872282608695652,
      "grad_norm": 5.562738418579102,
      "learning_rate": 1.1178199847756266e-05,
      "loss": 0.2539,
      "step": 2042
    },
    {
      "epoch": 1.387907608695652,
      "grad_norm": 3.147132396697998,
      "learning_rate": 1.1171134986423859e-05,
      "loss": 0.179,
      "step": 2043
    },
    {
      "epoch": 1.3885869565217392,
      "grad_norm": 4.40955924987793,
      "learning_rate": 1.116406953237286e-05,
      "loss": 0.05,
      "step": 2044
    },
    {
      "epoch": 1.3892663043478262,
      "grad_norm": 2.602247476577759,
      "learning_rate": 1.1157003489179132e-05,
      "loss": 0.1529,
      "step": 2045
    },
    {
      "epoch": 1.389945652173913,
      "grad_norm": 3.898470878601074,
      "learning_rate": 1.1149936860418846e-05,
      "loss": 0.1641,
      "step": 2046
    },
    {
      "epoch": 1.390625,
      "grad_norm": 0.13610230386257172,
      "learning_rate": 1.1142869649668467e-05,
      "loss": 0.0016,
      "step": 2047
    },
    {
      "epoch": 1.391304347826087,
      "grad_norm": 4.600898742675781,
      "learning_rate": 1.113580186050475e-05,
      "loss": 0.2376,
      "step": 2048
    },
    {
      "epoch": 1.3919836956521738,
      "grad_norm": 3.3441426753997803,
      "learning_rate": 1.1128733496504751e-05,
      "loss": 0.1209,
      "step": 2049
    },
    {
      "epoch": 1.3926630434782608,
      "grad_norm": 3.1274266242980957,
      "learning_rate": 1.1121664561245808e-05,
      "loss": 0.028,
      "step": 2050
    },
    {
      "epoch": 1.393342391304348,
      "grad_norm": 5.748494625091553,
      "learning_rate": 1.1114595058305555e-05,
      "loss": 0.056,
      "step": 2051
    },
    {
      "epoch": 1.3940217391304348,
      "grad_norm": 10.63448715209961,
      "learning_rate": 1.1107524991261913e-05,
      "loss": 0.6988,
      "step": 2052
    },
    {
      "epoch": 1.3947010869565217,
      "grad_norm": 3.5813729763031006,
      "learning_rate": 1.1100454363693083e-05,
      "loss": 0.2331,
      "step": 2053
    },
    {
      "epoch": 1.3953804347826086,
      "grad_norm": 2.6990156173706055,
      "learning_rate": 1.1093383179177553e-05,
      "loss": 0.0884,
      "step": 2054
    },
    {
      "epoch": 1.3960597826086958,
      "grad_norm": 1.7689064741134644,
      "learning_rate": 1.108631144129409e-05,
      "loss": 0.1696,
      "step": 2055
    },
    {
      "epoch": 1.3967391304347827,
      "grad_norm": 4.054348468780518,
      "learning_rate": 1.1079239153621753e-05,
      "loss": 0.1754,
      "step": 2056
    },
    {
      "epoch": 1.3974184782608696,
      "grad_norm": 2.994654893875122,
      "learning_rate": 1.1072166319739861e-05,
      "loss": 0.1107,
      "step": 2057
    },
    {
      "epoch": 1.3980978260869565,
      "grad_norm": 9.196080207824707,
      "learning_rate": 1.1065092943228024e-05,
      "loss": 0.0743,
      "step": 2058
    },
    {
      "epoch": 1.3987771739130435,
      "grad_norm": 0.26225337386131287,
      "learning_rate": 1.1058019027666119e-05,
      "loss": 0.0023,
      "step": 2059
    },
    {
      "epoch": 1.3994565217391304,
      "grad_norm": 1.6563260555267334,
      "learning_rate": 1.1050944576634298e-05,
      "loss": 0.0203,
      "step": 2060
    },
    {
      "epoch": 1.4001358695652173,
      "grad_norm": 14.253355026245117,
      "learning_rate": 1.1043869593712984e-05,
      "loss": 0.3637,
      "step": 2061
    },
    {
      "epoch": 1.4008152173913042,
      "grad_norm": 7.478396415710449,
      "learning_rate": 1.1036794082482868e-05,
      "loss": 0.2568,
      "step": 2062
    },
    {
      "epoch": 1.4014945652173914,
      "grad_norm": 0.019955433905124664,
      "learning_rate": 1.1029718046524916e-05,
      "loss": 0.0004,
      "step": 2063
    },
    {
      "epoch": 1.4021739130434783,
      "grad_norm": 14.123404502868652,
      "learning_rate": 1.1022641489420342e-05,
      "loss": 0.6148,
      "step": 2064
    },
    {
      "epoch": 1.4028532608695652,
      "grad_norm": 0.8793144822120667,
      "learning_rate": 1.1015564414750646e-05,
      "loss": 0.0124,
      "step": 2065
    },
    {
      "epoch": 1.403532608695652,
      "grad_norm": 4.378455638885498,
      "learning_rate": 1.1008486826097572e-05,
      "loss": 0.0606,
      "step": 2066
    },
    {
      "epoch": 1.4042119565217392,
      "grad_norm": 2.604846239089966,
      "learning_rate": 1.1001408727043135e-05,
      "loss": 0.073,
      "step": 2067
    },
    {
      "epoch": 1.4048913043478262,
      "grad_norm": 3.2960591316223145,
      "learning_rate": 1.0994330121169602e-05,
      "loss": 0.0997,
      "step": 2068
    },
    {
      "epoch": 1.405570652173913,
      "grad_norm": 0.11679086089134216,
      "learning_rate": 1.0987251012059501e-05,
      "loss": 0.0017,
      "step": 2069
    },
    {
      "epoch": 1.40625,
      "grad_norm": 0.08231696486473083,
      "learning_rate": 1.098017140329561e-05,
      "loss": 0.0012,
      "step": 2070
    },
    {
      "epoch": 1.406929347826087,
      "grad_norm": 6.33587646484375,
      "learning_rate": 1.0973091298460958e-05,
      "loss": 0.3018,
      "step": 2071
    },
    {
      "epoch": 1.4076086956521738,
      "grad_norm": 1.4379079341888428,
      "learning_rate": 1.0966010701138841e-05,
      "loss": 0.0607,
      "step": 2072
    },
    {
      "epoch": 1.4082880434782608,
      "grad_norm": 1.7757784128189087,
      "learning_rate": 1.0958929614912782e-05,
      "loss": 0.105,
      "step": 2073
    },
    {
      "epoch": 1.408967391304348,
      "grad_norm": 2.371553897857666,
      "learning_rate": 1.0951848043366571e-05,
      "loss": 0.1386,
      "step": 2074
    },
    {
      "epoch": 1.4096467391304348,
      "grad_norm": 3.2590157985687256,
      "learning_rate": 1.094476599008423e-05,
      "loss": 0.0581,
      "step": 2075
    },
    {
      "epoch": 1.4103260869565217,
      "grad_norm": 3.104410409927368,
      "learning_rate": 1.0937683458650029e-05,
      "loss": 0.1605,
      "step": 2076
    },
    {
      "epoch": 1.4110054347826086,
      "grad_norm": 31.563217163085938,
      "learning_rate": 1.0930600452648476e-05,
      "loss": 0.2315,
      "step": 2077
    },
    {
      "epoch": 1.4116847826086958,
      "grad_norm": 0.2832145690917969,
      "learning_rate": 1.0923516975664336e-05,
      "loss": 0.0031,
      "step": 2078
    },
    {
      "epoch": 1.4123641304347827,
      "grad_norm": 0.9567551016807556,
      "learning_rate": 1.0916433031282592e-05,
      "loss": 0.0366,
      "step": 2079
    },
    {
      "epoch": 1.4130434782608696,
      "grad_norm": 0.14726632833480835,
      "learning_rate": 1.0909348623088472e-05,
      "loss": 0.0015,
      "step": 2080
    },
    {
      "epoch": 1.4137228260869565,
      "grad_norm": 0.016232134774327278,
      "learning_rate": 1.0902263754667438e-05,
      "loss": 0.0004,
      "step": 2081
    },
    {
      "epoch": 1.4144021739130435,
      "grad_norm": 7.413636684417725,
      "learning_rate": 1.0895178429605189e-05,
      "loss": 0.1157,
      "step": 2082
    },
    {
      "epoch": 1.4150815217391304,
      "grad_norm": 2.910933017730713,
      "learning_rate": 1.088809265148765e-05,
      "loss": 0.0681,
      "step": 2083
    },
    {
      "epoch": 1.4157608695652173,
      "grad_norm": 0.04648986831307411,
      "learning_rate": 1.0881006423900975e-05,
      "loss": 0.0007,
      "step": 2084
    },
    {
      "epoch": 1.4164402173913042,
      "grad_norm": 0.026497775688767433,
      "learning_rate": 1.0873919750431548e-05,
      "loss": 0.0005,
      "step": 2085
    },
    {
      "epoch": 1.4171195652173914,
      "grad_norm": 0.0225958414375782,
      "learning_rate": 1.0866832634665977e-05,
      "loss": 0.0005,
      "step": 2086
    },
    {
      "epoch": 1.4177989130434783,
      "grad_norm": 0.4529930055141449,
      "learning_rate": 1.0859745080191098e-05,
      "loss": 0.0038,
      "step": 2087
    },
    {
      "epoch": 1.4184782608695652,
      "grad_norm": 0.03480636328458786,
      "learning_rate": 1.0852657090593961e-05,
      "loss": 0.0006,
      "step": 2088
    },
    {
      "epoch": 1.419157608695652,
      "grad_norm": 4.77266788482666,
      "learning_rate": 1.0845568669461845e-05,
      "loss": 0.1427,
      "step": 2089
    },
    {
      "epoch": 1.4198369565217392,
      "grad_norm": 2.5175528526306152,
      "learning_rate": 1.0838479820382242e-05,
      "loss": 0.0905,
      "step": 2090
    },
    {
      "epoch": 1.4205163043478262,
      "grad_norm": 0.056207336485385895,
      "learning_rate": 1.083139054694286e-05,
      "loss": 0.0009,
      "step": 2091
    },
    {
      "epoch": 1.421195652173913,
      "grad_norm": 0.021093985065817833,
      "learning_rate": 1.0824300852731631e-05,
      "loss": 0.0005,
      "step": 2092
    },
    {
      "epoch": 1.421875,
      "grad_norm": 0.19014400243759155,
      "learning_rate": 1.0817210741336684e-05,
      "loss": 0.0027,
      "step": 2093
    },
    {
      "epoch": 1.422554347826087,
      "grad_norm": 0.3222809135913849,
      "learning_rate": 1.0810120216346368e-05,
      "loss": 0.0043,
      "step": 2094
    },
    {
      "epoch": 1.4232336956521738,
      "grad_norm": 2.8708713054656982,
      "learning_rate": 1.0803029281349248e-05,
      "loss": 0.1355,
      "step": 2095
    },
    {
      "epoch": 1.4239130434782608,
      "grad_norm": 0.7696012854576111,
      "learning_rate": 1.0795937939934088e-05,
      "loss": 0.0086,
      "step": 2096
    },
    {
      "epoch": 1.424592391304348,
      "grad_norm": 9.910703659057617,
      "learning_rate": 1.0788846195689856e-05,
      "loss": 0.5411,
      "step": 2097
    },
    {
      "epoch": 1.4252717391304348,
      "grad_norm": 3.320842742919922,
      "learning_rate": 1.0781754052205729e-05,
      "loss": 0.1664,
      "step": 2098
    },
    {
      "epoch": 1.4259510869565217,
      "grad_norm": 1.9165507555007935,
      "learning_rate": 1.0774661513071084e-05,
      "loss": 0.0922,
      "step": 2099
    },
    {
      "epoch": 1.4266304347826086,
      "grad_norm": 11.209927558898926,
      "learning_rate": 1.0767568581875494e-05,
      "loss": 0.355,
      "step": 2100
    },
    {
      "epoch": 1.4273097826086958,
      "grad_norm": 0.09244435280561447,
      "learning_rate": 1.0760475262208742e-05,
      "loss": 0.0011,
      "step": 2101
    },
    {
      "epoch": 1.4279891304347827,
      "grad_norm": 12.731648445129395,
      "learning_rate": 1.0753381557660801e-05,
      "loss": 0.6512,
      "step": 2102
    },
    {
      "epoch": 1.4286684782608696,
      "grad_norm": 2.666625499725342,
      "learning_rate": 1.0746287471821833e-05,
      "loss": 0.1013,
      "step": 2103
    },
    {
      "epoch": 1.4293478260869565,
      "grad_norm": 0.44913312792778015,
      "learning_rate": 1.0739193008282203e-05,
      "loss": 0.0059,
      "step": 2104
    },
    {
      "epoch": 1.4300271739130435,
      "grad_norm": 3.947977304458618,
      "learning_rate": 1.0732098170632458e-05,
      "loss": 0.1964,
      "step": 2105
    },
    {
      "epoch": 1.4307065217391304,
      "grad_norm": 0.24880638718605042,
      "learning_rate": 1.072500296246334e-05,
      "loss": 0.0038,
      "step": 2106
    },
    {
      "epoch": 1.4313858695652173,
      "grad_norm": 1.3253915309906006,
      "learning_rate": 1.0717907387365779e-05,
      "loss": 0.0138,
      "step": 2107
    },
    {
      "epoch": 1.4320652173913042,
      "grad_norm": 6.139410495758057,
      "learning_rate": 1.0710811448930888e-05,
      "loss": 0.0588,
      "step": 2108
    },
    {
      "epoch": 1.4327445652173914,
      "grad_norm": 6.204453945159912,
      "learning_rate": 1.0703715150749967e-05,
      "loss": 0.1799,
      "step": 2109
    },
    {
      "epoch": 1.4334239130434783,
      "grad_norm": 0.21068282425403595,
      "learning_rate": 1.0696618496414495e-05,
      "loss": 0.0028,
      "step": 2110
    },
    {
      "epoch": 1.4341032608695652,
      "grad_norm": 2.197767496109009,
      "learning_rate": 1.0689521489516128e-05,
      "loss": 0.087,
      "step": 2111
    },
    {
      "epoch": 1.434782608695652,
      "grad_norm": 3.5086328983306885,
      "learning_rate": 1.0682424133646712e-05,
      "loss": 0.0904,
      "step": 2112
    },
    {
      "epoch": 1.4354619565217392,
      "grad_norm": 2.802293300628662,
      "learning_rate": 1.0675326432398257e-05,
      "loss": 0.0502,
      "step": 2113
    },
    {
      "epoch": 1.4361413043478262,
      "grad_norm": 5.530993461608887,
      "learning_rate": 1.0668228389362955e-05,
      "loss": 0.1238,
      "step": 2114
    },
    {
      "epoch": 1.436820652173913,
      "grad_norm": 4.639883518218994,
      "learning_rate": 1.0661130008133169e-05,
      "loss": 0.1359,
      "step": 2115
    },
    {
      "epoch": 1.4375,
      "grad_norm": 9.895322799682617,
      "learning_rate": 1.0654031292301432e-05,
      "loss": 0.2332,
      "step": 2116
    },
    {
      "epoch": 1.438179347826087,
      "grad_norm": 13.238862037658691,
      "learning_rate": 1.0646932245460448e-05,
      "loss": 0.2138,
      "step": 2117
    },
    {
      "epoch": 1.4388586956521738,
      "grad_norm": 2.6516685485839844,
      "learning_rate": 1.0639832871203094e-05,
      "loss": 0.1049,
      "step": 2118
    },
    {
      "epoch": 1.4395380434782608,
      "grad_norm": 0.1171085461974144,
      "learning_rate": 1.0632733173122395e-05,
      "loss": 0.0016,
      "step": 2119
    },
    {
      "epoch": 1.440217391304348,
      "grad_norm": 3.964350938796997,
      "learning_rate": 1.062563315481156e-05,
      "loss": 0.2054,
      "step": 2120
    },
    {
      "epoch": 1.4408967391304348,
      "grad_norm": 6.350618839263916,
      "learning_rate": 1.0618532819863953e-05,
      "loss": 0.284,
      "step": 2121
    },
    {
      "epoch": 1.4415760869565217,
      "grad_norm": 1.2869391441345215,
      "learning_rate": 1.0611432171873092e-05,
      "loss": 0.0106,
      "step": 2122
    },
    {
      "epoch": 1.4422554347826086,
      "grad_norm": 2.5472545623779297,
      "learning_rate": 1.0604331214432663e-05,
      "loss": 0.1852,
      "step": 2123
    },
    {
      "epoch": 1.4429347826086958,
      "grad_norm": 5.704638481140137,
      "learning_rate": 1.0597229951136498e-05,
      "loss": 0.2406,
      "step": 2124
    },
    {
      "epoch": 1.4436141304347827,
      "grad_norm": 12.634714126586914,
      "learning_rate": 1.0590128385578597e-05,
      "loss": 0.1144,
      "step": 2125
    },
    {
      "epoch": 1.4442934782608696,
      "grad_norm": 9.616191864013672,
      "learning_rate": 1.0583026521353102e-05,
      "loss": 0.4324,
      "step": 2126
    },
    {
      "epoch": 1.4449728260869565,
      "grad_norm": 6.733067035675049,
      "learning_rate": 1.057592436205431e-05,
      "loss": 0.2042,
      "step": 2127
    },
    {
      "epoch": 1.4456521739130435,
      "grad_norm": 2.410398483276367,
      "learning_rate": 1.056882191127667e-05,
      "loss": 0.1109,
      "step": 2128
    },
    {
      "epoch": 1.4463315217391304,
      "grad_norm": 3.2822482585906982,
      "learning_rate": 1.0561719172614769e-05,
      "loss": 0.2178,
      "step": 2129
    },
    {
      "epoch": 1.4470108695652173,
      "grad_norm": 3.4991941452026367,
      "learning_rate": 1.0554616149663355e-05,
      "loss": 0.0951,
      "step": 2130
    },
    {
      "epoch": 1.4476902173913042,
      "grad_norm": 12.811232566833496,
      "learning_rate": 1.0547512846017307e-05,
      "loss": 0.287,
      "step": 2131
    },
    {
      "epoch": 1.4483695652173914,
      "grad_norm": 2.3056349754333496,
      "learning_rate": 1.0540409265271652e-05,
      "loss": 0.1032,
      "step": 2132
    },
    {
      "epoch": 1.4490489130434783,
      "grad_norm": 0.2154264897108078,
      "learning_rate": 1.0533305411021555e-05,
      "loss": 0.0027,
      "step": 2133
    },
    {
      "epoch": 1.4497282608695652,
      "grad_norm": 2.348720073699951,
      "learning_rate": 1.052620128686232e-05,
      "loss": 0.0793,
      "step": 2134
    },
    {
      "epoch": 1.450407608695652,
      "grad_norm": 2.5107319355010986,
      "learning_rate": 1.0519096896389387e-05,
      "loss": 0.0553,
      "step": 2135
    },
    {
      "epoch": 1.4510869565217392,
      "grad_norm": 0.16186921298503876,
      "learning_rate": 1.0511992243198335e-05,
      "loss": 0.0018,
      "step": 2136
    },
    {
      "epoch": 1.4517663043478262,
      "grad_norm": 0.04140688478946686,
      "learning_rate": 1.0504887330884865e-05,
      "loss": 0.0006,
      "step": 2137
    },
    {
      "epoch": 1.452445652173913,
      "grad_norm": 1.4446247816085815,
      "learning_rate": 1.0497782163044825e-05,
      "loss": 0.0951,
      "step": 2138
    },
    {
      "epoch": 1.453125,
      "grad_norm": 4.30432653427124,
      "learning_rate": 1.0490676743274181e-05,
      "loss": 0.2593,
      "step": 2139
    },
    {
      "epoch": 1.453804347826087,
      "grad_norm": 2.888097047805786,
      "learning_rate": 1.048357107516903e-05,
      "loss": 0.1297,
      "step": 2140
    },
    {
      "epoch": 1.4544836956521738,
      "grad_norm": 2.6279137134552,
      "learning_rate": 1.0476465162325595e-05,
      "loss": 0.0327,
      "step": 2141
    },
    {
      "epoch": 1.4551630434782608,
      "grad_norm": 0.183952197432518,
      "learning_rate": 1.0469359008340216e-05,
      "loss": 0.0035,
      "step": 2142
    },
    {
      "epoch": 1.455842391304348,
      "grad_norm": 0.28837576508522034,
      "learning_rate": 1.0462252616809367e-05,
      "loss": 0.0039,
      "step": 2143
    },
    {
      "epoch": 1.4565217391304348,
      "grad_norm": 1.0650012493133545,
      "learning_rate": 1.0455145991329639e-05,
      "loss": 0.0091,
      "step": 2144
    },
    {
      "epoch": 1.4572010869565217,
      "grad_norm": 5.970633506774902,
      "learning_rate": 1.0448039135497732e-05,
      "loss": 0.0841,
      "step": 2145
    },
    {
      "epoch": 1.4578804347826086,
      "grad_norm": 0.04568525776267052,
      "learning_rate": 1.0440932052910468e-05,
      "loss": 0.0009,
      "step": 2146
    },
    {
      "epoch": 1.4585597826086958,
      "grad_norm": 2.717022657394409,
      "learning_rate": 1.0433824747164794e-05,
      "loss": 0.0516,
      "step": 2147
    },
    {
      "epoch": 1.4592391304347827,
      "grad_norm": 1.3098145723342896,
      "learning_rate": 1.0426717221857756e-05,
      "loss": 0.0103,
      "step": 2148
    },
    {
      "epoch": 1.4599184782608696,
      "grad_norm": 2.1780569553375244,
      "learning_rate": 1.0419609480586515e-05,
      "loss": 0.1876,
      "step": 2149
    },
    {
      "epoch": 1.4605978260869565,
      "grad_norm": 2.6342523097991943,
      "learning_rate": 1.0412501526948343e-05,
      "loss": 0.1359,
      "step": 2150
    },
    {
      "epoch": 1.4612771739130435,
      "grad_norm": 0.08889765292406082,
      "learning_rate": 1.0405393364540618e-05,
      "loss": 0.0017,
      "step": 2151
    },
    {
      "epoch": 1.4619565217391304,
      "grad_norm": 3.148512840270996,
      "learning_rate": 1.039828499696083e-05,
      "loss": 0.0927,
      "step": 2152
    },
    {
      "epoch": 1.4626358695652173,
      "grad_norm": 4.971157073974609,
      "learning_rate": 1.0391176427806564e-05,
      "loss": 0.0463,
      "step": 2153
    },
    {
      "epoch": 1.4633152173913042,
      "grad_norm": 3.266704797744751,
      "learning_rate": 1.0384067660675508e-05,
      "loss": 0.1323,
      "step": 2154
    },
    {
      "epoch": 1.4639945652173914,
      "grad_norm": 2.7726802825927734,
      "learning_rate": 1.0376958699165451e-05,
      "loss": 0.1094,
      "step": 2155
    },
    {
      "epoch": 1.4646739130434783,
      "grad_norm": 1.4332709312438965,
      "learning_rate": 1.036984954687429e-05,
      "loss": 0.014,
      "step": 2156
    },
    {
      "epoch": 1.4653532608695652,
      "grad_norm": 2.791297435760498,
      "learning_rate": 1.0362740207400006e-05,
      "loss": 0.0746,
      "step": 2157
    },
    {
      "epoch": 1.466032608695652,
      "grad_norm": 1.744593858718872,
      "learning_rate": 1.0355630684340678e-05,
      "loss": 0.0209,
      "step": 2158
    },
    {
      "epoch": 1.4667119565217392,
      "grad_norm": 4.147309303283691,
      "learning_rate": 1.034852098129448e-05,
      "loss": 0.081,
      "step": 2159
    },
    {
      "epoch": 1.4673913043478262,
      "grad_norm": 5.240901947021484,
      "learning_rate": 1.034141110185968e-05,
      "loss": 0.2384,
      "step": 2160
    },
    {
      "epoch": 1.468070652173913,
      "grad_norm": 0.02239140309393406,
      "learning_rate": 1.0334301049634624e-05,
      "loss": 0.0005,
      "step": 2161
    },
    {
      "epoch": 1.46875,
      "grad_norm": 0.019234798848628998,
      "learning_rate": 1.0327190828217763e-05,
      "loss": 0.0004,
      "step": 2162
    },
    {
      "epoch": 1.469429347826087,
      "grad_norm": 10.320466995239258,
      "learning_rate": 1.0320080441207616e-05,
      "loss": 0.3178,
      "step": 2163
    },
    {
      "epoch": 1.4701086956521738,
      "grad_norm": 3.614177703857422,
      "learning_rate": 1.0312969892202793e-05,
      "loss": 0.0468,
      "step": 2164
    },
    {
      "epoch": 1.4707880434782608,
      "grad_norm": 0.02880219928920269,
      "learning_rate": 1.0305859184801991e-05,
      "loss": 0.0005,
      "step": 2165
    },
    {
      "epoch": 1.471467391304348,
      "grad_norm": 4.107649803161621,
      "learning_rate": 1.0298748322603982e-05,
      "loss": 0.2399,
      "step": 2166
    },
    {
      "epoch": 1.4721467391304348,
      "grad_norm": 0.6770954728126526,
      "learning_rate": 1.0291637309207613e-05,
      "loss": 0.0102,
      "step": 2167
    },
    {
      "epoch": 1.4728260869565217,
      "grad_norm": 4.33624792098999,
      "learning_rate": 1.0284526148211815e-05,
      "loss": 0.0965,
      "step": 2168
    },
    {
      "epoch": 1.4735054347826086,
      "grad_norm": 4.460662364959717,
      "learning_rate": 1.027741484321559e-05,
      "loss": 0.1508,
      "step": 2169
    },
    {
      "epoch": 1.4741847826086958,
      "grad_norm": 3.5182178020477295,
      "learning_rate": 1.0270303397818011e-05,
      "loss": 0.0905,
      "step": 2170
    },
    {
      "epoch": 1.4748641304347827,
      "grad_norm": 0.01906413584947586,
      "learning_rate": 1.0263191815618227e-05,
      "loss": 0.0004,
      "step": 2171
    },
    {
      "epoch": 1.4755434782608696,
      "grad_norm": 0.05005194619297981,
      "learning_rate": 1.0256080100215448e-05,
      "loss": 0.0009,
      "step": 2172
    },
    {
      "epoch": 1.4762228260869565,
      "grad_norm": 4.103007793426514,
      "learning_rate": 1.0248968255208964e-05,
      "loss": 0.1336,
      "step": 2173
    },
    {
      "epoch": 1.4769021739130435,
      "grad_norm": 0.46532875299453735,
      "learning_rate": 1.024185628419812e-05,
      "loss": 0.0041,
      "step": 2174
    },
    {
      "epoch": 1.4775815217391304,
      "grad_norm": 0.5919230580329895,
      "learning_rate": 1.0234744190782326e-05,
      "loss": 0.0065,
      "step": 2175
    },
    {
      "epoch": 1.4782608695652173,
      "grad_norm": 0.26971739530563354,
      "learning_rate": 1.0227631978561057e-05,
      "loss": 0.0028,
      "step": 2176
    },
    {
      "epoch": 1.4789402173913042,
      "grad_norm": 2.4281883239746094,
      "learning_rate": 1.022051965113385e-05,
      "loss": 0.0871,
      "step": 2177
    },
    {
      "epoch": 1.4796195652173914,
      "grad_norm": 0.8654101490974426,
      "learning_rate": 1.0213407212100296e-05,
      "loss": 0.0087,
      "step": 2178
    },
    {
      "epoch": 1.4802989130434783,
      "grad_norm": 14.329415321350098,
      "learning_rate": 1.0206294665060046e-05,
      "loss": 0.5565,
      "step": 2179
    },
    {
      "epoch": 1.4809782608695652,
      "grad_norm": 0.09764042496681213,
      "learning_rate": 1.0199182013612797e-05,
      "loss": 0.0014,
      "step": 2180
    },
    {
      "epoch": 1.481657608695652,
      "grad_norm": 1.5062918663024902,
      "learning_rate": 1.0192069261358313e-05,
      "loss": 0.0164,
      "step": 2181
    },
    {
      "epoch": 1.4823369565217392,
      "grad_norm": 12.285381317138672,
      "learning_rate": 1.0184956411896396e-05,
      "loss": 0.4551,
      "step": 2182
    },
    {
      "epoch": 1.4830163043478262,
      "grad_norm": 3.0810697078704834,
      "learning_rate": 1.0177843468826909e-05,
      "loss": 0.107,
      "step": 2183
    },
    {
      "epoch": 1.483695652173913,
      "grad_norm": 5.211459159851074,
      "learning_rate": 1.017073043574975e-05,
      "loss": 0.2355,
      "step": 2184
    },
    {
      "epoch": 1.484375,
      "grad_norm": 10.715845108032227,
      "learning_rate": 1.0163617316264869e-05,
      "loss": 0.3336,
      "step": 2185
    },
    {
      "epoch": 1.485054347826087,
      "grad_norm": 1.1531627178192139,
      "learning_rate": 1.0156504113972263e-05,
      "loss": 0.0137,
      "step": 2186
    },
    {
      "epoch": 1.4857336956521738,
      "grad_norm": 3.8558130264282227,
      "learning_rate": 1.0149390832471965e-05,
      "loss": 0.1022,
      "step": 2187
    },
    {
      "epoch": 1.4864130434782608,
      "grad_norm": 3.4207794666290283,
      "learning_rate": 1.0142277475364053e-05,
      "loss": 0.2122,
      "step": 2188
    },
    {
      "epoch": 1.487092391304348,
      "grad_norm": 0.8216492533683777,
      "learning_rate": 1.0135164046248633e-05,
      "loss": 0.0062,
      "step": 2189
    },
    {
      "epoch": 1.4877717391304348,
      "grad_norm": 8.603221893310547,
      "learning_rate": 1.0128050548725865e-05,
      "loss": 0.1736,
      "step": 2190
    },
    {
      "epoch": 1.4884510869565217,
      "grad_norm": 2.7304446697235107,
      "learning_rate": 1.012093698639593e-05,
      "loss": 0.0459,
      "step": 2191
    },
    {
      "epoch": 1.4891304347826086,
      "grad_norm": 2.244818925857544,
      "learning_rate": 1.0113823362859042e-05,
      "loss": 0.0588,
      "step": 2192
    },
    {
      "epoch": 1.4898097826086958,
      "grad_norm": 10.315980911254883,
      "learning_rate": 1.0106709681715456e-05,
      "loss": 0.2295,
      "step": 2193
    },
    {
      "epoch": 1.4904891304347827,
      "grad_norm": 0.08178850263357162,
      "learning_rate": 1.0099595946565446e-05,
      "loss": 0.0011,
      "step": 2194
    },
    {
      "epoch": 1.4911684782608696,
      "grad_norm": 4.992526531219482,
      "learning_rate": 1.0092482161009314e-05,
      "loss": 0.0845,
      "step": 2195
    },
    {
      "epoch": 1.4918478260869565,
      "grad_norm": 19.718826293945312,
      "learning_rate": 1.0085368328647395e-05,
      "loss": 0.8892,
      "step": 2196
    },
    {
      "epoch": 1.4925271739130435,
      "grad_norm": 0.43765726685523987,
      "learning_rate": 1.0078254453080042e-05,
      "loss": 0.0042,
      "step": 2197
    },
    {
      "epoch": 1.4932065217391304,
      "grad_norm": 0.19142988324165344,
      "learning_rate": 1.0071140537907626e-05,
      "loss": 0.0025,
      "step": 2198
    },
    {
      "epoch": 1.4938858695652173,
      "grad_norm": 0.16437360644340515,
      "learning_rate": 1.0064026586730553e-05,
      "loss": 0.0017,
      "step": 2199
    },
    {
      "epoch": 1.4945652173913042,
      "grad_norm": 3.3308377265930176,
      "learning_rate": 1.0056912603149229e-05,
      "loss": 0.0901,
      "step": 2200
    },
    {
      "epoch": 1.4952445652173914,
      "grad_norm": 4.486888885498047,
      "learning_rate": 1.004979859076409e-05,
      "loss": 0.129,
      "step": 2201
    },
    {
      "epoch": 1.4959239130434783,
      "grad_norm": 4.22749137878418,
      "learning_rate": 1.0042684553175575e-05,
      "loss": 0.1871,
      "step": 2202
    },
    {
      "epoch": 1.4966032608695652,
      "grad_norm": 3.976022481918335,
      "learning_rate": 1.003557049398415e-05,
      "loss": 0.0878,
      "step": 2203
    },
    {
      "epoch": 1.497282608695652,
      "grad_norm": 3.1078710556030273,
      "learning_rate": 1.0028456416790278e-05,
      "loss": 0.188,
      "step": 2204
    },
    {
      "epoch": 1.4979619565217392,
      "grad_norm": 1.909680724143982,
      "learning_rate": 1.0021342325194441e-05,
      "loss": 0.0759,
      "step": 2205
    },
    {
      "epoch": 1.4986413043478262,
      "grad_norm": 10.558963775634766,
      "learning_rate": 1.0014228222797117e-05,
      "loss": 0.2617,
      "step": 2206
    },
    {
      "epoch": 1.499320652173913,
      "grad_norm": 3.2037723064422607,
      "learning_rate": 1.0007114113198809e-05,
      "loss": 0.0393,
      "step": 2207
    },
    {
      "epoch": 1.5,
      "grad_norm": 6.913980007171631,
      "learning_rate": 1e-05,
      "loss": 0.3067,
      "step": 2208
    },
    {
      "epoch": 1.500679347826087,
      "grad_norm": 0.728843629360199,
      "learning_rate": 9.992885886801194e-06,
      "loss": 0.0056,
      "step": 2209
    },
    {
      "epoch": 1.5013586956521738,
      "grad_norm": 0.04814666509628296,
      "learning_rate": 9.985771777202884e-06,
      "loss": 0.0005,
      "step": 2210
    },
    {
      "epoch": 1.5020380434782608,
      "grad_norm": 5.671650409698486,
      "learning_rate": 9.978657674805564e-06,
      "loss": 0.0741,
      "step": 2211
    },
    {
      "epoch": 1.5027173913043477,
      "grad_norm": 6.82209587097168,
      "learning_rate": 9.971543583209727e-06,
      "loss": 0.1805,
      "step": 2212
    },
    {
      "epoch": 1.5033967391304348,
      "grad_norm": 0.4256531298160553,
      "learning_rate": 9.964429506015851e-06,
      "loss": 0.0033,
      "step": 2213
    },
    {
      "epoch": 1.5040760869565217,
      "grad_norm": 3.290666341781616,
      "learning_rate": 9.957315446824425e-06,
      "loss": 0.094,
      "step": 2214
    },
    {
      "epoch": 1.5047554347826086,
      "grad_norm": 5.449222564697266,
      "learning_rate": 9.950201409235913e-06,
      "loss": 0.0696,
      "step": 2215
    },
    {
      "epoch": 1.5054347826086958,
      "grad_norm": 7.728121757507324,
      "learning_rate": 9.943087396850773e-06,
      "loss": 0.4537,
      "step": 2216
    },
    {
      "epoch": 1.5061141304347827,
      "grad_norm": 5.092411518096924,
      "learning_rate": 9.93597341326945e-06,
      "loss": 0.1912,
      "step": 2217
    },
    {
      "epoch": 1.5067934782608696,
      "grad_norm": 3.521920680999756,
      "learning_rate": 9.928859462092375e-06,
      "loss": 0.032,
      "step": 2218
    },
    {
      "epoch": 1.5074728260869565,
      "grad_norm": 2.711366653442383,
      "learning_rate": 9.921745546919963e-06,
      "loss": 0.1252,
      "step": 2219
    },
    {
      "epoch": 1.5081521739130435,
      "grad_norm": 3.49800181388855,
      "learning_rate": 9.91463167135261e-06,
      "loss": 0.1652,
      "step": 2220
    },
    {
      "epoch": 1.5088315217391304,
      "grad_norm": 11.036458015441895,
      "learning_rate": 9.907517838990689e-06,
      "loss": 0.4604,
      "step": 2221
    },
    {
      "epoch": 1.5095108695652173,
      "grad_norm": 0.024188026785850525,
      "learning_rate": 9.900404053434559e-06,
      "loss": 0.0004,
      "step": 2222
    },
    {
      "epoch": 1.5101902173913042,
      "grad_norm": 4.691273212432861,
      "learning_rate": 9.893290318284546e-06,
      "loss": 0.1741,
      "step": 2223
    },
    {
      "epoch": 1.5108695652173914,
      "grad_norm": 8.292896270751953,
      "learning_rate": 9.886176637140959e-06,
      "loss": 0.2476,
      "step": 2224
    },
    {
      "epoch": 1.5115489130434783,
      "grad_norm": 3.528550863265991,
      "learning_rate": 9.879063013604073e-06,
      "loss": 0.0829,
      "step": 2225
    },
    {
      "epoch": 1.5122282608695652,
      "grad_norm": 3.6158485412597656,
      "learning_rate": 9.871949451274137e-06,
      "loss": 0.1904,
      "step": 2226
    },
    {
      "epoch": 1.5129076086956523,
      "grad_norm": 2.3092892169952393,
      "learning_rate": 9.86483595375137e-06,
      "loss": 0.1264,
      "step": 2227
    },
    {
      "epoch": 1.5135869565217392,
      "grad_norm": 3.592700242996216,
      "learning_rate": 9.857722524635954e-06,
      "loss": 0.0808,
      "step": 2228
    },
    {
      "epoch": 1.5142663043478262,
      "grad_norm": 13.02305793762207,
      "learning_rate": 9.850609167528038e-06,
      "loss": 0.4863,
      "step": 2229
    },
    {
      "epoch": 1.514945652173913,
      "grad_norm": 2.884906768798828,
      "learning_rate": 9.843495886027738e-06,
      "loss": 0.1387,
      "step": 2230
    },
    {
      "epoch": 1.515625,
      "grad_norm": 2.336591958999634,
      "learning_rate": 9.836382683735133e-06,
      "loss": 0.124,
      "step": 2231
    },
    {
      "epoch": 1.516304347826087,
      "grad_norm": 0.3368391692638397,
      "learning_rate": 9.829269564250254e-06,
      "loss": 0.0035,
      "step": 2232
    },
    {
      "epoch": 1.5169836956521738,
      "grad_norm": 5.185005187988281,
      "learning_rate": 9.822156531173094e-06,
      "loss": 0.0524,
      "step": 2233
    },
    {
      "epoch": 1.5176630434782608,
      "grad_norm": 0.11052193492650986,
      "learning_rate": 9.815043588103606e-06,
      "loss": 0.0012,
      "step": 2234
    },
    {
      "epoch": 1.5183423913043477,
      "grad_norm": 1.7456868886947632,
      "learning_rate": 9.807930738641692e-06,
      "loss": 0.1837,
      "step": 2235
    },
    {
      "epoch": 1.5190217391304348,
      "grad_norm": 10.17674446105957,
      "learning_rate": 9.800817986387207e-06,
      "loss": 0.5156,
      "step": 2236
    },
    {
      "epoch": 1.5197010869565217,
      "grad_norm": 1.9965229034423828,
      "learning_rate": 9.79370533493996e-06,
      "loss": 0.1267,
      "step": 2237
    },
    {
      "epoch": 1.5203804347826086,
      "grad_norm": 4.159749984741211,
      "learning_rate": 9.786592787899707e-06,
      "loss": 0.1956,
      "step": 2238
    },
    {
      "epoch": 1.5210597826086958,
      "grad_norm": 4.255317687988281,
      "learning_rate": 9.77948034886615e-06,
      "loss": 0.2249,
      "step": 2239
    },
    {
      "epoch": 1.5217391304347827,
      "grad_norm": 2.241577386856079,
      "learning_rate": 9.772368021438943e-06,
      "loss": 0.0303,
      "step": 2240
    },
    {
      "epoch": 1.5224184782608696,
      "grad_norm": 0.05524953827261925,
      "learning_rate": 9.765255809217676e-06,
      "loss": 0.0007,
      "step": 2241
    },
    {
      "epoch": 1.5230978260869565,
      "grad_norm": 1.2960951328277588,
      "learning_rate": 9.758143715801884e-06,
      "loss": 0.0117,
      "step": 2242
    },
    {
      "epoch": 1.5237771739130435,
      "grad_norm": 3.4515159130096436,
      "learning_rate": 9.75103174479104e-06,
      "loss": 0.0279,
      "step": 2243
    },
    {
      "epoch": 1.5244565217391304,
      "grad_norm": 3.3597910404205322,
      "learning_rate": 9.743919899784555e-06,
      "loss": 0.1355,
      "step": 2244
    },
    {
      "epoch": 1.5251358695652173,
      "grad_norm": 9.074906349182129,
      "learning_rate": 9.736808184381778e-06,
      "loss": 0.2875,
      "step": 2245
    },
    {
      "epoch": 1.5258152173913042,
      "grad_norm": 0.05161551013588905,
      "learning_rate": 9.729696602181994e-06,
      "loss": 0.0007,
      "step": 2246
    },
    {
      "epoch": 1.5264945652173914,
      "grad_norm": 0.02237970009446144,
      "learning_rate": 9.72258515678441e-06,
      "loss": 0.0004,
      "step": 2247
    },
    {
      "epoch": 1.5271739130434783,
      "grad_norm": 0.044476594775915146,
      "learning_rate": 9.715473851788187e-06,
      "loss": 0.0007,
      "step": 2248
    },
    {
      "epoch": 1.5278532608695652,
      "grad_norm": 3.3741455078125,
      "learning_rate": 9.708362690792388e-06,
      "loss": 0.0465,
      "step": 2249
    },
    {
      "epoch": 1.5285326086956523,
      "grad_norm": 1.8767123222351074,
      "learning_rate": 9.701251677396021e-06,
      "loss": 0.021,
      "step": 2250
    },
    {
      "epoch": 1.5292119565217392,
      "grad_norm": 0.3306237459182739,
      "learning_rate": 9.69414081519801e-06,
      "loss": 0.0035,
      "step": 2251
    },
    {
      "epoch": 1.5298913043478262,
      "grad_norm": 0.755272388458252,
      "learning_rate": 9.687030107797209e-06,
      "loss": 0.008,
      "step": 2252
    },
    {
      "epoch": 1.530570652173913,
      "grad_norm": 5.7396321296691895,
      "learning_rate": 9.679919558792388e-06,
      "loss": 0.0225,
      "step": 2253
    },
    {
      "epoch": 1.53125,
      "grad_norm": 3.3004493713378906,
      "learning_rate": 9.67280917178224e-06,
      "loss": 0.0363,
      "step": 2254
    },
    {
      "epoch": 1.531929347826087,
      "grad_norm": 2.790849447250366,
      "learning_rate": 9.665698950365377e-06,
      "loss": 0.1908,
      "step": 2255
    },
    {
      "epoch": 1.5326086956521738,
      "grad_norm": 4.62697696685791,
      "learning_rate": 9.658588898140322e-06,
      "loss": 0.2665,
      "step": 2256
    },
    {
      "epoch": 1.5332880434782608,
      "grad_norm": 0.03390304744243622,
      "learning_rate": 9.65147901870552e-06,
      "loss": 0.0006,
      "step": 2257
    },
    {
      "epoch": 1.5339673913043477,
      "grad_norm": 6.6546759605407715,
      "learning_rate": 9.644369315659324e-06,
      "loss": 0.0888,
      "step": 2258
    },
    {
      "epoch": 1.5346467391304348,
      "grad_norm": 2.8702359199523926,
      "learning_rate": 9.637259792599997e-06,
      "loss": 0.1234,
      "step": 2259
    },
    {
      "epoch": 1.5353260869565217,
      "grad_norm": 4.021724224090576,
      "learning_rate": 9.630150453125711e-06,
      "loss": 0.0652,
      "step": 2260
    },
    {
      "epoch": 1.5360054347826086,
      "grad_norm": 3.7087442874908447,
      "learning_rate": 9.62304130083455e-06,
      "loss": 0.191,
      "step": 2261
    },
    {
      "epoch": 1.5366847826086958,
      "grad_norm": 1.9425785541534424,
      "learning_rate": 9.615932339324497e-06,
      "loss": 0.0545,
      "step": 2262
    },
    {
      "epoch": 1.5373641304347827,
      "grad_norm": 2.981039047241211,
      "learning_rate": 9.608823572193443e-06,
      "loss": 0.1009,
      "step": 2263
    },
    {
      "epoch": 1.5380434782608696,
      "grad_norm": 0.02427878975868225,
      "learning_rate": 9.601715003039174e-06,
      "loss": 0.0005,
      "step": 2264
    },
    {
      "epoch": 1.5387228260869565,
      "grad_norm": 3.107161521911621,
      "learning_rate": 9.59460663545938e-06,
      "loss": 0.1417,
      "step": 2265
    },
    {
      "epoch": 1.5394021739130435,
      "grad_norm": 0.8568967580795288,
      "learning_rate": 9.587498473051659e-06,
      "loss": 0.0075,
      "step": 2266
    },
    {
      "epoch": 1.5400815217391304,
      "grad_norm": 2.378516435623169,
      "learning_rate": 9.580390519413487e-06,
      "loss": 0.0865,
      "step": 2267
    },
    {
      "epoch": 1.5407608695652173,
      "grad_norm": 3.3285350799560547,
      "learning_rate": 9.573282778142246e-06,
      "loss": 0.1394,
      "step": 2268
    },
    {
      "epoch": 1.5414402173913042,
      "grad_norm": 0.7035377621650696,
      "learning_rate": 9.566175252835208e-06,
      "loss": 0.0071,
      "step": 2269
    },
    {
      "epoch": 1.5421195652173914,
      "grad_norm": 5.796802043914795,
      "learning_rate": 9.559067947089533e-06,
      "loss": 0.1279,
      "step": 2270
    },
    {
      "epoch": 1.5427989130434783,
      "grad_norm": 17.936721801757812,
      "learning_rate": 9.551960864502275e-06,
      "loss": 0.7295,
      "step": 2271
    },
    {
      "epoch": 1.5434782608695652,
      "grad_norm": 0.07377783954143524,
      "learning_rate": 9.544854008670366e-06,
      "loss": 0.0008,
      "step": 2272
    },
    {
      "epoch": 1.5441576086956523,
      "grad_norm": 12.199459075927734,
      "learning_rate": 9.537747383190631e-06,
      "loss": 0.2943,
      "step": 2273
    },
    {
      "epoch": 1.5448369565217392,
      "grad_norm": 3.4285178184509277,
      "learning_rate": 9.530640991659785e-06,
      "loss": 0.1055,
      "step": 2274
    },
    {
      "epoch": 1.5455163043478262,
      "grad_norm": 0.05319395288825035,
      "learning_rate": 9.523534837674408e-06,
      "loss": 0.0011,
      "step": 2275
    },
    {
      "epoch": 1.546195652173913,
      "grad_norm": 0.08007537573575974,
      "learning_rate": 9.516428924830971e-06,
      "loss": 0.001,
      "step": 2276
    },
    {
      "epoch": 1.546875,
      "grad_norm": 0.08749233931303024,
      "learning_rate": 9.50932325672582e-06,
      "loss": 0.0011,
      "step": 2277
    },
    {
      "epoch": 1.547554347826087,
      "grad_norm": 10.30943775177002,
      "learning_rate": 9.502217836955178e-06,
      "loss": 0.5146,
      "step": 2278
    },
    {
      "epoch": 1.5482336956521738,
      "grad_norm": 3.271312952041626,
      "learning_rate": 9.495112669115138e-06,
      "loss": 0.129,
      "step": 2279
    },
    {
      "epoch": 1.5489130434782608,
      "grad_norm": 17.61800193786621,
      "learning_rate": 9.488007756801672e-06,
      "loss": 0.2091,
      "step": 2280
    },
    {
      "epoch": 1.5495923913043477,
      "grad_norm": 0.17137907445430756,
      "learning_rate": 9.480903103610618e-06,
      "loss": 0.0021,
      "step": 2281
    },
    {
      "epoch": 1.5502717391304348,
      "grad_norm": 0.016178380697965622,
      "learning_rate": 9.473798713137684e-06,
      "loss": 0.0004,
      "step": 2282
    },
    {
      "epoch": 1.5509510869565217,
      "grad_norm": 6.468190670013428,
      "learning_rate": 9.466694588978448e-06,
      "loss": 0.231,
      "step": 2283
    },
    {
      "epoch": 1.5516304347826086,
      "grad_norm": 4.597667217254639,
      "learning_rate": 9.459590734728351e-06,
      "loss": 0.0571,
      "step": 2284
    },
    {
      "epoch": 1.5523097826086958,
      "grad_norm": 3.455972671508789,
      "learning_rate": 9.452487153982696e-06,
      "loss": 0.1392,
      "step": 2285
    },
    {
      "epoch": 1.5529891304347827,
      "grad_norm": 6.997279644012451,
      "learning_rate": 9.445383850336648e-06,
      "loss": 0.132,
      "step": 2286
    },
    {
      "epoch": 1.5536684782608696,
      "grad_norm": 4.159919261932373,
      "learning_rate": 9.438280827385233e-06,
      "loss": 0.1623,
      "step": 2287
    },
    {
      "epoch": 1.5543478260869565,
      "grad_norm": 0.018409650772809982,
      "learning_rate": 9.431178088723334e-06,
      "loss": 0.0005,
      "step": 2288
    },
    {
      "epoch": 1.5550271739130435,
      "grad_norm": 0.21369153261184692,
      "learning_rate": 9.424075637945692e-06,
      "loss": 0.0025,
      "step": 2289
    },
    {
      "epoch": 1.5557065217391304,
      "grad_norm": 5.406676292419434,
      "learning_rate": 9.416973478646898e-06,
      "loss": 0.1355,
      "step": 2290
    },
    {
      "epoch": 1.5563858695652173,
      "grad_norm": 4.1590423583984375,
      "learning_rate": 9.409871614421403e-06,
      "loss": 0.1119,
      "step": 2291
    },
    {
      "epoch": 1.5570652173913042,
      "grad_norm": 0.8863895535469055,
      "learning_rate": 9.402770048863502e-06,
      "loss": 0.0083,
      "step": 2292
    },
    {
      "epoch": 1.5577445652173914,
      "grad_norm": 3.377138614654541,
      "learning_rate": 9.395668785567339e-06,
      "loss": 0.1879,
      "step": 2293
    },
    {
      "epoch": 1.5584239130434783,
      "grad_norm": 3.201465606689453,
      "learning_rate": 9.38856782812691e-06,
      "loss": 0.1598,
      "step": 2294
    },
    {
      "epoch": 1.5591032608695652,
      "grad_norm": 1.7137179374694824,
      "learning_rate": 9.381467180136049e-06,
      "loss": 0.019,
      "step": 2295
    },
    {
      "epoch": 1.5597826086956523,
      "grad_norm": 0.04227352887392044,
      "learning_rate": 9.374366845188441e-06,
      "loss": 0.0005,
      "step": 2296
    },
    {
      "epoch": 1.5604619565217392,
      "grad_norm": 8.393268585205078,
      "learning_rate": 9.367266826877608e-06,
      "loss": 0.1965,
      "step": 2297
    },
    {
      "epoch": 1.5611413043478262,
      "grad_norm": 11.21587085723877,
      "learning_rate": 9.360167128796913e-06,
      "loss": 0.3524,
      "step": 2298
    },
    {
      "epoch": 1.561820652173913,
      "grad_norm": 3.3362340927124023,
      "learning_rate": 9.353067754539552e-06,
      "loss": 0.1586,
      "step": 2299
    },
    {
      "epoch": 1.5625,
      "grad_norm": 3.412639617919922,
      "learning_rate": 9.34596870769857e-06,
      "loss": 0.1773,
      "step": 2300
    },
    {
      "epoch": 1.563179347826087,
      "grad_norm": 0.26536092162132263,
      "learning_rate": 9.338869991866833e-06,
      "loss": 0.0032,
      "step": 2301
    },
    {
      "epoch": 1.5638586956521738,
      "grad_norm": 0.015184884890913963,
      "learning_rate": 9.331771610637048e-06,
      "loss": 0.0004,
      "step": 2302
    },
    {
      "epoch": 1.5645380434782608,
      "grad_norm": 0.06907754391431808,
      "learning_rate": 9.324673567601747e-06,
      "loss": 0.0007,
      "step": 2303
    },
    {
      "epoch": 1.5652173913043477,
      "grad_norm": 0.022070782259106636,
      "learning_rate": 9.317575866353293e-06,
      "loss": 0.0006,
      "step": 2304
    },
    {
      "epoch": 1.5658967391304348,
      "grad_norm": 0.01547542866319418,
      "learning_rate": 9.310478510483875e-06,
      "loss": 0.0003,
      "step": 2305
    },
    {
      "epoch": 1.5665760869565217,
      "grad_norm": 0.030612608417868614,
      "learning_rate": 9.30338150358551e-06,
      "loss": 0.0004,
      "step": 2306
    },
    {
      "epoch": 1.5672554347826086,
      "grad_norm": 2.4616622924804688,
      "learning_rate": 9.296284849250038e-06,
      "loss": 0.1302,
      "step": 2307
    },
    {
      "epoch": 1.5679347826086958,
      "grad_norm": 2.1992697715759277,
      "learning_rate": 9.289188551069112e-06,
      "loss": 0.1574,
      "step": 2308
    },
    {
      "epoch": 1.5686141304347827,
      "grad_norm": 4.655874729156494,
      "learning_rate": 9.282092612634223e-06,
      "loss": 0.1897,
      "step": 2309
    },
    {
      "epoch": 1.5692934782608696,
      "grad_norm": 13.978249549865723,
      "learning_rate": 9.274997037536663e-06,
      "loss": 0.1486,
      "step": 2310
    },
    {
      "epoch": 1.5699728260869565,
      "grad_norm": 6.201448917388916,
      "learning_rate": 9.267901829367546e-06,
      "loss": 0.0797,
      "step": 2311
    },
    {
      "epoch": 1.5706521739130435,
      "grad_norm": 5.335968971252441,
      "learning_rate": 9.260806991717802e-06,
      "loss": 0.1508,
      "step": 2312
    },
    {
      "epoch": 1.5713315217391304,
      "grad_norm": 0.016203856095671654,
      "learning_rate": 9.253712528178169e-06,
      "loss": 0.0004,
      "step": 2313
    },
    {
      "epoch": 1.5720108695652173,
      "grad_norm": 3.8204615116119385,
      "learning_rate": 9.246618442339202e-06,
      "loss": 0.1769,
      "step": 2314
    },
    {
      "epoch": 1.5726902173913042,
      "grad_norm": 2.4721782207489014,
      "learning_rate": 9.23952473779126e-06,
      "loss": 0.1123,
      "step": 2315
    },
    {
      "epoch": 1.5733695652173914,
      "grad_norm": 0.9997378587722778,
      "learning_rate": 9.232431418124507e-06,
      "loss": 0.0113,
      "step": 2316
    },
    {
      "epoch": 1.5740489130434783,
      "grad_norm": 0.16355203092098236,
      "learning_rate": 9.225338486928921e-06,
      "loss": 0.0014,
      "step": 2317
    },
    {
      "epoch": 1.5747282608695652,
      "grad_norm": 6.352291107177734,
      "learning_rate": 9.218245947794275e-06,
      "loss": 0.4396,
      "step": 2318
    },
    {
      "epoch": 1.5754076086956523,
      "grad_norm": 2.753326416015625,
      "learning_rate": 9.211153804310146e-06,
      "loss": 0.221,
      "step": 2319
    },
    {
      "epoch": 1.5760869565217392,
      "grad_norm": 0.07849729806184769,
      "learning_rate": 9.204062060065915e-06,
      "loss": 0.001,
      "step": 2320
    },
    {
      "epoch": 1.5767663043478262,
      "grad_norm": 4.909149646759033,
      "learning_rate": 9.196970718650753e-06,
      "loss": 0.0989,
      "step": 2321
    },
    {
      "epoch": 1.577445652173913,
      "grad_norm": 6.546762466430664,
      "learning_rate": 9.189879783653633e-06,
      "loss": 0.0604,
      "step": 2322
    },
    {
      "epoch": 1.578125,
      "grad_norm": 7.0725626945495605,
      "learning_rate": 9.182789258663321e-06,
      "loss": 0.2497,
      "step": 2323
    },
    {
      "epoch": 1.578804347826087,
      "grad_norm": 1.3612172603607178,
      "learning_rate": 9.175699147268374e-06,
      "loss": 0.0141,
      "step": 2324
    },
    {
      "epoch": 1.5794836956521738,
      "grad_norm": 0.20347942411899567,
      "learning_rate": 9.16860945305714e-06,
      "loss": 0.0012,
      "step": 2325
    },
    {
      "epoch": 1.5801630434782608,
      "grad_norm": 1.2556424140930176,
      "learning_rate": 9.16152017961776e-06,
      "loss": 0.0195,
      "step": 2326
    },
    {
      "epoch": 1.5808423913043477,
      "grad_norm": 3.02396559715271,
      "learning_rate": 9.154431330538156e-06,
      "loss": 0.1156,
      "step": 2327
    },
    {
      "epoch": 1.5815217391304348,
      "grad_norm": 7.041845798492432,
      "learning_rate": 9.14734290940604e-06,
      "loss": 0.3743,
      "step": 2328
    },
    {
      "epoch": 1.5822010869565217,
      "grad_norm": 4.107609748840332,
      "learning_rate": 9.140254919808907e-06,
      "loss": 0.1494,
      "step": 2329
    },
    {
      "epoch": 1.5828804347826086,
      "grad_norm": 3.9919357299804688,
      "learning_rate": 9.133167365334027e-06,
      "loss": 0.2242,
      "step": 2330
    },
    {
      "epoch": 1.5835597826086958,
      "grad_norm": 10.712578773498535,
      "learning_rate": 9.126080249568457e-06,
      "loss": 0.4134,
      "step": 2331
    },
    {
      "epoch": 1.5842391304347827,
      "grad_norm": 1.8039242029190063,
      "learning_rate": 9.118993576099032e-06,
      "loss": 0.0457,
      "step": 2332
    },
    {
      "epoch": 1.5849184782608696,
      "grad_norm": 1.5688621997833252,
      "learning_rate": 9.111907348512356e-06,
      "loss": 0.1267,
      "step": 2333
    },
    {
      "epoch": 1.5855978260869565,
      "grad_norm": 3.070387125015259,
      "learning_rate": 9.104821570394811e-06,
      "loss": 0.0666,
      "step": 2334
    },
    {
      "epoch": 1.5862771739130435,
      "grad_norm": 9.342364311218262,
      "learning_rate": 9.097736245332562e-06,
      "loss": 0.2864,
      "step": 2335
    },
    {
      "epoch": 1.5869565217391304,
      "grad_norm": 1.7988107204437256,
      "learning_rate": 9.090651376911532e-06,
      "loss": 0.0848,
      "step": 2336
    },
    {
      "epoch": 1.5876358695652173,
      "grad_norm": 2.7695302963256836,
      "learning_rate": 9.083566968717412e-06,
      "loss": 0.0941,
      "step": 2337
    },
    {
      "epoch": 1.5883152173913042,
      "grad_norm": 2.286073684692383,
      "learning_rate": 9.076483024335667e-06,
      "loss": 0.1539,
      "step": 2338
    },
    {
      "epoch": 1.5889945652173914,
      "grad_norm": 3.5219619274139404,
      "learning_rate": 9.069399547351526e-06,
      "loss": 0.1272,
      "step": 2339
    },
    {
      "epoch": 1.5896739130434783,
      "grad_norm": 1.5001263618469238,
      "learning_rate": 9.062316541349978e-06,
      "loss": 0.0903,
      "step": 2340
    },
    {
      "epoch": 1.5903532608695652,
      "grad_norm": 8.317906379699707,
      "learning_rate": 9.055234009915777e-06,
      "loss": 0.1263,
      "step": 2341
    },
    {
      "epoch": 1.5910326086956523,
      "grad_norm": 4.979013919830322,
      "learning_rate": 9.048151956633432e-06,
      "loss": 0.1438,
      "step": 2342
    },
    {
      "epoch": 1.5917119565217392,
      "grad_norm": 1.8408509492874146,
      "learning_rate": 9.04107038508722e-06,
      "loss": 0.0165,
      "step": 2343
    },
    {
      "epoch": 1.5923913043478262,
      "grad_norm": 3.6548454761505127,
      "learning_rate": 9.033989298861162e-06,
      "loss": 0.2508,
      "step": 2344
    },
    {
      "epoch": 1.593070652173913,
      "grad_norm": 1.9373445510864258,
      "learning_rate": 9.026908701539043e-06,
      "loss": 0.0793,
      "step": 2345
    },
    {
      "epoch": 1.59375,
      "grad_norm": 1.2566088438034058,
      "learning_rate": 9.019828596704394e-06,
      "loss": 0.0142,
      "step": 2346
    },
    {
      "epoch": 1.594429347826087,
      "grad_norm": 0.4769083857536316,
      "learning_rate": 9.012748987940502e-06,
      "loss": 0.0051,
      "step": 2347
    },
    {
      "epoch": 1.5951086956521738,
      "grad_norm": 6.578539848327637,
      "learning_rate": 9.005669878830399e-06,
      "loss": 0.2953,
      "step": 2348
    },
    {
      "epoch": 1.5957880434782608,
      "grad_norm": 3.6027402877807617,
      "learning_rate": 8.998591272956866e-06,
      "loss": 0.1342,
      "step": 2349
    },
    {
      "epoch": 1.5964673913043477,
      "grad_norm": 2.0905215740203857,
      "learning_rate": 8.99151317390243e-06,
      "loss": 0.139,
      "step": 2350
    },
    {
      "epoch": 1.5971467391304348,
      "grad_norm": 5.478010654449463,
      "learning_rate": 8.984435585249355e-06,
      "loss": 0.1804,
      "step": 2351
    },
    {
      "epoch": 1.5978260869565217,
      "grad_norm": 0.7098469734191895,
      "learning_rate": 8.977358510579658e-06,
      "loss": 0.0053,
      "step": 2352
    },
    {
      "epoch": 1.5985054347826086,
      "grad_norm": 0.2894378900527954,
      "learning_rate": 8.970281953475088e-06,
      "loss": 0.0033,
      "step": 2353
    },
    {
      "epoch": 1.5991847826086958,
      "grad_norm": 8.984582901000977,
      "learning_rate": 8.963205917517133e-06,
      "loss": 0.1125,
      "step": 2354
    },
    {
      "epoch": 1.5998641304347827,
      "grad_norm": 0.06211988627910614,
      "learning_rate": 8.95613040628702e-06,
      "loss": 0.0008,
      "step": 2355
    },
    {
      "epoch": 1.6005434782608696,
      "grad_norm": 3.446333408355713,
      "learning_rate": 8.949055423365708e-06,
      "loss": 0.0636,
      "step": 2356
    },
    {
      "epoch": 1.6012228260869565,
      "grad_norm": 0.055679064244031906,
      "learning_rate": 8.941980972333886e-06,
      "loss": 0.0009,
      "step": 2357
    },
    {
      "epoch": 1.6019021739130435,
      "grad_norm": 1.2007114887237549,
      "learning_rate": 8.93490705677198e-06,
      "loss": 0.0342,
      "step": 2358
    },
    {
      "epoch": 1.6025815217391304,
      "grad_norm": 1.9650907516479492,
      "learning_rate": 8.927833680260139e-06,
      "loss": 0.1147,
      "step": 2359
    },
    {
      "epoch": 1.6032608695652173,
      "grad_norm": 3.7778215408325195,
      "learning_rate": 8.920760846378248e-06,
      "loss": 0.2309,
      "step": 2360
    },
    {
      "epoch": 1.6039402173913042,
      "grad_norm": 0.20215338468551636,
      "learning_rate": 8.91368855870591e-06,
      "loss": 0.0021,
      "step": 2361
    },
    {
      "epoch": 1.6046195652173914,
      "grad_norm": 10.66049861907959,
      "learning_rate": 8.906616820822452e-06,
      "loss": 0.4732,
      "step": 2362
    },
    {
      "epoch": 1.6052989130434783,
      "grad_norm": 6.241322040557861,
      "learning_rate": 8.899545636306922e-06,
      "loss": 0.2648,
      "step": 2363
    },
    {
      "epoch": 1.6059782608695652,
      "grad_norm": 0.9406355619430542,
      "learning_rate": 8.89247500873809e-06,
      "loss": 0.0372,
      "step": 2364
    },
    {
      "epoch": 1.6066576086956523,
      "grad_norm": 0.30779916048049927,
      "learning_rate": 8.885404941694448e-06,
      "loss": 0.0037,
      "step": 2365
    },
    {
      "epoch": 1.6073369565217392,
      "grad_norm": 0.021824510768055916,
      "learning_rate": 8.878335438754195e-06,
      "loss": 0.0004,
      "step": 2366
    },
    {
      "epoch": 1.6080163043478262,
      "grad_norm": 5.389884948730469,
      "learning_rate": 8.871266503495255e-06,
      "loss": 0.2812,
      "step": 2367
    },
    {
      "epoch": 1.608695652173913,
      "grad_norm": 3.3947341442108154,
      "learning_rate": 8.86419813949525e-06,
      "loss": 0.1664,
      "step": 2368
    },
    {
      "epoch": 1.609375,
      "grad_norm": 0.03458864241838455,
      "learning_rate": 8.857130350331535e-06,
      "loss": 0.0006,
      "step": 2369
    },
    {
      "epoch": 1.610054347826087,
      "grad_norm": 10.374979019165039,
      "learning_rate": 8.850063139581156e-06,
      "loss": 0.0952,
      "step": 2370
    },
    {
      "epoch": 1.6107336956521738,
      "grad_norm": 7.91171407699585,
      "learning_rate": 8.84299651082087e-06,
      "loss": 0.1041,
      "step": 2371
    },
    {
      "epoch": 1.6114130434782608,
      "grad_norm": 0.7842516899108887,
      "learning_rate": 8.835930467627142e-06,
      "loss": 0.0048,
      "step": 2372
    },
    {
      "epoch": 1.6120923913043477,
      "grad_norm": 0.21187756955623627,
      "learning_rate": 8.828865013576143e-06,
      "loss": 0.0021,
      "step": 2373
    },
    {
      "epoch": 1.6127717391304348,
      "grad_norm": 9.652790069580078,
      "learning_rate": 8.821800152243738e-06,
      "loss": 0.1508,
      "step": 2374
    },
    {
      "epoch": 1.6134510869565217,
      "grad_norm": 1.874290943145752,
      "learning_rate": 8.814735887205499e-06,
      "loss": 0.0763,
      "step": 2375
    },
    {
      "epoch": 1.6141304347826086,
      "grad_norm": 15.968792915344238,
      "learning_rate": 8.807672222036692e-06,
      "loss": 0.1367,
      "step": 2376
    },
    {
      "epoch": 1.6148097826086958,
      "grad_norm": 2.483118772506714,
      "learning_rate": 8.800609160312281e-06,
      "loss": 0.0247,
      "step": 2377
    },
    {
      "epoch": 1.6154891304347827,
      "grad_norm": 0.1042243093252182,
      "learning_rate": 8.793546705606928e-06,
      "loss": 0.0014,
      "step": 2378
    },
    {
      "epoch": 1.6161684782608696,
      "grad_norm": 0.027971098199486732,
      "learning_rate": 8.786484861494984e-06,
      "loss": 0.0004,
      "step": 2379
    },
    {
      "epoch": 1.6168478260869565,
      "grad_norm": 8.013591766357422,
      "learning_rate": 8.77942363155049e-06,
      "loss": 0.2358,
      "step": 2380
    },
    {
      "epoch": 1.6175271739130435,
      "grad_norm": 0.24393752217292786,
      "learning_rate": 8.77236301934718e-06,
      "loss": 0.0037,
      "step": 2381
    },
    {
      "epoch": 1.6182065217391304,
      "grad_norm": 0.48466774821281433,
      "learning_rate": 8.765303028458468e-06,
      "loss": 0.0047,
      "step": 2382
    },
    {
      "epoch": 1.6188858695652173,
      "grad_norm": 0.025931421667337418,
      "learning_rate": 8.758243662457464e-06,
      "loss": 0.0006,
      "step": 2383
    },
    {
      "epoch": 1.6195652173913042,
      "grad_norm": 4.866594314575195,
      "learning_rate": 8.751184924916954e-06,
      "loss": 0.1493,
      "step": 2384
    },
    {
      "epoch": 1.6202445652173914,
      "grad_norm": 0.22722935676574707,
      "learning_rate": 8.744126819409405e-06,
      "loss": 0.0023,
      "step": 2385
    },
    {
      "epoch": 1.6209239130434783,
      "grad_norm": 2.5882441997528076,
      "learning_rate": 8.737069349506977e-06,
      "loss": 0.1829,
      "step": 2386
    },
    {
      "epoch": 1.6216032608695652,
      "grad_norm": 3.6272923946380615,
      "learning_rate": 8.73001251878149e-06,
      "loss": 0.1745,
      "step": 2387
    },
    {
      "epoch": 1.6222826086956523,
      "grad_norm": 0.3414157032966614,
      "learning_rate": 8.722956330804456e-06,
      "loss": 0.0039,
      "step": 2388
    },
    {
      "epoch": 1.6229619565217392,
      "grad_norm": 13.021746635437012,
      "learning_rate": 8.715900789147048e-06,
      "loss": 0.258,
      "step": 2389
    },
    {
      "epoch": 1.6236413043478262,
      "grad_norm": 0.021961720660328865,
      "learning_rate": 8.708845897380123e-06,
      "loss": 0.0004,
      "step": 2390
    },
    {
      "epoch": 1.624320652173913,
      "grad_norm": 13.453227043151855,
      "learning_rate": 8.701791659074206e-06,
      "loss": 0.4339,
      "step": 2391
    },
    {
      "epoch": 1.625,
      "grad_norm": 2.626129388809204,
      "learning_rate": 8.694738077799487e-06,
      "loss": 0.1714,
      "step": 2392
    },
    {
      "epoch": 1.625679347826087,
      "grad_norm": 0.07567644119262695,
      "learning_rate": 8.687685157125829e-06,
      "loss": 0.0008,
      "step": 2393
    },
    {
      "epoch": 1.6263586956521738,
      "grad_norm": 0.03613878786563873,
      "learning_rate": 8.680632900622752e-06,
      "loss": 0.0005,
      "step": 2394
    },
    {
      "epoch": 1.6270380434782608,
      "grad_norm": 3.1448144912719727,
      "learning_rate": 8.673581311859456e-06,
      "loss": 0.1021,
      "step": 2395
    },
    {
      "epoch": 1.6277173913043477,
      "grad_norm": 0.011188982985913754,
      "learning_rate": 8.666530394404791e-06,
      "loss": 0.0003,
      "step": 2396
    },
    {
      "epoch": 1.6283967391304348,
      "grad_norm": 8.772504806518555,
      "learning_rate": 8.659480151827267e-06,
      "loss": 0.2333,
      "step": 2397
    },
    {
      "epoch": 1.6290760869565217,
      "grad_norm": 0.3274097144603729,
      "learning_rate": 8.652430587695056e-06,
      "loss": 0.0041,
      "step": 2398
    },
    {
      "epoch": 1.6297554347826086,
      "grad_norm": 7.20989465713501,
      "learning_rate": 8.645381705575985e-06,
      "loss": 0.0502,
      "step": 2399
    },
    {
      "epoch": 1.6304347826086958,
      "grad_norm": 5.293813228607178,
      "learning_rate": 8.638333509037537e-06,
      "loss": 0.0856,
      "step": 2400
    },
    {
      "epoch": 1.6311141304347827,
      "grad_norm": 0.018224146217107773,
      "learning_rate": 8.631286001646845e-06,
      "loss": 0.0003,
      "step": 2401
    },
    {
      "epoch": 1.6317934782608696,
      "grad_norm": 4.837211608886719,
      "learning_rate": 8.6242391869707e-06,
      "loss": 0.1792,
      "step": 2402
    },
    {
      "epoch": 1.6324728260869565,
      "grad_norm": 4.225895404815674,
      "learning_rate": 8.617193068575534e-06,
      "loss": 0.1993,
      "step": 2403
    },
    {
      "epoch": 1.6331521739130435,
      "grad_norm": 0.022873487323522568,
      "learning_rate": 8.610147650027433e-06,
      "loss": 0.0005,
      "step": 2404
    },
    {
      "epoch": 1.6338315217391304,
      "grad_norm": 3.288975715637207,
      "learning_rate": 8.603102934892127e-06,
      "loss": 0.1763,
      "step": 2405
    },
    {
      "epoch": 1.6345108695652173,
      "grad_norm": 0.035092148929834366,
      "learning_rate": 8.59605892673499e-06,
      "loss": 0.0006,
      "step": 2406
    },
    {
      "epoch": 1.6351902173913042,
      "grad_norm": 0.12137749791145325,
      "learning_rate": 8.589015629121034e-06,
      "loss": 0.0014,
      "step": 2407
    },
    {
      "epoch": 1.6358695652173914,
      "grad_norm": 4.900501728057861,
      "learning_rate": 8.58197304561492e-06,
      "loss": 0.28,
      "step": 2408
    },
    {
      "epoch": 1.6365489130434783,
      "grad_norm": 3.6294119358062744,
      "learning_rate": 8.57493117978094e-06,
      "loss": 0.0752,
      "step": 2409
    },
    {
      "epoch": 1.6372282608695652,
      "grad_norm": 1.2983567714691162,
      "learning_rate": 8.567890035183025e-06,
      "loss": 0.0149,
      "step": 2410
    },
    {
      "epoch": 1.6379076086956523,
      "grad_norm": 0.0880158320069313,
      "learning_rate": 8.56084961538474e-06,
      "loss": 0.0012,
      "step": 2411
    },
    {
      "epoch": 1.6385869565217392,
      "grad_norm": 7.925155162811279,
      "learning_rate": 8.55380992394929e-06,
      "loss": 0.2146,
      "step": 2412
    },
    {
      "epoch": 1.6392663043478262,
      "grad_norm": 2.4657928943634033,
      "learning_rate": 8.546770964439502e-06,
      "loss": 0.1527,
      "step": 2413
    },
    {
      "epoch": 1.639945652173913,
      "grad_norm": 0.017106376588344574,
      "learning_rate": 8.539732740417838e-06,
      "loss": 0.0004,
      "step": 2414
    },
    {
      "epoch": 1.640625,
      "grad_norm": 3.7174878120422363,
      "learning_rate": 8.532695255446384e-06,
      "loss": 0.1542,
      "step": 2415
    },
    {
      "epoch": 1.641304347826087,
      "grad_norm": 8.551868438720703,
      "learning_rate": 8.525658513086857e-06,
      "loss": 0.3992,
      "step": 2416
    },
    {
      "epoch": 1.6419836956521738,
      "grad_norm": 1.5307003259658813,
      "learning_rate": 8.518622516900594e-06,
      "loss": 0.0192,
      "step": 2417
    },
    {
      "epoch": 1.6426630434782608,
      "grad_norm": 2.2372307777404785,
      "learning_rate": 8.511587270448556e-06,
      "loss": 0.1001,
      "step": 2418
    },
    {
      "epoch": 1.6433423913043477,
      "grad_norm": 4.013713836669922,
      "learning_rate": 8.504552777291326e-06,
      "loss": 0.1022,
      "step": 2419
    },
    {
      "epoch": 1.6440217391304348,
      "grad_norm": 8.475324630737305,
      "learning_rate": 8.497519040989096e-06,
      "loss": 0.1148,
      "step": 2420
    },
    {
      "epoch": 1.6447010869565217,
      "grad_norm": 8.763720512390137,
      "learning_rate": 8.490486065101698e-06,
      "loss": 0.4392,
      "step": 2421
    },
    {
      "epoch": 1.6453804347826086,
      "grad_norm": 0.014813198707997799,
      "learning_rate": 8.483453853188552e-06,
      "loss": 0.0003,
      "step": 2422
    },
    {
      "epoch": 1.6460597826086958,
      "grad_norm": 2.8483567237854004,
      "learning_rate": 8.47642240880871e-06,
      "loss": 0.1023,
      "step": 2423
    },
    {
      "epoch": 1.6467391304347827,
      "grad_norm": 0.9397978782653809,
      "learning_rate": 8.469391735520824e-06,
      "loss": 0.0116,
      "step": 2424
    },
    {
      "epoch": 1.6474184782608696,
      "grad_norm": 2.7405190467834473,
      "learning_rate": 8.462361836883165e-06,
      "loss": 0.1237,
      "step": 2425
    },
    {
      "epoch": 1.6480978260869565,
      "grad_norm": 5.307534217834473,
      "learning_rate": 8.455332716453605e-06,
      "loss": 0.2123,
      "step": 2426
    },
    {
      "epoch": 1.6487771739130435,
      "grad_norm": 4.873639106750488,
      "learning_rate": 8.448304377789628e-06,
      "loss": 0.1216,
      "step": 2427
    },
    {
      "epoch": 1.6494565217391304,
      "grad_norm": 11.890890121459961,
      "learning_rate": 8.441276824448312e-06,
      "loss": 0.2723,
      "step": 2428
    },
    {
      "epoch": 1.6501358695652173,
      "grad_norm": 0.22501660883426666,
      "learning_rate": 8.434250059986355e-06,
      "loss": 0.0025,
      "step": 2429
    },
    {
      "epoch": 1.6508152173913042,
      "grad_norm": 1.8398606777191162,
      "learning_rate": 8.42722408796004e-06,
      "loss": 0.145,
      "step": 2430
    },
    {
      "epoch": 1.6514945652173914,
      "grad_norm": 10.496088981628418,
      "learning_rate": 8.420198911925257e-06,
      "loss": 0.4333,
      "step": 2431
    },
    {
      "epoch": 1.6521739130434783,
      "grad_norm": 2.080235719680786,
      "learning_rate": 8.413174535437486e-06,
      "loss": 0.1117,
      "step": 2432
    },
    {
      "epoch": 1.6528532608695652,
      "grad_norm": 0.213311105966568,
      "learning_rate": 8.406150962051813e-06,
      "loss": 0.0023,
      "step": 2433
    },
    {
      "epoch": 1.6535326086956523,
      "grad_norm": 2.1692497730255127,
      "learning_rate": 8.399128195322908e-06,
      "loss": 0.162,
      "step": 2434
    },
    {
      "epoch": 1.6542119565217392,
      "grad_norm": 3.004148006439209,
      "learning_rate": 8.392106238805038e-06,
      "loss": 0.1124,
      "step": 2435
    },
    {
      "epoch": 1.6548913043478262,
      "grad_norm": 0.5225709080696106,
      "learning_rate": 8.385085096052053e-06,
      "loss": 0.0088,
      "step": 2436
    },
    {
      "epoch": 1.655570652173913,
      "grad_norm": 0.048993069678545,
      "learning_rate": 8.3780647706174e-06,
      "loss": 0.0006,
      "step": 2437
    },
    {
      "epoch": 1.65625,
      "grad_norm": 0.32438987493515015,
      "learning_rate": 8.371045266054114e-06,
      "loss": 0.0032,
      "step": 2438
    },
    {
      "epoch": 1.656929347826087,
      "grad_norm": 0.14883959293365479,
      "learning_rate": 8.364026585914802e-06,
      "loss": 0.0019,
      "step": 2439
    },
    {
      "epoch": 1.6576086956521738,
      "grad_norm": 1.7470077276229858,
      "learning_rate": 8.357008733751664e-06,
      "loss": 0.1263,
      "step": 2440
    },
    {
      "epoch": 1.6582880434782608,
      "grad_norm": 2.078798770904541,
      "learning_rate": 8.349991713116478e-06,
      "loss": 0.1658,
      "step": 2441
    },
    {
      "epoch": 1.6589673913043477,
      "grad_norm": 1.5915855169296265,
      "learning_rate": 8.342975527560601e-06,
      "loss": 0.0882,
      "step": 2442
    },
    {
      "epoch": 1.6596467391304348,
      "grad_norm": 2.740464687347412,
      "learning_rate": 8.335960180634965e-06,
      "loss": 0.1375,
      "step": 2443
    },
    {
      "epoch": 1.6603260869565217,
      "grad_norm": 0.3056025505065918,
      "learning_rate": 8.328945675890085e-06,
      "loss": 0.0034,
      "step": 2444
    },
    {
      "epoch": 1.6610054347826086,
      "grad_norm": 2.8557932376861572,
      "learning_rate": 8.32193201687604e-06,
      "loss": 0.1894,
      "step": 2445
    },
    {
      "epoch": 1.6616847826086958,
      "grad_norm": 1.8112300634384155,
      "learning_rate": 8.314919207142486e-06,
      "loss": 0.046,
      "step": 2446
    },
    {
      "epoch": 1.6623641304347827,
      "grad_norm": 4.110917091369629,
      "learning_rate": 8.307907250238654e-06,
      "loss": 0.1714,
      "step": 2447
    },
    {
      "epoch": 1.6630434782608696,
      "grad_norm": 1.2312074899673462,
      "learning_rate": 8.300896149713334e-06,
      "loss": 0.0957,
      "step": 2448
    },
    {
      "epoch": 1.6637228260869565,
      "grad_norm": 5.425134181976318,
      "learning_rate": 8.29388590911489e-06,
      "loss": 0.093,
      "step": 2449
    },
    {
      "epoch": 1.6644021739130435,
      "grad_norm": 3.333041191101074,
      "learning_rate": 8.286876531991246e-06,
      "loss": 0.1687,
      "step": 2450
    },
    {
      "epoch": 1.6650815217391304,
      "grad_norm": 2.7634127140045166,
      "learning_rate": 8.27986802188989e-06,
      "loss": 0.1084,
      "step": 2451
    },
    {
      "epoch": 1.6657608695652173,
      "grad_norm": 0.2526433765888214,
      "learning_rate": 8.272860382357873e-06,
      "loss": 0.0026,
      "step": 2452
    },
    {
      "epoch": 1.6664402173913042,
      "grad_norm": 12.968170166015625,
      "learning_rate": 8.265853616941803e-06,
      "loss": 0.2059,
      "step": 2453
    },
    {
      "epoch": 1.6671195652173914,
      "grad_norm": 6.522838115692139,
      "learning_rate": 8.258847729187845e-06,
      "loss": 0.2607,
      "step": 2454
    },
    {
      "epoch": 1.6677989130434783,
      "grad_norm": 0.044047292321920395,
      "learning_rate": 8.25184272264173e-06,
      "loss": 0.0006,
      "step": 2455
    },
    {
      "epoch": 1.6684782608695652,
      "grad_norm": 0.3499351441860199,
      "learning_rate": 8.244838600848727e-06,
      "loss": 0.0037,
      "step": 2456
    },
    {
      "epoch": 1.6691576086956523,
      "grad_norm": 0.29102203249931335,
      "learning_rate": 8.237835367353668e-06,
      "loss": 0.0033,
      "step": 2457
    },
    {
      "epoch": 1.6698369565217392,
      "grad_norm": 3.4216043949127197,
      "learning_rate": 8.230833025700932e-06,
      "loss": 0.2472,
      "step": 2458
    },
    {
      "epoch": 1.6705163043478262,
      "grad_norm": 7.071958065032959,
      "learning_rate": 8.223831579434449e-06,
      "loss": 0.2296,
      "step": 2459
    },
    {
      "epoch": 1.671195652173913,
      "grad_norm": 2.3039133548736572,
      "learning_rate": 8.216831032097689e-06,
      "loss": 0.1877,
      "step": 2460
    },
    {
      "epoch": 1.671875,
      "grad_norm": 1.560025930404663,
      "learning_rate": 8.209831387233675e-06,
      "loss": 0.0391,
      "step": 2461
    },
    {
      "epoch": 1.672554347826087,
      "grad_norm": 5.025294303894043,
      "learning_rate": 8.202832648384971e-06,
      "loss": 0.1864,
      "step": 2462
    },
    {
      "epoch": 1.6732336956521738,
      "grad_norm": 0.8991199135780334,
      "learning_rate": 8.195834819093677e-06,
      "loss": 0.1099,
      "step": 2463
    },
    {
      "epoch": 1.6739130434782608,
      "grad_norm": 11.19612979888916,
      "learning_rate": 8.188837902901441e-06,
      "loss": 0.5362,
      "step": 2464
    },
    {
      "epoch": 1.6745923913043477,
      "grad_norm": 0.52529376745224,
      "learning_rate": 8.181841903349448e-06,
      "loss": 0.0053,
      "step": 2465
    },
    {
      "epoch": 1.6752717391304348,
      "grad_norm": 2.7098703384399414,
      "learning_rate": 8.174846823978412e-06,
      "loss": 0.1797,
      "step": 2466
    },
    {
      "epoch": 1.6759510869565217,
      "grad_norm": 3.009530544281006,
      "learning_rate": 8.167852668328588e-06,
      "loss": 0.124,
      "step": 2467
    },
    {
      "epoch": 1.6766304347826086,
      "grad_norm": 4.252041339874268,
      "learning_rate": 8.16085943993976e-06,
      "loss": 0.2274,
      "step": 2468
    },
    {
      "epoch": 1.6773097826086958,
      "grad_norm": 1.5974618196487427,
      "learning_rate": 8.153867142351242e-06,
      "loss": 0.0942,
      "step": 2469
    },
    {
      "epoch": 1.6779891304347827,
      "grad_norm": 4.89107084274292,
      "learning_rate": 8.146875779101882e-06,
      "loss": 0.3041,
      "step": 2470
    },
    {
      "epoch": 1.6786684782608696,
      "grad_norm": 2.124777317047119,
      "learning_rate": 8.139885353730048e-06,
      "loss": 0.0323,
      "step": 2471
    },
    {
      "epoch": 1.6793478260869565,
      "grad_norm": 3.5419790744781494,
      "learning_rate": 8.132895869773638e-06,
      "loss": 0.1623,
      "step": 2472
    },
    {
      "epoch": 1.6800271739130435,
      "grad_norm": 1.6501882076263428,
      "learning_rate": 8.125907330770075e-06,
      "loss": 0.1476,
      "step": 2473
    },
    {
      "epoch": 1.6807065217391304,
      "grad_norm": 2.4327943325042725,
      "learning_rate": 8.1189197402563e-06,
      "loss": 0.0464,
      "step": 2474
    },
    {
      "epoch": 1.6813858695652173,
      "grad_norm": 6.832833766937256,
      "learning_rate": 8.111933101768779e-06,
      "loss": 0.2613,
      "step": 2475
    },
    {
      "epoch": 1.6820652173913042,
      "grad_norm": 1.877143383026123,
      "learning_rate": 8.104947418843487e-06,
      "loss": 0.1008,
      "step": 2476
    },
    {
      "epoch": 1.6827445652173914,
      "grad_norm": 0.14871858060359955,
      "learning_rate": 8.097962695015923e-06,
      "loss": 0.0023,
      "step": 2477
    },
    {
      "epoch": 1.6834239130434783,
      "grad_norm": 8.42976188659668,
      "learning_rate": 8.0909789338211e-06,
      "loss": 0.3971,
      "step": 2478
    },
    {
      "epoch": 1.6841032608695652,
      "grad_norm": 0.3812443017959595,
      "learning_rate": 8.08399613879354e-06,
      "loss": 0.004,
      "step": 2479
    },
    {
      "epoch": 1.6847826086956523,
      "grad_norm": 2.7293200492858887,
      "learning_rate": 8.077014313467274e-06,
      "loss": 0.0312,
      "step": 2480
    },
    {
      "epoch": 1.6854619565217392,
      "grad_norm": 1.8575692176818848,
      "learning_rate": 8.070033461375857e-06,
      "loss": 0.0883,
      "step": 2481
    },
    {
      "epoch": 1.6861413043478262,
      "grad_norm": 3.832719326019287,
      "learning_rate": 8.063053586052336e-06,
      "loss": 0.0821,
      "step": 2482
    },
    {
      "epoch": 1.686820652173913,
      "grad_norm": 1.4058295488357544,
      "learning_rate": 8.05607469102927e-06,
      "loss": 0.0137,
      "step": 2483
    },
    {
      "epoch": 1.6875,
      "grad_norm": 3.2344818115234375,
      "learning_rate": 8.04909677983872e-06,
      "loss": 0.1105,
      "step": 2484
    },
    {
      "epoch": 1.688179347826087,
      "grad_norm": 1.018608808517456,
      "learning_rate": 8.042119856012246e-06,
      "loss": 0.0102,
      "step": 2485
    },
    {
      "epoch": 1.6888586956521738,
      "grad_norm": 2.578423500061035,
      "learning_rate": 8.035143923080917e-06,
      "loss": 0.1001,
      "step": 2486
    },
    {
      "epoch": 1.6895380434782608,
      "grad_norm": 0.33120155334472656,
      "learning_rate": 8.028168984575292e-06,
      "loss": 0.0049,
      "step": 2487
    },
    {
      "epoch": 1.6902173913043477,
      "grad_norm": 0.3814116418361664,
      "learning_rate": 8.021195044025432e-06,
      "loss": 0.0035,
      "step": 2488
    },
    {
      "epoch": 1.6908967391304348,
      "grad_norm": 2.097756862640381,
      "learning_rate": 8.014222104960888e-06,
      "loss": 0.0828,
      "step": 2489
    },
    {
      "epoch": 1.6915760869565217,
      "grad_norm": 3.952442169189453,
      "learning_rate": 8.00725017091071e-06,
      "loss": 0.1873,
      "step": 2490
    },
    {
      "epoch": 1.6922554347826086,
      "grad_norm": 3.47143292427063,
      "learning_rate": 8.000279245403439e-06,
      "loss": 0.1874,
      "step": 2491
    },
    {
      "epoch": 1.6929347826086958,
      "grad_norm": 1.1706984043121338,
      "learning_rate": 7.9933093319671e-06,
      "loss": 0.0138,
      "step": 2492
    },
    {
      "epoch": 1.6936141304347827,
      "grad_norm": 3.5943026542663574,
      "learning_rate": 7.98634043412921e-06,
      "loss": 0.1437,
      "step": 2493
    },
    {
      "epoch": 1.6942934782608696,
      "grad_norm": 1.694304347038269,
      "learning_rate": 7.979372555416768e-06,
      "loss": 0.0222,
      "step": 2494
    },
    {
      "epoch": 1.6949728260869565,
      "grad_norm": 3.7496609687805176,
      "learning_rate": 7.972405699356263e-06,
      "loss": 0.1935,
      "step": 2495
    },
    {
      "epoch": 1.6956521739130435,
      "grad_norm": 1.9456050395965576,
      "learning_rate": 7.965439869473664e-06,
      "loss": 0.0307,
      "step": 2496
    },
    {
      "epoch": 1.6963315217391304,
      "grad_norm": 0.03685898706316948,
      "learning_rate": 7.958475069294417e-06,
      "loss": 0.0004,
      "step": 2497
    },
    {
      "epoch": 1.6970108695652173,
      "grad_norm": 0.011388036422431469,
      "learning_rate": 7.951511302343454e-06,
      "loss": 0.0003,
      "step": 2498
    },
    {
      "epoch": 1.6976902173913042,
      "grad_norm": 2.9297051429748535,
      "learning_rate": 7.944548572145178e-06,
      "loss": 0.1369,
      "step": 2499
    },
    {
      "epoch": 1.6983695652173914,
      "grad_norm": 3.030329942703247,
      "learning_rate": 7.93758688222347e-06,
      "loss": 0.0226,
      "step": 2500
    },
    {
      "epoch": 1.6990489130434783,
      "grad_norm": 1.810869574546814,
      "learning_rate": 7.930626236101684e-06,
      "loss": 0.1112,
      "step": 2501
    },
    {
      "epoch": 1.6997282608695652,
      "grad_norm": 2.4473605155944824,
      "learning_rate": 7.923666637302643e-06,
      "loss": 0.0962,
      "step": 2502
    },
    {
      "epoch": 1.7004076086956523,
      "grad_norm": 2.968250036239624,
      "learning_rate": 7.916708089348649e-06,
      "loss": 0.1153,
      "step": 2503
    },
    {
      "epoch": 1.7010869565217392,
      "grad_norm": 2.8653297424316406,
      "learning_rate": 7.909750595761459e-06,
      "loss": 0.1313,
      "step": 2504
    },
    {
      "epoch": 1.7017663043478262,
      "grad_norm": 10.814727783203125,
      "learning_rate": 7.902794160062303e-06,
      "loss": 0.3458,
      "step": 2505
    },
    {
      "epoch": 1.702445652173913,
      "grad_norm": 2.247907876968384,
      "learning_rate": 7.895838785771881e-06,
      "loss": 0.1342,
      "step": 2506
    },
    {
      "epoch": 1.703125,
      "grad_norm": 1.7190836668014526,
      "learning_rate": 7.888884476410348e-06,
      "loss": 0.0801,
      "step": 2507
    },
    {
      "epoch": 1.703804347826087,
      "grad_norm": 1.4296600818634033,
      "learning_rate": 7.881931235497324e-06,
      "loss": 0.0882,
      "step": 2508
    },
    {
      "epoch": 1.7044836956521738,
      "grad_norm": 0.10104665160179138,
      "learning_rate": 7.874979066551886e-06,
      "loss": 0.0009,
      "step": 2509
    },
    {
      "epoch": 1.7051630434782608,
      "grad_norm": 8.670924186706543,
      "learning_rate": 7.868027973092568e-06,
      "loss": 0.2508,
      "step": 2510
    },
    {
      "epoch": 1.7058423913043477,
      "grad_norm": 0.22083275020122528,
      "learning_rate": 7.861077958637365e-06,
      "loss": 0.0023,
      "step": 2511
    },
    {
      "epoch": 1.7065217391304348,
      "grad_norm": 0.31940120458602905,
      "learning_rate": 7.854129026703716e-06,
      "loss": 0.0033,
      "step": 2512
    },
    {
      "epoch": 1.7072010869565217,
      "grad_norm": 0.7660369873046875,
      "learning_rate": 7.847181180808522e-06,
      "loss": 0.0079,
      "step": 2513
    },
    {
      "epoch": 1.7078804347826086,
      "grad_norm": 6.965301513671875,
      "learning_rate": 7.84023442446813e-06,
      "loss": 0.3303,
      "step": 2514
    },
    {
      "epoch": 1.7085597826086958,
      "grad_norm": 9.845136642456055,
      "learning_rate": 7.833288761198329e-06,
      "loss": 0.3254,
      "step": 2515
    },
    {
      "epoch": 1.7092391304347827,
      "grad_norm": 1.0368503332138062,
      "learning_rate": 7.826344194514374e-06,
      "loss": 0.0094,
      "step": 2516
    },
    {
      "epoch": 1.7099184782608696,
      "grad_norm": 1.664551854133606,
      "learning_rate": 7.819400727930947e-06,
      "loss": 0.1059,
      "step": 2517
    },
    {
      "epoch": 1.7105978260869565,
      "grad_norm": 0.09182994067668915,
      "learning_rate": 7.812458364962177e-06,
      "loss": 0.0012,
      "step": 2518
    },
    {
      "epoch": 1.7112771739130435,
      "grad_norm": 0.043281201273202896,
      "learning_rate": 7.80551710912164e-06,
      "loss": 0.0007,
      "step": 2519
    },
    {
      "epoch": 1.7119565217391304,
      "grad_norm": 15.955202102661133,
      "learning_rate": 7.798576963922347e-06,
      "loss": 0.6859,
      "step": 2520
    },
    {
      "epoch": 1.7126358695652173,
      "grad_norm": 0.04588855057954788,
      "learning_rate": 7.791637932876746e-06,
      "loss": 0.0006,
      "step": 2521
    },
    {
      "epoch": 1.7133152173913042,
      "grad_norm": 3.6888699531555176,
      "learning_rate": 7.784700019496725e-06,
      "loss": 0.1844,
      "step": 2522
    },
    {
      "epoch": 1.7139945652173914,
      "grad_norm": 7.1754279136657715,
      "learning_rate": 7.7777632272936e-06,
      "loss": 0.2882,
      "step": 2523
    },
    {
      "epoch": 1.7146739130434783,
      "grad_norm": 2.7938992977142334,
      "learning_rate": 7.770827559778131e-06,
      "loss": 0.0197,
      "step": 2524
    },
    {
      "epoch": 1.7153532608695652,
      "grad_norm": 3.0333054065704346,
      "learning_rate": 7.7638930204605e-06,
      "loss": 0.1574,
      "step": 2525
    },
    {
      "epoch": 1.7160326086956523,
      "grad_norm": 8.641605377197266,
      "learning_rate": 7.75695961285032e-06,
      "loss": 0.3177,
      "step": 2526
    },
    {
      "epoch": 1.7167119565217392,
      "grad_norm": 2.961535692214966,
      "learning_rate": 7.75002734045663e-06,
      "loss": 0.1411,
      "step": 2527
    },
    {
      "epoch": 1.7173913043478262,
      "grad_norm": 3.357530355453491,
      "learning_rate": 7.743096206787894e-06,
      "loss": 0.109,
      "step": 2528
    },
    {
      "epoch": 1.718070652173913,
      "grad_norm": 1.1500515937805176,
      "learning_rate": 7.736166215352004e-06,
      "loss": 0.0164,
      "step": 2529
    },
    {
      "epoch": 1.71875,
      "grad_norm": 0.04141318425536156,
      "learning_rate": 7.72923736965627e-06,
      "loss": 0.0004,
      "step": 2530
    },
    {
      "epoch": 1.719429347826087,
      "grad_norm": 0.046924151480197906,
      "learning_rate": 7.722309673207423e-06,
      "loss": 0.0006,
      "step": 2531
    },
    {
      "epoch": 1.7201086956521738,
      "grad_norm": 1.8186653852462769,
      "learning_rate": 7.71538312951161e-06,
      "loss": 0.0594,
      "step": 2532
    },
    {
      "epoch": 1.7207880434782608,
      "grad_norm": 3.6354434490203857,
      "learning_rate": 7.708457742074403e-06,
      "loss": 0.1669,
      "step": 2533
    },
    {
      "epoch": 1.7214673913043477,
      "grad_norm": 0.5107187032699585,
      "learning_rate": 7.701533514400779e-06,
      "loss": 0.0057,
      "step": 2534
    },
    {
      "epoch": 1.7221467391304348,
      "grad_norm": 1.242938756942749,
      "learning_rate": 7.694610449995133e-06,
      "loss": 0.0689,
      "step": 2535
    },
    {
      "epoch": 1.7228260869565217,
      "grad_norm": 0.9338932037353516,
      "learning_rate": 7.687688552361272e-06,
      "loss": 0.0238,
      "step": 2536
    },
    {
      "epoch": 1.7235054347826086,
      "grad_norm": 1.50331711769104,
      "learning_rate": 7.680767825002409e-06,
      "loss": 0.1033,
      "step": 2537
    },
    {
      "epoch": 1.7241847826086958,
      "grad_norm": 3.821547746658325,
      "learning_rate": 7.673848271421166e-06,
      "loss": 0.0343,
      "step": 2538
    },
    {
      "epoch": 1.7248641304347827,
      "grad_norm": 2.338373899459839,
      "learning_rate": 7.666929895119574e-06,
      "loss": 0.103,
      "step": 2539
    },
    {
      "epoch": 1.7255434782608696,
      "grad_norm": 4.534121990203857,
      "learning_rate": 7.660012699599062e-06,
      "loss": 0.0804,
      "step": 2540
    },
    {
      "epoch": 1.7262228260869565,
      "grad_norm": 1.5545377731323242,
      "learning_rate": 7.653096688360465e-06,
      "loss": 0.1086,
      "step": 2541
    },
    {
      "epoch": 1.7269021739130435,
      "grad_norm": 2.4632482528686523,
      "learning_rate": 7.646181864904024e-06,
      "loss": 0.1032,
      "step": 2542
    },
    {
      "epoch": 1.7275815217391304,
      "grad_norm": 3.2123186588287354,
      "learning_rate": 7.639268232729369e-06,
      "loss": 0.035,
      "step": 2543
    },
    {
      "epoch": 1.7282608695652173,
      "grad_norm": 0.13703155517578125,
      "learning_rate": 7.632355795335533e-06,
      "loss": 0.001,
      "step": 2544
    },
    {
      "epoch": 1.7289402173913042,
      "grad_norm": 1.5440196990966797,
      "learning_rate": 7.6254445562209444e-06,
      "loss": 0.0181,
      "step": 2545
    },
    {
      "epoch": 1.7296195652173914,
      "grad_norm": 0.06362415850162506,
      "learning_rate": 7.6185345188834215e-06,
      "loss": 0.0007,
      "step": 2546
    },
    {
      "epoch": 1.7302989130434783,
      "grad_norm": 1.1352711915969849,
      "learning_rate": 7.611625686820177e-06,
      "loss": 0.0267,
      "step": 2547
    },
    {
      "epoch": 1.7309782608695652,
      "grad_norm": 1.3225518465042114,
      "learning_rate": 7.6047180635278135e-06,
      "loss": 0.0408,
      "step": 2548
    },
    {
      "epoch": 1.7316576086956523,
      "grad_norm": 0.7304888963699341,
      "learning_rate": 7.597811652502318e-06,
      "loss": 0.0068,
      "step": 2549
    },
    {
      "epoch": 1.7323369565217392,
      "grad_norm": 4.686365604400635,
      "learning_rate": 7.590906457239073e-06,
      "loss": 0.1089,
      "step": 2550
    },
    {
      "epoch": 1.7330163043478262,
      "grad_norm": 1.1926238536834717,
      "learning_rate": 7.584002481232841e-06,
      "loss": 0.0172,
      "step": 2551
    },
    {
      "epoch": 1.733695652173913,
      "grad_norm": 0.0070633371360599995,
      "learning_rate": 7.577099727977762e-06,
      "loss": 0.0002,
      "step": 2552
    },
    {
      "epoch": 1.734375,
      "grad_norm": 0.06340306252241135,
      "learning_rate": 7.570198200967363e-06,
      "loss": 0.0007,
      "step": 2553
    },
    {
      "epoch": 1.735054347826087,
      "grad_norm": 4.494779109954834,
      "learning_rate": 7.563297903694549e-06,
      "loss": 0.201,
      "step": 2554
    },
    {
      "epoch": 1.7357336956521738,
      "grad_norm": 1.4921114444732666,
      "learning_rate": 7.556398839651603e-06,
      "loss": 0.0507,
      "step": 2555
    },
    {
      "epoch": 1.7364130434782608,
      "grad_norm": 2.037850856781006,
      "learning_rate": 7.549501012330184e-06,
      "loss": 0.094,
      "step": 2556
    },
    {
      "epoch": 1.7370923913043477,
      "grad_norm": 0.2980026602745056,
      "learning_rate": 7.5426044252213245e-06,
      "loss": 0.0027,
      "step": 2557
    },
    {
      "epoch": 1.7377717391304348,
      "grad_norm": 0.413986474275589,
      "learning_rate": 7.5357090818154275e-06,
      "loss": 0.0043,
      "step": 2558
    },
    {
      "epoch": 1.7384510869565217,
      "grad_norm": 4.2998247146606445,
      "learning_rate": 7.528814985602273e-06,
      "loss": 0.1513,
      "step": 2559
    },
    {
      "epoch": 1.7391304347826086,
      "grad_norm": 9.451120376586914,
      "learning_rate": 7.521922140071003e-06,
      "loss": 0.0484,
      "step": 2560
    },
    {
      "epoch": 1.7398097826086958,
      "grad_norm": 3.192455768585205,
      "learning_rate": 7.515030548710127e-06,
      "loss": 0.0694,
      "step": 2561
    },
    {
      "epoch": 1.7404891304347827,
      "grad_norm": 1.4017354249954224,
      "learning_rate": 7.508140215007526e-06,
      "loss": 0.0137,
      "step": 2562
    },
    {
      "epoch": 1.7411684782608696,
      "grad_norm": 11.60051441192627,
      "learning_rate": 7.501251142450436e-06,
      "loss": 0.1112,
      "step": 2563
    },
    {
      "epoch": 1.7418478260869565,
      "grad_norm": 6.1550679206848145,
      "learning_rate": 7.4943633345254585e-06,
      "loss": 0.0533,
      "step": 2564
    },
    {
      "epoch": 1.7425271739130435,
      "grad_norm": 3.709895133972168,
      "learning_rate": 7.4874767947185586e-06,
      "loss": 0.1421,
      "step": 2565
    },
    {
      "epoch": 1.7432065217391304,
      "grad_norm": 2.914940118789673,
      "learning_rate": 7.480591526515053e-06,
      "loss": 0.1043,
      "step": 2566
    },
    {
      "epoch": 1.7438858695652173,
      "grad_norm": 0.020056378096342087,
      "learning_rate": 7.473707533399624e-06,
      "loss": 0.0004,
      "step": 2567
    },
    {
      "epoch": 1.7445652173913042,
      "grad_norm": 5.4819111824035645,
      "learning_rate": 7.466824818856296e-06,
      "loss": 0.2798,
      "step": 2568
    },
    {
      "epoch": 1.7452445652173914,
      "grad_norm": 0.2987445592880249,
      "learning_rate": 7.459943386368458e-06,
      "loss": 0.0027,
      "step": 2569
    },
    {
      "epoch": 1.7459239130434783,
      "grad_norm": 3.34014892578125,
      "learning_rate": 7.453063239418842e-06,
      "loss": 0.0973,
      "step": 2570
    },
    {
      "epoch": 1.7466032608695652,
      "grad_norm": 2.8474764823913574,
      "learning_rate": 7.446184381489533e-06,
      "loss": 0.1565,
      "step": 2571
    },
    {
      "epoch": 1.7472826086956523,
      "grad_norm": 3.9964849948883057,
      "learning_rate": 7.439306816061964e-06,
      "loss": 0.0893,
      "step": 2572
    },
    {
      "epoch": 1.7479619565217392,
      "grad_norm": 8.990806579589844,
      "learning_rate": 7.432430546616913e-06,
      "loss": 0.105,
      "step": 2573
    },
    {
      "epoch": 1.7486413043478262,
      "grad_norm": 3.238044261932373,
      "learning_rate": 7.4255555766345025e-06,
      "loss": 0.1994,
      "step": 2574
    },
    {
      "epoch": 1.749320652173913,
      "grad_norm": 5.017924785614014,
      "learning_rate": 7.4186819095941895e-06,
      "loss": 0.0754,
      "step": 2575
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.011343510821461678,
      "learning_rate": 7.411809548974792e-06,
      "loss": 0.0002,
      "step": 2576
    },
    {
      "epoch": 1.750679347826087,
      "grad_norm": 5.240862846374512,
      "learning_rate": 7.404938498254448e-06,
      "loss": 0.1856,
      "step": 2577
    },
    {
      "epoch": 1.7513586956521738,
      "grad_norm": 2.3677775859832764,
      "learning_rate": 7.398068760910637e-06,
      "loss": 0.0268,
      "step": 2578
    },
    {
      "epoch": 1.7520380434782608,
      "grad_norm": 8.147876739501953,
      "learning_rate": 7.391200340420176e-06,
      "loss": 0.1068,
      "step": 2579
    },
    {
      "epoch": 1.7527173913043477,
      "grad_norm": 2.3525261878967285,
      "learning_rate": 7.384333240259216e-06,
      "loss": 0.1401,
      "step": 2580
    },
    {
      "epoch": 1.7533967391304348,
      "grad_norm": 0.03345245495438576,
      "learning_rate": 7.3774674639032365e-06,
      "loss": 0.0006,
      "step": 2581
    },
    {
      "epoch": 1.7540760869565217,
      "grad_norm": 3.4321210384368896,
      "learning_rate": 7.370603014827049e-06,
      "loss": 0.1548,
      "step": 2582
    },
    {
      "epoch": 1.7547554347826086,
      "grad_norm": 0.016258710995316505,
      "learning_rate": 7.363739896504795e-06,
      "loss": 0.0004,
      "step": 2583
    },
    {
      "epoch": 1.7554347826086958,
      "grad_norm": 13.118325233459473,
      "learning_rate": 7.356878112409936e-06,
      "loss": 0.6131,
      "step": 2584
    },
    {
      "epoch": 1.7561141304347827,
      "grad_norm": 6.522861480712891,
      "learning_rate": 7.350017666015272e-06,
      "loss": 0.2305,
      "step": 2585
    },
    {
      "epoch": 1.7567934782608696,
      "grad_norm": 14.710443496704102,
      "learning_rate": 7.34315856079291e-06,
      "loss": 0.4127,
      "step": 2586
    },
    {
      "epoch": 1.7574728260869565,
      "grad_norm": 2.4128289222717285,
      "learning_rate": 7.336300800214289e-06,
      "loss": 0.0712,
      "step": 2587
    },
    {
      "epoch": 1.7581521739130435,
      "grad_norm": 4.850280284881592,
      "learning_rate": 7.32944438775016e-06,
      "loss": 0.4056,
      "step": 2588
    },
    {
      "epoch": 1.7588315217391304,
      "grad_norm": 4.042938232421875,
      "learning_rate": 7.322589326870597e-06,
      "loss": 0.1457,
      "step": 2589
    },
    {
      "epoch": 1.7595108695652173,
      "grad_norm": 9.930252075195312,
      "learning_rate": 7.315735621044989e-06,
      "loss": 0.2091,
      "step": 2590
    },
    {
      "epoch": 1.7601902173913042,
      "grad_norm": 1.302565574645996,
      "learning_rate": 7.3088832737420375e-06,
      "loss": 0.0589,
      "step": 2591
    },
    {
      "epoch": 1.7608695652173914,
      "grad_norm": 0.24549640715122223,
      "learning_rate": 7.3020322884297565e-06,
      "loss": 0.0022,
      "step": 2592
    },
    {
      "epoch": 1.7615489130434783,
      "grad_norm": 0.2800600528717041,
      "learning_rate": 7.295182668575475e-06,
      "loss": 0.002,
      "step": 2593
    },
    {
      "epoch": 1.7622282608695652,
      "grad_norm": 2.701612710952759,
      "learning_rate": 7.288334417645827e-06,
      "loss": 0.1549,
      "step": 2594
    },
    {
      "epoch": 1.7629076086956523,
      "grad_norm": 3.6154799461364746,
      "learning_rate": 7.281487539106752e-06,
      "loss": 0.084,
      "step": 2595
    },
    {
      "epoch": 1.7635869565217392,
      "grad_norm": 13.9185791015625,
      "learning_rate": 7.274642036423498e-06,
      "loss": 0.1938,
      "step": 2596
    },
    {
      "epoch": 1.7642663043478262,
      "grad_norm": 4.103794574737549,
      "learning_rate": 7.267797913060617e-06,
      "loss": 0.0609,
      "step": 2597
    },
    {
      "epoch": 1.764945652173913,
      "grad_norm": 4.091822147369385,
      "learning_rate": 7.260955172481959e-06,
      "loss": 0.158,
      "step": 2598
    },
    {
      "epoch": 1.765625,
      "grad_norm": 0.16382291913032532,
      "learning_rate": 7.25411381815068e-06,
      "loss": 0.0018,
      "step": 2599
    },
    {
      "epoch": 1.766304347826087,
      "grad_norm": 4.895662307739258,
      "learning_rate": 7.2472738535292295e-06,
      "loss": 0.2296,
      "step": 2600
    },
    {
      "epoch": 1.7669836956521738,
      "grad_norm": 0.047070227563381195,
      "learning_rate": 7.240435282079352e-06,
      "loss": 0.0007,
      "step": 2601
    },
    {
      "epoch": 1.7676630434782608,
      "grad_norm": 5.367059707641602,
      "learning_rate": 7.2335981072621e-06,
      "loss": 0.1918,
      "step": 2602
    },
    {
      "epoch": 1.7683423913043477,
      "grad_norm": 2.85176157951355,
      "learning_rate": 7.226762332537803e-06,
      "loss": 0.1061,
      "step": 2603
    },
    {
      "epoch": 1.7690217391304348,
      "grad_norm": 3.488435745239258,
      "learning_rate": 7.219927961366091e-06,
      "loss": 0.1029,
      "step": 2604
    },
    {
      "epoch": 1.7697010869565217,
      "grad_norm": 4.580801963806152,
      "learning_rate": 7.213094997205878e-06,
      "loss": 0.0565,
      "step": 2605
    },
    {
      "epoch": 1.7703804347826086,
      "grad_norm": 2.5028469562530518,
      "learning_rate": 7.2062634435153725e-06,
      "loss": 0.1157,
      "step": 2606
    },
    {
      "epoch": 1.7710597826086958,
      "grad_norm": 4.966559410095215,
      "learning_rate": 7.199433303752064e-06,
      "loss": 0.1225,
      "step": 2607
    },
    {
      "epoch": 1.7717391304347827,
      "grad_norm": 0.3647649586200714,
      "learning_rate": 7.192604581372727e-06,
      "loss": 0.0038,
      "step": 2608
    },
    {
      "epoch": 1.7724184782608696,
      "grad_norm": 0.6527119278907776,
      "learning_rate": 7.185777279833421e-06,
      "loss": 0.0047,
      "step": 2609
    },
    {
      "epoch": 1.7730978260869565,
      "grad_norm": 2.1404991149902344,
      "learning_rate": 7.178951402589482e-06,
      "loss": 0.121,
      "step": 2610
    },
    {
      "epoch": 1.7737771739130435,
      "grad_norm": 19.67093276977539,
      "learning_rate": 7.172126953095535e-06,
      "loss": 0.362,
      "step": 2611
    },
    {
      "epoch": 1.7744565217391304,
      "grad_norm": 2.049420118331909,
      "learning_rate": 7.165303934805472e-06,
      "loss": 0.0647,
      "step": 2612
    },
    {
      "epoch": 1.7751358695652173,
      "grad_norm": 0.01663811504840851,
      "learning_rate": 7.158482351172465e-06,
      "loss": 0.0003,
      "step": 2613
    },
    {
      "epoch": 1.7758152173913042,
      "grad_norm": 0.05700790882110596,
      "learning_rate": 7.151662205648959e-06,
      "loss": 0.0005,
      "step": 2614
    },
    {
      "epoch": 1.7764945652173914,
      "grad_norm": 2.662175416946411,
      "learning_rate": 7.144843501686671e-06,
      "loss": 0.0641,
      "step": 2615
    },
    {
      "epoch": 1.7771739130434783,
      "grad_norm": 0.09771604835987091,
      "learning_rate": 7.1380262427365885e-06,
      "loss": 0.0015,
      "step": 2616
    },
    {
      "epoch": 1.7778532608695652,
      "grad_norm": 20.226587295532227,
      "learning_rate": 7.131210432248969e-06,
      "loss": 0.1377,
      "step": 2617
    },
    {
      "epoch": 1.7785326086956523,
      "grad_norm": 1.824257493019104,
      "learning_rate": 7.124396073673334e-06,
      "loss": 0.0141,
      "step": 2618
    },
    {
      "epoch": 1.7792119565217392,
      "grad_norm": 6.469019412994385,
      "learning_rate": 7.117583170458478e-06,
      "loss": 0.1312,
      "step": 2619
    },
    {
      "epoch": 1.7798913043478262,
      "grad_norm": 7.318963050842285,
      "learning_rate": 7.110771726052446e-06,
      "loss": 0.2035,
      "step": 2620
    },
    {
      "epoch": 1.780570652173913,
      "grad_norm": 1.9073201417922974,
      "learning_rate": 7.103961743902554e-06,
      "loss": 0.0717,
      "step": 2621
    },
    {
      "epoch": 1.78125,
      "grad_norm": 3.4312007427215576,
      "learning_rate": 7.097153227455379e-06,
      "loss": 0.1924,
      "step": 2622
    },
    {
      "epoch": 1.781929347826087,
      "grad_norm": 6.129371643066406,
      "learning_rate": 7.090346180156747e-06,
      "loss": 0.1775,
      "step": 2623
    },
    {
      "epoch": 1.7826086956521738,
      "grad_norm": 3.60223388671875,
      "learning_rate": 7.0835406054517505e-06,
      "loss": 0.183,
      "step": 2624
    },
    {
      "epoch": 1.7832880434782608,
      "grad_norm": 0.01997990719974041,
      "learning_rate": 7.076736506784734e-06,
      "loss": 0.0005,
      "step": 2625
    },
    {
      "epoch": 1.7839673913043477,
      "grad_norm": 1.4098424911499023,
      "learning_rate": 7.06993388759929e-06,
      "loss": 0.0338,
      "step": 2626
    },
    {
      "epoch": 1.7846467391304348,
      "grad_norm": 1.957072377204895,
      "learning_rate": 7.063132751338265e-06,
      "loss": 0.152,
      "step": 2627
    },
    {
      "epoch": 1.7853260869565217,
      "grad_norm": 0.5038583278656006,
      "learning_rate": 7.056333101443761e-06,
      "loss": 0.0067,
      "step": 2628
    },
    {
      "epoch": 1.7860054347826086,
      "grad_norm": 17.930574417114258,
      "learning_rate": 7.049534941357118e-06,
      "loss": 0.177,
      "step": 2629
    },
    {
      "epoch": 1.7866847826086958,
      "grad_norm": 0.014969118870794773,
      "learning_rate": 7.042738274518928e-06,
      "loss": 0.0003,
      "step": 2630
    },
    {
      "epoch": 1.7873641304347827,
      "grad_norm": 0.06005610525608063,
      "learning_rate": 7.035943104369026e-06,
      "loss": 0.0005,
      "step": 2631
    },
    {
      "epoch": 1.7880434782608696,
      "grad_norm": 13.570069313049316,
      "learning_rate": 7.0291494343464896e-06,
      "loss": 0.4399,
      "step": 2632
    },
    {
      "epoch": 1.7887228260869565,
      "grad_norm": 3.8782472610473633,
      "learning_rate": 7.0223572678896345e-06,
      "loss": 0.1263,
      "step": 2633
    },
    {
      "epoch": 1.7894021739130435,
      "grad_norm": 15.365872383117676,
      "learning_rate": 7.01556660843602e-06,
      "loss": 0.8032,
      "step": 2634
    },
    {
      "epoch": 1.7900815217391304,
      "grad_norm": 2.8094069957733154,
      "learning_rate": 7.008777459422436e-06,
      "loss": 0.1586,
      "step": 2635
    },
    {
      "epoch": 1.7907608695652173,
      "grad_norm": 3.7284111976623535,
      "learning_rate": 7.001989824284919e-06,
      "loss": 0.1619,
      "step": 2636
    },
    {
      "epoch": 1.7914402173913042,
      "grad_norm": 1.7790230512619019,
      "learning_rate": 6.995203706458731e-06,
      "loss": 0.1096,
      "step": 2637
    },
    {
      "epoch": 1.7921195652173914,
      "grad_norm": 7.967321395874023,
      "learning_rate": 6.988419109378367e-06,
      "loss": 0.3991,
      "step": 2638
    },
    {
      "epoch": 1.7927989130434783,
      "grad_norm": 8.074838638305664,
      "learning_rate": 6.981636036477553e-06,
      "loss": 0.4269,
      "step": 2639
    },
    {
      "epoch": 1.7934782608695652,
      "grad_norm": 1.5145574808120728,
      "learning_rate": 6.974854491189243e-06,
      "loss": 0.0117,
      "step": 2640
    },
    {
      "epoch": 1.7941576086956523,
      "grad_norm": 1.0582233667373657,
      "learning_rate": 6.968074476945621e-06,
      "loss": 0.0238,
      "step": 2641
    },
    {
      "epoch": 1.7948369565217392,
      "grad_norm": 0.2207939177751541,
      "learning_rate": 6.96129599717809e-06,
      "loss": 0.0018,
      "step": 2642
    },
    {
      "epoch": 1.7955163043478262,
      "grad_norm": 9.500417709350586,
      "learning_rate": 6.9545190553172836e-06,
      "loss": 0.2907,
      "step": 2643
    },
    {
      "epoch": 1.796195652173913,
      "grad_norm": 4.118831634521484,
      "learning_rate": 6.947743654793049e-06,
      "loss": 0.1353,
      "step": 2644
    },
    {
      "epoch": 1.796875,
      "grad_norm": 0.038477104157209396,
      "learning_rate": 6.940969799034465e-06,
      "loss": 0.0006,
      "step": 2645
    },
    {
      "epoch": 1.797554347826087,
      "grad_norm": 8.243051528930664,
      "learning_rate": 6.934197491469818e-06,
      "loss": 0.111,
      "step": 2646
    },
    {
      "epoch": 1.7982336956521738,
      "grad_norm": 5.3353166580200195,
      "learning_rate": 6.927426735526612e-06,
      "loss": 0.0348,
      "step": 2647
    },
    {
      "epoch": 1.7989130434782608,
      "grad_norm": 9.073705673217773,
      "learning_rate": 6.920657534631573e-06,
      "loss": 0.3926,
      "step": 2648
    },
    {
      "epoch": 1.7995923913043477,
      "grad_norm": 0.03343486413359642,
      "learning_rate": 6.913889892210631e-06,
      "loss": 0.0005,
      "step": 2649
    },
    {
      "epoch": 1.8002717391304348,
      "grad_norm": 2.189840078353882,
      "learning_rate": 6.907123811688934e-06,
      "loss": 0.0987,
      "step": 2650
    },
    {
      "epoch": 1.8009510869565217,
      "grad_norm": 2.492534637451172,
      "learning_rate": 6.900359296490834e-06,
      "loss": 0.1199,
      "step": 2651
    },
    {
      "epoch": 1.8016304347826086,
      "grad_norm": 5.326902866363525,
      "learning_rate": 6.893596350039896e-06,
      "loss": 0.0509,
      "step": 2652
    },
    {
      "epoch": 1.8023097826086958,
      "grad_norm": 4.5662007331848145,
      "learning_rate": 6.886834975758885e-06,
      "loss": 0.1106,
      "step": 2653
    },
    {
      "epoch": 1.8029891304347827,
      "grad_norm": 0.01657174713909626,
      "learning_rate": 6.880075177069779e-06,
      "loss": 0.0003,
      "step": 2654
    },
    {
      "epoch": 1.8036684782608696,
      "grad_norm": 1.7242017984390259,
      "learning_rate": 6.873316957393752e-06,
      "loss": 0.0551,
      "step": 2655
    },
    {
      "epoch": 1.8043478260869565,
      "grad_norm": 4.060439109802246,
      "learning_rate": 6.866560320151179e-06,
      "loss": 0.0464,
      "step": 2656
    },
    {
      "epoch": 1.8050271739130435,
      "grad_norm": 1.2172794342041016,
      "learning_rate": 6.859805268761637e-06,
      "loss": 0.0422,
      "step": 2657
    },
    {
      "epoch": 1.8057065217391304,
      "grad_norm": 8.258342742919922,
      "learning_rate": 6.853051806643898e-06,
      "loss": 0.1942,
      "step": 2658
    },
    {
      "epoch": 1.8063858695652173,
      "grad_norm": 0.07852007448673248,
      "learning_rate": 6.84629993721593e-06,
      "loss": 0.0008,
      "step": 2659
    },
    {
      "epoch": 1.8070652173913042,
      "grad_norm": 4.687266826629639,
      "learning_rate": 6.839549663894897e-06,
      "loss": 0.1869,
      "step": 2660
    },
    {
      "epoch": 1.8077445652173914,
      "grad_norm": 10.823945045471191,
      "learning_rate": 6.832800990097148e-06,
      "loss": 0.2164,
      "step": 2661
    },
    {
      "epoch": 1.8084239130434783,
      "grad_norm": 3.1624512672424316,
      "learning_rate": 6.826053919238238e-06,
      "loss": 0.2236,
      "step": 2662
    },
    {
      "epoch": 1.8091032608695652,
      "grad_norm": 2.3527371883392334,
      "learning_rate": 6.819308454732896e-06,
      "loss": 0.1566,
      "step": 2663
    },
    {
      "epoch": 1.8097826086956523,
      "grad_norm": 1.4137752056121826,
      "learning_rate": 6.812564599995042e-06,
      "loss": 0.0438,
      "step": 2664
    },
    {
      "epoch": 1.8104619565217392,
      "grad_norm": 6.5577874183654785,
      "learning_rate": 6.805822358437784e-06,
      "loss": 0.0621,
      "step": 2665
    },
    {
      "epoch": 1.8111413043478262,
      "grad_norm": 6.011987686157227,
      "learning_rate": 6.799081733473411e-06,
      "loss": 0.2914,
      "step": 2666
    },
    {
      "epoch": 1.811820652173913,
      "grad_norm": 0.0148671455681324,
      "learning_rate": 6.7923427285133945e-06,
      "loss": 0.0004,
      "step": 2667
    },
    {
      "epoch": 1.8125,
      "grad_norm": 3.2822422981262207,
      "learning_rate": 6.785605346968387e-06,
      "loss": 0.1312,
      "step": 2668
    },
    {
      "epoch": 1.813179347826087,
      "grad_norm": 3.007697820663452,
      "learning_rate": 6.778869592248217e-06,
      "loss": 0.1552,
      "step": 2669
    },
    {
      "epoch": 1.8138586956521738,
      "grad_norm": 6.959433078765869,
      "learning_rate": 6.772135467761889e-06,
      "loss": 0.1854,
      "step": 2670
    },
    {
      "epoch": 1.8145380434782608,
      "grad_norm": 0.5504086017608643,
      "learning_rate": 6.765402976917591e-06,
      "loss": 0.0049,
      "step": 2671
    },
    {
      "epoch": 1.8152173913043477,
      "grad_norm": 0.15005850791931152,
      "learning_rate": 6.758672123122675e-06,
      "loss": 0.0014,
      "step": 2672
    },
    {
      "epoch": 1.8158967391304348,
      "grad_norm": 2.36184024810791,
      "learning_rate": 6.7519429097836675e-06,
      "loss": 0.0434,
      "step": 2673
    },
    {
      "epoch": 1.8165760869565217,
      "grad_norm": 1.582832932472229,
      "learning_rate": 6.745215340306264e-06,
      "loss": 0.0969,
      "step": 2674
    },
    {
      "epoch": 1.8172554347826086,
      "grad_norm": 5.7578959465026855,
      "learning_rate": 6.738489418095329e-06,
      "loss": 0.15,
      "step": 2675
    },
    {
      "epoch": 1.8179347826086958,
      "grad_norm": 2.5002903938293457,
      "learning_rate": 6.731765146554891e-06,
      "loss": 0.1232,
      "step": 2676
    },
    {
      "epoch": 1.8186141304347827,
      "grad_norm": 1.3366527557373047,
      "learning_rate": 6.72504252908815e-06,
      "loss": 0.0121,
      "step": 2677
    },
    {
      "epoch": 1.8192934782608696,
      "grad_norm": 12.423142433166504,
      "learning_rate": 6.718321569097459e-06,
      "loss": 0.6111,
      "step": 2678
    },
    {
      "epoch": 1.8199728260869565,
      "grad_norm": 0.08915111422538757,
      "learning_rate": 6.711602269984339e-06,
      "loss": 0.0009,
      "step": 2679
    },
    {
      "epoch": 1.8206521739130435,
      "grad_norm": 4.240799427032471,
      "learning_rate": 6.704884635149467e-06,
      "loss": 0.2008,
      "step": 2680
    },
    {
      "epoch": 1.8213315217391304,
      "grad_norm": 5.853081703186035,
      "learning_rate": 6.698168667992681e-06,
      "loss": 0.2473,
      "step": 2681
    },
    {
      "epoch": 1.8220108695652173,
      "grad_norm": 3.19089937210083,
      "learning_rate": 6.691454371912974e-06,
      "loss": 0.0745,
      "step": 2682
    },
    {
      "epoch": 1.8226902173913042,
      "grad_norm": 0.024351703003048897,
      "learning_rate": 6.68474175030849e-06,
      "loss": 0.0003,
      "step": 2683
    },
    {
      "epoch": 1.8233695652173914,
      "grad_norm": 12.381834030151367,
      "learning_rate": 6.67803080657653e-06,
      "loss": 0.5156,
      "step": 2684
    },
    {
      "epoch": 1.8240489130434783,
      "grad_norm": 0.07064329832792282,
      "learning_rate": 6.6713215441135424e-06,
      "loss": 0.0009,
      "step": 2685
    },
    {
      "epoch": 1.8247282608695652,
      "grad_norm": 15.839860916137695,
      "learning_rate": 6.664613966315127e-06,
      "loss": 0.4097,
      "step": 2686
    },
    {
      "epoch": 1.8254076086956523,
      "grad_norm": 3.0568628311157227,
      "learning_rate": 6.657908076576028e-06,
      "loss": 0.1657,
      "step": 2687
    },
    {
      "epoch": 1.8260869565217392,
      "grad_norm": 6.794680595397949,
      "learning_rate": 6.651203878290139e-06,
      "loss": 0.03,
      "step": 2688
    },
    {
      "epoch": 1.8267663043478262,
      "grad_norm": 6.948114395141602,
      "learning_rate": 6.644501374850496e-06,
      "loss": 0.1723,
      "step": 2689
    },
    {
      "epoch": 1.827445652173913,
      "grad_norm": 0.1234983429312706,
      "learning_rate": 6.637800569649278e-06,
      "loss": 0.0012,
      "step": 2690
    },
    {
      "epoch": 1.828125,
      "grad_norm": 3.5045599937438965,
      "learning_rate": 6.631101466077801e-06,
      "loss": 0.121,
      "step": 2691
    },
    {
      "epoch": 1.828804347826087,
      "grad_norm": 10.118956565856934,
      "learning_rate": 6.624404067526524e-06,
      "loss": 0.2571,
      "step": 2692
    },
    {
      "epoch": 1.8294836956521738,
      "grad_norm": 3.5711586475372314,
      "learning_rate": 6.617708377385041e-06,
      "loss": 0.0858,
      "step": 2693
    },
    {
      "epoch": 1.8301630434782608,
      "grad_norm": 3.7671501636505127,
      "learning_rate": 6.6110143990420824e-06,
      "loss": 0.1305,
      "step": 2694
    },
    {
      "epoch": 1.8308423913043477,
      "grad_norm": 0.012115448713302612,
      "learning_rate": 6.604322135885513e-06,
      "loss": 0.0002,
      "step": 2695
    },
    {
      "epoch": 1.8315217391304348,
      "grad_norm": 0.2417193055152893,
      "learning_rate": 6.597631591302319e-06,
      "loss": 0.0022,
      "step": 2696
    },
    {
      "epoch": 1.8322010869565217,
      "grad_norm": 0.030269701033830643,
      "learning_rate": 6.5909427686786386e-06,
      "loss": 0.0005,
      "step": 2697
    },
    {
      "epoch": 1.8328804347826086,
      "grad_norm": 11.478096961975098,
      "learning_rate": 6.584255671399722e-06,
      "loss": 0.2626,
      "step": 2698
    },
    {
      "epoch": 1.8335597826086958,
      "grad_norm": 0.04683167487382889,
      "learning_rate": 6.577570302849947e-06,
      "loss": 0.0004,
      "step": 2699
    },
    {
      "epoch": 1.8342391304347827,
      "grad_norm": 4.34712028503418,
      "learning_rate": 6.570886666412823e-06,
      "loss": 0.1185,
      "step": 2700
    },
    {
      "epoch": 1.8349184782608696,
      "grad_norm": 12.505964279174805,
      "learning_rate": 6.564204765470978e-06,
      "loss": 0.5475,
      "step": 2701
    },
    {
      "epoch": 1.8355978260869565,
      "grad_norm": 0.03687872365117073,
      "learning_rate": 6.557524603406162e-06,
      "loss": 0.0005,
      "step": 2702
    },
    {
      "epoch": 1.8362771739130435,
      "grad_norm": 4.45965051651001,
      "learning_rate": 6.550846183599249e-06,
      "loss": 0.0376,
      "step": 2703
    },
    {
      "epoch": 1.8369565217391304,
      "grad_norm": 4.703202724456787,
      "learning_rate": 6.544169509430219e-06,
      "loss": 0.1157,
      "step": 2704
    },
    {
      "epoch": 1.8376358695652173,
      "grad_norm": 4.606138229370117,
      "learning_rate": 6.53749458427819e-06,
      "loss": 0.275,
      "step": 2705
    },
    {
      "epoch": 1.8383152173913042,
      "grad_norm": 1.83762526512146,
      "learning_rate": 6.5308214115213785e-06,
      "loss": 0.012,
      "step": 2706
    },
    {
      "epoch": 1.8389945652173914,
      "grad_norm": 1.3661328554153442,
      "learning_rate": 6.524149994537117e-06,
      "loss": 0.0096,
      "step": 2707
    },
    {
      "epoch": 1.8396739130434783,
      "grad_norm": 0.014700442552566528,
      "learning_rate": 6.5174803367018495e-06,
      "loss": 0.0004,
      "step": 2708
    },
    {
      "epoch": 1.8403532608695652,
      "grad_norm": 7.794834136962891,
      "learning_rate": 6.510812441391131e-06,
      "loss": 0.1859,
      "step": 2709
    },
    {
      "epoch": 1.8410326086956523,
      "grad_norm": 6.424923419952393,
      "learning_rate": 6.504146311979627e-06,
      "loss": 0.1788,
      "step": 2710
    },
    {
      "epoch": 1.8417119565217392,
      "grad_norm": 5.865367412567139,
      "learning_rate": 6.497481951841102e-06,
      "loss": 0.3583,
      "step": 2711
    },
    {
      "epoch": 1.8423913043478262,
      "grad_norm": 4.132260322570801,
      "learning_rate": 6.490819364348434e-06,
      "loss": 0.1948,
      "step": 2712
    },
    {
      "epoch": 1.843070652173913,
      "grad_norm": 3.9324004650115967,
      "learning_rate": 6.484158552873594e-06,
      "loss": 0.2298,
      "step": 2713
    },
    {
      "epoch": 1.84375,
      "grad_norm": 3.861067771911621,
      "learning_rate": 6.4774995207876654e-06,
      "loss": 0.0422,
      "step": 2714
    },
    {
      "epoch": 1.844429347826087,
      "grad_norm": 6.336215496063232,
      "learning_rate": 6.470842271460823e-06,
      "loss": 0.2891,
      "step": 2715
    },
    {
      "epoch": 1.8451086956521738,
      "grad_norm": 12.171527862548828,
      "learning_rate": 6.464186808262341e-06,
      "loss": 0.2755,
      "step": 2716
    },
    {
      "epoch": 1.8457880434782608,
      "grad_norm": 2.390901565551758,
      "learning_rate": 6.45753313456059e-06,
      "loss": 0.1138,
      "step": 2717
    },
    {
      "epoch": 1.8464673913043477,
      "grad_norm": 4.763308525085449,
      "learning_rate": 6.450881253723035e-06,
      "loss": 0.2346,
      "step": 2718
    },
    {
      "epoch": 1.8471467391304348,
      "grad_norm": 0.2843592166900635,
      "learning_rate": 6.444231169116233e-06,
      "loss": 0.0029,
      "step": 2719
    },
    {
      "epoch": 1.8478260869565217,
      "grad_norm": 2.3096137046813965,
      "learning_rate": 6.437582884105835e-06,
      "loss": 0.0271,
      "step": 2720
    },
    {
      "epoch": 1.8485054347826086,
      "grad_norm": 2.8052115440368652,
      "learning_rate": 6.430936402056577e-06,
      "loss": 0.1537,
      "step": 2721
    },
    {
      "epoch": 1.8491847826086958,
      "grad_norm": 0.8419730067253113,
      "learning_rate": 6.42429172633228e-06,
      "loss": 0.0072,
      "step": 2722
    },
    {
      "epoch": 1.8498641304347827,
      "grad_norm": 8.886357307434082,
      "learning_rate": 6.417648860295864e-06,
      "loss": 0.2029,
      "step": 2723
    },
    {
      "epoch": 1.8505434782608696,
      "grad_norm": 0.0637584775686264,
      "learning_rate": 6.41100780730932e-06,
      "loss": 0.0007,
      "step": 2724
    },
    {
      "epoch": 1.8512228260869565,
      "grad_norm": 8.817179679870605,
      "learning_rate": 6.4043685707337255e-06,
      "loss": 0.2167,
      "step": 2725
    },
    {
      "epoch": 1.8519021739130435,
      "grad_norm": 2.6361896991729736,
      "learning_rate": 6.397731153929239e-06,
      "loss": 0.1495,
      "step": 2726
    },
    {
      "epoch": 1.8525815217391304,
      "grad_norm": 3.4625895023345947,
      "learning_rate": 6.391095560255098e-06,
      "loss": 0.1843,
      "step": 2727
    },
    {
      "epoch": 1.8532608695652173,
      "grad_norm": 0.4083709120750427,
      "learning_rate": 6.384461793069616e-06,
      "loss": 0.0034,
      "step": 2728
    },
    {
      "epoch": 1.8539402173913042,
      "grad_norm": 6.890499114990234,
      "learning_rate": 6.377829855730185e-06,
      "loss": 0.282,
      "step": 2729
    },
    {
      "epoch": 1.8546195652173914,
      "grad_norm": 0.19410450756549835,
      "learning_rate": 6.371199751593264e-06,
      "loss": 0.0021,
      "step": 2730
    },
    {
      "epoch": 1.8552989130434783,
      "grad_norm": 0.7319960594177246,
      "learning_rate": 6.3645714840143965e-06,
      "loss": 0.0044,
      "step": 2731
    },
    {
      "epoch": 1.8559782608695652,
      "grad_norm": 3.1363630294799805,
      "learning_rate": 6.3579450563481895e-06,
      "loss": 0.0927,
      "step": 2732
    },
    {
      "epoch": 1.8566576086956523,
      "grad_norm": 5.370767593383789,
      "learning_rate": 6.351320471948313e-06,
      "loss": 0.228,
      "step": 2733
    },
    {
      "epoch": 1.8573369565217392,
      "grad_norm": 0.06183743104338646,
      "learning_rate": 6.3446977341675135e-06,
      "loss": 0.0007,
      "step": 2734
    },
    {
      "epoch": 1.8580163043478262,
      "grad_norm": 5.263754367828369,
      "learning_rate": 6.338076846357597e-06,
      "loss": 0.26,
      "step": 2735
    },
    {
      "epoch": 1.858695652173913,
      "grad_norm": 3.5490219593048096,
      "learning_rate": 6.331457811869437e-06,
      "loss": 0.1197,
      "step": 2736
    },
    {
      "epoch": 1.859375,
      "grad_norm": 2.865840435028076,
      "learning_rate": 6.3248406340529665e-06,
      "loss": 0.2013,
      "step": 2737
    },
    {
      "epoch": 1.860054347826087,
      "grad_norm": 0.02197406254708767,
      "learning_rate": 6.31822531625718e-06,
      "loss": 0.0003,
      "step": 2738
    },
    {
      "epoch": 1.8607336956521738,
      "grad_norm": 2.371407985687256,
      "learning_rate": 6.311611861830129e-06,
      "loss": 0.1255,
      "step": 2739
    },
    {
      "epoch": 1.8614130434782608,
      "grad_norm": 0.07744115591049194,
      "learning_rate": 6.305000274118926e-06,
      "loss": 0.0007,
      "step": 2740
    },
    {
      "epoch": 1.8620923913043477,
      "grad_norm": 1.761040210723877,
      "learning_rate": 6.298390556469735e-06,
      "loss": 0.1725,
      "step": 2741
    },
    {
      "epoch": 1.8627717391304348,
      "grad_norm": 1.4121298789978027,
      "learning_rate": 6.291782712227776e-06,
      "loss": 0.0991,
      "step": 2742
    },
    {
      "epoch": 1.8634510869565217,
      "grad_norm": 2.0253310203552246,
      "learning_rate": 6.285176744737318e-06,
      "loss": 0.0859,
      "step": 2743
    },
    {
      "epoch": 1.8641304347826086,
      "grad_norm": 0.17129798233509064,
      "learning_rate": 6.278572657341682e-06,
      "loss": 0.0018,
      "step": 2744
    },
    {
      "epoch": 1.8648097826086958,
      "grad_norm": 4.114361763000488,
      "learning_rate": 6.271970453383235e-06,
      "loss": 0.164,
      "step": 2745
    },
    {
      "epoch": 1.8654891304347827,
      "grad_norm": 14.598546981811523,
      "learning_rate": 6.265370136203396e-06,
      "loss": 0.2297,
      "step": 2746
    },
    {
      "epoch": 1.8661684782608696,
      "grad_norm": 1.9609136581420898,
      "learning_rate": 6.258771709142623e-06,
      "loss": 0.0846,
      "step": 2747
    },
    {
      "epoch": 1.8668478260869565,
      "grad_norm": 0.03691282123327255,
      "learning_rate": 6.2521751755404226e-06,
      "loss": 0.0004,
      "step": 2748
    },
    {
      "epoch": 1.8675271739130435,
      "grad_norm": 0.20767056941986084,
      "learning_rate": 6.245580538735341e-06,
      "loss": 0.0018,
      "step": 2749
    },
    {
      "epoch": 1.8682065217391304,
      "grad_norm": 3.7286036014556885,
      "learning_rate": 6.238987802064964e-06,
      "loss": 0.0418,
      "step": 2750
    },
    {
      "epoch": 1.8688858695652173,
      "grad_norm": 2.434075355529785,
      "learning_rate": 6.232396968865916e-06,
      "loss": 0.0628,
      "step": 2751
    },
    {
      "epoch": 1.8695652173913042,
      "grad_norm": 3.292658567428589,
      "learning_rate": 6.225808042473857e-06,
      "loss": 0.1942,
      "step": 2752
    },
    {
      "epoch": 1.8702445652173914,
      "grad_norm": 4.999084949493408,
      "learning_rate": 6.219221026223485e-06,
      "loss": 0.2056,
      "step": 2753
    },
    {
      "epoch": 1.8709239130434783,
      "grad_norm": 0.2439086139202118,
      "learning_rate": 6.212635923448526e-06,
      "loss": 0.002,
      "step": 2754
    },
    {
      "epoch": 1.8716032608695652,
      "grad_norm": 5.950164794921875,
      "learning_rate": 6.2060527374817455e-06,
      "loss": 0.1401,
      "step": 2755
    },
    {
      "epoch": 1.8722826086956523,
      "grad_norm": 0.1405923068523407,
      "learning_rate": 6.199471471654928e-06,
      "loss": 0.0016,
      "step": 2756
    },
    {
      "epoch": 1.8729619565217392,
      "grad_norm": 0.40074077248573303,
      "learning_rate": 6.192892129298898e-06,
      "loss": 0.0047,
      "step": 2757
    },
    {
      "epoch": 1.8736413043478262,
      "grad_norm": 13.005843162536621,
      "learning_rate": 6.1863147137435e-06,
      "loss": 0.4309,
      "step": 2758
    },
    {
      "epoch": 1.874320652173913,
      "grad_norm": 0.052687130868434906,
      "learning_rate": 6.179739228317605e-06,
      "loss": 0.0007,
      "step": 2759
    },
    {
      "epoch": 1.875,
      "grad_norm": 4.45760440826416,
      "learning_rate": 6.173165676349103e-06,
      "loss": 0.2273,
      "step": 2760
    },
    {
      "epoch": 1.875679347826087,
      "grad_norm": 1.8001681566238403,
      "learning_rate": 6.166594061164912e-06,
      "loss": 0.0225,
      "step": 2761
    },
    {
      "epoch": 1.8763586956521738,
      "grad_norm": 3.5181453227996826,
      "learning_rate": 6.160024386090966e-06,
      "loss": 0.1309,
      "step": 2762
    },
    {
      "epoch": 1.8770380434782608,
      "grad_norm": 1.717043399810791,
      "learning_rate": 6.1534566544522175e-06,
      "loss": 0.0426,
      "step": 2763
    },
    {
      "epoch": 1.8777173913043477,
      "grad_norm": 9.5433988571167,
      "learning_rate": 6.146890869572637e-06,
      "loss": 0.1257,
      "step": 2764
    },
    {
      "epoch": 1.8783967391304348,
      "grad_norm": 0.19799019396305084,
      "learning_rate": 6.140327034775202e-06,
      "loss": 0.0024,
      "step": 2765
    },
    {
      "epoch": 1.8790760869565217,
      "grad_norm": 0.11988475918769836,
      "learning_rate": 6.133765153381918e-06,
      "loss": 0.0011,
      "step": 2766
    },
    {
      "epoch": 1.8797554347826086,
      "grad_norm": 6.295966625213623,
      "learning_rate": 6.127205228713791e-06,
      "loss": 0.1636,
      "step": 2767
    },
    {
      "epoch": 1.8804347826086958,
      "grad_norm": 9.704166412353516,
      "learning_rate": 6.120647264090839e-06,
      "loss": 0.1512,
      "step": 2768
    },
    {
      "epoch": 1.8811141304347827,
      "grad_norm": 1.665753960609436,
      "learning_rate": 6.114091262832087e-06,
      "loss": 0.0923,
      "step": 2769
    },
    {
      "epoch": 1.8817934782608696,
      "grad_norm": 2.3110759258270264,
      "learning_rate": 6.107537228255568e-06,
      "loss": 0.1275,
      "step": 2770
    },
    {
      "epoch": 1.8824728260869565,
      "grad_norm": 4.698545455932617,
      "learning_rate": 6.100985163678319e-06,
      "loss": 0.1595,
      "step": 2771
    },
    {
      "epoch": 1.8831521739130435,
      "grad_norm": 0.14582523703575134,
      "learning_rate": 6.094435072416379e-06,
      "loss": 0.0015,
      "step": 2772
    },
    {
      "epoch": 1.8838315217391304,
      "grad_norm": 1.9511711597442627,
      "learning_rate": 6.08788695778479e-06,
      "loss": 0.0219,
      "step": 2773
    },
    {
      "epoch": 1.8845108695652173,
      "grad_norm": 8.297882080078125,
      "learning_rate": 6.0813408230975935e-06,
      "loss": 0.3016,
      "step": 2774
    },
    {
      "epoch": 1.8851902173913042,
      "grad_norm": 0.5246710777282715,
      "learning_rate": 6.074796671667829e-06,
      "loss": 0.005,
      "step": 2775
    },
    {
      "epoch": 1.8858695652173914,
      "grad_norm": 0.0744977593421936,
      "learning_rate": 6.0682545068075315e-06,
      "loss": 0.0008,
      "step": 2776
    },
    {
      "epoch": 1.8865489130434783,
      "grad_norm": 9.78244686126709,
      "learning_rate": 6.0617143318277286e-06,
      "loss": 0.2522,
      "step": 2777
    },
    {
      "epoch": 1.8872282608695652,
      "grad_norm": 0.113547183573246,
      "learning_rate": 6.055176150038445e-06,
      "loss": 0.0013,
      "step": 2778
    },
    {
      "epoch": 1.8879076086956523,
      "grad_norm": 0.2659064829349518,
      "learning_rate": 6.048639964748695e-06,
      "loss": 0.0024,
      "step": 2779
    },
    {
      "epoch": 1.8885869565217392,
      "grad_norm": 4.212218761444092,
      "learning_rate": 6.042105779266479e-06,
      "loss": 0.1516,
      "step": 2780
    },
    {
      "epoch": 1.8892663043478262,
      "grad_norm": 3.220858573913574,
      "learning_rate": 6.035573596898789e-06,
      "loss": 0.0462,
      "step": 2781
    },
    {
      "epoch": 1.889945652173913,
      "grad_norm": 3.330050230026245,
      "learning_rate": 6.029043420951606e-06,
      "loss": 0.0795,
      "step": 2782
    },
    {
      "epoch": 1.890625,
      "grad_norm": 0.005109875928610563,
      "learning_rate": 6.02251525472989e-06,
      "loss": 0.0002,
      "step": 2783
    },
    {
      "epoch": 1.891304347826087,
      "grad_norm": 5.8356099128723145,
      "learning_rate": 6.015989101537586e-06,
      "loss": 0.1639,
      "step": 2784
    },
    {
      "epoch": 1.8919836956521738,
      "grad_norm": 21.75616455078125,
      "learning_rate": 6.009464964677621e-06,
      "loss": 0.7234,
      "step": 2785
    },
    {
      "epoch": 1.8926630434782608,
      "grad_norm": 1.881855845451355,
      "learning_rate": 6.002942847451898e-06,
      "loss": 0.0146,
      "step": 2786
    },
    {
      "epoch": 1.8933423913043477,
      "grad_norm": 1.628313660621643,
      "learning_rate": 5.996422753161304e-06,
      "loss": 0.0825,
      "step": 2787
    },
    {
      "epoch": 1.8940217391304348,
      "grad_norm": 0.13699989020824432,
      "learning_rate": 5.989904685105696e-06,
      "loss": 0.0014,
      "step": 2788
    },
    {
      "epoch": 1.8947010869565217,
      "grad_norm": 0.785301923751831,
      "learning_rate": 5.98338864658391e-06,
      "loss": 0.0079,
      "step": 2789
    },
    {
      "epoch": 1.8953804347826086,
      "grad_norm": 0.41833892464637756,
      "learning_rate": 5.976874640893751e-06,
      "loss": 0.0029,
      "step": 2790
    },
    {
      "epoch": 1.8960597826086958,
      "grad_norm": 0.7133172154426575,
      "learning_rate": 5.970362671331995e-06,
      "loss": 0.0041,
      "step": 2791
    },
    {
      "epoch": 1.8967391304347827,
      "grad_norm": 15.427908897399902,
      "learning_rate": 5.963852741194397e-06,
      "loss": 0.2976,
      "step": 2792
    },
    {
      "epoch": 1.8974184782608696,
      "grad_norm": 1.7878010272979736,
      "learning_rate": 5.957344853775668e-06,
      "loss": 0.084,
      "step": 2793
    },
    {
      "epoch": 1.8980978260869565,
      "grad_norm": 0.071344293653965,
      "learning_rate": 5.950839012369491e-06,
      "loss": 0.0007,
      "step": 2794
    },
    {
      "epoch": 1.8987771739130435,
      "grad_norm": 0.1082598865032196,
      "learning_rate": 5.944335220268512e-06,
      "loss": 0.0012,
      "step": 2795
    },
    {
      "epoch": 1.8994565217391304,
      "grad_norm": 9.696215629577637,
      "learning_rate": 5.937833480764339e-06,
      "loss": 0.2831,
      "step": 2796
    },
    {
      "epoch": 1.9001358695652173,
      "grad_norm": 2.3258376121520996,
      "learning_rate": 5.931333797147543e-06,
      "loss": 0.183,
      "step": 2797
    },
    {
      "epoch": 1.9008152173913042,
      "grad_norm": 4.197210788726807,
      "learning_rate": 5.924836172707653e-06,
      "loss": 0.243,
      "step": 2798
    },
    {
      "epoch": 1.9014945652173914,
      "grad_norm": 2.8173060417175293,
      "learning_rate": 5.918340610733154e-06,
      "loss": 0.0747,
      "step": 2799
    },
    {
      "epoch": 1.9021739130434783,
      "grad_norm": 0.12740319967269897,
      "learning_rate": 5.911847114511497e-06,
      "loss": 0.0011,
      "step": 2800
    },
    {
      "epoch": 1.9028532608695652,
      "grad_norm": 4.153894424438477,
      "learning_rate": 5.905355687329075e-06,
      "loss": 0.2083,
      "step": 2801
    },
    {
      "epoch": 1.9035326086956523,
      "grad_norm": 3.9563655853271484,
      "learning_rate": 5.898866332471241e-06,
      "loss": 0.0441,
      "step": 2802
    },
    {
      "epoch": 1.9042119565217392,
      "grad_norm": 10.711536407470703,
      "learning_rate": 5.892379053222297e-06,
      "loss": 0.2469,
      "step": 2803
    },
    {
      "epoch": 1.9048913043478262,
      "grad_norm": 1.501381754875183,
      "learning_rate": 5.8858938528654915e-06,
      "loss": 0.0436,
      "step": 2804
    },
    {
      "epoch": 1.905570652173913,
      "grad_norm": 8.840526580810547,
      "learning_rate": 5.87941073468303e-06,
      "loss": 0.1676,
      "step": 2805
    },
    {
      "epoch": 1.90625,
      "grad_norm": 1.8428571224212646,
      "learning_rate": 5.872929701956054e-06,
      "loss": 0.1654,
      "step": 2806
    },
    {
      "epoch": 1.906929347826087,
      "grad_norm": 1.9493364095687866,
      "learning_rate": 5.866450757964656e-06,
      "loss": 0.117,
      "step": 2807
    },
    {
      "epoch": 1.9076086956521738,
      "grad_norm": 4.866242408752441,
      "learning_rate": 5.859973905987866e-06,
      "loss": 0.2756,
      "step": 2808
    },
    {
      "epoch": 1.9082880434782608,
      "grad_norm": 0.03877142071723938,
      "learning_rate": 5.853499149303662e-06,
      "loss": 0.0005,
      "step": 2809
    },
    {
      "epoch": 1.9089673913043477,
      "grad_norm": 0.017924195155501366,
      "learning_rate": 5.8470264911889575e-06,
      "loss": 0.0003,
      "step": 2810
    },
    {
      "epoch": 1.9096467391304348,
      "grad_norm": 1.6543529033660889,
      "learning_rate": 5.840555934919604e-06,
      "loss": 0.0171,
      "step": 2811
    },
    {
      "epoch": 1.9103260869565217,
      "grad_norm": 2.8762550354003906,
      "learning_rate": 5.83408748377039e-06,
      "loss": 0.1042,
      "step": 2812
    },
    {
      "epoch": 1.9110054347826086,
      "grad_norm": 4.11359167098999,
      "learning_rate": 5.827621141015034e-06,
      "loss": 0.0715,
      "step": 2813
    },
    {
      "epoch": 1.9116847826086958,
      "grad_norm": 0.15282076597213745,
      "learning_rate": 5.821156909926202e-06,
      "loss": 0.0016,
      "step": 2814
    },
    {
      "epoch": 1.9123641304347827,
      "grad_norm": 0.3386324346065521,
      "learning_rate": 5.814694793775469e-06,
      "loss": 0.0038,
      "step": 2815
    },
    {
      "epoch": 1.9130434782608696,
      "grad_norm": 7.548580646514893,
      "learning_rate": 5.8082347958333625e-06,
      "loss": 0.2504,
      "step": 2816
    },
    {
      "epoch": 1.9137228260869565,
      "grad_norm": 13.40174674987793,
      "learning_rate": 5.801776919369317e-06,
      "loss": 0.4156,
      "step": 2817
    },
    {
      "epoch": 1.9144021739130435,
      "grad_norm": 0.054926544427871704,
      "learning_rate": 5.7953211676517085e-06,
      "loss": 0.0009,
      "step": 2818
    },
    {
      "epoch": 1.9150815217391304,
      "grad_norm": 0.15853546559810638,
      "learning_rate": 5.788867543947832e-06,
      "loss": 0.0019,
      "step": 2819
    },
    {
      "epoch": 1.9157608695652173,
      "grad_norm": 3.036240816116333,
      "learning_rate": 5.782416051523909e-06,
      "loss": 0.2144,
      "step": 2820
    },
    {
      "epoch": 1.9164402173913042,
      "grad_norm": 1.9178587198257446,
      "learning_rate": 5.7759666936450745e-06,
      "loss": 0.0585,
      "step": 2821
    },
    {
      "epoch": 1.9171195652173914,
      "grad_norm": 0.21051593124866486,
      "learning_rate": 5.769519473575391e-06,
      "loss": 0.0022,
      "step": 2822
    },
    {
      "epoch": 1.9177989130434783,
      "grad_norm": 0.21204723417758942,
      "learning_rate": 5.763074394577835e-06,
      "loss": 0.002,
      "step": 2823
    },
    {
      "epoch": 1.9184782608695652,
      "grad_norm": 2.6477935314178467,
      "learning_rate": 5.756631459914302e-06,
      "loss": 0.105,
      "step": 2824
    },
    {
      "epoch": 1.9191576086956523,
      "grad_norm": 8.51050090789795,
      "learning_rate": 5.750190672845596e-06,
      "loss": 0.1455,
      "step": 2825
    },
    {
      "epoch": 1.9198369565217392,
      "grad_norm": 2.6350667476654053,
      "learning_rate": 5.743752036631443e-06,
      "loss": 0.2001,
      "step": 2826
    },
    {
      "epoch": 1.9205163043478262,
      "grad_norm": 4.576971530914307,
      "learning_rate": 5.7373155545304785e-06,
      "loss": 0.1312,
      "step": 2827
    },
    {
      "epoch": 1.921195652173913,
      "grad_norm": 0.24076424539089203,
      "learning_rate": 5.730881229800238e-06,
      "loss": 0.0028,
      "step": 2828
    },
    {
      "epoch": 1.921875,
      "grad_norm": 2.145256996154785,
      "learning_rate": 5.724449065697182e-06,
      "loss": 0.1217,
      "step": 2829
    },
    {
      "epoch": 1.922554347826087,
      "grad_norm": 0.40139248967170715,
      "learning_rate": 5.718019065476659e-06,
      "loss": 0.0039,
      "step": 2830
    },
    {
      "epoch": 1.9232336956521738,
      "grad_norm": 2.046945810317993,
      "learning_rate": 5.71159123239294e-06,
      "loss": 0.0982,
      "step": 2831
    },
    {
      "epoch": 1.9239130434782608,
      "grad_norm": 3.3982834815979004,
      "learning_rate": 5.7051655696991825e-06,
      "loss": 0.148,
      "step": 2832
    },
    {
      "epoch": 1.9245923913043477,
      "grad_norm": 3.281752586364746,
      "learning_rate": 5.698742080647462e-06,
      "loss": 0.0836,
      "step": 2833
    },
    {
      "epoch": 1.9252717391304348,
      "grad_norm": 13.585445404052734,
      "learning_rate": 5.692320768488735e-06,
      "loss": 0.2918,
      "step": 2834
    },
    {
      "epoch": 1.9259510869565217,
      "grad_norm": 1.2287416458129883,
      "learning_rate": 5.6859016364728795e-06,
      "loss": 0.0823,
      "step": 2835
    },
    {
      "epoch": 1.9266304347826086,
      "grad_norm": 1.815934658050537,
      "learning_rate": 5.679484687848649e-06,
      "loss": 0.1194,
      "step": 2836
    },
    {
      "epoch": 1.9273097826086958,
      "grad_norm": 6.6949005126953125,
      "learning_rate": 5.673069925863706e-06,
      "loss": 0.1494,
      "step": 2837
    },
    {
      "epoch": 1.9279891304347827,
      "grad_norm": 5.5900654792785645,
      "learning_rate": 5.666657353764594e-06,
      "loss": 0.1815,
      "step": 2838
    },
    {
      "epoch": 1.9286684782608696,
      "grad_norm": 3.1418774127960205,
      "learning_rate": 5.660246974796764e-06,
      "loss": 0.0978,
      "step": 2839
    },
    {
      "epoch": 1.9293478260869565,
      "grad_norm": 12.3584623336792,
      "learning_rate": 5.653838792204538e-06,
      "loss": 0.4872,
      "step": 2840
    },
    {
      "epoch": 1.9300271739130435,
      "grad_norm": 2.609076976776123,
      "learning_rate": 5.647432809231147e-06,
      "loss": 0.1072,
      "step": 2841
    },
    {
      "epoch": 1.9307065217391304,
      "grad_norm": 1.7501013278961182,
      "learning_rate": 5.641029029118685e-06,
      "loss": 0.0635,
      "step": 2842
    },
    {
      "epoch": 1.9313858695652173,
      "grad_norm": 1.5521644353866577,
      "learning_rate": 5.634627455108158e-06,
      "loss": 0.0124,
      "step": 2843
    },
    {
      "epoch": 1.9320652173913042,
      "grad_norm": 0.048172637820243835,
      "learning_rate": 5.628228090439434e-06,
      "loss": 0.0006,
      "step": 2844
    },
    {
      "epoch": 1.9327445652173914,
      "grad_norm": 1.913464903831482,
      "learning_rate": 5.621830938351276e-06,
      "loss": 0.0694,
      "step": 2845
    },
    {
      "epoch": 1.9334239130434783,
      "grad_norm": 5.730377674102783,
      "learning_rate": 5.615436002081316e-06,
      "loss": 0.1192,
      "step": 2846
    },
    {
      "epoch": 1.9341032608695652,
      "grad_norm": 8.561563491821289,
      "learning_rate": 5.609043284866076e-06,
      "loss": 0.1749,
      "step": 2847
    },
    {
      "epoch": 1.9347826086956523,
      "grad_norm": 4.071923732757568,
      "learning_rate": 5.602652789940941e-06,
      "loss": 0.1706,
      "step": 2848
    },
    {
      "epoch": 1.9354619565217392,
      "grad_norm": 5.642059326171875,
      "learning_rate": 5.596264520540191e-06,
      "loss": 0.2956,
      "step": 2849
    },
    {
      "epoch": 1.9361413043478262,
      "grad_norm": 5.0195488929748535,
      "learning_rate": 5.589878479896959e-06,
      "loss": 0.2362,
      "step": 2850
    },
    {
      "epoch": 1.936820652173913,
      "grad_norm": 0.7784736156463623,
      "learning_rate": 5.583494671243262e-06,
      "loss": 0.024,
      "step": 2851
    },
    {
      "epoch": 1.9375,
      "grad_norm": 1.9285449981689453,
      "learning_rate": 5.5771130978099896e-06,
      "loss": 0.0668,
      "step": 2852
    },
    {
      "epoch": 1.938179347826087,
      "grad_norm": 9.865476608276367,
      "learning_rate": 5.5707337628268864e-06,
      "loss": 0.0915,
      "step": 2853
    },
    {
      "epoch": 1.9388586956521738,
      "grad_norm": 0.04333723708987236,
      "learning_rate": 5.564356669522581e-06,
      "loss": 0.0006,
      "step": 2854
    },
    {
      "epoch": 1.9395380434782608,
      "grad_norm": 18.75200080871582,
      "learning_rate": 5.557981821124554e-06,
      "loss": 0.1663,
      "step": 2855
    },
    {
      "epoch": 1.9402173913043477,
      "grad_norm": 2.564220666885376,
      "learning_rate": 5.55160922085916e-06,
      "loss": 0.0992,
      "step": 2856
    },
    {
      "epoch": 1.9408967391304348,
      "grad_norm": 2.2385637760162354,
      "learning_rate": 5.545238871951606e-06,
      "loss": 0.064,
      "step": 2857
    },
    {
      "epoch": 1.9415760869565217,
      "grad_norm": 0.12887872755527496,
      "learning_rate": 5.538870777625969e-06,
      "loss": 0.0012,
      "step": 2858
    },
    {
      "epoch": 1.9422554347826086,
      "grad_norm": 9.995359420776367,
      "learning_rate": 5.532504941105176e-06,
      "loss": 0.2104,
      "step": 2859
    },
    {
      "epoch": 1.9429347826086958,
      "grad_norm": 0.6706715822219849,
      "learning_rate": 5.526141365611018e-06,
      "loss": 0.0043,
      "step": 2860
    },
    {
      "epoch": 1.9436141304347827,
      "grad_norm": 0.06250174343585968,
      "learning_rate": 5.5197800543641385e-06,
      "loss": 0.0006,
      "step": 2861
    },
    {
      "epoch": 1.9442934782608696,
      "grad_norm": 4.588057518005371,
      "learning_rate": 5.513421010584044e-06,
      "loss": 0.0578,
      "step": 2862
    },
    {
      "epoch": 1.9449728260869565,
      "grad_norm": 0.009174038656055927,
      "learning_rate": 5.507064237489075e-06,
      "loss": 0.0002,
      "step": 2863
    },
    {
      "epoch": 1.9456521739130435,
      "grad_norm": 0.14946550130844116,
      "learning_rate": 5.50070973829644e-06,
      "loss": 0.0013,
      "step": 2864
    },
    {
      "epoch": 1.9463315217391304,
      "grad_norm": 1.744314432144165,
      "learning_rate": 5.494357516222184e-06,
      "loss": 0.0415,
      "step": 2865
    },
    {
      "epoch": 1.9470108695652173,
      "grad_norm": 1.8553396463394165,
      "learning_rate": 5.488007574481213e-06,
      "loss": 0.1038,
      "step": 2866
    },
    {
      "epoch": 1.9476902173913042,
      "grad_norm": 2.002121925354004,
      "learning_rate": 5.481659916287264e-06,
      "loss": 0.0187,
      "step": 2867
    },
    {
      "epoch": 1.9483695652173914,
      "grad_norm": 6.749298572540283,
      "learning_rate": 5.4753145448529284e-06,
      "loss": 0.194,
      "step": 2868
    },
    {
      "epoch": 1.9490489130434783,
      "grad_norm": 1.0498042106628418,
      "learning_rate": 5.468971463389639e-06,
      "loss": 0.0171,
      "step": 2869
    },
    {
      "epoch": 1.9497282608695652,
      "grad_norm": 10.812362670898438,
      "learning_rate": 5.462630675107672e-06,
      "loss": 0.1763,
      "step": 2870
    },
    {
      "epoch": 1.9504076086956523,
      "grad_norm": 5.7901225090026855,
      "learning_rate": 5.45629218321613e-06,
      "loss": 0.1833,
      "step": 2871
    },
    {
      "epoch": 1.9510869565217392,
      "grad_norm": 1.9033783674240112,
      "learning_rate": 5.449955990922973e-06,
      "loss": 0.0637,
      "step": 2872
    },
    {
      "epoch": 1.9517663043478262,
      "grad_norm": 2.5254383087158203,
      "learning_rate": 5.4436221014349754e-06,
      "loss": 0.065,
      "step": 2873
    },
    {
      "epoch": 1.952445652173913,
      "grad_norm": 3.111971378326416,
      "learning_rate": 5.437290517957767e-06,
      "loss": 0.0403,
      "step": 2874
    },
    {
      "epoch": 1.953125,
      "grad_norm": 3.1381473541259766,
      "learning_rate": 5.430961243695794e-06,
      "loss": 0.1561,
      "step": 2875
    },
    {
      "epoch": 1.953804347826087,
      "grad_norm": 5.0116987228393555,
      "learning_rate": 5.424634281852348e-06,
      "loss": 0.1536,
      "step": 2876
    },
    {
      "epoch": 1.9544836956521738,
      "grad_norm": 4.823467254638672,
      "learning_rate": 5.418309635629536e-06,
      "loss": 0.0706,
      "step": 2877
    },
    {
      "epoch": 1.9551630434782608,
      "grad_norm": 4.476360321044922,
      "learning_rate": 5.4119873082283035e-06,
      "loss": 0.1759,
      "step": 2878
    },
    {
      "epoch": 1.9558423913043477,
      "grad_norm": 0.22658337652683258,
      "learning_rate": 5.405667302848419e-06,
      "loss": 0.0027,
      "step": 2879
    },
    {
      "epoch": 1.9565217391304348,
      "grad_norm": 0.10531728714704514,
      "learning_rate": 5.399349622688479e-06,
      "loss": 0.0011,
      "step": 2880
    },
    {
      "epoch": 1.9572010869565217,
      "grad_norm": 8.905033111572266,
      "learning_rate": 5.393034270945895e-06,
      "loss": 0.2208,
      "step": 2881
    },
    {
      "epoch": 1.9578804347826086,
      "grad_norm": 9.45196533203125,
      "learning_rate": 5.386721250816911e-06,
      "loss": 0.0599,
      "step": 2882
    },
    {
      "epoch": 1.9585597826086958,
      "grad_norm": 2.220785140991211,
      "learning_rate": 5.3804105654965784e-06,
      "loss": 0.1792,
      "step": 2883
    },
    {
      "epoch": 1.9592391304347827,
      "grad_norm": 2.261003017425537,
      "learning_rate": 5.374102218178781e-06,
      "loss": 0.1713,
      "step": 2884
    },
    {
      "epoch": 1.9599184782608696,
      "grad_norm": 5.576530456542969,
      "learning_rate": 5.367796212056202e-06,
      "loss": 0.2888,
      "step": 2885
    },
    {
      "epoch": 1.9605978260869565,
      "grad_norm": 1.3554749488830566,
      "learning_rate": 5.3614925503203586e-06,
      "loss": 0.0108,
      "step": 2886
    },
    {
      "epoch": 1.9612771739130435,
      "grad_norm": 3.2300920486450195,
      "learning_rate": 5.355191236161572e-06,
      "loss": 0.0599,
      "step": 2887
    },
    {
      "epoch": 1.9619565217391304,
      "grad_norm": 6.899606227874756,
      "learning_rate": 5.348892272768972e-06,
      "loss": 0.1292,
      "step": 2888
    },
    {
      "epoch": 1.9626358695652173,
      "grad_norm": 3.915402889251709,
      "learning_rate": 5.3425956633305075e-06,
      "loss": 0.107,
      "step": 2889
    },
    {
      "epoch": 1.9633152173913042,
      "grad_norm": 2.719365358352661,
      "learning_rate": 5.336301411032923e-06,
      "loss": 0.1656,
      "step": 2890
    },
    {
      "epoch": 1.9639945652173914,
      "grad_norm": 3.210876703262329,
      "learning_rate": 5.330009519061789e-06,
      "loss": 0.1997,
      "step": 2891
    },
    {
      "epoch": 1.9646739130434783,
      "grad_norm": 3.663912773132324,
      "learning_rate": 5.323719990601459e-06,
      "loss": 0.2064,
      "step": 2892
    },
    {
      "epoch": 1.9653532608695652,
      "grad_norm": 2.538299083709717,
      "learning_rate": 5.317432828835114e-06,
      "loss": 0.1549,
      "step": 2893
    },
    {
      "epoch": 1.9660326086956523,
      "grad_norm": 2.126878023147583,
      "learning_rate": 5.311148036944709e-06,
      "loss": 0.0905,
      "step": 2894
    },
    {
      "epoch": 1.9667119565217392,
      "grad_norm": 0.06899583339691162,
      "learning_rate": 5.304865618111034e-06,
      "loss": 0.0006,
      "step": 2895
    },
    {
      "epoch": 1.9673913043478262,
      "grad_norm": 3.1527535915374756,
      "learning_rate": 5.298585575513649e-06,
      "loss": 0.1207,
      "step": 2896
    },
    {
      "epoch": 1.968070652173913,
      "grad_norm": 2.985887289047241,
      "learning_rate": 5.292307912330925e-06,
      "loss": 0.2036,
      "step": 2897
    },
    {
      "epoch": 1.96875,
      "grad_norm": 1.0613707304000854,
      "learning_rate": 5.286032631740023e-06,
      "loss": 0.0092,
      "step": 2898
    },
    {
      "epoch": 1.969429347826087,
      "grad_norm": 2.639836549758911,
      "learning_rate": 5.2797597369169075e-06,
      "loss": 0.1338,
      "step": 2899
    },
    {
      "epoch": 1.9701086956521738,
      "grad_norm": 0.6633321642875671,
      "learning_rate": 5.273489231036321e-06,
      "loss": 0.009,
      "step": 2900
    },
    {
      "epoch": 1.9707880434782608,
      "grad_norm": 0.03432488441467285,
      "learning_rate": 5.267221117271812e-06,
      "loss": 0.0004,
      "step": 2901
    },
    {
      "epoch": 1.9714673913043477,
      "grad_norm": 6.607594013214111,
      "learning_rate": 5.260955398795704e-06,
      "loss": 0.2039,
      "step": 2902
    },
    {
      "epoch": 1.9721467391304348,
      "grad_norm": 2.8079919815063477,
      "learning_rate": 5.254692078779118e-06,
      "loss": 0.1049,
      "step": 2903
    },
    {
      "epoch": 1.9728260869565217,
      "grad_norm": 11.28402042388916,
      "learning_rate": 5.248431160391963e-06,
      "loss": 0.2905,
      "step": 2904
    },
    {
      "epoch": 1.9735054347826086,
      "grad_norm": 0.14888279139995575,
      "learning_rate": 5.242172646802927e-06,
      "loss": 0.0012,
      "step": 2905
    },
    {
      "epoch": 1.9741847826086958,
      "grad_norm": 0.010017008520662785,
      "learning_rate": 5.235916541179477e-06,
      "loss": 0.0002,
      "step": 2906
    },
    {
      "epoch": 1.9748641304347827,
      "grad_norm": 0.3257557153701782,
      "learning_rate": 5.229662846687873e-06,
      "loss": 0.0029,
      "step": 2907
    },
    {
      "epoch": 1.9755434782608696,
      "grad_norm": 0.34124088287353516,
      "learning_rate": 5.223411566493141e-06,
      "loss": 0.0027,
      "step": 2908
    },
    {
      "epoch": 1.9762228260869565,
      "grad_norm": 1.0038093328475952,
      "learning_rate": 5.217162703759102e-06,
      "loss": 0.0074,
      "step": 2909
    },
    {
      "epoch": 1.9769021739130435,
      "grad_norm": 0.25145095586776733,
      "learning_rate": 5.2109162616483325e-06,
      "loss": 0.0024,
      "step": 2910
    },
    {
      "epoch": 1.9775815217391304,
      "grad_norm": 0.5370054841041565,
      "learning_rate": 5.2046722433222e-06,
      "loss": 0.005,
      "step": 2911
    },
    {
      "epoch": 1.9782608695652173,
      "grad_norm": 0.025034915655851364,
      "learning_rate": 5.198430651940846e-06,
      "loss": 0.0003,
      "step": 2912
    },
    {
      "epoch": 1.9789402173913042,
      "grad_norm": 2.3690805435180664,
      "learning_rate": 5.192191490663168e-06,
      "loss": 0.0909,
      "step": 2913
    },
    {
      "epoch": 1.9796195652173914,
      "grad_norm": 3.5148844718933105,
      "learning_rate": 5.1859547626468545e-06,
      "loss": 0.1365,
      "step": 2914
    },
    {
      "epoch": 1.9802989130434783,
      "grad_norm": 0.04315716400742531,
      "learning_rate": 5.179720471048341e-06,
      "loss": 0.0005,
      "step": 2915
    },
    {
      "epoch": 1.9809782608695652,
      "grad_norm": 0.04146334528923035,
      "learning_rate": 5.1734886190228496e-06,
      "loss": 0.0007,
      "step": 2916
    },
    {
      "epoch": 1.9816576086956523,
      "grad_norm": 2.0081684589385986,
      "learning_rate": 5.1672592097243515e-06,
      "loss": 0.1168,
      "step": 2917
    },
    {
      "epoch": 1.9823369565217392,
      "grad_norm": 3.2537875175476074,
      "learning_rate": 5.161032246305597e-06,
      "loss": 0.0697,
      "step": 2918
    },
    {
      "epoch": 1.9830163043478262,
      "grad_norm": 3.5315701961517334,
      "learning_rate": 5.154807731918081e-06,
      "loss": 0.0861,
      "step": 2919
    },
    {
      "epoch": 1.983695652173913,
      "grad_norm": 3.238943099975586,
      "learning_rate": 5.148585669712074e-06,
      "loss": 0.0314,
      "step": 2920
    },
    {
      "epoch": 1.984375,
      "grad_norm": 3.0884928703308105,
      "learning_rate": 5.142366062836599e-06,
      "loss": 0.1252,
      "step": 2921
    },
    {
      "epoch": 1.985054347826087,
      "grad_norm": 0.14247503876686096,
      "learning_rate": 5.136148914439441e-06,
      "loss": 0.0013,
      "step": 2922
    },
    {
      "epoch": 1.9857336956521738,
      "grad_norm": 3.459237575531006,
      "learning_rate": 5.1299342276671295e-06,
      "loss": 0.1506,
      "step": 2923
    },
    {
      "epoch": 1.9864130434782608,
      "grad_norm": 5.76373815536499,
      "learning_rate": 5.123722005664964e-06,
      "loss": 0.3274,
      "step": 2924
    },
    {
      "epoch": 1.9870923913043477,
      "grad_norm": 5.526997089385986,
      "learning_rate": 5.117512251576978e-06,
      "loss": 0.2334,
      "step": 2925
    },
    {
      "epoch": 1.9877717391304348,
      "grad_norm": 0.5619979500770569,
      "learning_rate": 5.111304968545976e-06,
      "loss": 0.0088,
      "step": 2926
    },
    {
      "epoch": 1.9884510869565217,
      "grad_norm": 0.7767500877380371,
      "learning_rate": 5.105100159713494e-06,
      "loss": 0.0074,
      "step": 2927
    },
    {
      "epoch": 1.9891304347826086,
      "grad_norm": 6.618314266204834,
      "learning_rate": 5.098897828219831e-06,
      "loss": 0.0726,
      "step": 2928
    },
    {
      "epoch": 1.9898097826086958,
      "grad_norm": 6.056064605712891,
      "learning_rate": 5.092697977204016e-06,
      "loss": 0.0667,
      "step": 2929
    },
    {
      "epoch": 1.9904891304347827,
      "grad_norm": 5.079329967498779,
      "learning_rate": 5.086500609803841e-06,
      "loss": 0.2397,
      "step": 2930
    },
    {
      "epoch": 1.9911684782608696,
      "grad_norm": 3.319594621658325,
      "learning_rate": 5.0803057291558255e-06,
      "loss": 0.1122,
      "step": 2931
    },
    {
      "epoch": 1.9918478260869565,
      "grad_norm": 2.656635046005249,
      "learning_rate": 5.074113338395241e-06,
      "loss": 0.0971,
      "step": 2932
    },
    {
      "epoch": 1.9925271739130435,
      "grad_norm": 1.9816151857376099,
      "learning_rate": 5.06792344065609e-06,
      "loss": 0.142,
      "step": 2933
    },
    {
      "epoch": 1.9932065217391304,
      "grad_norm": 0.458248496055603,
      "learning_rate": 5.061736039071124e-06,
      "loss": 0.0041,
      "step": 2934
    },
    {
      "epoch": 1.9938858695652173,
      "grad_norm": 4.407209396362305,
      "learning_rate": 5.055551136771815e-06,
      "loss": 0.1248,
      "step": 2935
    },
    {
      "epoch": 1.9945652173913042,
      "grad_norm": 14.130354881286621,
      "learning_rate": 5.049368736888391e-06,
      "loss": 0.532,
      "step": 2936
    },
    {
      "epoch": 1.9952445652173914,
      "grad_norm": 0.05314243584871292,
      "learning_rate": 5.043188842549789e-06,
      "loss": 0.0006,
      "step": 2937
    },
    {
      "epoch": 1.9959239130434783,
      "grad_norm": 6.457744121551514,
      "learning_rate": 5.0370114568837055e-06,
      "loss": 0.2751,
      "step": 2938
    },
    {
      "epoch": 1.9966032608695652,
      "grad_norm": 1.2563979625701904,
      "learning_rate": 5.030836583016545e-06,
      "loss": 0.0086,
      "step": 2939
    },
    {
      "epoch": 1.9972826086956523,
      "grad_norm": 3.309075117111206,
      "learning_rate": 5.024664224073454e-06,
      "loss": 0.1476,
      "step": 2940
    },
    {
      "epoch": 1.9979619565217392,
      "grad_norm": 3.7403149604797363,
      "learning_rate": 5.018494383178296e-06,
      "loss": 0.2057,
      "step": 2941
    },
    {
      "epoch": 1.9986413043478262,
      "grad_norm": 6.574490070343018,
      "learning_rate": 5.0123270634536716e-06,
      "loss": 0.2097,
      "step": 2942
    },
    {
      "epoch": 1.999320652173913,
      "grad_norm": 0.14972952008247375,
      "learning_rate": 5.006162268020891e-06,
      "loss": 0.0012,
      "step": 2943
    },
    {
      "epoch": 2.0,
      "grad_norm": 5.732705116271973,
      "learning_rate": 5.000000000000003e-06,
      "loss": 0.1134,
      "step": 2944
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.4268292682926829,
      "eval_loss": 0.14244668185710907,
      "eval_runtime": 135.8138,
      "eval_samples_per_second": 1.208,
      "eval_steps_per_second": 1.208,
      "step": 2944
    }
  ],
  "logging_steps": 1,
  "max_steps": 4416,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.0839573957300224e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
